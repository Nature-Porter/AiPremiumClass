{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%writefile ner_ddp.py\n\n# 导包\nimport os\nfrom transformers import AutoModelForTokenClassification , AutoTokenizer \nfrom transformers import DataCollatorForTokenClassification , TrainingArguments , Trainer\nfrom datasets import load_dataset\nimport numpy as np\nimport evaluate   # pip install evaluate\nimport seqeval  # pip install seqeval\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom transformers import get_linear_schedule_with_warmup\nimport torch.optim as optim\nimport torch\nfrom tqdm import tqdm\nfrom transformers import pipeline\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\n# 设置分布式环境\ndef setup(rank , world_size):\n    os.environ['MASTER_ADDP'] = 'localhost'\n    od.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\" , rank = rank , worid_size = world_size)\n\n# 清理分布式环境\ndef cleanup():\n    dist.destory_process_group()\n\ndef train(rank , world_size):\n    setup(rank , world_size)\n    # 加载数据\n    ds = load_dataset('doushabao4766/msra_ner_k_V3')\n    \n    # 加载分词器\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n\n    # 构建映射标签\n    entites = list({'per' , 'loc' , 'org'})\n    tags = ['O']\n    for entity in entites:\n        tags.append('B-' + entity.upper())  # upper()方法是转换为大写\n        tags.append('I-' + entity.upper())\n\n    # 创建构建方法 [tag + [0] * (512 - len(tag)) for tag in item['ner_tags']]\n    def data_input_proc(item):\n        input_data = tokenizer(item['tokens'],\n                              truncation = True ,  # 超过最大长度允许截断防止溢出\n                              max_length = 512 ,   #最大512\n                              add_special_tokens = False ,  # 禁止添加特殊标记  确保标签对其\n                              is_split_into_words = True) # 因为该数据集已经按照字符划分，所以用id_split_into_words = True 表明一个字符一个字符的传入\n        # 设置标签映射（超过512 截断）\n        labels = [lbl[:512] for lbl in item['ner_tags']]\n        input_data['labels'] = labels\n        return input_data\n    ds1 = ds.map(data_input_proc , batched = True)\n\n    # 选择模型需要输入的列 将其转换为 torch张量类型\n    ds1.set_format('torch' , columns = ['input_ids' ,  # token 索引序列\n                                        'token_type_ids' ,  # 段落标记\n                                        'attention_mask' ,  # 注意力掩码\n                                        'labels']) # NER标签序列\n    local_rank = rank\n\n    # 构建模型初始化可读标签参数，\n    id2lbl = {i:tag for i,tag in enumerate(tags)}\n    lbl2id = {tag:i for i,tag in enumerate(tags)}\n    \n    model = AutoModelForTokenClassification.from_pretrained(\"bert-base-chinese\" , # 预训练模型\n                                                           num_labels = len(tags) ,  # 输出的分类数量\n                                                           id2label = id2lbl , \n                                                           label2id = lbl2id)\n    model.to(local_rank)\n\n    # 构建评估函数\n    def compute_metric(result):\n        # 传入的result是一个元祖 (predicts,labels)\n    \n        # 加载序列标注评估指标库\n        seqeval = evaluate.load('seqeval')\n        # 解构模型输出的结果\n        predicts,labels = result\n        # 沿着axis = 2 的维度 取最大值索引 然后将predicts转换为预测标签ID\n        predicts = np.argmax(predicts , axis = 2)\n        # 准备评估数据 将数字ID转换为文本标签 并且过滤填充数值-100\n        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        results = seqeval.compute(predictions = predicts , references = labels)\n        return results\n\n        # 批量处理序列数据 动态填充长度保证对齐\n        data_collator = DataCollatorForTokenClassification(tokenizer = tokenizer , padding = True)\n\n        # 设置训练相关参数\n        args = TrainingArguments(\n            output_dir = 'ner_train' , # 设置模型输出目录\n            num_train_epochs = 3 , # 训练轮数\n            #save_safetensor = False # 模型禁止保存safe格式 可以用troch.load加载\n            per_device_train_batch_size = 32 , # 训练批次\n            per_device_eval_batch_size = 32 ,  # 评估批次\n            report_to = 'tensorboard' , # 设置训练输出记录为tensorboard\n            eval_strategy = 'epoch' ,  # 每轮评估一次\n            local_rank = local_rank ,  # 设置当前进程RANK \n            fp16 = True ,  # 使用混合精度\n            lr_scheduler_type = 'linear' ,  # 设置动态学习率\n            warmup_steps = 100 ,  # 预热的步数\n            ddp_find_unused_parameters = False # 优化DDP性能\n        )\n\n    # 模型训练\n    trainer = Trainer(\n        model = model ,  # 指定模型\n        args = args , # 指定设置参数\n        train_dataset = ds1['train'] ,  # 输入训练数据\n        eval_dataset = ds1['test'] ,  # 输入评估数据\n        compute_metrics = compute_metric , # 指定评估函数\n        data_collator = data_collator  # 指定数据收集器\n        )\n    trainer.train()\n\ndef main():\n    world_size = torch.cuda.device_count()\n    mp.spawn(train , args = (world_size) , nprocs = world_size , join = True)\n\nif __name__ == \"__main__\":\n    main()\n\n    pipeline = pipeline('token-classification', 'ner_train/checkpoint-2112')\n\n    text = pipeline('双方确定了今后发展中美关系的指导方针')\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:46:04.649452Z","iopub.execute_input":"2025-06-12T14:46:04.650280Z","iopub.status.idle":"2025-06-12T14:46:04.658851Z","shell.execute_reply.started":"2025-06-12T14:46:04.650248Z","shell.execute_reply":"2025-06-12T14:46:04.658230Z"}},"outputs":[{"name":"stdout","text":"Overwriting ner_ddp.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!python ner_ddp.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:46:04.659918Z","iopub.execute_input":"2025-06-12T14:46:04.660123Z","iopub.status.idle":"2025-06-12T14:46:27.016507Z","shell.execute_reply.started":"2025-06-12T14:46:04.660109Z","shell.execute_reply":"2025-06-12T14:46:27.015756Z"}},"outputs":[{"name":"stdout","text":"2025-06-12 14:46:09.634288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749739569.657559     150 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749739569.664672     150 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-12 14:46:19.306809: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749739579.329691     165 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749739579.336684     165 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-12 14:46:19.342543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749739579.365760     164 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749739579.372776     164 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0612 14:46:25.149000 150 torch/multiprocessing/spawn.py:169] Terminating process 164 via signal SIGTERM\nTraceback (most recent call last):\n  File \"/kaggle/working/ner_ddp.py\", line 128, in <module>\n    main()\n  File \"/kaggle/working/ner_ddp.py\", line 125, in main\n    mp.spawn(train , args = (world_size) , nprocs = world_size , join = True)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 340, in spawn\n    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 296, in start_processes\n    while not context.join():\n              ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 215, in join\n    raise ProcessRaisedException(msg, error_index, failed_process.pid)\ntorch.multiprocessing.spawn.ProcessRaisedException: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n    fn(i, *args)\nTypeError: Value after * must be an iterable, not int\n\n","output_type":"stream"}],"execution_count":16}]}