{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"L第12周作业：\n1. 利用上周NER模型训练任务代码，复现课堂案例中：动态学习率、混合精度、DDP训练实现。\n2. 利用课堂案例，实现分布式DDP模型训练。存盘后加载实现推理。","metadata":{}},{"cell_type":"code","source":"# 安装评估包\n!pip -q install evaluate seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:43:38.914964Z","iopub.execute_input":"2025-06-12T06:43:38.915722Z","iopub.status.idle":"2025-06-12T06:43:46.295806Z","shell.execute_reply.started":"2025-06-12T06:43:38.915696Z","shell.execute_reply":"2025-06-12T06:43:46.294921Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 导包\nfrom transformers import AutoModelForTokenClassification , AutoTokenizer \nfrom transformers import DataCollatorForTokenClassification , TrainingArguments , Trainer\nfrom datasets import load_dataset\nimport numpy as np\nimport evaluate   # pip install evaluate\nimport seqeval  # pip install seqeval\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom transformers import get_linear_schedule_with_warmup\nimport torch.optim as optim\nimport torch\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:43:21.706291Z","iopub.execute_input":"2025-06-12T13:43:21.706566Z","iopub.status.idle":"2025-06-12T13:43:21.711385Z","shell.execute_reply.started":"2025-06-12T13:43:21.706544Z","shell.execute_reply":"2025-06-12T13:43:21.710591Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## 1、加载数据、加载分词器","metadata":{}},{"cell_type":"code","source":"# 加载数据\nds = load_dataset('doushabao4766/msra_ner_k_V3')\n\n# 加载分词器\ntokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n\nfor items in ds['train']:\n    print(items['tokens'])\n    print(items['ner_tags'])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:17.543167Z","iopub.execute_input":"2025-06-12T12:13:17.543447Z","iopub.status.idle":"2025-06-12T12:13:21.651214Z","shell.execute_reply.started":"2025-06-12T12:13:17.543427Z","shell.execute_reply":"2025-06-12T12:13:21.650417Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/697 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf9a71acc474dc5a5ecf1d3503d9baf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-42717a92413393f9.parquet:   0%|          | 0.00/13.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5391211725cc43fe90da3e3786a40c0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-8899cab5fdab45bc.parquet:   0%|          | 0.00/946k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56318a90e3ea4b1484aa5eaa9e903873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/45001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04765fc0b0c34e4489744fb75904f154"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3443 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7bc9757bd14be087492e79b0505424"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"237b73f6c6d04ea19d868f410adcfcc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bfa9bd17fe84d7e92e624f559dad6ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43074a0c91e24712a2bb04b9c48db237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76106cb65a5f4f23b5f0b65113b09075"}},"metadata":{}},{"name":"stdout","text":"['当', '希', '望', '工', '程', '救', '助', '的', '百', '万', '儿', '童', '成', '长', '起', '来', '，', '科', '教', '兴', '国', '蔚', '然', '成', '风', '时', '，', '今', '天', '有', '收', '藏', '价', '值', '的', '书', '你', '没', '买', '，', '明', '日', '就', '叫', '你', '悔', '不', '当', '初', '！']\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## 2、自定义实体映射字典 \n’O':0   \n'B-PER':1   \n'I-PER':2   \n'B-LOC':3   \n'I-LOC':4   \n'B-ORG':5   \n'I-ORG':6 ","metadata":{}},{"cell_type":"code","source":"# 查看tag标签数量\ntags_id = set()\nfor tags in ds['train']:\n    tags_id.update(tags['ner_tags'])\n\ntags_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:26.191738Z","iopub.execute_input":"2025-06-12T12:13:26.192257Z","iopub.status.idle":"2025-06-12T12:13:31.307312Z","shell.execute_reply.started":"2025-06-12T12:13:26.192233Z","shell.execute_reply":"2025-06-12T12:13:31.306726Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{0, 1, 2, 3, 4, 5, 6}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# 构建映射标签\nentites = list({'per' , 'loc' , 'org'})\ntags = ['O']\nfor entity in entites:\n    tags.append('B-' + entity.upper())  # upper()方法是转换为大写\n    tags.append('I-' + entity.upper())\ntags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:34.447788Z","iopub.execute_input":"2025-06-12T12:13:34.448446Z","iopub.status.idle":"2025-06-12T12:13:34.453704Z","shell.execute_reply.started":"2025-06-12T12:13:34.448423Z","shell.execute_reply":"2025-06-12T12:13:34.453047Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['O', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER']"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# 创建构建方法 [tag + [0] * (512 - len(tag)) for tag in item['ner_tags']]\ndef data_input_proc(item):\n    input_data = tokenizer(item['tokens'],\n                          truncation = True ,  # 超过最大长度允许截断防止溢出\n                          max_length = 512 ,   #最大512\n                          add_special_tokens = False ,  # 禁止添加特殊标记  确保标签对其\n                          is_split_into_words = True) # 因为该数据集已经按照字符划分，所以用id_split_into_words = True 表明一个字符一个字符的传入\n    # 设置标签映射（超过512 截断）\n    labels = [lbl[:512] for lbl in item['ner_tags']]\n    input_data['labels'] = labels\n    return input_data\nds1 = ds.map(data_input_proc , batched = True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:36.831279Z","iopub.execute_input":"2025-06-12T12:13:36.831773Z","iopub.status.idle":"2025-06-12T12:13:48.697959Z","shell.execute_reply.started":"2025-06-12T12:13:36.831747Z","shell.execute_reply":"2025-06-12T12:13:48.697167Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5748f5f26a894febaa959a63952f5dea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3443 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c71a26321538476cb0698f656641fe12"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"for item in ds1['train']:\n    print(item['tokens'])\n    print(item['ner_tags'])\n    print(item['knowledge'])\n    print(item['input_ids'])\n    print(item['token_type_ids'])\n    print(item['attention_mask'])\n    print(item['labels'])\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:49.856559Z","iopub.execute_input":"2025-06-12T12:13:49.857256Z","iopub.status.idle":"2025-06-12T12:13:49.862760Z","shell.execute_reply.started":"2025-06-12T12:13:49.857232Z","shell.execute_reply":"2025-06-12T12:13:49.861865Z"}},"outputs":[{"name":"stdout","text":"['当', '希', '望', '工', '程', '救', '助', '的', '百', '万', '儿', '童', '成', '长', '起', '来', '，', '科', '教', '兴', '国', '蔚', '然', '成', '风', '时', '，', '今', '天', '有', '收', '藏', '价', '值', '的', '书', '你', '没', '买', '，', '明', '日', '就', '叫', '你', '悔', '不', '当', '初', '！']\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n\n[2496, 2361, 3307, 2339, 4923, 3131, 1221, 4638, 4636, 674, 1036, 4997, 2768, 7270, 6629, 3341, 8024, 4906, 3136, 1069, 1744, 5917, 4197, 2768, 7599, 3198, 8024, 791, 1921, 3300, 3119, 5966, 817, 966, 4638, 741, 872, 3766, 743, 8024, 3209, 3189, 2218, 1373, 872, 2637, 679, 2496, 1159, 8013]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# 选择模型需要输入的列 将其转换为 torch张量类型\nds1.set_format('torch' , columns = ['input_ids' ,  # token 索引序列\n                                    'token_type_ids' ,  # 段落标记\n                                    'attention_mask' ,  # 注意力掩码\n                                    'labels']) # NER标签序列\nfor item in ds1['train']:\n    print(item)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:52.766934Z","iopub.execute_input":"2025-06-12T12:13:52.767236Z","iopub.status.idle":"2025-06-12T12:13:52.783447Z","shell.execute_reply.started":"2025-06-12T12:13:52.767212Z","shell.execute_reply":"2025-06-12T12:13:52.782580Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([2496, 2361, 3307, 2339, 4923, 3131, 1221, 4638, 4636,  674, 1036, 4997,\n        2768, 7270, 6629, 3341, 8024, 4906, 3136, 1069, 1744, 5917, 4197, 2768,\n        7599, 3198, 8024,  791, 1921, 3300, 3119, 5966,  817,  966, 4638,  741,\n         872, 3766,  743, 8024, 3209, 3189, 2218, 1373,  872, 2637,  679, 2496,\n        1159, 8013]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0])}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## 3 构建模型对象\n","metadata":{}},{"cell_type":"code","source":"# 构建模型初始化可读标签参数，\nid2lbl = {i:tag for i,tag in enumerate(tags)}\nlbl2id = {tag:i for i,tag in enumerate(tags)}\n\nmodel = AutoModelForTokenClassification.from_pretrained(\"bert-base-chinese\" , # 预训练模型\n                                                       num_labels = len(tags) ,  # 输出的分类数量\n                                                       id2label = id2lbl , \n                                                       label2id = lbl2id)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:13:56.920389Z","iopub.execute_input":"2025-06-12T12:13:56.920728Z","iopub.status.idle":"2025-06-12T12:13:59.822616Z","shell.execute_reply.started":"2025-06-12T12:13:56.920707Z","shell.execute_reply":"2025-06-12T12:13:59.822022Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"009ea933aafe414aa317bd0a44be2fd4"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# 动态学习率","metadata":{}},{"cell_type":"code","source":"# 自动填充对其\ndata_collator = DataCollatorForTokenClassification(tokenizer = tokenizer , padding = True)\n# 在DataLoader中使用\ntrain_dl = DataLoader(\n    ds1['train'], \n    batch_size=16,\n    shuffle = True,\n    collate_fn = data_collator\n)\n\n\nmodel.to('cuda')\n\n# 模型参数分组\n\n# 获取模型参数\nparam_optimizer = list(model.named_parameters())\nbert_params, classifier_params = [],[]\n\nfor name,params in param_optimizer:\n    # 获取预训练模型\n    if 'bert' in name:\n        bert_params.append(params)\n    else:\n        classifier_params.append(params)\n\nparam_groups = [\n    {'params':bert_params, 'lr':1e-5},  # 预训练模型的学习率较低 保持稳定性\n    {'params':classifier_params, 'weight_decay':0.1, 'lr':1e-3} # 新的分类层学习率较高 更好的学习，'weight_decay':0.1 使用正则化L2\n]\n\n# optimizer\noptimizer = optim.AdamW(param_groups) # 优化器\n\n# 学习率调度器\n\n# 步长 从初始设置值到0 衰减需要的步长\ntrain_steps = len(train_dl) * 5\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            # 预热 从0到初始设置值的步长\n                                            num_warmup_steps=100, \n                                            # 衰减 从初始设置值到0 衰减需要的步长\n                                            num_training_steps=train_steps)\n\n\nfor item in train_dl:\n    print(item['input_ids'].shape, \n          item['token_type_ids'].shape, \n          item['attention_mask'].shape, \n          item['labels'].shape)\n    break\n\nDEVICE='cuda'\n\nfor epoch in range(5):\n    model.train()\n    tpbar = tqdm(train_dl)\n    for items in tpbar:\n        # 张量移动到指定的设备商\n        items = {k:v.to(DEVICE) for k,v in items.items()}\n        # 数据传入模型\n        outputs = model(**items)\n        # 计算损失\n        loss = outputs.loss\n        # 反向传播计算梯度\n        loss.backward()\n        # 更新模型参数的梯度\n        optimizer.step()\n        # 更新学习率\n        scheduler.step()\n        # 模型参数的梯度清零\n        optimizer.zero_grad()\n    \n        tpbar.set_description(f'Epoch:{epoch+1} ' + \n                          f'bert_lr:{scheduler.get_lr()[0]} ' + \n                          f'classifier_lr:{scheduler.get_lr()[1]} '+\n                          f'Loss:{loss.item():.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:21:06.437914Z","iopub.execute_input":"2025-06-12T12:21:06.438645Z","iopub.status.idle":"2025-06-12T13:41:34.814272Z","shell.execute_reply.started":"2025-06-12T12:21:06.438623Z","shell.execute_reply":"2025-06-12T13:41:34.813635Z"}},"outputs":[{"name":"stdout","text":"torch.Size([16, 140]) torch.Size([16, 140]) torch.Size([16, 140]) torch.Size([16, 140])\n","output_type":"stream"},{"name":"stderr","text":"Epoch:1 bert_lr:8.057286072323668e-06 classifier_lr:0.0008057286072323666 Loss:0.0036: 100%|██████████| 2813/2813 [16:06<00:00,  2.91it/s]\nEpoch:2 bert_lr:6.042964554242751e-06 classifier_lr:0.000604296455424275 Loss:0.0315: 100%|██████████| 2813/2813 [16:06<00:00,  2.91it/s]  \nEpoch:3 bert_lr:4.028643036161834e-06 classifier_lr:0.0004028643036161833 Loss:0.0789: 100%|██████████| 2813/2813 [16:06<00:00,  2.91it/s]  \nEpoch:4 bert_lr:2.014321518080917e-06 classifier_lr:0.00020143215180809166 Loss:0.0002: 100%|██████████| 2813/2813 [16:04<00:00,  2.92it/s] \nEpoch:5 bert_lr:0.0 classifier_lr:0.0 Loss:0.0003: 100%|██████████| 2813/2813 [16:03<00:00,  2.92it/s]                                      \n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# 混合精度","metadata":{}},{"cell_type":"code","source":"# 自动填充对其\ndata_collator = DataCollatorForTokenClassification(tokenizer = tokenizer , padding = True)\n# 在DataLoader中使用\ntrain_dl = DataLoader(\n    ds1['train'], \n    batch_size=16,\n    shuffle = True,\n    collate_fn = data_collator\n)\n\n\nmodel.to('cuda')\n\n# 模型参数分组\n\n# 获取模型参数\nparam_optimizer = list(model.named_parameters())\nbert_params, classifier_params = [],[]\n\nfor name,params in param_optimizer:\n    # 获取预训练模型\n    if 'bert' in name:\n        bert_params.append(params)\n    else:\n        classifier_params.append(params)\n\nparam_groups = [\n    {'params':bert_params, 'lr':1e-5},  # 预训练模型的学习率较低 保持稳定性\n    {'params':classifier_params, 'weight_decay':0.1, 'lr':1e-3} # 新的分类层学习率较高 更好的学习，'weight_decay':0.1 使用正则化L2\n]\n\n# optimizer\noptimizer = optim.AdamW(param_groups) # 优化器\n\n# 学习率调度器\n\n# 步长 从初始设置值到0 衰减需要的步长\ntrain_steps = len(train_dl) * 5\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            # 预热 从0到初始设置值的步长\n                                            num_warmup_steps=100, \n                                            # 衰减 从初始设置值到0 衰减需要的步长\n                                            num_training_steps=train_steps)\n\n\n# for item in train_dl:\n#     print(item['input_ids'].shape, \n#           item['token_type_ids'].shape, \n#           item['attention_mask'].shape, \n#           item['labels'].shape)\n#     break\n\nDEVICE='cuda'\n\n# 梯度计算缩放器\nscaler = torch.GradScaler()\n\nfor epoch in range(3):\n    model.train()\n    tpbar = tqdm(train_dl)\n    for items in tpbar:\n        # 张量移动到指定的设备商\n        items = {k:v.to(DEVICE) for k,v in items.items()}\n        # 数据传入模型\n        outputs = model(**items)\n        # 计算损失\n        loss = outputs.loss\n        \n        # 缩放loss后 调用反向传播计算梯度\n        scaler.scale(loss).backward()\n        # 更新模型参数的梯度\n        scaler.step(optimizer)\n        scaler.update()\n\n        \n        # 更新学习率\n        scheduler.step()\n        # 模型参数的梯度清零\n        optimizer.zero_grad()\n    \n        tpbar.set_description(f'Epoch:{epoch+1} ' + \n                          f'bert_lr:{scheduler.get_lr()[0]} ' + \n                          f'classifier_lr:{scheduler.get_lr()[1]} '+\n                          f'Loss:{loss.item():.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:43:27.926056Z","iopub.execute_input":"2025-06-12T13:43:27.926748Z","iopub.status.idle":"2025-06-12T14:32:24.151387Z","shell.execute_reply.started":"2025-06-12T13:43:27.926725Z","shell.execute_reply":"2025-06-12T14:32:24.150644Z"}},"outputs":[{"name":"stderr","text":"Epoch:1 bert_lr:8.057286072323668e-06 classifier_lr:0.0008057286072323666 Loss:0.0150: 100%|██████████| 2813/2813 [16:17<00:00,  2.88it/s]\nEpoch:2 bert_lr:6.042964554242751e-06 classifier_lr:0.000604296455424275 Loss:0.0001: 100%|██████████| 2813/2813 [16:19<00:00,  2.87it/s]  \nEpoch:3 bert_lr:4.028643036161834e-06 classifier_lr:0.0004028643036161833 Loss:0.0013: 100%|██████████| 2813/2813 [16:19<00:00,  2.87it/s]  \n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 4 创建评估函数","metadata":{}},{"cell_type":"code","source":"\ndef compute_metric(result):\n    # 传入的result是一个元祖 (predicts,labels)\n\n    # 加载序列标注评估指标库\n    seqeval = evaluate.load('seqeval')\n    # 解构模型输出的结果\n    predicts,labels = result\n    # 沿着axis = 2 的维度 取最大值索引 然后将predicts转换为预测标签ID\n    predicts = np.argmax(predicts , axis = 2)\n    # 准备评估数据 将数字ID转换为文本标签 并且过滤填充数值-100\n    predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    results = seqeval.compute(predictions = predicts , references = labels)\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:24:44.810252Z","iopub.execute_input":"2025-06-12T02:24:44.810721Z","iopub.status.idle":"2025-06-12T02:24:44.815512Z","shell.execute_reply.started":"2025-06-12T02:24:44.810697Z","shell.execute_reply":"2025-06-12T02:24:44.814759Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"[[[0.1, 0.8, 0.1],  # 预测为1(B-PER)\n  [0.3, 0.2, 0.5],  # 预测为2(I-PER) \n  [0.9, 0.05, 0.05]] # 预测为0(O)\n]\n经过argsmax转换后得到\n[1, 2, 0]","metadata":{}},{"cell_type":"markdown","source":"## 5 批量处理序列数据 动态填充长度保证对齐","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer = tokenizer , padding = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T09:52:27.748060Z","iopub.execute_input":"2025-06-12T09:52:27.748348Z","iopub.status.idle":"2025-06-12T09:52:27.752178Z","shell.execute_reply.started":"2025-06-12T09:52:27.748314Z","shell.execute_reply":"2025-06-12T09:52:27.751289Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"## 6 设置模型训练相关参数 TrainingArguments","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir = 'ner_train' , # 设置模型输出目录\n    num_train_epochs = 3 , # 训练轮数\n    #save_safetensor = False # 模型禁止保存safe格式 可以用troch.load加载\n    per_device_train_batch_size = 32 , # 训练批次\n    per_device_eval_batch_size = 32 ,  # 评估批次\n    report_to = 'tensorboard' , # 设置训练输出记录为tensorboard\n    eval_strategy = 'epoch'  # 每轮评估一次\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:24:44.835883Z","iopub.execute_input":"2025-06-12T02:24:44.836075Z","iopub.status.idle":"2025-06-12T02:24:44.877623Z","shell.execute_reply.started":"2025-06-12T02:24:44.836061Z","shell.execute_reply":"2025-06-12T02:24:44.877122Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## 7 创建模型训练","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model = model ,  # 指定模型\n    args = args , # 指定设置参数\n    train_dataset = ds1['train'] ,  # 输入训练数据\n    eval_dataset = ds1['test'] ,  # 输入评估数据\n    compute_metrics = compute_metric , # 指定评估函数\n    data_collator = data_collator  # 指定数据收集器\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:24:44.878313Z","iopub.execute_input":"2025-06-12T02:24:44.878576Z","iopub.status.idle":"2025-06-12T02:24:45.469517Z","shell.execute_reply.started":"2025-06-12T02:24:44.878555Z","shell.execute_reply":"2025-06-12T02:24:45.468894Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## 8 模型训练","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T02:24:45.471858Z","iopub.execute_input":"2025-06-12T02:24:45.472530Z","iopub.status.idle":"2025-06-12T03:05:38.568279Z","shell.execute_reply.started":"2025-06-12T02:24:45.472505Z","shell.execute_reply":"2025-06-12T03:05:38.567759Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2112' max='2112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2112/2112 40:49, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc</th>\n      <th>Org</th>\n      <th>Per</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.061700</td>\n      <td>0.026402</td>\n      <td>{'precision': 0.9412915851272016, 'recall': 0.9600798403193613, 'f1': 0.950592885375494, 'number': 1503}</td>\n      <td>{'precision': 0.8319559228650137, 'recall': 0.9151515151515152, 'f1': 0.8715728715728714, 'number': 1320}</td>\n      <td>{'precision': 0.9541054141269272, 'recall': 0.9330294530154277, 'f1': 0.9434497429533769, 'number': 2852}</td>\n      <td>0.919986</td>\n      <td>0.936035</td>\n      <td>0.927941</td>\n      <td>0.992429</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.019900</td>\n      <td>0.028749</td>\n      <td>{'precision': 0.9419439008480104, 'recall': 0.9607451763140386, 'f1': 0.9512516469038209, 'number': 1503}</td>\n      <td>{'precision': 0.8693790149892934, 'recall': 0.9227272727272727, 'f1': 0.8952590959206175, 'number': 1320}</td>\n      <td>{'precision': 0.952567760342368, 'recall': 0.9365357643758766, 'f1': 0.9444837340876945, 'number': 2852}</td>\n      <td>0.929418</td>\n      <td>0.939736</td>\n      <td>0.934548</td>\n      <td>0.992964</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.006600</td>\n      <td>0.031673</td>\n      <td>{'precision': 0.9476439790575916, 'recall': 0.9634065202927479, 'f1': 0.9554602441438469, 'number': 1503}</td>\n      <td>{'precision': 0.8745493871665465, 'recall': 0.918939393939394, 'f1': 0.8961950498707056, 'number': 1320}</td>\n      <td>{'precision': 0.954561590344338, 'recall': 0.9428471248246845, 'f1': 0.9486681954489328, 'number': 2852}</td>\n      <td>0.933357</td>\n      <td>0.942731</td>\n      <td>0.938021</td>\n      <td>0.993275</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ae67d39baa44f1eb817f92f5ccd457d"}},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'precision': 0.9412915851272016, 'recall': 0.9600798403193613, 'f1': 0.950592885375494, 'number': 1503}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8319559228650137, 'recall': 0.9151515151515152, 'f1': 0.8715728715728714, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9541054141269272, 'recall': 0.9330294530154277, 'f1': 0.9434497429533769, 'number': 2852}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nTrainer is attempting to log a value of \"{'precision': 0.9419439008480104, 'recall': 0.9607451763140386, 'f1': 0.9512516469038209, 'number': 1503}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8693790149892934, 'recall': 0.9227272727272727, 'f1': 0.8952590959206175, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.952567760342368, 'recall': 0.9365357643758766, 'f1': 0.9444837340876945, 'number': 2852}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nTrainer is attempting to log a value of \"{'precision': 0.9476439790575916, 'recall': 0.9634065202927479, 'f1': 0.9554602441438469, 'number': 1503}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8745493871665465, 'recall': 0.918939393939394, 'f1': 0.8961950498707056, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.954561590344338, 'recall': 0.9428471248246845, 'f1': 0.9486681954489328, 'number': 2852}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2112, training_loss=0.02409702581776814, metrics={'train_runtime': 2452.6864, 'train_samples_per_second': 55.043, 'train_steps_per_second': 0.861, 'total_flos': 1.180990200098808e+16, 'train_loss': 0.02409702581776814, 'epoch': 3.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## 9 输入语句检测","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\npipeline = pipeline('token-classification', 'ner_train/checkpoint-2112')\n\ntext = pipeline('双方确定了今后发展中美关系的指导方针')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:35:25.817734Z","iopub.execute_input":"2025-06-12T14:35:25.818057Z","iopub.status.idle":"2025-06-12T14:35:26.119680Z","shell.execute_reply.started":"2025-06-12T14:35:25.818036Z","shell.execute_reply":"2025-06-12T14:35:26.119047Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":18}]}