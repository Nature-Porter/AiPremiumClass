{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11848733,"sourceType":"datasetVersion","datasetId":1957174}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":3011.412426,"end_time":"2024-06-14T05:00:04.050455","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-14T04:09:52.638029","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"095f2b73a4484d32bf06c7f072816073":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1177707110374609b8ad81c420bddba2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1e0f03b64a4a689c409628d49b3982":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53d23fd5f76842d586e34087cf3ec32b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1177707110374609b8ad81c420bddba2","placeholder":"​","style":"IPY_MODEL_9f951f600e7d41058dd7dd376ba42aec","value":"100%"}},"722faeb2dc4048a7885b5c70557803c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8458028b5384314a80095f4701d8700","placeholder":"​","style":"IPY_MODEL_fc6233265b024389acfe58161df2bcbb","value":" 705/705 [49:21&lt;00:00,  3.58s/it]"}},"963776a9db78420c8e9731a34aae287e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53d23fd5f76842d586e34087cf3ec32b","IPY_MODEL_9bbc0b4abe80491b9d7dd5c387fc9755","IPY_MODEL_722faeb2dc4048a7885b5c70557803c2"],"layout":"IPY_MODEL_af85bfe8aab04429a0f413f03abc6e77"}},"9bbc0b4abe80491b9d7dd5c387fc9755":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_095f2b73a4484d32bf06c7f072816073","max":705,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c1e0f03b64a4a689c409628d49b3982","value":705}},"9f951f600e7d41058dd7dd376ba42aec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af85bfe8aab04429a0f413f03abc6e77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8458028b5384314a80095f4701d8700":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc6233265b024389acfe58161df2bcbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport pandas as pd\nimport torch\nfrom tqdm.notebook import tqdm\n\nfrom torch.utils.data import DataLoader\n\nbatch_size = 500\nwindow_size = 21","metadata":{"_cell_guid":"9dde5fe2-3837-40e1-841d-f3f60c0beb66","_uuid":"6bc16464-4804-42ed-b4ff-ff827cbb7729","collapsed":false,"jupyter":{"outputs_hidden":false},"papermill":{"duration":4.605869,"end_time":"2024-06-14T04:10:00.053593","exception":false,"start_time":"2024-06-14T04:09:55.447724","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T00:21:51.001619Z","iopub.execute_input":"2025-07-10T00:21:51.002322Z","iopub.status.idle":"2025-07-10T00:21:51.006785Z","shell.execute_reply.started":"2025-07-10T00:21:51.002294Z","shell.execute_reply":"2025-07-10T00:21:51.005845Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/renmindaily/RenMin_Daily.csv')\ndf","metadata":{"_cell_guid":"59cacbcb-f418-47f0-9a13-e87e8cde0517","_uuid":"d05b4502-4926-4d2c-83b1-6ec6f3c9acec","collapsed":true,"jupyter":{"outputs_hidden":true},"papermill":{"duration":6.331095,"end_time":"2024-06-14T04:10:06.390883","exception":false,"start_time":"2024-06-14T04:10:00.059788","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T00:21:53.127398Z","iopub.execute_input":"2025-07-10T00:21:53.128026Z","iopub.status.idle":"2025-07-10T00:22:04.656129Z","shell.execute_reply.started":"2025-07-10T00:21:53.127998Z","shell.execute_reply":"2025-07-10T00:22:04.655097Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                    id      date  \\\n0       20210101-01-01  20210101   \n1       20210101-01-02  20210101   \n2       20210101-01-03  20210101   \n3       20210101-01-04  20210101   \n4       20210101-02-01  20210101   \n...                ...       ...   \n106329  20250517-08-02  20250517   \n106330  20250517-08-03  20250517   \n106331  20250517-08-04  20250517   \n106332  20250517-08-05  20250517   \n106333  20250517-08-06  20250517   \n\n                                                 title  \\\n0                           中俄两国元首互致新年贺电 中俄两国总理互致新年贺电    \n1                                  国家主席习近平发表二〇二一年新年贺词    \n2                  艰难方显勇毅，磨砺始得玉成 ——习近平主席二〇二一年新年贺词启示录①    \n3       全国政协举行新年茶话会 习近平发表重要讲话李克强栗战书王沪宁赵乐际韩正王岐山出席 汪洋主持    \n4                        在全国政协新年茶话会上的讲话 （2020年12月31日）    \n...                                                ...   \n106329                                数字化，让文物迸发丰沛的生命力    \n106330                                        看中国也看世界    \n106331                                     小县城有所“大学校”    \n106332                                   文创，萃取文物的美学价值    \n106333                                  第一次感觉文物离自己这么近    \n\n                                                  content  \n0       　　新华社北京12月31日电 2020年12月31日，国家主席习近平和俄罗斯总统普京互致新年...  \n1       　　■ 2020年是极不平凡的一年。面对突如其来的新冠肺炎疫情，我们以人民至上、生命至上诠释...  \n2       　　新故相推，日生不滞。在风雨兼程中，我们告别2020年，迎来2021年。\\n　　“艰难方显...  \n3       　　新华社北京12月31日电 中国人民政治协商会议全国委员会12月31日上午在全国政协礼堂举...  \n4       同志们，朋友们：\\n　　在风雨兼程中，我们即将送别2020年，迎来2021年新年。很高兴在这...  \n...                                                   ...  \n106329  \\t\\t\\t\\t\\t\\t\\t许  蒙\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...  \n106330  \\t\\t\\t\\t\\t\\t\\t王  樾\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...  \n106331  \\t\\t\\t\\t\\t\\t\\t邓建胜\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（2025...  \n106332  \\t\\t\\t\\t\\t\\t\\t胡继禹\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（2025...  \n106333  \\t\\t\\t\\t\\t\\t\\t姚雪青 \\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...  \n\n[106334 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>title</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20210101-01-01</td>\n      <td>20210101</td>\n      <td>中俄两国元首互致新年贺电 中俄两国总理互致新年贺电</td>\n      <td>新华社北京12月31日电 2020年12月31日，国家主席习近平和俄罗斯总统普京互致新年...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20210101-01-02</td>\n      <td>20210101</td>\n      <td>国家主席习近平发表二〇二一年新年贺词</td>\n      <td>■ 2020年是极不平凡的一年。面对突如其来的新冠肺炎疫情，我们以人民至上、生命至上诠释...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20210101-01-03</td>\n      <td>20210101</td>\n      <td>艰难方显勇毅，磨砺始得玉成 ——习近平主席二〇二一年新年贺词启示录①</td>\n      <td>新故相推，日生不滞。在风雨兼程中，我们告别2020年，迎来2021年。\\n　　“艰难方显...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20210101-01-04</td>\n      <td>20210101</td>\n      <td>全国政协举行新年茶话会 习近平发表重要讲话李克强栗战书王沪宁赵乐际韩正王岐山出席 汪洋主持</td>\n      <td>新华社北京12月31日电 中国人民政治协商会议全国委员会12月31日上午在全国政协礼堂举...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20210101-02-01</td>\n      <td>20210101</td>\n      <td>在全国政协新年茶话会上的讲话 （2020年12月31日）</td>\n      <td>同志们，朋友们：\\n　　在风雨兼程中，我们即将送别2020年，迎来2021年新年。很高兴在这...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>106329</th>\n      <td>20250517-08-02</td>\n      <td>20250517</td>\n      <td>数字化，让文物迸发丰沛的生命力</td>\n      <td>\\t\\t\\t\\t\\t\\t\\t许  蒙\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...</td>\n    </tr>\n    <tr>\n      <th>106330</th>\n      <td>20250517-08-03</td>\n      <td>20250517</td>\n      <td>看中国也看世界</td>\n      <td>\\t\\t\\t\\t\\t\\t\\t王  樾\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...</td>\n    </tr>\n    <tr>\n      <th>106331</th>\n      <td>20250517-08-04</td>\n      <td>20250517</td>\n      <td>小县城有所“大学校”</td>\n      <td>\\t\\t\\t\\t\\t\\t\\t邓建胜\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（2025...</td>\n    </tr>\n    <tr>\n      <th>106332</th>\n      <td>20250517-08-05</td>\n      <td>20250517</td>\n      <td>文创，萃取文物的美学价值</td>\n      <td>\\t\\t\\t\\t\\t\\t\\t胡继禹\\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（2025...</td>\n    </tr>\n    <tr>\n      <th>106333</th>\n      <td>20250517-08-06</td>\n      <td>20250517</td>\n      <td>第一次感觉文物离自己这么近</td>\n      <td>\\t\\t\\t\\t\\t\\t\\t姚雪青 \\n\\t\\t\\t\\t\\t\\t\\t\\t《人民日报》（202...</td>\n    </tr>\n  </tbody>\n</table>\n<p>106334 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import csv\n\ndef csv_to_text(csv_path, txt_path, separator=' '):\n    with open(csv_path, 'r', encoding='utf-8') as csvfile:\n        reader = csv.reader(csvfile)\n        all_text = []\n        for row in reader:\n            # 将每行的所有单元格用分隔符连接\n            row_text = separator.join(str(cell) for cell in row)\n            all_text.append(row_text)\n        \n        # 将所有行合并为一个字符串\n        final_text = '\\n'.join(all_text)\n        \n        # 写入文本文件\n        with open(txt_path, 'w', encoding='utf-8') as txtfile:\n            txtfile.write(final_text)\n\n# 使用示例\ncsv_to_text('/kaggle/input/renmindaily/RenMin_Daily.csv', 'output.txt', separator=' ')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T02:28:21.614184Z","iopub.execute_input":"2025-07-10T02:28:21.614994Z","iopub.status.idle":"2025-07-10T02:28:32.005057Z","shell.execute_reply.started":"2025-07-10T02:28:21.614965Z","shell.execute_reply":"2025-07-10T02:28:32.004382Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_text('/kaggle/working/output.txt')\ndf","metadata":{"_cell_guid":"b3a7f663-5260-4dce-a493-a7a60319e361","_uuid":"00c661e2-fec5-4a77-bcff-21a74e3e7677","collapsed":true,"jupyter":{"outputs_hidden":true},"papermill":{"duration":0.023575,"end_time":"2024-06-14T04:10:06.419403","exception":false,"start_time":"2024-06-14T04:10:06.395828","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T02:29:16.226030Z","iopub.execute_input":"2025-07-10T02:29:16.226359Z","iopub.status.idle":"2025-07-10T02:29:16.244908Z","shell.execute_reply.started":"2025-07-10T02:29:16.226316Z","shell.execute_reply":"2025-07-10T02:29:16.243764Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/output.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef get_batch(split):\n    # 选择训练或验证数据集\n    data = train_data if split == 'train' else val_data\n\n    # 动态从数据集中选择位置索引\n    if len(data) < block_size:\n        # 如果数据不足，填充到block_size长度\n        padding = torch.zeros(block_size + 1 - len(data), dtype=torch.long)\n        data = torch.cat([data, padding])\n    \n    # 生成随机索引\n    ix = torch.randint(len(data) - block_size, (batch_size,))\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n\n    return x.to(device),y.to(device)\n\nclass Head(nn.Module):\n    \"\"\"单头 self-attention \"\"\"\n    def __init__(self, n_embd):\n        super().__init__()\n        self.key = nn.Linear(n_embd, n_embd, bias=False)\n        self.query = nn.Linear(n_embd, n_embd, bias=False)\n        self.value = nn.Linear(n_embd, n_embd, bias=False)\n\n    def forward(self, input_x):\n        B, T, C = input_x.shape\n\n        k = self.key(input_x)\n        q = self.query(input_x)\n        v = self.value(input_x)\n\n        wei = q @ k.transpose(-2,-1) * C ** -0.5\n        T = wei.shape[-1]\n        tril = torch.tril(torch.ones(T,T, device=device))\n        wei = wei.masked_fill(tril == 0, float('-inf'))\n        wei = wei.softmax(dim=-1)\n\n        out = wei @ v\n        return out\n\n\nclass BingramLanguageModel(nn.Module):\n    \n    def __init__(self, block_size, vocab_size, n_embd):\n        super().__init__()\n        # 每个token都直接从Embedding中查询对应的logits值 以进行下一个token的推理\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        # 位置编码\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n\n        # one head self-attention\n        self.sa_head = Head(n_embd)\n        # larg model forward\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n        \n    def forward(self, idx, targets=None):\n        B,T = idx.shape\n        \n        # idx值和targets值都是整型张量 (B,T)\n        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n        x = tok_emb + pos_emb\n        x = self.sa_head(x)\n        logits = self.lm_head(x)\n        \n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(-1)\n            loss = F.cross_entropy(logits, targets)\n        \n        return logits, loss\n    \n    def generate(self, idx, max_new_tokens):\n        # idx指当前语料集(B,T)中的索引\n        for _ in range(max_new_tokens):\n            # 限定索引列的取值范围\n            idx_cond = idx[:, -block_size:]\n            # 推理\n            logits, loss = self(idx_cond)\n            # 只提取最后一个时间步的结果\n            logits = logits[:, -1, :]  # (B,C)\n            # 通过softmax转换为概率值\n            probs = F.softmax(logits, dim=-1)  # (B,C)\n            # 随机采样\n            idx_next = torch.multinomial(probs, num_samples=1)  # (B,1)\n            # 把采样的索引追加在当前解码序列末尾\n            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n        return idx\n\nif __name__ == '__main__':\n\n    # 模型训练数据集\n    block_size = 8\n    batch_size = 32\n    max_iter = 10000\n    learn_rate = 1e-3\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    n_embd = 32\n    eval_interval = 500\n    eval_iters = 200\n\n    \n    with open('/kaggle/working/output.txt') as f:\n        text = f.read()\n\n    # 字典、编码器(函数)、解码器(函数)\n    chars = sorted(list(set(text)))\n    vocab_size = len(chars)\n    stoi = {ch:i for i,ch in enumerate(chars)}  #str_to_index\n    itos = {i:ch for i,ch in enumerate(chars)}  #index_to_str\n\n    encode = lambda s: [stoi[c] for c in s]\n    decode = lambda l: ''.join([itos[i] for i in l])\n\n    # 文本转换token index\n    data = torch.tensor(encode(text), dtype=torch.long)\n\n    # 拆分数据集\n    n = int(len(data) * .9)\n    train_data = data[:n]\n    val_data = data[n:]\n\n    # 模型训练\n    model = BingramLanguageModel(block_size, vocab_size, n_embd)\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learn_rate)\n\n    @torch.no_grad()\n    def estimate_loss():\n        out = {}\n        model.eval()\n        for split in ['train', 'val']:\n            losses = torch.zeros(eval_iters)\n            for k in range(eval_iters):\n                X, Y = get_batch(split)\n                logits, loss = model(X, Y)\n                losses[k] = loss.item()\n                print(f\"Batch{k}: loss = {loss.item():.4f}\")\n            out[split] = losses.mean()\n        model.train()\n        return out\n\n    for iter in range(max_iter):\n\n        if iter % eval_interval == 0:\n            losses = estimate_loss()\n            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n\n        # 批次样本\n        xb, yb = get_batch('train')\n\n        logits, loss = model(xb, yb)\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n\n    # 模型生成\n    idx = torch.zeros((1,1), dtype=torch.long, device=device)\n    print(decode(model.generate(idx, max_new_tokens=500)[0].tolist())) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T02:48:41.017776Z","iopub.execute_input":"2025-07-10T02:48:41.018102Z","iopub.status.idle":"2025-07-10T02:50:08.648005Z","shell.execute_reply.started":"2025-07-10T02:48:41.018077Z","shell.execute_reply":"2025-07-10T02:50:08.647145Z"}},"outputs":[{"name":"stdout","text":"Batch0: loss = 9.0275\nBatch1: loss = 8.9897\nBatch2: loss = 9.0359\nBatch3: loss = 9.0041\nBatch4: loss = 9.0099\nBatch5: loss = 8.9970\nBatch6: loss = 9.0272\nBatch7: loss = 9.0276\nBatch8: loss = 9.0214\nBatch9: loss = 9.0408\nBatch10: loss = 9.0187\nBatch11: loss = 8.9905\nBatch12: loss = 8.9607\nBatch13: loss = 9.0132\nBatch14: loss = 9.0373\nBatch15: loss = 8.9967\nBatch16: loss = 8.9650\nBatch17: loss = 9.0063\nBatch18: loss = 9.0186\nBatch19: loss = 9.0261\nBatch20: loss = 9.0158\nBatch21: loss = 8.9993\nBatch22: loss = 8.9803\nBatch23: loss = 8.9986\nBatch24: loss = 8.9857\nBatch25: loss = 9.0145\nBatch26: loss = 9.0004\nBatch27: loss = 8.9998\nBatch28: loss = 8.9775\nBatch29: loss = 8.9986\nBatch30: loss = 8.9861\nBatch31: loss = 8.9944\nBatch32: loss = 9.0111\nBatch33: loss = 9.0049\nBatch34: loss = 9.0326\nBatch35: loss = 9.0078\nBatch36: loss = 8.9935\nBatch37: loss = 8.9993\nBatch38: loss = 9.0050\nBatch39: loss = 8.9690\nBatch40: loss = 9.0056\nBatch41: loss = 9.0229\nBatch42: loss = 9.0213\nBatch43: loss = 9.0195\nBatch44: loss = 8.9976\nBatch45: loss = 8.9899\nBatch46: loss = 9.0094\nBatch47: loss = 9.0270\nBatch48: loss = 9.0053\nBatch49: loss = 9.0192\nBatch50: loss = 9.0127\nBatch51: loss = 8.9827\nBatch52: loss = 9.0453\nBatch53: loss = 9.0115\nBatch54: loss = 9.0102\nBatch55: loss = 9.0031\nBatch56: loss = 8.9947\nBatch57: loss = 9.0214\nBatch58: loss = 8.9856\nBatch59: loss = 8.9837\nBatch60: loss = 8.9881\nBatch61: loss = 8.9731\nBatch62: loss = 8.9997\nBatch63: loss = 8.9895\nBatch64: loss = 9.0061\nBatch65: loss = 9.0371\nBatch66: loss = 9.0266\nBatch67: loss = 9.0163\nBatch68: loss = 9.0095\nBatch69: loss = 9.0070\nBatch70: loss = 8.9849\nBatch71: loss = 9.0058\nBatch72: loss = 8.9666\nBatch73: loss = 9.0280\nBatch74: loss = 9.0518\nBatch75: loss = 8.9515\nBatch76: loss = 9.0370\nBatch77: loss = 9.0018\nBatch78: loss = 9.0209\nBatch79: loss = 8.9722\nBatch80: loss = 8.9968\nBatch81: loss = 9.0508\nBatch82: loss = 9.0124\nBatch83: loss = 9.0116\nBatch84: loss = 8.9618\nBatch85: loss = 9.0247\nBatch86: loss = 9.0227\nBatch87: loss = 8.9976\nBatch88: loss = 9.0211\nBatch89: loss = 9.0058\nBatch90: loss = 9.0345\nBatch91: loss = 9.0078\nBatch92: loss = 9.0158\nBatch93: loss = 9.0055\nBatch94: loss = 8.9923\nBatch95: loss = 9.0167\nBatch96: loss = 9.0101\nBatch97: loss = 8.9915\nBatch98: loss = 8.9936\nBatch99: loss = 8.9808\nBatch100: loss = 9.0252\nBatch101: loss = 9.0424\nBatch102: loss = 9.0427\nBatch103: loss = 9.0301\nBatch104: loss = 9.0316\nBatch105: loss = 9.0306\nBatch106: loss = 9.0060\nBatch107: loss = 8.9961\nBatch108: loss = 9.0000\nBatch109: loss = 9.0063\nBatch110: loss = 8.9704\nBatch111: loss = 8.9882\nBatch112: loss = 9.0433\nBatch113: loss = 8.9868\nBatch114: loss = 8.9886\nBatch115: loss = 9.0221\nBatch116: loss = 9.0064\nBatch117: loss = 9.0110\nBatch118: loss = 8.9968\nBatch119: loss = 9.0022\nBatch120: loss = 8.9749\nBatch121: loss = 8.9943\nBatch122: loss = 9.0039\nBatch123: loss = 8.9860\nBatch124: loss = 9.0325\nBatch125: loss = 9.0375\nBatch126: loss = 9.0554\nBatch127: loss = 8.9930\nBatch128: loss = 8.9936\nBatch129: loss = 8.9922\nBatch130: loss = 9.0007\nBatch131: loss = 9.0082\nBatch132: loss = 8.9974\nBatch133: loss = 8.9754\nBatch134: loss = 8.9753\nBatch135: loss = 9.0216\nBatch136: loss = 9.0181\nBatch137: loss = 9.0198\nBatch138: loss = 8.9858\nBatch139: loss = 8.9925\nBatch140: loss = 9.0228\nBatch141: loss = 8.9963\nBatch142: loss = 8.9946\nBatch143: loss = 9.0078\nBatch144: loss = 8.9848\nBatch145: loss = 9.0135\nBatch146: loss = 9.0378\nBatch147: loss = 9.0098\nBatch148: loss = 8.9950\nBatch149: loss = 8.9922\nBatch150: loss = 9.0157\nBatch151: loss = 9.0075\nBatch152: loss = 8.9941\nBatch153: loss = 9.0174\nBatch154: loss = 9.0120\nBatch155: loss = 9.0156\nBatch156: loss = 9.0154\nBatch157: loss = 8.9998\nBatch158: loss = 8.9813\nBatch159: loss = 9.0013\nBatch160: loss = 9.0090\nBatch161: loss = 8.9821\nBatch162: loss = 9.0208\nBatch163: loss = 9.0092\nBatch164: loss = 9.0176\nBatch165: loss = 8.9549\nBatch166: loss = 8.9874\nBatch167: loss = 9.0073\nBatch168: loss = 8.9846\nBatch169: loss = 9.0359\nBatch170: loss = 8.9922\nBatch171: loss = 9.0236\nBatch172: loss = 9.0051\nBatch173: loss = 9.0234\nBatch174: loss = 8.9774\nBatch175: loss = 8.9568\nBatch176: loss = 9.0239\nBatch177: loss = 8.9666\nBatch178: loss = 9.0087\nBatch179: loss = 8.9739\nBatch180: loss = 9.0016\nBatch181: loss = 9.0359\nBatch182: loss = 9.0014\nBatch183: loss = 9.0329\nBatch184: loss = 8.9762\nBatch185: loss = 9.0131\nBatch186: loss = 8.9665\nBatch187: loss = 8.9777\nBatch188: loss = 8.9793\nBatch189: loss = 9.0312\nBatch190: loss = 8.9798\nBatch191: loss = 8.9904\nBatch192: loss = 9.0085\nBatch193: loss = 8.9843\nBatch194: loss = 8.9945\nBatch195: loss = 9.0375\nBatch196: loss = 9.0307\nBatch197: loss = 9.0210\nBatch198: loss = 8.9992\nBatch199: loss = 9.0424\nBatch0: loss = 9.0116\nBatch1: loss = 8.9860\nBatch2: loss = 8.9838\nBatch3: loss = 9.0138\nBatch4: loss = 8.9861\nBatch5: loss = 8.9790\nBatch6: loss = 9.0017\nBatch7: loss = 9.0219\nBatch8: loss = 9.0367\nBatch9: loss = 9.0055\nBatch10: loss = 9.0126\nBatch11: loss = 9.0193\nBatch12: loss = 8.9878\nBatch13: loss = 9.0006\nBatch14: loss = 9.0175\nBatch15: loss = 8.9719\nBatch16: loss = 8.9768\nBatch17: loss = 9.0098\nBatch18: loss = 8.9997\nBatch19: loss = 8.9876\nBatch20: loss = 8.9906\nBatch21: loss = 9.0263\nBatch22: loss = 8.9913\nBatch23: loss = 8.9697\nBatch24: loss = 8.9827\nBatch25: loss = 8.9918\nBatch26: loss = 8.9878\nBatch27: loss = 8.9904\nBatch28: loss = 8.9859\nBatch29: loss = 9.0248\nBatch30: loss = 9.0243\nBatch31: loss = 9.0107\nBatch32: loss = 9.0542\nBatch33: loss = 9.0035\nBatch34: loss = 9.0166\nBatch35: loss = 8.9982\nBatch36: loss = 9.0141\nBatch37: loss = 8.9986\nBatch38: loss = 9.0051\nBatch39: loss = 9.0134\nBatch40: loss = 8.9913\nBatch41: loss = 8.9922\nBatch42: loss = 8.9958\nBatch43: loss = 9.0184\nBatch44: loss = 8.9866\nBatch45: loss = 8.9814\nBatch46: loss = 8.9629\nBatch47: loss = 9.0301\nBatch48: loss = 8.9935\nBatch49: loss = 9.0078\nBatch50: loss = 9.0418\nBatch51: loss = 9.0098\nBatch52: loss = 8.9856\nBatch53: loss = 8.9938\nBatch54: loss = 9.0111\nBatch55: loss = 9.0532\nBatch56: loss = 9.0206\nBatch57: loss = 9.0056\nBatch58: loss = 8.9925\nBatch59: loss = 8.9760\nBatch60: loss = 9.0093\nBatch61: loss = 9.0336\nBatch62: loss = 9.0203\nBatch63: loss = 9.0069\nBatch64: loss = 8.9814\nBatch65: loss = 9.0191\nBatch66: loss = 8.9699\nBatch67: loss = 8.9833\nBatch68: loss = 9.0064\nBatch69: loss = 8.9884\nBatch70: loss = 8.9772\nBatch71: loss = 8.9957\nBatch72: loss = 9.0169\nBatch73: loss = 9.0140\nBatch74: loss = 8.9780\nBatch75: loss = 8.9893\nBatch76: loss = 8.9876\nBatch77: loss = 8.9782\nBatch78: loss = 9.0028\nBatch79: loss = 9.0009\nBatch80: loss = 9.0041\nBatch81: loss = 8.9765\nBatch82: loss = 9.0203\nBatch83: loss = 9.0188\nBatch84: loss = 8.9827\nBatch85: loss = 8.9882\nBatch86: loss = 9.0131\nBatch87: loss = 9.0011\nBatch88: loss = 8.9876\nBatch89: loss = 8.9815\nBatch90: loss = 9.0221\nBatch91: loss = 8.9826\nBatch92: loss = 8.9869\nBatch93: loss = 8.9919\nBatch94: loss = 9.0218\nBatch95: loss = 8.9804\nBatch96: loss = 9.0407\nBatch97: loss = 8.9530\nBatch98: loss = 8.9476\nBatch99: loss = 8.9941\nBatch100: loss = 8.9861\nBatch101: loss = 9.0199\nBatch102: loss = 8.9934\nBatch103: loss = 8.9809\nBatch104: loss = 9.0184\nBatch105: loss = 9.0045\nBatch106: loss = 8.9868\nBatch107: loss = 8.9935\nBatch108: loss = 9.0191\nBatch109: loss = 8.9880\nBatch110: loss = 9.0062\nBatch111: loss = 8.9841\nBatch112: loss = 8.9839\nBatch113: loss = 9.0181\nBatch114: loss = 8.9931\nBatch115: loss = 8.9903\nBatch116: loss = 9.0152\nBatch117: loss = 8.9332\nBatch118: loss = 9.0107\nBatch119: loss = 8.9782\nBatch120: loss = 8.9882\nBatch121: loss = 9.0003\nBatch122: loss = 8.9718\nBatch123: loss = 9.0048\nBatch124: loss = 8.9789\nBatch125: loss = 9.0464\nBatch126: loss = 9.0117\nBatch127: loss = 8.9802\nBatch128: loss = 8.9938\nBatch129: loss = 8.9965\nBatch130: loss = 8.9791\nBatch131: loss = 8.9715\nBatch132: loss = 9.0167\nBatch133: loss = 8.9728\nBatch134: loss = 9.0657\nBatch135: loss = 9.0222\nBatch136: loss = 8.9656\nBatch137: loss = 8.9818\nBatch138: loss = 9.0238\nBatch139: loss = 9.0114\nBatch140: loss = 9.0226\nBatch141: loss = 9.0064\nBatch142: loss = 8.9792\nBatch143: loss = 8.9843\nBatch144: loss = 8.9327\nBatch145: loss = 8.9798\nBatch146: loss = 9.0168\nBatch147: loss = 9.0005\nBatch148: loss = 8.9942\nBatch149: loss = 9.0429\nBatch150: loss = 9.0058\nBatch151: loss = 9.0010\nBatch152: loss = 8.9985\nBatch153: loss = 8.9822\nBatch154: loss = 9.0139\nBatch155: loss = 8.9812\nBatch156: loss = 9.0107\nBatch157: loss = 9.0048\nBatch158: loss = 8.9722\nBatch159: loss = 8.9994\nBatch160: loss = 9.0284\nBatch161: loss = 8.9953\nBatch162: loss = 8.9736\nBatch163: loss = 9.0090\nBatch164: loss = 8.9955\nBatch165: loss = 9.0038\nBatch166: loss = 8.9890\nBatch167: loss = 8.9923\nBatch168: loss = 8.9758\nBatch169: loss = 8.9733\nBatch170: loss = 8.9751\nBatch171: loss = 9.0148\nBatch172: loss = 9.0164\nBatch173: loss = 9.0000\nBatch174: loss = 9.0085\nBatch175: loss = 9.0212\nBatch176: loss = 9.0234\nBatch177: loss = 8.9973\nBatch178: loss = 9.0212\nBatch179: loss = 9.0177\nBatch180: loss = 8.9913\nBatch181: loss = 9.0390\nBatch182: loss = 9.0517\nBatch183: loss = 8.9879\nBatch184: loss = 8.9955\nBatch185: loss = 9.0158\nBatch186: loss = 9.0197\nBatch187: loss = 9.0267\nBatch188: loss = 9.0053\nBatch189: loss = 8.9925\nBatch190: loss = 8.9905\nBatch191: loss = 9.0014\nBatch192: loss = 9.0243\nBatch193: loss = 9.0553\nBatch194: loss = 9.0111\nBatch195: loss = 9.0380\nBatch196: loss = 8.9776\nBatch197: loss = 8.9967\nBatch198: loss = 8.9942\nBatch199: loss = 8.9737\nstep 0: train loss 9.0052, val loss 9.0001\nBatch0: loss = 6.2799\nBatch1: loss = 6.2653\nBatch2: loss = 6.3541\nBatch3: loss = 6.7278\nBatch4: loss = 6.1993\nBatch5: loss = 6.5759\nBatch6: loss = 6.7184\nBatch7: loss = 6.4949\nBatch8: loss = 6.4051\nBatch9: loss = 6.2056\nBatch10: loss = 6.4891\nBatch11: loss = 6.4830\nBatch12: loss = 6.5630\nBatch13: loss = 6.5161\nBatch14: loss = 6.2369\nBatch15: loss = 6.3127\nBatch16: loss = 6.4004\nBatch17: loss = 6.3000\nBatch18: loss = 6.2656\nBatch19: loss = 6.3063\nBatch20: loss = 6.4555\nBatch21: loss = 6.1752\nBatch22: loss = 6.4340\nBatch23: loss = 6.6688\nBatch24: loss = 6.2456\nBatch25: loss = 6.5596\nBatch26: loss = 6.5176\nBatch27: loss = 6.4809\nBatch28: loss = 6.2764\nBatch29: loss = 6.4552\nBatch30: loss = 6.4580\nBatch31: loss = 6.6063\nBatch32: loss = 6.5905\nBatch33: loss = 6.4928\nBatch34: loss = 6.3112\nBatch35: loss = 6.2357\nBatch36: loss = 6.4247\nBatch37: loss = 6.2371\nBatch38: loss = 6.4190\nBatch39: loss = 6.4658\nBatch40: loss = 6.4444\nBatch41: loss = 6.6780\nBatch42: loss = 6.3007\nBatch43: loss = 6.6096\nBatch44: loss = 6.1955\nBatch45: loss = 6.3902\nBatch46: loss = 6.4345\nBatch47: loss = 6.7395\nBatch48: loss = 6.3846\nBatch49: loss = 6.5304\nBatch50: loss = 6.3988\nBatch51: loss = 6.4500\nBatch52: loss = 6.5487\nBatch53: loss = 6.7081\nBatch54: loss = 6.3414\nBatch55: loss = 6.2748\nBatch56: loss = 6.2774\nBatch57: loss = 6.6973\nBatch58: loss = 6.5075\nBatch59: loss = 6.3568\nBatch60: loss = 6.4695\nBatch61: loss = 6.6928\nBatch62: loss = 6.1308\nBatch63: loss = 6.3402\nBatch64: loss = 6.7311\nBatch65: loss = 6.3671\nBatch66: loss = 6.2178\nBatch67: loss = 6.0380\nBatch68: loss = 6.4864\nBatch69: loss = 6.4227\nBatch70: loss = 6.3794\nBatch71: loss = 6.2340\nBatch72: loss = 6.7938\nBatch73: loss = 6.3420\nBatch74: loss = 6.6328\nBatch75: loss = 6.7498\nBatch76: loss = 6.2785\nBatch77: loss = 6.3852\nBatch78: loss = 6.3869\nBatch79: loss = 6.5291\nBatch80: loss = 6.5869\nBatch81: loss = 6.2891\nBatch82: loss = 6.3454\nBatch83: loss = 6.5613\nBatch84: loss = 6.4043\nBatch85: loss = 6.4685\nBatch86: loss = 6.6340\nBatch87: loss = 6.3204\nBatch88: loss = 6.7233\nBatch89: loss = 6.0467\nBatch90: loss = 6.3272\nBatch91: loss = 6.5009\nBatch92: loss = 6.2560\nBatch93: loss = 6.5206\nBatch94: loss = 6.5362\nBatch95: loss = 6.1586\nBatch96: loss = 6.4368\nBatch97: loss = 6.3537\nBatch98: loss = 6.5860\nBatch99: loss = 6.2608\nBatch100: loss = 6.4373\nBatch101: loss = 6.1778\nBatch102: loss = 6.3925\nBatch103: loss = 6.6673\nBatch104: loss = 6.1928\nBatch105: loss = 6.1763\nBatch106: loss = 6.3379\nBatch107: loss = 6.5667\nBatch108: loss = 6.4175\nBatch109: loss = 6.0373\nBatch110: loss = 6.1470\nBatch111: loss = 6.3561\nBatch112: loss = 6.2760\nBatch113: loss = 6.4489\nBatch114: loss = 6.5367\nBatch115: loss = 6.4171\nBatch116: loss = 6.2233\nBatch117: loss = 6.4325\nBatch118: loss = 6.3286\nBatch119: loss = 6.2683\nBatch120: loss = 6.4321\nBatch121: loss = 6.3345\nBatch122: loss = 6.2611\nBatch123: loss = 6.3774\nBatch124: loss = 6.4147\nBatch125: loss = 6.3494\nBatch126: loss = 6.3504\nBatch127: loss = 6.5564\nBatch128: loss = 6.1921\nBatch129: loss = 6.4341\nBatch130: loss = 6.4300\nBatch131: loss = 6.5936\nBatch132: loss = 6.4543\nBatch133: loss = 6.3734\nBatch134: loss = 6.4289\nBatch135: loss = 6.1084\nBatch136: loss = 6.3801\nBatch137: loss = 6.3927\nBatch138: loss = 6.5624\nBatch139: loss = 6.4524\nBatch140: loss = 6.1959\nBatch141: loss = 6.1578\nBatch142: loss = 6.4991\nBatch143: loss = 6.3480\nBatch144: loss = 6.4215\nBatch145: loss = 6.1930\nBatch146: loss = 6.3605\nBatch147: loss = 6.6604\nBatch148: loss = 6.3056\nBatch149: loss = 6.4753\nBatch150: loss = 6.4156\nBatch151: loss = 6.2808\nBatch152: loss = 6.5443\nBatch153: loss = 6.1923\nBatch154: loss = 6.1131\nBatch155: loss = 6.4833\nBatch156: loss = 6.3390\nBatch157: loss = 6.2292\nBatch158: loss = 6.3866\nBatch159: loss = 6.4741\nBatch160: loss = 6.3360\nBatch161: loss = 6.3647\nBatch162: loss = 6.2740\nBatch163: loss = 6.0552\nBatch164: loss = 6.6515\nBatch165: loss = 6.4779\nBatch166: loss = 6.5555\nBatch167: loss = 6.4637\nBatch168: loss = 6.6320\nBatch169: loss = 6.5624\nBatch170: loss = 6.1332\nBatch171: loss = 6.2997\nBatch172: loss = 6.3979\nBatch173: loss = 6.3303\nBatch174: loss = 6.5057\nBatch175: loss = 6.3263\nBatch176: loss = 6.3197\nBatch177: loss = 6.3850\nBatch178: loss = 6.2324\nBatch179: loss = 6.6250\nBatch180: loss = 6.4635\nBatch181: loss = 6.3310\nBatch182: loss = 6.6562\nBatch183: loss = 6.7462\nBatch184: loss = 6.3982\nBatch185: loss = 6.4262\nBatch186: loss = 6.4600\nBatch187: loss = 6.1037\nBatch188: loss = 6.5422\nBatch189: loss = 6.3981\nBatch190: loss = 6.4560\nBatch191: loss = 6.7700\nBatch192: loss = 6.4575\nBatch193: loss = 6.3408\nBatch194: loss = 6.3514\nBatch195: loss = 6.6633\nBatch196: loss = 6.4637\nBatch197: loss = 6.3569\nBatch198: loss = 6.3131\nBatch199: loss = 6.5095\nBatch0: loss = 6.4303\nBatch1: loss = 6.3723\nBatch2: loss = 6.5911\nBatch3: loss = 6.3793\nBatch4: loss = 6.5565\nBatch5: loss = 6.3508\nBatch6: loss = 6.5515\nBatch7: loss = 6.7504\nBatch8: loss = 6.5899\nBatch9: loss = 6.4274\nBatch10: loss = 6.5034\nBatch11: loss = 6.4577\nBatch12: loss = 6.6894\nBatch13: loss = 6.5114\nBatch14: loss = 6.6213\nBatch15: loss = 6.6701\nBatch16: loss = 6.6466\nBatch17: loss = 6.4561\nBatch18: loss = 6.4648\nBatch19: loss = 6.6472\nBatch20: loss = 6.6608\nBatch21: loss = 6.5408\nBatch22: loss = 6.6631\nBatch23: loss = 6.4389\nBatch24: loss = 6.5328\nBatch25: loss = 6.5081\nBatch26: loss = 6.6404\nBatch27: loss = 6.4486\nBatch28: loss = 6.4685\nBatch29: loss = 6.5439\nBatch30: loss = 6.4396\nBatch31: loss = 6.8953\nBatch32: loss = 6.4772\nBatch33: loss = 6.6073\nBatch34: loss = 6.4814\nBatch35: loss = 6.3200\nBatch36: loss = 6.6891\nBatch37: loss = 6.4001\nBatch38: loss = 6.4483\nBatch39: loss = 6.4379\nBatch40: loss = 6.5000\nBatch41: loss = 6.3786\nBatch42: loss = 6.5783\nBatch43: loss = 6.4956\nBatch44: loss = 6.3967\nBatch45: loss = 6.6069\nBatch46: loss = 6.3571\nBatch47: loss = 6.5394\nBatch48: loss = 6.4432\nBatch49: loss = 6.6677\nBatch50: loss = 6.3963\nBatch51: loss = 6.6565\nBatch52: loss = 6.5344\nBatch53: loss = 6.6148\nBatch54: loss = 6.5816\nBatch55: loss = 6.3480\nBatch56: loss = 6.6972\nBatch57: loss = 6.3856\nBatch58: loss = 6.6232\nBatch59: loss = 6.6105\nBatch60: loss = 6.3456\nBatch61: loss = 6.4600\nBatch62: loss = 6.5943\nBatch63: loss = 6.5666\nBatch64: loss = 6.4369\nBatch65: loss = 6.2817\nBatch66: loss = 6.5447\nBatch67: loss = 6.9293\nBatch68: loss = 6.6207\nBatch69: loss = 6.4997\nBatch70: loss = 6.2490\nBatch71: loss = 6.6692\nBatch72: loss = 6.6335\nBatch73: loss = 6.7407\nBatch74: loss = 6.3588\nBatch75: loss = 6.6355\nBatch76: loss = 6.5967\nBatch77: loss = 6.4360\nBatch78: loss = 6.5890\nBatch79: loss = 6.6098\nBatch80: loss = 6.3624\nBatch81: loss = 6.6451\nBatch82: loss = 6.4189\nBatch83: loss = 6.3540\nBatch84: loss = 6.6884\nBatch85: loss = 6.4401\nBatch86: loss = 6.4315\nBatch87: loss = 6.3038\nBatch88: loss = 6.2292\nBatch89: loss = 6.3207\nBatch90: loss = 6.7188\nBatch91: loss = 6.5375\nBatch92: loss = 6.8139\nBatch93: loss = 6.7614\nBatch94: loss = 6.7337\nBatch95: loss = 6.4321\nBatch96: loss = 6.4433\nBatch97: loss = 6.5831\nBatch98: loss = 6.4458\nBatch99: loss = 6.6583\nBatch100: loss = 6.7140\nBatch101: loss = 6.7047\nBatch102: loss = 6.4029\nBatch103: loss = 6.0282\nBatch104: loss = 6.5771\nBatch105: loss = 6.4403\nBatch106: loss = 6.2709\nBatch107: loss = 6.7158\nBatch108: loss = 6.1821\nBatch109: loss = 6.4575\nBatch110: loss = 6.2413\nBatch111: loss = 7.0378\nBatch112: loss = 6.4615\nBatch113: loss = 6.2150\nBatch114: loss = 6.7347\nBatch115: loss = 6.2546\nBatch116: loss = 6.5971\nBatch117: loss = 6.7089\nBatch118: loss = 6.3473\nBatch119: loss = 6.5868\nBatch120: loss = 6.6742\nBatch121: loss = 6.7052\nBatch122: loss = 6.3898\nBatch123: loss = 6.3100\nBatch124: loss = 6.3697\nBatch125: loss = 6.6537\nBatch126: loss = 6.4623\nBatch127: loss = 6.3425\nBatch128: loss = 6.6215\nBatch129: loss = 6.3597\nBatch130: loss = 6.7667\nBatch131: loss = 6.6074\nBatch132: loss = 6.5635\nBatch133: loss = 6.4093\nBatch134: loss = 6.6596\nBatch135: loss = 6.6114\nBatch136: loss = 6.2587\nBatch137: loss = 6.4956\nBatch138: loss = 6.4905\nBatch139: loss = 6.5350\nBatch140: loss = 6.5770\nBatch141: loss = 6.4742\nBatch142: loss = 6.4898\nBatch143: loss = 6.4379\nBatch144: loss = 6.4911\nBatch145: loss = 6.3647\nBatch146: loss = 6.5236\nBatch147: loss = 6.6038\nBatch148: loss = 6.5720\nBatch149: loss = 6.6623\nBatch150: loss = 6.5050\nBatch151: loss = 6.6837\nBatch152: loss = 6.6963\nBatch153: loss = 6.4018\nBatch154: loss = 6.4128\nBatch155: loss = 6.3756\nBatch156: loss = 6.4099\nBatch157: loss = 6.4474\nBatch158: loss = 6.7951\nBatch159: loss = 6.4298\nBatch160: loss = 6.4166\nBatch161: loss = 6.4173\nBatch162: loss = 6.3754\nBatch163: loss = 6.3499\nBatch164: loss = 6.5877\nBatch165: loss = 6.4888\nBatch166: loss = 6.5525\nBatch167: loss = 6.3666\nBatch168: loss = 6.5650\nBatch169: loss = 6.4216\nBatch170: loss = 6.3939\nBatch171: loss = 6.7538\nBatch172: loss = 6.4714\nBatch173: loss = 6.8042\nBatch174: loss = 6.6634\nBatch175: loss = 6.3340\nBatch176: loss = 6.5772\nBatch177: loss = 6.4559\nBatch178: loss = 6.8229\nBatch179: loss = 6.7608\nBatch180: loss = 6.2000\nBatch181: loss = 6.7691\nBatch182: loss = 6.4197\nBatch183: loss = 6.6716\nBatch184: loss = 6.4394\nBatch185: loss = 6.2887\nBatch186: loss = 6.5728\nBatch187: loss = 6.5776\nBatch188: loss = 6.5510\nBatch189: loss = 6.7635\nBatch190: loss = 6.7404\nBatch191: loss = 6.5750\nBatch192: loss = 6.5938\nBatch193: loss = 6.4303\nBatch194: loss = 6.5342\nBatch195: loss = 6.5723\nBatch196: loss = 6.1861\nBatch197: loss = 6.6644\nBatch198: loss = 6.4874\nBatch199: loss = 6.7721\nstep 500: train loss 6.4087, val loss 6.5227\nBatch0: loss = 6.0382\nBatch1: loss = 6.0842\nBatch2: loss = 6.3350\nBatch3: loss = 6.1980\nBatch4: loss = 6.3757\nBatch5: loss = 5.8810\nBatch6: loss = 6.1934\nBatch7: loss = 6.3894\nBatch8: loss = 6.0148\nBatch9: loss = 6.1314\nBatch10: loss = 6.1741\nBatch11: loss = 6.3167\nBatch12: loss = 6.2215\nBatch13: loss = 6.2880\nBatch14: loss = 6.3732\nBatch15: loss = 6.2670\nBatch16: loss = 5.9936\nBatch17: loss = 6.3126\nBatch18: loss = 6.3333\nBatch19: loss = 6.1060\nBatch20: loss = 6.0430\nBatch21: loss = 6.1970\nBatch22: loss = 6.3326\nBatch23: loss = 5.8895\nBatch24: loss = 6.1018\nBatch25: loss = 6.2506\nBatch26: loss = 6.1545\nBatch27: loss = 6.0888\nBatch28: loss = 6.1494\nBatch29: loss = 6.2872\nBatch30: loss = 6.1605\nBatch31: loss = 6.2886\nBatch32: loss = 6.1052\nBatch33: loss = 6.1453\nBatch34: loss = 6.0833\nBatch35: loss = 5.9239\nBatch36: loss = 6.4383\nBatch37: loss = 6.0555\nBatch38: loss = 5.9659\nBatch39: loss = 6.0903\nBatch40: loss = 6.4139\nBatch41: loss = 6.0619\nBatch42: loss = 6.0768\nBatch43: loss = 6.2380\nBatch44: loss = 6.0845\nBatch45: loss = 6.4752\nBatch46: loss = 6.0746\nBatch47: loss = 5.9832\nBatch48: loss = 6.0066\nBatch49: loss = 6.2744\nBatch50: loss = 5.9082\nBatch51: loss = 6.1189\nBatch52: loss = 6.3485\nBatch53: loss = 5.8832\nBatch54: loss = 6.0632\nBatch55: loss = 6.2034\nBatch56: loss = 5.9831\nBatch57: loss = 6.1214\nBatch58: loss = 6.3193\nBatch59: loss = 6.2281\nBatch60: loss = 5.6865\nBatch61: loss = 6.2218\nBatch62: loss = 6.0401\nBatch63: loss = 6.1535\nBatch64: loss = 6.1398\nBatch65: loss = 6.1458\nBatch66: loss = 6.1836\nBatch67: loss = 6.5622\nBatch68: loss = 6.2158\nBatch69: loss = 6.1721\nBatch70: loss = 6.4454\nBatch71: loss = 5.8814\nBatch72: loss = 6.2077\nBatch73: loss = 6.4841\nBatch74: loss = 6.1624\nBatch75: loss = 5.7884\nBatch76: loss = 6.1115\nBatch77: loss = 6.5394\nBatch78: loss = 5.9412\nBatch79: loss = 6.1625\nBatch80: loss = 6.2097\nBatch81: loss = 6.2622\nBatch82: loss = 5.7881\nBatch83: loss = 6.4033\nBatch84: loss = 6.4821\nBatch85: loss = 6.2727\nBatch86: loss = 6.3397\nBatch87: loss = 6.1876\nBatch88: loss = 6.1997\nBatch89: loss = 6.0950\nBatch90: loss = 6.2090\nBatch91: loss = 6.0083\nBatch92: loss = 6.2005\nBatch93: loss = 6.2158\nBatch94: loss = 6.1286\nBatch95: loss = 6.1508\nBatch96: loss = 6.4636\nBatch97: loss = 6.0165\nBatch98: loss = 6.2135\nBatch99: loss = 6.5276\nBatch100: loss = 6.0920\nBatch101: loss = 5.9821\nBatch102: loss = 6.1480\nBatch103: loss = 6.4833\nBatch104: loss = 6.5840\nBatch105: loss = 5.9525\nBatch106: loss = 6.5980\nBatch107: loss = 6.3239\nBatch108: loss = 6.3312\nBatch109: loss = 6.4976\nBatch110: loss = 6.2577\nBatch111: loss = 6.2325\nBatch112: loss = 5.8110\nBatch113: loss = 6.2977\nBatch114: loss = 6.1716\nBatch115: loss = 6.1146\nBatch116: loss = 6.6059\nBatch117: loss = 5.9447\nBatch118: loss = 5.8178\nBatch119: loss = 6.3307\nBatch120: loss = 6.1140\nBatch121: loss = 6.0757\nBatch122: loss = 5.9317\nBatch123: loss = 6.0433\nBatch124: loss = 5.9542\nBatch125: loss = 6.0356\nBatch126: loss = 6.2988\nBatch127: loss = 6.5437\nBatch128: loss = 5.9823\nBatch129: loss = 6.3242\nBatch130: loss = 6.1757\nBatch131: loss = 5.9251\nBatch132: loss = 6.0948\nBatch133: loss = 6.1333\nBatch134: loss = 6.1399\nBatch135: loss = 6.1554\nBatch136: loss = 6.3795\nBatch137: loss = 6.0689\nBatch138: loss = 6.5031\nBatch139: loss = 6.1481\nBatch140: loss = 6.0240\nBatch141: loss = 6.4075\nBatch142: loss = 6.0410\nBatch143: loss = 5.8704\nBatch144: loss = 6.3477\nBatch145: loss = 5.9982\nBatch146: loss = 5.9110\nBatch147: loss = 5.9795\nBatch148: loss = 5.9501\nBatch149: loss = 6.0092\nBatch150: loss = 6.1635\nBatch151: loss = 6.1966\nBatch152: loss = 6.3343\nBatch153: loss = 6.0689\nBatch154: loss = 6.0309\nBatch155: loss = 6.2428\nBatch156: loss = 6.2532\nBatch157: loss = 6.2314\nBatch158: loss = 6.4397\nBatch159: loss = 6.0721\nBatch160: loss = 6.1156\nBatch161: loss = 5.9137\nBatch162: loss = 6.0707\nBatch163: loss = 6.1897\nBatch164: loss = 6.1298\nBatch165: loss = 6.1134\nBatch166: loss = 5.8393\nBatch167: loss = 6.2084\nBatch168: loss = 6.5725\nBatch169: loss = 6.1603\nBatch170: loss = 6.2857\nBatch171: loss = 6.1662\nBatch172: loss = 5.9557\nBatch173: loss = 6.0851\nBatch174: loss = 6.3282\nBatch175: loss = 6.0930\nBatch176: loss = 5.9204\nBatch177: loss = 5.7172\nBatch178: loss = 5.8454\nBatch179: loss = 6.1239\nBatch180: loss = 5.8765\nBatch181: loss = 6.3983\nBatch182: loss = 5.8947\nBatch183: loss = 6.0721\nBatch184: loss = 6.2562\nBatch185: loss = 6.1529\nBatch186: loss = 5.9493\nBatch187: loss = 6.3878\nBatch188: loss = 6.1208\nBatch189: loss = 6.0332\nBatch190: loss = 5.9720\nBatch191: loss = 5.9299\nBatch192: loss = 6.3332\nBatch193: loss = 5.9815\nBatch194: loss = 6.6315\nBatch195: loss = 6.5088\nBatch196: loss = 6.3435\nBatch197: loss = 6.0727\nBatch198: loss = 6.0654\nBatch199: loss = 6.2829\nBatch0: loss = 6.1050\nBatch1: loss = 6.1071\nBatch2: loss = 5.8913\nBatch3: loss = 6.4733\nBatch4: loss = 6.2573\nBatch5: loss = 5.7927\nBatch6: loss = 6.0918\nBatch7: loss = 6.1899\nBatch8: loss = 6.2812\nBatch9: loss = 6.3573\nBatch10: loss = 6.1028\nBatch11: loss = 6.0814\nBatch12: loss = 6.1142\nBatch13: loss = 5.8518\nBatch14: loss = 6.1718\nBatch15: loss = 6.3862\nBatch16: loss = 6.2168\nBatch17: loss = 6.1555\nBatch18: loss = 6.3388\nBatch19: loss = 6.0211\nBatch20: loss = 6.0777\nBatch21: loss = 5.9004\nBatch22: loss = 6.3182\nBatch23: loss = 6.3794\nBatch24: loss = 6.1954\nBatch25: loss = 6.2873\nBatch26: loss = 6.2441\nBatch27: loss = 6.0586\nBatch28: loss = 6.5265\nBatch29: loss = 6.1566\nBatch30: loss = 6.3058\nBatch31: loss = 6.2155\nBatch32: loss = 6.3396\nBatch33: loss = 6.2561\nBatch34: loss = 6.3275\nBatch35: loss = 6.0582\nBatch36: loss = 6.4860\nBatch37: loss = 5.7436\nBatch38: loss = 6.3653\nBatch39: loss = 6.1295\nBatch40: loss = 6.4011\nBatch41: loss = 6.3893\nBatch42: loss = 6.1400\nBatch43: loss = 6.4437\nBatch44: loss = 6.3244\nBatch45: loss = 6.2661\nBatch46: loss = 5.8359\nBatch47: loss = 6.2732\nBatch48: loss = 6.1856\nBatch49: loss = 6.2924\nBatch50: loss = 5.8916\nBatch51: loss = 6.4746\nBatch52: loss = 6.3687\nBatch53: loss = 6.1210\nBatch54: loss = 6.2908\nBatch55: loss = 6.1779\nBatch56: loss = 6.3227\nBatch57: loss = 6.4850\nBatch58: loss = 6.4345\nBatch59: loss = 6.2391\nBatch60: loss = 6.1101\nBatch61: loss = 6.1340\nBatch62: loss = 6.1742\nBatch63: loss = 6.1931\nBatch64: loss = 6.3797\nBatch65: loss = 6.2497\nBatch66: loss = 6.3624\nBatch67: loss = 6.5590\nBatch68: loss = 6.4463\nBatch69: loss = 6.3871\nBatch70: loss = 6.1489\nBatch71: loss = 6.3085\nBatch72: loss = 6.1793\nBatch73: loss = 5.9888\nBatch74: loss = 6.3964\nBatch75: loss = 5.9889\nBatch76: loss = 6.2108\nBatch77: loss = 6.2720\nBatch78: loss = 6.3589\nBatch79: loss = 6.3366\nBatch80: loss = 5.9944\nBatch81: loss = 6.2524\nBatch82: loss = 6.4406\nBatch83: loss = 6.4571\nBatch84: loss = 6.7923\nBatch85: loss = 6.2789\nBatch86: loss = 6.2039\nBatch87: loss = 6.0926\nBatch88: loss = 6.3137\nBatch89: loss = 6.3470\nBatch90: loss = 6.0827\nBatch91: loss = 6.0430\nBatch92: loss = 6.1224\nBatch93: loss = 6.5219\nBatch94: loss = 6.2464\nBatch95: loss = 6.4433\nBatch96: loss = 6.2648\nBatch97: loss = 6.2721\nBatch98: loss = 6.2429\nBatch99: loss = 6.5004\nBatch100: loss = 6.1331\nBatch101: loss = 6.2910\nBatch102: loss = 5.9449\nBatch103: loss = 6.4597\nBatch104: loss = 6.0219\nBatch105: loss = 6.4235\nBatch106: loss = 6.3640\nBatch107: loss = 6.4193\nBatch108: loss = 5.9249\nBatch109: loss = 6.5122\nBatch110: loss = 6.2730\nBatch111: loss = 6.3800\nBatch112: loss = 5.8635\nBatch113: loss = 6.4067\nBatch114: loss = 6.1687\nBatch115: loss = 6.4930\nBatch116: loss = 6.2027\nBatch117: loss = 6.1606\nBatch118: loss = 6.0060\nBatch119: loss = 6.3065\nBatch120: loss = 6.3079\nBatch121: loss = 6.4010\nBatch122: loss = 6.3514\nBatch123: loss = 6.4053\nBatch124: loss = 6.0806\nBatch125: loss = 6.4143\nBatch126: loss = 6.7594\nBatch127: loss = 6.1676\nBatch128: loss = 6.4548\nBatch129: loss = 6.1250\nBatch130: loss = 6.5117\nBatch131: loss = 6.3475\nBatch132: loss = 6.2054\nBatch133: loss = 6.0109\nBatch134: loss = 6.3662\nBatch135: loss = 6.1641\nBatch136: loss = 6.4372\nBatch137: loss = 6.3794\nBatch138: loss = 6.4373\nBatch139: loss = 6.3589\nBatch140: loss = 6.2434\nBatch141: loss = 6.4963\nBatch142: loss = 6.3722\nBatch143: loss = 6.4209\nBatch144: loss = 6.4103\nBatch145: loss = 6.0882\nBatch146: loss = 6.4698\nBatch147: loss = 6.2807\nBatch148: loss = 6.2571\nBatch149: loss = 6.1802\nBatch150: loss = 5.9335\nBatch151: loss = 6.3277\nBatch152: loss = 6.2001\nBatch153: loss = 6.3357\nBatch154: loss = 6.5260\nBatch155: loss = 6.3053\nBatch156: loss = 6.0568\nBatch157: loss = 6.1392\nBatch158: loss = 6.2487\nBatch159: loss = 6.3834\nBatch160: loss = 6.4018\nBatch161: loss = 6.1417\nBatch162: loss = 5.9178\nBatch163: loss = 6.1225\nBatch164: loss = 6.2621\nBatch165: loss = 6.1436\nBatch166: loss = 6.5428\nBatch167: loss = 5.9555\nBatch168: loss = 6.3918\nBatch169: loss = 6.3458\nBatch170: loss = 5.9446\nBatch171: loss = 6.2034\nBatch172: loss = 6.3266\nBatch173: loss = 5.9140\nBatch174: loss = 6.2280\nBatch175: loss = 6.3865\nBatch176: loss = 6.4691\nBatch177: loss = 6.3332\nBatch178: loss = 6.3359\nBatch179: loss = 6.2598\nBatch180: loss = 6.4707\nBatch181: loss = 6.2009\nBatch182: loss = 6.2633\nBatch183: loss = 6.1899\nBatch184: loss = 6.3467\nBatch185: loss = 6.1036\nBatch186: loss = 6.0123\nBatch187: loss = 5.8960\nBatch188: loss = 6.3538\nBatch189: loss = 6.2976\nBatch190: loss = 6.3641\nBatch191: loss = 6.3453\nBatch192: loss = 6.1680\nBatch193: loss = 5.9048\nBatch194: loss = 5.9889\nBatch195: loss = 6.4728\nBatch196: loss = 6.4171\nBatch197: loss = 6.2893\nBatch198: loss = 6.4151\nBatch199: loss = 6.3404\nstep 1000: train loss 6.1627, val loss 6.2520\nBatch0: loss = 5.8317\nBatch1: loss = 5.9831\nBatch2: loss = 5.7790\nBatch3: loss = 6.0060\nBatch4: loss = 5.9894\nBatch5: loss = 6.0296\nBatch6: loss = 5.7322\nBatch7: loss = 5.9028\nBatch8: loss = 5.7027\nBatch9: loss = 5.8840\nBatch10: loss = 5.6733\nBatch11: loss = 6.0754\nBatch12: loss = 5.9623\nBatch13: loss = 5.9540\nBatch14: loss = 5.9105\nBatch15: loss = 5.9062\nBatch16: loss = 5.9917\nBatch17: loss = 5.9180\nBatch18: loss = 5.7813\nBatch19: loss = 5.9919\nBatch20: loss = 6.1457\nBatch21: loss = 5.8962\nBatch22: loss = 5.9414\nBatch23: loss = 5.7294\nBatch24: loss = 5.4374\nBatch25: loss = 5.8657\nBatch26: loss = 5.4687\nBatch27: loss = 5.6097\nBatch28: loss = 5.8169\nBatch29: loss = 5.7261\nBatch30: loss = 5.5448\nBatch31: loss = 5.7430\nBatch32: loss = 5.7629\nBatch33: loss = 5.8320\nBatch34: loss = 5.1436\nBatch35: loss = 5.8598\nBatch36: loss = 5.8534\nBatch37: loss = 5.8893\nBatch38: loss = 5.9211\nBatch39: loss = 5.7191\nBatch40: loss = 5.9087\nBatch41: loss = 5.8986\nBatch42: loss = 6.1798\nBatch43: loss = 5.9602\nBatch44: loss = 6.1766\nBatch45: loss = 5.7764\nBatch46: loss = 5.7508\nBatch47: loss = 5.5395\nBatch48: loss = 6.1556\nBatch49: loss = 5.0296\nBatch50: loss = 6.0704\nBatch51: loss = 5.9863\nBatch52: loss = 6.2415\nBatch53: loss = 5.7650\nBatch54: loss = 5.6656\nBatch55: loss = 5.8529\nBatch56: loss = 6.1020\nBatch57: loss = 6.2240\nBatch58: loss = 6.1067\nBatch59: loss = 5.7941\nBatch60: loss = 6.1060\nBatch61: loss = 6.0888\nBatch62: loss = 5.8100\nBatch63: loss = 5.8638\nBatch64: loss = 5.6671\nBatch65: loss = 5.5207\nBatch66: loss = 5.7405\nBatch67: loss = 5.9200\nBatch68: loss = 5.8513\nBatch69: loss = 5.6722\nBatch70: loss = 6.0037\nBatch71: loss = 5.8048\nBatch72: loss = 5.9154\nBatch73: loss = 5.5186\nBatch74: loss = 5.7962\nBatch75: loss = 5.6261\nBatch76: loss = 5.9289\nBatch77: loss = 6.0261\nBatch78: loss = 5.5141\nBatch79: loss = 6.0357\nBatch80: loss = 5.8918\nBatch81: loss = 5.7488\nBatch82: loss = 5.7474\nBatch83: loss = 5.7564\nBatch84: loss = 5.9015\nBatch85: loss = 6.1223\nBatch86: loss = 5.5290\nBatch87: loss = 5.8812\nBatch88: loss = 6.0154\nBatch89: loss = 5.7213\nBatch90: loss = 5.9637\nBatch91: loss = 5.7535\nBatch92: loss = 5.5414\nBatch93: loss = 5.9357\nBatch94: loss = 5.4903\nBatch95: loss = 5.8936\nBatch96: loss = 6.0066\nBatch97: loss = 6.1389\nBatch98: loss = 5.9359\nBatch99: loss = 5.8712\nBatch100: loss = 5.6141\nBatch101: loss = 5.7906\nBatch102: loss = 6.1264\nBatch103: loss = 5.8891\nBatch104: loss = 6.0459\nBatch105: loss = 5.7155\nBatch106: loss = 5.9032\nBatch107: loss = 5.7446\nBatch108: loss = 5.5942\nBatch109: loss = 5.8876\nBatch110: loss = 5.7923\nBatch111: loss = 5.8639\nBatch112: loss = 5.7982\nBatch113: loss = 5.9866\nBatch114: loss = 6.2097\nBatch115: loss = 6.0005\nBatch116: loss = 5.8119\nBatch117: loss = 5.6588\nBatch118: loss = 5.9952\nBatch119: loss = 5.8237\nBatch120: loss = 6.2112\nBatch121: loss = 6.0507\nBatch122: loss = 5.8680\nBatch123: loss = 5.7513\nBatch124: loss = 6.1968\nBatch125: loss = 5.8015\nBatch126: loss = 6.0423\nBatch127: loss = 5.7772\nBatch128: loss = 5.7794\nBatch129: loss = 6.0784\nBatch130: loss = 5.8336\nBatch131: loss = 5.8223\nBatch132: loss = 5.8721\nBatch133: loss = 5.9016\nBatch134: loss = 5.7718\nBatch135: loss = 6.1063\nBatch136: loss = 6.1037\nBatch137: loss = 5.6993\nBatch138: loss = 6.1244\nBatch139: loss = 5.8863\nBatch140: loss = 5.7933\nBatch141: loss = 5.4529\nBatch142: loss = 5.7635\nBatch143: loss = 5.6261\nBatch144: loss = 5.8440\nBatch145: loss = 6.0242\nBatch146: loss = 5.9647\nBatch147: loss = 5.5636\nBatch148: loss = 6.1532\nBatch149: loss = 5.5127\nBatch150: loss = 5.7048\nBatch151: loss = 5.7688\nBatch152: loss = 5.6671\nBatch153: loss = 6.0326\nBatch154: loss = 5.7600\nBatch155: loss = 5.8571\nBatch156: loss = 5.5628\nBatch157: loss = 5.7500\nBatch158: loss = 5.8797\nBatch159: loss = 5.7317\nBatch160: loss = 5.7946\nBatch161: loss = 5.6696\nBatch162: loss = 5.6644\nBatch163: loss = 5.9352\nBatch164: loss = 5.6645\nBatch165: loss = 5.7832\nBatch166: loss = 5.5769\nBatch167: loss = 5.4709\nBatch168: loss = 6.0875\nBatch169: loss = 6.0060\nBatch170: loss = 6.0653\nBatch171: loss = 5.4225\nBatch172: loss = 5.5871\nBatch173: loss = 5.7708\nBatch174: loss = 6.0141\nBatch175: loss = 6.2448\nBatch176: loss = 5.8969\nBatch177: loss = 5.7322\nBatch178: loss = 6.2100\nBatch179: loss = 5.4707\nBatch180: loss = 6.0402\nBatch181: loss = 5.6321\nBatch182: loss = 5.9953\nBatch183: loss = 5.8523\nBatch184: loss = 5.8337\nBatch185: loss = 5.8373\nBatch186: loss = 5.6428\nBatch187: loss = 6.0970\nBatch188: loss = 5.3849\nBatch189: loss = 6.1291\nBatch190: loss = 6.0816\nBatch191: loss = 5.9547\nBatch192: loss = 5.5873\nBatch193: loss = 5.7576\nBatch194: loss = 6.1705\nBatch195: loss = 5.9159\nBatch196: loss = 5.6945\nBatch197: loss = 5.6599\nBatch198: loss = 5.5226\nBatch199: loss = 5.7289\nBatch0: loss = 5.9908\nBatch1: loss = 6.1706\nBatch2: loss = 5.8465\nBatch3: loss = 6.2757\nBatch4: loss = 5.9860\nBatch5: loss = 5.7654\nBatch6: loss = 5.6033\nBatch7: loss = 5.5672\nBatch8: loss = 5.8623\nBatch9: loss = 5.6791\nBatch10: loss = 5.7329\nBatch11: loss = 6.2758\nBatch12: loss = 6.0506\nBatch13: loss = 6.2096\nBatch14: loss = 5.7197\nBatch15: loss = 5.9108\nBatch16: loss = 6.0078\nBatch17: loss = 5.8542\nBatch18: loss = 6.3095\nBatch19: loss = 5.9475\nBatch20: loss = 6.0771\nBatch21: loss = 5.8725\nBatch22: loss = 6.0008\nBatch23: loss = 5.8986\nBatch24: loss = 6.0149\nBatch25: loss = 5.8438\nBatch26: loss = 6.0987\nBatch27: loss = 5.7851\nBatch28: loss = 5.9619\nBatch29: loss = 5.6230\nBatch30: loss = 5.9859\nBatch31: loss = 6.0973\nBatch32: loss = 6.1318\nBatch33: loss = 6.0236\nBatch34: loss = 6.0435\nBatch35: loss = 5.9823\nBatch36: loss = 6.3168\nBatch37: loss = 6.0430\nBatch38: loss = 5.9609\nBatch39: loss = 6.1901\nBatch40: loss = 6.1513\nBatch41: loss = 5.9765\nBatch42: loss = 6.1140\nBatch43: loss = 5.7575\nBatch44: loss = 5.9741\nBatch45: loss = 6.1247\nBatch46: loss = 5.8204\nBatch47: loss = 5.8258\nBatch48: loss = 5.9235\nBatch49: loss = 6.1723\nBatch50: loss = 6.0733\nBatch51: loss = 5.9913\nBatch52: loss = 6.0403\nBatch53: loss = 6.0688\nBatch54: loss = 5.8256\nBatch55: loss = 5.8869\nBatch56: loss = 5.7606\nBatch57: loss = 6.2490\nBatch58: loss = 5.8857\nBatch59: loss = 5.8336\nBatch60: loss = 5.7722\nBatch61: loss = 5.7310\nBatch62: loss = 6.0019\nBatch63: loss = 6.1358\nBatch64: loss = 5.8580\nBatch65: loss = 5.9158\nBatch66: loss = 5.8221\nBatch67: loss = 5.8458\nBatch68: loss = 5.9177\nBatch69: loss = 5.9846\nBatch70: loss = 5.8001\nBatch71: loss = 5.9055\nBatch72: loss = 5.8189\nBatch73: loss = 6.2036\nBatch74: loss = 6.2442\nBatch75: loss = 5.8448\nBatch76: loss = 6.2839\nBatch77: loss = 5.4691\nBatch78: loss = 6.1196\nBatch79: loss = 6.2362\nBatch80: loss = 6.2855\nBatch81: loss = 6.1342\nBatch82: loss = 6.5423\nBatch83: loss = 5.8342\nBatch84: loss = 5.9347\nBatch85: loss = 5.7582\nBatch86: loss = 6.1494\nBatch87: loss = 5.9797\nBatch88: loss = 6.0241\nBatch89: loss = 6.1838\nBatch90: loss = 5.6928\nBatch91: loss = 5.7097\nBatch92: loss = 6.2684\nBatch93: loss = 6.1323\nBatch94: loss = 6.3762\nBatch95: loss = 5.8595\nBatch96: loss = 6.0624\nBatch97: loss = 6.0660\nBatch98: loss = 6.0515\nBatch99: loss = 5.8215\nBatch100: loss = 6.0733\nBatch101: loss = 6.1428\nBatch102: loss = 6.1166\nBatch103: loss = 6.0700\nBatch104: loss = 6.1691\nBatch105: loss = 6.0520\nBatch106: loss = 6.0526\nBatch107: loss = 6.1605\nBatch108: loss = 5.7983\nBatch109: loss = 5.9288\nBatch110: loss = 6.1074\nBatch111: loss = 6.0582\nBatch112: loss = 6.4308\nBatch113: loss = 5.9652\nBatch114: loss = 6.0403\nBatch115: loss = 5.7588\nBatch116: loss = 5.8611\nBatch117: loss = 5.8724\nBatch118: loss = 6.2147\nBatch119: loss = 5.9850\nBatch120: loss = 6.1294\nBatch121: loss = 5.7172\nBatch122: loss = 5.9750\nBatch123: loss = 5.6799\nBatch124: loss = 5.7864\nBatch125: loss = 5.8312\nBatch126: loss = 5.6869\nBatch127: loss = 5.7491\nBatch128: loss = 6.0474\nBatch129: loss = 6.2497\nBatch130: loss = 5.7576\nBatch131: loss = 5.8422\nBatch132: loss = 6.2626\nBatch133: loss = 5.9106\nBatch134: loss = 5.6649\nBatch135: loss = 5.6984\nBatch136: loss = 6.1746\nBatch137: loss = 5.7995\nBatch138: loss = 5.8699\nBatch139: loss = 5.8143\nBatch140: loss = 6.0001\nBatch141: loss = 6.1033\nBatch142: loss = 6.0142\nBatch143: loss = 6.1393\nBatch144: loss = 5.3071\nBatch145: loss = 6.1694\nBatch146: loss = 5.6558\nBatch147: loss = 5.8898\nBatch148: loss = 6.0170\nBatch149: loss = 6.3472\nBatch150: loss = 6.2409\nBatch151: loss = 5.9592\nBatch152: loss = 5.8946\nBatch153: loss = 6.0592\nBatch154: loss = 6.2087\nBatch155: loss = 6.3465\nBatch156: loss = 6.1458\nBatch157: loss = 5.9142\nBatch158: loss = 5.8865\nBatch159: loss = 5.7538\nBatch160: loss = 6.0196\nBatch161: loss = 6.2342\nBatch162: loss = 6.2072\nBatch163: loss = 6.1568\nBatch164: loss = 5.8645\nBatch165: loss = 5.9148\nBatch166: loss = 5.9622\nBatch167: loss = 6.1506\nBatch168: loss = 6.1006\nBatch169: loss = 5.7579\nBatch170: loss = 6.4241\nBatch171: loss = 5.9244\nBatch172: loss = 6.2916\nBatch173: loss = 6.2689\nBatch174: loss = 6.3720\nBatch175: loss = 5.8836\nBatch176: loss = 5.5966\nBatch177: loss = 5.9044\nBatch178: loss = 6.0272\nBatch179: loss = 5.9554\nBatch180: loss = 5.9005\nBatch181: loss = 5.9547\nBatch182: loss = 6.2825\nBatch183: loss = 6.2068\nBatch184: loss = 6.0878\nBatch185: loss = 6.0720\nBatch186: loss = 5.8968\nBatch187: loss = 6.0819\nBatch188: loss = 5.8458\nBatch189: loss = 5.8720\nBatch190: loss = 6.0577\nBatch191: loss = 6.1894\nBatch192: loss = 6.4736\nBatch193: loss = 5.9568\nBatch194: loss = 6.4029\nBatch195: loss = 5.7117\nBatch196: loss = 6.0432\nBatch197: loss = 5.6031\nBatch198: loss = 5.8624\nBatch199: loss = 5.8616\nstep 1500: train loss 5.8414, val loss 5.9894\nBatch0: loss = 5.6723\nBatch1: loss = 6.0682\nBatch2: loss = 5.4895\nBatch3: loss = 5.5076\nBatch4: loss = 5.3968\nBatch5: loss = 5.5354\nBatch6: loss = 5.4423\nBatch7: loss = 5.9042\nBatch8: loss = 5.8779\nBatch9: loss = 5.8004\nBatch10: loss = 5.6687\nBatch11: loss = 5.6307\nBatch12: loss = 5.6005\nBatch13: loss = 5.8703\nBatch14: loss = 5.2328\nBatch15: loss = 5.7313\nBatch16: loss = 5.6072\nBatch17: loss = 5.6976\nBatch18: loss = 5.5236\nBatch19: loss = 5.1193\nBatch20: loss = 5.6350\nBatch21: loss = 6.0684\nBatch22: loss = 5.2589\nBatch23: loss = 5.8883\nBatch24: loss = 5.4228\nBatch25: loss = 5.8394\nBatch26: loss = 5.1519\nBatch27: loss = 5.7844\nBatch28: loss = 5.5195\nBatch29: loss = 5.1092\nBatch30: loss = 5.8164\nBatch31: loss = 5.4613\nBatch32: loss = 5.7519\nBatch33: loss = 5.5667\nBatch34: loss = 5.7944\nBatch35: loss = 5.4852\nBatch36: loss = 5.3359\nBatch37: loss = 5.7433\nBatch38: loss = 5.4332\nBatch39: loss = 5.5873\nBatch40: loss = 5.5762\nBatch41: loss = 5.1329\nBatch42: loss = 5.5825\nBatch43: loss = 5.6447\nBatch44: loss = 5.9415\nBatch45: loss = 5.5955\nBatch46: loss = 5.6250\nBatch47: loss = 5.7262\nBatch48: loss = 5.6358\nBatch49: loss = 5.3699\nBatch50: loss = 5.7153\nBatch51: loss = 5.7603\nBatch52: loss = 5.8362\nBatch53: loss = 5.7464\nBatch54: loss = 5.8888\nBatch55: loss = 5.9200\nBatch56: loss = 5.1767\nBatch57: loss = 5.2156\nBatch58: loss = 5.4850\nBatch59: loss = 5.6142\nBatch60: loss = 5.5473\nBatch61: loss = 5.5281\nBatch62: loss = 6.0341\nBatch63: loss = 5.4069\nBatch64: loss = 5.3229\nBatch65: loss = 5.7670\nBatch66: loss = 5.7120\nBatch67: loss = 5.5540\nBatch68: loss = 5.7631\nBatch69: loss = 5.2520\nBatch70: loss = 5.8826\nBatch71: loss = 5.5204\nBatch72: loss = 5.5233\nBatch73: loss = 5.5490\nBatch74: loss = 5.8751\nBatch75: loss = 5.3102\nBatch76: loss = 5.5061\nBatch77: loss = 5.8611\nBatch78: loss = 5.4253\nBatch79: loss = 5.7015\nBatch80: loss = 5.2733\nBatch81: loss = 5.5213\nBatch82: loss = 5.4889\nBatch83: loss = 5.6789\nBatch84: loss = 5.7910\nBatch85: loss = 5.7641\nBatch86: loss = 5.5495\nBatch87: loss = 5.5224\nBatch88: loss = 5.6812\nBatch89: loss = 5.5215\nBatch90: loss = 5.5490\nBatch91: loss = 5.6132\nBatch92: loss = 5.7416\nBatch93: loss = 5.6540\nBatch94: loss = 5.6675\nBatch95: loss = 5.6115\nBatch96: loss = 5.4492\nBatch97: loss = 5.7243\nBatch98: loss = 5.6102\nBatch99: loss = 5.2720\nBatch100: loss = 5.6436\nBatch101: loss = 5.5887\nBatch102: loss = 5.3405\nBatch103: loss = 5.2560\nBatch104: loss = 5.3750\nBatch105: loss = 5.5764\nBatch106: loss = 5.4210\nBatch107: loss = 5.7199\nBatch108: loss = 5.2815\nBatch109: loss = 5.5216\nBatch110: loss = 5.2266\nBatch111: loss = 5.4374\nBatch112: loss = 6.0535\nBatch113: loss = 5.6954\nBatch114: loss = 5.5067\nBatch115: loss = 6.0307\nBatch116: loss = 5.3776\nBatch117: loss = 5.5299\nBatch118: loss = 5.5388\nBatch119: loss = 5.5513\nBatch120: loss = 5.8095\nBatch121: loss = 5.8419\nBatch122: loss = 5.6030\nBatch123: loss = 5.5389\nBatch124: loss = 5.4356\nBatch125: loss = 5.6373\nBatch126: loss = 5.7794\nBatch127: loss = 5.5282\nBatch128: loss = 5.6810\nBatch129: loss = 5.2343\nBatch130: loss = 5.4101\nBatch131: loss = 5.8183\nBatch132: loss = 5.9265\nBatch133: loss = 5.3684\nBatch134: loss = 5.5326\nBatch135: loss = 5.1810\nBatch136: loss = 5.6402\nBatch137: loss = 5.3565\nBatch138: loss = 5.1576\nBatch139: loss = 5.5870\nBatch140: loss = 5.6029\nBatch141: loss = 6.1499\nBatch142: loss = 5.7816\nBatch143: loss = 5.5887\nBatch144: loss = 5.4795\nBatch145: loss = 5.6092\nBatch146: loss = 5.5742\nBatch147: loss = 5.8020\nBatch148: loss = 5.3958\nBatch149: loss = 5.8344\nBatch150: loss = 6.1666\nBatch151: loss = 5.4501\nBatch152: loss = 5.6558\nBatch153: loss = 5.7004\nBatch154: loss = 5.0084\nBatch155: loss = 5.8387\nBatch156: loss = 5.8181\nBatch157: loss = 5.6252\nBatch158: loss = 5.4326\nBatch159: loss = 5.5511\nBatch160: loss = 5.6090\nBatch161: loss = 5.6925\nBatch162: loss = 5.7416\nBatch163: loss = 5.6848\nBatch164: loss = 5.3869\nBatch165: loss = 5.8466\nBatch166: loss = 5.5647\nBatch167: loss = 5.7925\nBatch168: loss = 5.5572\nBatch169: loss = 5.8774\nBatch170: loss = 5.4165\nBatch171: loss = 5.6048\nBatch172: loss = 5.6368\nBatch173: loss = 5.6180\nBatch174: loss = 5.7471\nBatch175: loss = 5.9130\nBatch176: loss = 5.3564\nBatch177: loss = 5.5105\nBatch178: loss = 5.6214\nBatch179: loss = 5.4297\nBatch180: loss = 5.5874\nBatch181: loss = 5.2408\nBatch182: loss = 5.7459\nBatch183: loss = 5.4817\nBatch184: loss = 5.6442\nBatch185: loss = 5.6111\nBatch186: loss = 5.5807\nBatch187: loss = 5.5217\nBatch188: loss = 5.6792\nBatch189: loss = 5.8620\nBatch190: loss = 5.5081\nBatch191: loss = 5.3871\nBatch192: loss = 5.2228\nBatch193: loss = 5.5328\nBatch194: loss = 5.4239\nBatch195: loss = 5.6612\nBatch196: loss = 5.5398\nBatch197: loss = 5.5615\nBatch198: loss = 5.5660\nBatch199: loss = 5.4686\nBatch0: loss = 5.6216\nBatch1: loss = 5.8120\nBatch2: loss = 5.7934\nBatch3: loss = 5.5272\nBatch4: loss = 5.6283\nBatch5: loss = 5.6212\nBatch6: loss = 5.3166\nBatch7: loss = 5.8793\nBatch8: loss = 5.8549\nBatch9: loss = 5.9311\nBatch10: loss = 5.5085\nBatch11: loss = 5.8604\nBatch12: loss = 5.5697\nBatch13: loss = 5.7909\nBatch14: loss = 5.6438\nBatch15: loss = 5.6243\nBatch16: loss = 5.2866\nBatch17: loss = 6.2079\nBatch18: loss = 5.3642\nBatch19: loss = 5.8829\nBatch20: loss = 5.6865\nBatch21: loss = 5.6685\nBatch22: loss = 6.1336\nBatch23: loss = 6.0957\nBatch24: loss = 6.0428\nBatch25: loss = 5.5563\nBatch26: loss = 6.0038\nBatch27: loss = 6.0540\nBatch28: loss = 5.8374\nBatch29: loss = 5.5227\nBatch30: loss = 5.9908\nBatch31: loss = 6.0784\nBatch32: loss = 5.5638\nBatch33: loss = 5.7656\nBatch34: loss = 6.1712\nBatch35: loss = 6.0450\nBatch36: loss = 5.5828\nBatch37: loss = 6.0657\nBatch38: loss = 5.8313\nBatch39: loss = 6.1026\nBatch40: loss = 5.3374\nBatch41: loss = 5.7845\nBatch42: loss = 5.9067\nBatch43: loss = 5.3797\nBatch44: loss = 5.5745\nBatch45: loss = 5.8662\nBatch46: loss = 5.3795\nBatch47: loss = 5.7748\nBatch48: loss = 5.8483\nBatch49: loss = 5.4509\nBatch50: loss = 5.8124\nBatch51: loss = 6.2187\nBatch52: loss = 6.0138\nBatch53: loss = 5.3641\nBatch54: loss = 5.7129\nBatch55: loss = 6.1269\nBatch56: loss = 5.6113\nBatch57: loss = 5.7617\nBatch58: loss = 5.4588\nBatch59: loss = 5.8082\nBatch60: loss = 5.4954\nBatch61: loss = 5.7492\nBatch62: loss = 5.6645\nBatch63: loss = 5.4809\nBatch64: loss = 5.2889\nBatch65: loss = 6.5533\nBatch66: loss = 6.0207\nBatch67: loss = 5.8438\nBatch68: loss = 5.8544\nBatch69: loss = 5.9637\nBatch70: loss = 5.6022\nBatch71: loss = 5.5723\nBatch72: loss = 5.9319\nBatch73: loss = 5.8234\nBatch74: loss = 5.8702\nBatch75: loss = 5.6333\nBatch76: loss = 5.3465\nBatch77: loss = 5.8919\nBatch78: loss = 5.5910\nBatch79: loss = 5.4224\nBatch80: loss = 5.2203\nBatch81: loss = 6.1315\nBatch82: loss = 5.9357\nBatch83: loss = 5.8623\nBatch84: loss = 6.0151\nBatch85: loss = 5.9828\nBatch86: loss = 5.9995\nBatch87: loss = 5.8160\nBatch88: loss = 5.7929\nBatch89: loss = 5.5045\nBatch90: loss = 5.8568\nBatch91: loss = 5.4610\nBatch92: loss = 5.6844\nBatch93: loss = 5.7247\nBatch94: loss = 5.5222\nBatch95: loss = 5.8066\nBatch96: loss = 6.0926\nBatch97: loss = 6.1166\nBatch98: loss = 5.5920\nBatch99: loss = 5.5040\nBatch100: loss = 5.9722\nBatch101: loss = 5.8397\nBatch102: loss = 6.0641\nBatch103: loss = 5.5563\nBatch104: loss = 5.9267\nBatch105: loss = 5.6388\nBatch106: loss = 5.9504\nBatch107: loss = 5.6120\nBatch108: loss = 5.5844\nBatch109: loss = 5.7611\nBatch110: loss = 5.7680\nBatch111: loss = 5.9151\nBatch112: loss = 5.6968\nBatch113: loss = 5.6281\nBatch114: loss = 5.9863\nBatch115: loss = 5.6988\nBatch116: loss = 5.8282\nBatch117: loss = 5.9293\nBatch118: loss = 5.6745\nBatch119: loss = 6.2411\nBatch120: loss = 5.7831\nBatch121: loss = 5.7256\nBatch122: loss = 5.8137\nBatch123: loss = 5.8375\nBatch124: loss = 5.4970\nBatch125: loss = 5.9575\nBatch126: loss = 5.7133\nBatch127: loss = 5.9865\nBatch128: loss = 5.7398\nBatch129: loss = 5.6725\nBatch130: loss = 5.9848\nBatch131: loss = 5.9312\nBatch132: loss = 5.4682\nBatch133: loss = 5.9190\nBatch134: loss = 6.3333\nBatch135: loss = 5.7608\nBatch136: loss = 5.5359\nBatch137: loss = 5.9698\nBatch138: loss = 6.0668\nBatch139: loss = 5.9772\nBatch140: loss = 5.5290\nBatch141: loss = 5.8835\nBatch142: loss = 5.8925\nBatch143: loss = 6.0053\nBatch144: loss = 5.6868\nBatch145: loss = 6.0404\nBatch146: loss = 5.6793\nBatch147: loss = 5.7403\nBatch148: loss = 5.9441\nBatch149: loss = 5.5175\nBatch150: loss = 5.5596\nBatch151: loss = 5.3958\nBatch152: loss = 5.8248\nBatch153: loss = 5.8431\nBatch154: loss = 5.8108\nBatch155: loss = 5.5369\nBatch156: loss = 6.0891\nBatch157: loss = 5.8998\nBatch158: loss = 5.9975\nBatch159: loss = 5.7608\nBatch160: loss = 5.7318\nBatch161: loss = 6.1698\nBatch162: loss = 5.6155\nBatch163: loss = 5.8638\nBatch164: loss = 5.5274\nBatch165: loss = 5.4799\nBatch166: loss = 5.7987\nBatch167: loss = 5.8212\nBatch168: loss = 5.7343\nBatch169: loss = 5.5488\nBatch170: loss = 5.9324\nBatch171: loss = 6.0547\nBatch172: loss = 5.7223\nBatch173: loss = 5.5876\nBatch174: loss = 6.1657\nBatch175: loss = 5.8395\nBatch176: loss = 5.3859\nBatch177: loss = 5.5430\nBatch178: loss = 5.3949\nBatch179: loss = 5.8072\nBatch180: loss = 5.7787\nBatch181: loss = 5.9164\nBatch182: loss = 5.7366\nBatch183: loss = 6.0047\nBatch184: loss = 5.4469\nBatch185: loss = 5.5314\nBatch186: loss = 6.0281\nBatch187: loss = 5.7159\nBatch188: loss = 5.9410\nBatch189: loss = 5.6048\nBatch190: loss = 5.8488\nBatch191: loss = 5.6784\nBatch192: loss = 5.7588\nBatch193: loss = 5.9998\nBatch194: loss = 5.7405\nBatch195: loss = 6.1525\nBatch196: loss = 5.4338\nBatch197: loss = 5.4298\nBatch198: loss = 5.6328\nBatch199: loss = 5.6110\nstep 2000: train loss 5.5909, val loss 5.7712\nBatch0: loss = 5.5378\nBatch1: loss = 5.7615\nBatch2: loss = 5.5667\nBatch3: loss = 5.3793\nBatch4: loss = 5.1278\nBatch5: loss = 5.6152\nBatch6: loss = 5.4738\nBatch7: loss = 5.5954\nBatch8: loss = 5.2643\nBatch9: loss = 5.5202\nBatch10: loss = 5.4905\nBatch11: loss = 5.2870\nBatch12: loss = 5.1440\nBatch13: loss = 5.6390\nBatch14: loss = 5.5137\nBatch15: loss = 5.5532\nBatch16: loss = 5.2744\nBatch17: loss = 5.3189\nBatch18: loss = 5.4557\nBatch19: loss = 5.4765\nBatch20: loss = 5.2150\nBatch21: loss = 5.4192\nBatch22: loss = 5.5591\nBatch23: loss = 5.3367\nBatch24: loss = 5.6082\nBatch25: loss = 5.2477\nBatch26: loss = 6.2621\nBatch27: loss = 5.4246\nBatch28: loss = 5.6115\nBatch29: loss = 5.4144\nBatch30: loss = 5.6309\nBatch31: loss = 5.5143\nBatch32: loss = 5.5893\nBatch33: loss = 5.4917\nBatch34: loss = 5.6174\nBatch35: loss = 5.5488\nBatch36: loss = 5.1071\nBatch37: loss = 5.4403\nBatch38: loss = 5.5300\nBatch39: loss = 5.5046\nBatch40: loss = 5.3603\nBatch41: loss = 5.2227\nBatch42: loss = 5.7626\nBatch43: loss = 5.6632\nBatch44: loss = 5.3046\nBatch45: loss = 4.7861\nBatch46: loss = 5.4241\nBatch47: loss = 5.5876\nBatch48: loss = 5.5056\nBatch49: loss = 5.3615\nBatch50: loss = 5.6269\nBatch51: loss = 5.2939\nBatch52: loss = 5.3593\nBatch53: loss = 5.7681\nBatch54: loss = 5.6067\nBatch55: loss = 5.1811\nBatch56: loss = 5.3174\nBatch57: loss = 5.3393\nBatch58: loss = 5.5612\nBatch59: loss = 5.4910\nBatch60: loss = 5.2758\nBatch61: loss = 5.6820\nBatch62: loss = 5.8549\nBatch63: loss = 5.4820\nBatch64: loss = 5.4807\nBatch65: loss = 5.7671\nBatch66: loss = 5.9652\nBatch67: loss = 5.4936\nBatch68: loss = 5.3573\nBatch69: loss = 5.2960\nBatch70: loss = 5.1859\nBatch71: loss = 5.0610\nBatch72: loss = 5.3546\nBatch73: loss = 5.2795\nBatch74: loss = 5.7089\nBatch75: loss = 5.6236\nBatch76: loss = 5.5475\nBatch77: loss = 5.2401\nBatch78: loss = 5.3784\nBatch79: loss = 5.9430\nBatch80: loss = 5.6376\nBatch81: loss = 5.2557\nBatch82: loss = 5.4912\nBatch83: loss = 5.6729\nBatch84: loss = 5.1886\nBatch85: loss = 5.3632\nBatch86: loss = 5.5661\nBatch87: loss = 5.4639\nBatch88: loss = 5.3895\nBatch89: loss = 5.4986\nBatch90: loss = 5.4475\nBatch91: loss = 5.2740\nBatch92: loss = 5.3339\nBatch93: loss = 5.4570\nBatch94: loss = 6.1338\nBatch95: loss = 5.2992\nBatch96: loss = 4.9601\nBatch97: loss = 5.7554\nBatch98: loss = 5.5053\nBatch99: loss = 5.5095\nBatch100: loss = 5.6922\nBatch101: loss = 5.2955\nBatch102: loss = 5.6911\nBatch103: loss = 5.6522\nBatch104: loss = 5.6261\nBatch105: loss = 5.6099\nBatch106: loss = 5.4962\nBatch107: loss = 5.7920\nBatch108: loss = 5.3794\nBatch109: loss = 5.5372\nBatch110: loss = 5.3414\nBatch111: loss = 4.8535\nBatch112: loss = 5.3124\nBatch113: loss = 5.3265\nBatch114: loss = 5.4476\nBatch115: loss = 5.7434\nBatch116: loss = 5.2527\nBatch117: loss = 5.2235\nBatch118: loss = 5.3906\nBatch119: loss = 5.5486\nBatch120: loss = 5.4580\nBatch121: loss = 5.2703\nBatch122: loss = 5.2035\nBatch123: loss = 5.9028\nBatch124: loss = 5.4800\nBatch125: loss = 5.7685\nBatch126: loss = 5.3116\nBatch127: loss = 5.2071\nBatch128: loss = 5.9670\nBatch129: loss = 5.2398\nBatch130: loss = 5.4784\nBatch131: loss = 5.2511\nBatch132: loss = 5.5375\nBatch133: loss = 5.1991\nBatch134: loss = 5.0412\nBatch135: loss = 5.3504\nBatch136: loss = 5.1538\nBatch137: loss = 5.1450\nBatch138: loss = 5.3572\nBatch139: loss = 5.3090\nBatch140: loss = 5.3015\nBatch141: loss = 5.3648\nBatch142: loss = 5.1927\nBatch143: loss = 5.6003\nBatch144: loss = 5.3932\nBatch145: loss = 5.2252\nBatch146: loss = 5.0784\nBatch147: loss = 5.6597\nBatch148: loss = 5.6275\nBatch149: loss = 5.4616\nBatch150: loss = 5.4592\nBatch151: loss = 5.2736\nBatch152: loss = 5.5873\nBatch153: loss = 5.9876\nBatch154: loss = 5.3074\nBatch155: loss = 5.4801\nBatch156: loss = 5.6269\nBatch157: loss = 5.1640\nBatch158: loss = 5.9285\nBatch159: loss = 5.2962\nBatch160: loss = 5.4331\nBatch161: loss = 5.4238\nBatch162: loss = 5.6564\nBatch163: loss = 5.0619\nBatch164: loss = 5.1391\nBatch165: loss = 5.2072\nBatch166: loss = 5.6264\nBatch167: loss = 4.8891\nBatch168: loss = 5.5238\nBatch169: loss = 5.5868\nBatch170: loss = 5.4847\nBatch171: loss = 5.2640\nBatch172: loss = 5.4613\nBatch173: loss = 5.4540\nBatch174: loss = 5.3971\nBatch175: loss = 5.2503\nBatch176: loss = 5.3470\nBatch177: loss = 5.2825\nBatch178: loss = 5.2631\nBatch179: loss = 5.7368\nBatch180: loss = 5.5708\nBatch181: loss = 5.5579\nBatch182: loss = 5.6051\nBatch183: loss = 5.2669\nBatch184: loss = 5.4060\nBatch185: loss = 5.5329\nBatch186: loss = 5.4019\nBatch187: loss = 5.6880\nBatch188: loss = 5.5556\nBatch189: loss = 5.5874\nBatch190: loss = 5.7653\nBatch191: loss = 5.6078\nBatch192: loss = 4.9968\nBatch193: loss = 5.4581\nBatch194: loss = 5.1937\nBatch195: loss = 5.1570\nBatch196: loss = 5.3532\nBatch197: loss = 5.6958\nBatch198: loss = 6.0415\nBatch199: loss = 5.2737\nBatch0: loss = 5.5400\nBatch1: loss = 5.7725\nBatch2: loss = 5.6458\nBatch3: loss = 5.6593\nBatch4: loss = 5.1131\nBatch5: loss = 5.7087\nBatch6: loss = 5.3596\nBatch7: loss = 5.7133\nBatch8: loss = 5.8125\nBatch9: loss = 5.7238\nBatch10: loss = 5.4985\nBatch11: loss = 5.5791\nBatch12: loss = 5.8080\nBatch13: loss = 5.5927\nBatch14: loss = 5.4709\nBatch15: loss = 6.0015\nBatch16: loss = 5.5146\nBatch17: loss = 5.6309\nBatch18: loss = 5.6015\nBatch19: loss = 5.8201\nBatch20: loss = 5.8933\nBatch21: loss = 5.5289\nBatch22: loss = 5.5325\nBatch23: loss = 5.8360\nBatch24: loss = 5.7739\nBatch25: loss = 5.7961\nBatch26: loss = 5.4950\nBatch27: loss = 5.6739\nBatch28: loss = 5.7683\nBatch29: loss = 5.9596\nBatch30: loss = 5.7196\nBatch31: loss = 5.4682\nBatch32: loss = 5.4379\nBatch33: loss = 5.2602\nBatch34: loss = 5.4029\nBatch35: loss = 5.8114\nBatch36: loss = 5.4395\nBatch37: loss = 5.5936\nBatch38: loss = 5.9625\nBatch39: loss = 5.2643\nBatch40: loss = 5.2659\nBatch41: loss = 5.9149\nBatch42: loss = 5.4370\nBatch43: loss = 5.5296\nBatch44: loss = 5.5334\nBatch45: loss = 5.5404\nBatch46: loss = 5.3660\nBatch47: loss = 5.4112\nBatch48: loss = 5.7784\nBatch49: loss = 5.7985\nBatch50: loss = 5.5664\nBatch51: loss = 5.4669\nBatch52: loss = 5.7991\nBatch53: loss = 6.1704\nBatch54: loss = 5.4454\nBatch55: loss = 5.6270\nBatch56: loss = 5.5773\nBatch57: loss = 5.8291\nBatch58: loss = 5.5613\nBatch59: loss = 5.6431\nBatch60: loss = 5.6223\nBatch61: loss = 5.4306\nBatch62: loss = 5.4419\nBatch63: loss = 5.6854\nBatch64: loss = 5.8530\nBatch65: loss = 5.7666\nBatch66: loss = 5.6553\nBatch67: loss = 5.5959\nBatch68: loss = 5.8955\nBatch69: loss = 5.6660\nBatch70: loss = 6.0228\nBatch71: loss = 6.0253\nBatch72: loss = 5.7809\nBatch73: loss = 5.8684\nBatch74: loss = 6.0512\nBatch75: loss = 5.6144\nBatch76: loss = 5.5140\nBatch77: loss = 5.6907\nBatch78: loss = 5.6529\nBatch79: loss = 5.9505\nBatch80: loss = 5.6099\nBatch81: loss = 5.5997\nBatch82: loss = 5.7449\nBatch83: loss = 5.6571\nBatch84: loss = 5.4458\nBatch85: loss = 5.5794\nBatch86: loss = 5.9406\nBatch87: loss = 5.3418\nBatch88: loss = 5.7522\nBatch89: loss = 5.5399\nBatch90: loss = 5.4616\nBatch91: loss = 5.8553\nBatch92: loss = 5.3876\nBatch93: loss = 6.3096\nBatch94: loss = 5.6184\nBatch95: loss = 6.0364\nBatch96: loss = 5.7519\nBatch97: loss = 5.2544\nBatch98: loss = 5.4056\nBatch99: loss = 6.1004\nBatch100: loss = 5.5888\nBatch101: loss = 5.8324\nBatch102: loss = 5.4809\nBatch103: loss = 5.6215\nBatch104: loss = 5.6209\nBatch105: loss = 5.7183\nBatch106: loss = 5.7262\nBatch107: loss = 5.6431\nBatch108: loss = 5.7568\nBatch109: loss = 5.1870\nBatch110: loss = 5.9558\nBatch111: loss = 5.7476\nBatch112: loss = 5.7710\nBatch113: loss = 5.7936\nBatch114: loss = 5.5446\nBatch115: loss = 6.0335\nBatch116: loss = 5.7867\nBatch117: loss = 5.4278\nBatch118: loss = 5.7317\nBatch119: loss = 5.5314\nBatch120: loss = 5.5975\nBatch121: loss = 5.8290\nBatch122: loss = 5.8521\nBatch123: loss = 5.6452\nBatch124: loss = 5.1567\nBatch125: loss = 5.2418\nBatch126: loss = 5.3118\nBatch127: loss = 5.6108\nBatch128: loss = 5.4029\nBatch129: loss = 5.6227\nBatch130: loss = 5.6791\nBatch131: loss = 5.5224\nBatch132: loss = 5.5684\nBatch133: loss = 5.8206\nBatch134: loss = 5.7777\nBatch135: loss = 5.7617\nBatch136: loss = 5.7664\nBatch137: loss = 5.7433\nBatch138: loss = 5.6047\nBatch139: loss = 5.8254\nBatch140: loss = 5.2121\nBatch141: loss = 5.6475\nBatch142: loss = 6.0271\nBatch143: loss = 5.8428\nBatch144: loss = 5.2883\nBatch145: loss = 5.6327\nBatch146: loss = 5.9396\nBatch147: loss = 5.4829\nBatch148: loss = 5.5147\nBatch149: loss = 6.1027\nBatch150: loss = 5.5845\nBatch151: loss = 5.3330\nBatch152: loss = 5.4170\nBatch153: loss = 5.7224\nBatch154: loss = 5.9051\nBatch155: loss = 5.7584\nBatch156: loss = 5.6008\nBatch157: loss = 6.0418\nBatch158: loss = 6.1380\nBatch159: loss = 5.7553\nBatch160: loss = 5.6576\nBatch161: loss = 5.8755\nBatch162: loss = 5.6160\nBatch163: loss = 5.8089\nBatch164: loss = 5.7470\nBatch165: loss = 5.9763\nBatch166: loss = 5.6020\nBatch167: loss = 6.0008\nBatch168: loss = 6.3167\nBatch169: loss = 5.8169\nBatch170: loss = 5.8841\nBatch171: loss = 5.8564\nBatch172: loss = 5.6711\nBatch173: loss = 5.8719\nBatch174: loss = 5.6036\nBatch175: loss = 6.0195\nBatch176: loss = 5.5452\nBatch177: loss = 5.4311\nBatch178: loss = 5.5306\nBatch179: loss = 5.7976\nBatch180: loss = 5.8939\nBatch181: loss = 6.1158\nBatch182: loss = 5.7694\nBatch183: loss = 5.7530\nBatch184: loss = 5.7823\nBatch185: loss = 5.8333\nBatch186: loss = 5.5074\nBatch187: loss = 5.7520\nBatch188: loss = 5.7125\nBatch189: loss = 5.5843\nBatch190: loss = 5.7533\nBatch191: loss = 5.6122\nBatch192: loss = 5.8334\nBatch193: loss = 6.0414\nBatch194: loss = 5.8178\nBatch195: loss = 5.5471\nBatch196: loss = 5.6627\nBatch197: loss = 5.3728\nBatch198: loss = 5.7072\nBatch199: loss = 5.8290\nstep 2500: train loss 5.4492, val loss 5.6796\nBatch0: loss = 4.9999\nBatch1: loss = 4.7003\nBatch2: loss = 4.9997\nBatch3: loss = 5.6496\nBatch4: loss = 5.3175\nBatch5: loss = 5.5322\nBatch6: loss = 5.0740\nBatch7: loss = 5.5386\nBatch8: loss = 5.0486\nBatch9: loss = 5.8906\nBatch10: loss = 5.2265\nBatch11: loss = 5.2888\nBatch12: loss = 5.6377\nBatch13: loss = 5.4922\nBatch14: loss = 5.3202\nBatch15: loss = 5.1522\nBatch16: loss = 5.7263\nBatch17: loss = 5.5508\nBatch18: loss = 5.3318\nBatch19: loss = 5.4464\nBatch20: loss = 5.2737\nBatch21: loss = 5.4422\nBatch22: loss = 5.4067\nBatch23: loss = 5.2239\nBatch24: loss = 5.4083\nBatch25: loss = 5.8718\nBatch26: loss = 5.5553\nBatch27: loss = 5.5103\nBatch28: loss = 5.1574\nBatch29: loss = 5.5761\nBatch30: loss = 5.2813\nBatch31: loss = 5.7687\nBatch32: loss = 5.6185\nBatch33: loss = 5.0325\nBatch34: loss = 5.3087\nBatch35: loss = 5.5777\nBatch36: loss = 5.3107\nBatch37: loss = 5.2742\nBatch38: loss = 5.3428\nBatch39: loss = 5.6958\nBatch40: loss = 5.5656\nBatch41: loss = 5.1636\nBatch42: loss = 5.2660\nBatch43: loss = 5.0019\nBatch44: loss = 5.2333\nBatch45: loss = 5.0886\nBatch46: loss = 5.2915\nBatch47: loss = 5.2585\nBatch48: loss = 5.3306\nBatch49: loss = 5.5631\nBatch50: loss = 5.6603\nBatch51: loss = 5.2806\nBatch52: loss = 5.5504\nBatch53: loss = 5.6722\nBatch54: loss = 5.2532\nBatch55: loss = 5.4668\nBatch56: loss = 5.1653\nBatch57: loss = 5.6249\nBatch58: loss = 5.2438\nBatch59: loss = 5.2574\nBatch60: loss = 5.8090\nBatch61: loss = 5.0941\nBatch62: loss = 5.2922\nBatch63: loss = 5.3879\nBatch64: loss = 5.2631\nBatch65: loss = 5.5654\nBatch66: loss = 5.7266\nBatch67: loss = 5.0624\nBatch68: loss = 5.1452\nBatch69: loss = 5.2031\nBatch70: loss = 4.8225\nBatch71: loss = 5.4905\nBatch72: loss = 5.0125\nBatch73: loss = 5.5478\nBatch74: loss = 5.4863\nBatch75: loss = 5.5154\nBatch76: loss = 5.5102\nBatch77: loss = 5.2468\nBatch78: loss = 5.2972\nBatch79: loss = 5.4901\nBatch80: loss = 5.2986\nBatch81: loss = 5.6121\nBatch82: loss = 5.1080\nBatch83: loss = 5.5595\nBatch84: loss = 5.1910\nBatch85: loss = 5.9070\nBatch86: loss = 5.1041\nBatch87: loss = 5.5055\nBatch88: loss = 5.1842\nBatch89: loss = 5.5932\nBatch90: loss = 5.7376\nBatch91: loss = 5.4251\nBatch92: loss = 5.3654\nBatch93: loss = 5.2926\nBatch94: loss = 5.6623\nBatch95: loss = 5.1969\nBatch96: loss = 5.1779\nBatch97: loss = 5.2266\nBatch98: loss = 5.1590\nBatch99: loss = 5.3951\nBatch100: loss = 5.2191\nBatch101: loss = 5.2325\nBatch102: loss = 5.2800\nBatch103: loss = 5.6087\nBatch104: loss = 5.1648\nBatch105: loss = 5.1184\nBatch106: loss = 5.4839\nBatch107: loss = 5.5117\nBatch108: loss = 5.0313\nBatch109: loss = 5.2918\nBatch110: loss = 5.3489\nBatch111: loss = 4.7482\nBatch112: loss = 5.2926\nBatch113: loss = 5.3852\nBatch114: loss = 5.4426\nBatch115: loss = 5.7028\nBatch116: loss = 5.5387\nBatch117: loss = 5.2798\nBatch118: loss = 5.1983\nBatch119: loss = 5.7538\nBatch120: loss = 5.3834\nBatch121: loss = 5.5835\nBatch122: loss = 5.5397\nBatch123: loss = 5.3030\nBatch124: loss = 5.6328\nBatch125: loss = 5.6183\nBatch126: loss = 5.0222\nBatch127: loss = 5.1736\nBatch128: loss = 5.7127\nBatch129: loss = 5.3139\nBatch130: loss = 5.0926\nBatch131: loss = 4.9842\nBatch132: loss = 5.7441\nBatch133: loss = 5.9990\nBatch134: loss = 5.5443\nBatch135: loss = 5.4467\nBatch136: loss = 5.3974\nBatch137: loss = 5.4842\nBatch138: loss = 5.6434\nBatch139: loss = 5.1696\nBatch140: loss = 5.5960\nBatch141: loss = 5.3251\nBatch142: loss = 5.6907\nBatch143: loss = 5.4838\nBatch144: loss = 5.5688\nBatch145: loss = 5.2557\nBatch146: loss = 5.3111\nBatch147: loss = 5.4660\nBatch148: loss = 5.6773\nBatch149: loss = 5.6504\nBatch150: loss = 5.6527\nBatch151: loss = 4.9561\nBatch152: loss = 5.4457\nBatch153: loss = 5.0557\nBatch154: loss = 5.6424\nBatch155: loss = 5.6117\nBatch156: loss = 5.4033\nBatch157: loss = 5.5971\nBatch158: loss = 5.6256\nBatch159: loss = 5.1495\nBatch160: loss = 5.1280\nBatch161: loss = 5.4785\nBatch162: loss = 5.2041\nBatch163: loss = 5.7088\nBatch164: loss = 5.3161\nBatch165: loss = 5.5270\nBatch166: loss = 5.0849\nBatch167: loss = 5.3590\nBatch168: loss = 5.5183\nBatch169: loss = 5.3349\nBatch170: loss = 5.5727\nBatch171: loss = 5.2357\nBatch172: loss = 4.9986\nBatch173: loss = 5.3966\nBatch174: loss = 5.2322\nBatch175: loss = 5.5319\nBatch176: loss = 5.3710\nBatch177: loss = 5.6155\nBatch178: loss = 5.1812\nBatch179: loss = 5.3140\nBatch180: loss = 5.6088\nBatch181: loss = 5.8709\nBatch182: loss = 5.1411\nBatch183: loss = 5.1318\nBatch184: loss = 5.2610\nBatch185: loss = 5.5983\nBatch186: loss = 5.4692\nBatch187: loss = 5.5858\nBatch188: loss = 5.2886\nBatch189: loss = 5.1601\nBatch190: loss = 5.2941\nBatch191: loss = 5.4913\nBatch192: loss = 5.3916\nBatch193: loss = 5.3540\nBatch194: loss = 5.5447\nBatch195: loss = 5.2122\nBatch196: loss = 5.4720\nBatch197: loss = 5.3888\nBatch198: loss = 5.0760\nBatch199: loss = 5.5136\nBatch0: loss = 5.3939\nBatch1: loss = 5.4945\nBatch2: loss = 5.8594\nBatch3: loss = 5.4057\nBatch4: loss = 5.2581\nBatch5: loss = 5.4932\nBatch6: loss = 5.9212\nBatch7: loss = 5.6760\nBatch8: loss = 5.0273\nBatch9: loss = 5.4676\nBatch10: loss = 5.5985\nBatch11: loss = 6.0649\nBatch12: loss = 5.4004\nBatch13: loss = 5.3311\nBatch14: loss = 6.0312\nBatch15: loss = 5.8228\nBatch16: loss = 6.2058\nBatch17: loss = 5.3818\nBatch18: loss = 5.2878\nBatch19: loss = 5.5305\nBatch20: loss = 5.7865\nBatch21: loss = 5.6530\nBatch22: loss = 5.2419\nBatch23: loss = 5.5421\nBatch24: loss = 5.7658\nBatch25: loss = 5.8672\nBatch26: loss = 5.8509\nBatch27: loss = 5.5430\nBatch28: loss = 5.4474\nBatch29: loss = 5.8531\nBatch30: loss = 5.8603\nBatch31: loss = 5.1553\nBatch32: loss = 5.5506\nBatch33: loss = 5.4597\nBatch34: loss = 5.5626\nBatch35: loss = 5.7045\nBatch36: loss = 5.6359\nBatch37: loss = 5.5881\nBatch38: loss = 5.1416\nBatch39: loss = 5.4696\nBatch40: loss = 5.4881\nBatch41: loss = 5.4196\nBatch42: loss = 5.3678\nBatch43: loss = 5.8262\nBatch44: loss = 5.7261\nBatch45: loss = 5.6975\nBatch46: loss = 5.5527\nBatch47: loss = 5.8462\nBatch48: loss = 5.5607\nBatch49: loss = 5.4328\nBatch50: loss = 5.0143\nBatch51: loss = 5.2355\nBatch52: loss = 5.7366\nBatch53: loss = 5.4943\nBatch54: loss = 5.9266\nBatch55: loss = 5.9939\nBatch56: loss = 5.4788\nBatch57: loss = 5.9337\nBatch58: loss = 5.3795\nBatch59: loss = 5.4970\nBatch60: loss = 5.5840\nBatch61: loss = 5.8012\nBatch62: loss = 5.3481\nBatch63: loss = 4.9291\nBatch64: loss = 5.5018\nBatch65: loss = 5.8632\nBatch66: loss = 5.7815\nBatch67: loss = 5.4903\nBatch68: loss = 5.8214\nBatch69: loss = 5.2584\nBatch70: loss = 5.3089\nBatch71: loss = 5.5752\nBatch72: loss = 5.6872\nBatch73: loss = 5.3268\nBatch74: loss = 5.8202\nBatch75: loss = 5.2817\nBatch76: loss = 5.8364\nBatch77: loss = 5.1418\nBatch78: loss = 5.4794\nBatch79: loss = 5.7410\nBatch80: loss = 5.6885\nBatch81: loss = 5.8957\nBatch82: loss = 5.5956\nBatch83: loss = 5.3582\nBatch84: loss = 5.3155\nBatch85: loss = 5.3504\nBatch86: loss = 5.8967\nBatch87: loss = 5.6533\nBatch88: loss = 5.4610\nBatch89: loss = 5.6461\nBatch90: loss = 5.2511\nBatch91: loss = 5.5476\nBatch92: loss = 5.5697\nBatch93: loss = 5.7414\nBatch94: loss = 5.2466\nBatch95: loss = 6.0160\nBatch96: loss = 5.9451\nBatch97: loss = 5.1016\nBatch98: loss = 5.8902\nBatch99: loss = 5.4512\nBatch100: loss = 5.4110\nBatch101: loss = 5.4733\nBatch102: loss = 5.9680\nBatch103: loss = 5.0300\nBatch104: loss = 5.4916\nBatch105: loss = 5.6795\nBatch106: loss = 6.1220\nBatch107: loss = 4.9693\nBatch108: loss = 5.5041\nBatch109: loss = 5.4350\nBatch110: loss = 5.0882\nBatch111: loss = 5.2318\nBatch112: loss = 5.6002\nBatch113: loss = 5.5977\nBatch114: loss = 5.6901\nBatch115: loss = 5.2877\nBatch116: loss = 5.6822\nBatch117: loss = 5.2340\nBatch118: loss = 5.4185\nBatch119: loss = 5.6866\nBatch120: loss = 5.4153\nBatch121: loss = 5.4784\nBatch122: loss = 5.7035\nBatch123: loss = 5.9409\nBatch124: loss = 5.7253\nBatch125: loss = 6.0101\nBatch126: loss = 5.4686\nBatch127: loss = 5.4468\nBatch128: loss = 5.2179\nBatch129: loss = 5.6894\nBatch130: loss = 5.4922\nBatch131: loss = 5.6811\nBatch132: loss = 5.9428\nBatch133: loss = 5.5113\nBatch134: loss = 5.2916\nBatch135: loss = 5.3532\nBatch136: loss = 5.7282\nBatch137: loss = 5.6059\nBatch138: loss = 5.6124\nBatch139: loss = 5.7722\nBatch140: loss = 5.5720\nBatch141: loss = 5.6257\nBatch142: loss = 5.9263\nBatch143: loss = 5.3658\nBatch144: loss = 5.7682\nBatch145: loss = 5.1095\nBatch146: loss = 5.5961\nBatch147: loss = 5.5750\nBatch148: loss = 5.5338\nBatch149: loss = 5.4374\nBatch150: loss = 5.7184\nBatch151: loss = 5.8650\nBatch152: loss = 5.6058\nBatch153: loss = 5.8474\nBatch154: loss = 5.8303\nBatch155: loss = 5.5077\nBatch156: loss = 5.4377\nBatch157: loss = 5.5008\nBatch158: loss = 5.2996\nBatch159: loss = 5.7669\nBatch160: loss = 5.2881\nBatch161: loss = 5.9324\nBatch162: loss = 5.5393\nBatch163: loss = 5.1330\nBatch164: loss = 5.6064\nBatch165: loss = 5.7073\nBatch166: loss = 5.7543\nBatch167: loss = 5.6155\nBatch168: loss = 5.1434\nBatch169: loss = 5.5118\nBatch170: loss = 5.3024\nBatch171: loss = 5.8261\nBatch172: loss = 5.3827\nBatch173: loss = 5.7617\nBatch174: loss = 5.4560\nBatch175: loss = 5.4872\nBatch176: loss = 5.7712\nBatch177: loss = 5.9112\nBatch178: loss = 5.8441\nBatch179: loss = 5.1909\nBatch180: loss = 5.7766\nBatch181: loss = 5.4347\nBatch182: loss = 5.6742\nBatch183: loss = 5.6379\nBatch184: loss = 5.3775\nBatch185: loss = 5.4398\nBatch186: loss = 5.1433\nBatch187: loss = 5.7319\nBatch188: loss = 5.5244\nBatch189: loss = 6.1705\nBatch190: loss = 5.5859\nBatch191: loss = 5.9340\nBatch192: loss = 5.8666\nBatch193: loss = 5.4104\nBatch194: loss = 5.3576\nBatch195: loss = 5.6594\nBatch196: loss = 5.9722\nBatch197: loss = 5.6556\nBatch198: loss = 5.4222\nBatch199: loss = 5.4875\nstep 3000: train loss 5.3836, val loss 5.5707\nBatch0: loss = 5.1697\nBatch1: loss = 5.4300\nBatch2: loss = 5.6411\nBatch3: loss = 5.0806\nBatch4: loss = 5.3307\nBatch5: loss = 5.1086\nBatch6: loss = 5.3653\nBatch7: loss = 5.2654\nBatch8: loss = 5.0404\nBatch9: loss = 5.2779\nBatch10: loss = 4.8564\nBatch11: loss = 5.2827\nBatch12: loss = 5.3823\nBatch13: loss = 5.4785\nBatch14: loss = 5.2822\nBatch15: loss = 5.2582\nBatch16: loss = 5.3108\nBatch17: loss = 5.0769\nBatch18: loss = 5.1273\nBatch19: loss = 4.9940\nBatch20: loss = 5.6529\nBatch21: loss = 5.3129\nBatch22: loss = 5.4564\nBatch23: loss = 5.1570\nBatch24: loss = 5.7078\nBatch25: loss = 5.1153\nBatch26: loss = 5.2625\nBatch27: loss = 5.4396\nBatch28: loss = 5.0959\nBatch29: loss = 5.4146\nBatch30: loss = 5.4029\nBatch31: loss = 5.2574\nBatch32: loss = 5.1831\nBatch33: loss = 5.3216\nBatch34: loss = 4.7313\nBatch35: loss = 5.5484\nBatch36: loss = 5.1035\nBatch37: loss = 5.1910\nBatch38: loss = 5.4932\nBatch39: loss = 5.2632\nBatch40: loss = 5.2941\nBatch41: loss = 5.5459\nBatch42: loss = 5.3872\nBatch43: loss = 5.3811\nBatch44: loss = 5.1848\nBatch45: loss = 4.9738\nBatch46: loss = 5.0683\nBatch47: loss = 5.1155\nBatch48: loss = 5.1643\nBatch49: loss = 5.3603\nBatch50: loss = 5.1980\nBatch51: loss = 5.2122\nBatch52: loss = 5.0666\nBatch53: loss = 5.1552\nBatch54: loss = 5.0918\nBatch55: loss = 4.9885\nBatch56: loss = 5.4456\nBatch57: loss = 5.0075\nBatch58: loss = 5.2148\nBatch59: loss = 5.2978\nBatch60: loss = 5.4984\nBatch61: loss = 5.4356\nBatch62: loss = 5.0420\nBatch63: loss = 5.1621\nBatch64: loss = 5.2732\nBatch65: loss = 5.5901\nBatch66: loss = 5.3681\nBatch67: loss = 5.4625\nBatch68: loss = 5.5540\nBatch69: loss = 4.8723\nBatch70: loss = 4.9804\nBatch71: loss = 5.4372\nBatch72: loss = 5.6453\nBatch73: loss = 5.4997\nBatch74: loss = 5.0299\nBatch75: loss = 4.7615\nBatch76: loss = 5.4020\nBatch77: loss = 4.9353\nBatch78: loss = 5.0593\nBatch79: loss = 5.1904\nBatch80: loss = 4.9433\nBatch81: loss = 5.7158\nBatch82: loss = 5.1188\nBatch83: loss = 5.0222\nBatch84: loss = 5.4557\nBatch85: loss = 5.0548\nBatch86: loss = 5.3521\nBatch87: loss = 5.5596\nBatch88: loss = 5.1442\nBatch89: loss = 5.0739\nBatch90: loss = 4.8708\nBatch91: loss = 5.4660\nBatch92: loss = 5.4114\nBatch93: loss = 5.4289\nBatch94: loss = 5.1125\nBatch95: loss = 5.0451\nBatch96: loss = 5.5897\nBatch97: loss = 5.2488\nBatch98: loss = 5.2702\nBatch99: loss = 5.4883\nBatch100: loss = 4.8312\nBatch101: loss = 5.1957\nBatch102: loss = 5.2781\nBatch103: loss = 5.6450\nBatch104: loss = 5.3420\nBatch105: loss = 5.2485\nBatch106: loss = 5.0855\nBatch107: loss = 5.0339\nBatch108: loss = 5.0233\nBatch109: loss = 5.0831\nBatch110: loss = 5.8077\nBatch111: loss = 5.3267\nBatch112: loss = 5.1116\nBatch113: loss = 5.3135\nBatch114: loss = 5.5229\nBatch115: loss = 5.0517\nBatch116: loss = 5.3712\nBatch117: loss = 5.3949\nBatch118: loss = 5.6269\nBatch119: loss = 5.3891\nBatch120: loss = 5.6043\nBatch121: loss = 5.6046\nBatch122: loss = 5.2659\nBatch123: loss = 5.5289\nBatch124: loss = 5.2514\nBatch125: loss = 5.4433\nBatch126: loss = 5.3020\nBatch127: loss = 5.2078\nBatch128: loss = 5.4302\nBatch129: loss = 5.1223\nBatch130: loss = 5.3515\nBatch131: loss = 5.3835\nBatch132: loss = 5.2421\nBatch133: loss = 5.2389\nBatch134: loss = 5.1373\nBatch135: loss = 5.3091\nBatch136: loss = 5.1030\nBatch137: loss = 5.5561\nBatch138: loss = 5.3406\nBatch139: loss = 5.1656\nBatch140: loss = 5.3688\nBatch141: loss = 5.5528\nBatch142: loss = 5.3001\nBatch143: loss = 5.3291\nBatch144: loss = 5.6114\nBatch145: loss = 5.1564\nBatch146: loss = 5.5345\nBatch147: loss = 5.6395\nBatch148: loss = 5.1781\nBatch149: loss = 5.2776\nBatch150: loss = 5.4399\nBatch151: loss = 4.9573\nBatch152: loss = 5.4008\nBatch153: loss = 5.3258\nBatch154: loss = 5.0144\nBatch155: loss = 5.1999\nBatch156: loss = 5.5676\nBatch157: loss = 5.1264\nBatch158: loss = 5.6297\nBatch159: loss = 5.5214\nBatch160: loss = 5.3238\nBatch161: loss = 5.1543\nBatch162: loss = 5.6548\nBatch163: loss = 5.3271\nBatch164: loss = 5.3451\nBatch165: loss = 5.0014\nBatch166: loss = 5.2229\nBatch167: loss = 5.0806\nBatch168: loss = 5.4675\nBatch169: loss = 5.3974\nBatch170: loss = 4.8829\nBatch171: loss = 5.0997\nBatch172: loss = 5.6475\nBatch173: loss = 5.1391\nBatch174: loss = 5.3041\nBatch175: loss = 5.7691\nBatch176: loss = 5.3336\nBatch177: loss = 5.6057\nBatch178: loss = 5.4177\nBatch179: loss = 5.3830\nBatch180: loss = 5.6079\nBatch181: loss = 4.8916\nBatch182: loss = 5.0832\nBatch183: loss = 5.3881\nBatch184: loss = 5.6916\nBatch185: loss = 4.9484\nBatch186: loss = 5.2415\nBatch187: loss = 5.3449\nBatch188: loss = 4.8943\nBatch189: loss = 4.9448\nBatch190: loss = 5.4703\nBatch191: loss = 5.3081\nBatch192: loss = 5.5627\nBatch193: loss = 5.4704\nBatch194: loss = 5.3783\nBatch195: loss = 5.3939\nBatch196: loss = 5.0595\nBatch197: loss = 5.2401\nBatch198: loss = 5.0168\nBatch199: loss = 5.2825\nBatch0: loss = 5.1801\nBatch1: loss = 5.7663\nBatch2: loss = 5.4936\nBatch3: loss = 5.7663\nBatch4: loss = 5.0212\nBatch5: loss = 5.8688\nBatch6: loss = 5.5175\nBatch7: loss = 5.4868\nBatch8: loss = 5.7896\nBatch9: loss = 5.6782\nBatch10: loss = 5.5620\nBatch11: loss = 5.4325\nBatch12: loss = 5.6088\nBatch13: loss = 5.5019\nBatch14: loss = 5.3568\nBatch15: loss = 5.4764\nBatch16: loss = 5.2852\nBatch17: loss = 5.3979\nBatch18: loss = 5.5692\nBatch19: loss = 5.4829\nBatch20: loss = 5.0610\nBatch21: loss = 5.5250\nBatch22: loss = 5.3215\nBatch23: loss = 5.0741\nBatch24: loss = 5.3652\nBatch25: loss = 5.7456\nBatch26: loss = 5.3634\nBatch27: loss = 5.3098\nBatch28: loss = 5.8724\nBatch29: loss = 5.8755\nBatch30: loss = 5.2750\nBatch31: loss = 5.2099\nBatch32: loss = 5.4775\nBatch33: loss = 5.8543\nBatch34: loss = 5.3143\nBatch35: loss = 5.4611\nBatch36: loss = 5.7184\nBatch37: loss = 5.3794\nBatch38: loss = 5.3434\nBatch39: loss = 5.0950\nBatch40: loss = 5.2068\nBatch41: loss = 5.3799\nBatch42: loss = 5.3503\nBatch43: loss = 5.5401\nBatch44: loss = 5.4480\nBatch45: loss = 5.7082\nBatch46: loss = 5.2385\nBatch47: loss = 5.4553\nBatch48: loss = 5.3965\nBatch49: loss = 5.0762\nBatch50: loss = 5.7899\nBatch51: loss = 5.7165\nBatch52: loss = 5.4496\nBatch53: loss = 5.7682\nBatch54: loss = 5.6158\nBatch55: loss = 5.8413\nBatch56: loss = 5.4199\nBatch57: loss = 5.2320\nBatch58: loss = 5.0485\nBatch59: loss = 5.3060\nBatch60: loss = 5.6907\nBatch61: loss = 5.0699\nBatch62: loss = 5.6086\nBatch63: loss = 5.2199\nBatch64: loss = 5.8403\nBatch65: loss = 5.8583\nBatch66: loss = 5.6121\nBatch67: loss = 5.6602\nBatch68: loss = 5.5308\nBatch69: loss = 5.2124\nBatch70: loss = 5.6788\nBatch71: loss = 5.3196\nBatch72: loss = 5.5335\nBatch73: loss = 5.6018\nBatch74: loss = 5.7107\nBatch75: loss = 5.2909\nBatch76: loss = 5.5657\nBatch77: loss = 5.2606\nBatch78: loss = 5.4573\nBatch79: loss = 6.0339\nBatch80: loss = 5.2607\nBatch81: loss = 5.8603\nBatch82: loss = 5.3327\nBatch83: loss = 5.0836\nBatch84: loss = 5.2934\nBatch85: loss = 5.4195\nBatch86: loss = 5.5872\nBatch87: loss = 5.0901\nBatch88: loss = 5.7503\nBatch89: loss = 5.6042\nBatch90: loss = 5.5545\nBatch91: loss = 5.4592\nBatch92: loss = 5.5836\nBatch93: loss = 5.4379\nBatch94: loss = 5.5422\nBatch95: loss = 5.6179\nBatch96: loss = 5.6114\nBatch97: loss = 5.1242\nBatch98: loss = 5.8171\nBatch99: loss = 5.1684\nBatch100: loss = 5.4063\nBatch101: loss = 5.7882\nBatch102: loss = 5.2002\nBatch103: loss = 5.9347\nBatch104: loss = 5.5776\nBatch105: loss = 5.7313\nBatch106: loss = 5.4902\nBatch107: loss = 5.1621\nBatch108: loss = 5.6679\nBatch109: loss = 5.8577\nBatch110: loss = 5.4090\nBatch111: loss = 5.5941\nBatch112: loss = 5.4584\nBatch113: loss = 5.6575\nBatch114: loss = 5.3334\nBatch115: loss = 5.7356\nBatch116: loss = 5.1868\nBatch117: loss = 5.6671\nBatch118: loss = 5.5723\nBatch119: loss = 5.2749\nBatch120: loss = 5.4709\nBatch121: loss = 5.5177\nBatch122: loss = 5.5291\nBatch123: loss = 5.4380\nBatch124: loss = 5.4925\nBatch125: loss = 5.5850\nBatch126: loss = 5.3267\nBatch127: loss = 5.4342\nBatch128: loss = 5.4880\nBatch129: loss = 5.9300\nBatch130: loss = 5.4341\nBatch131: loss = 6.0162\nBatch132: loss = 5.6112\nBatch133: loss = 5.0384\nBatch134: loss = 5.2886\nBatch135: loss = 5.8823\nBatch136: loss = 5.6568\nBatch137: loss = 5.7417\nBatch138: loss = 5.2581\nBatch139: loss = 5.3434\nBatch140: loss = 5.4126\nBatch141: loss = 5.7325\nBatch142: loss = 5.2326\nBatch143: loss = 5.6981\nBatch144: loss = 5.5250\nBatch145: loss = 5.3911\nBatch146: loss = 5.3643\nBatch147: loss = 5.7432\nBatch148: loss = 5.5830\nBatch149: loss = 5.7113\nBatch150: loss = 5.1960\nBatch151: loss = 5.4896\nBatch152: loss = 5.1949\nBatch153: loss = 5.5791\nBatch154: loss = 5.3782\nBatch155: loss = 6.0459\nBatch156: loss = 5.1389\nBatch157: loss = 5.2143\nBatch158: loss = 5.5834\nBatch159: loss = 5.1800\nBatch160: loss = 5.7677\nBatch161: loss = 5.5579\nBatch162: loss = 5.2920\nBatch163: loss = 5.6842\nBatch164: loss = 5.2544\nBatch165: loss = 5.3621\nBatch166: loss = 5.7123\nBatch167: loss = 5.3045\nBatch168: loss = 5.6291\nBatch169: loss = 5.8594\nBatch170: loss = 5.3071\nBatch171: loss = 5.5999\nBatch172: loss = 5.4090\nBatch173: loss = 5.3241\nBatch174: loss = 5.5584\nBatch175: loss = 5.3429\nBatch176: loss = 5.7860\nBatch177: loss = 5.2367\nBatch178: loss = 5.3752\nBatch179: loss = 5.6323\nBatch180: loss = 5.5919\nBatch181: loss = 5.2069\nBatch182: loss = 5.3188\nBatch183: loss = 5.6675\nBatch184: loss = 5.4423\nBatch185: loss = 5.4776\nBatch186: loss = 5.1499\nBatch187: loss = 5.2665\nBatch188: loss = 5.3873\nBatch189: loss = 5.5569\nBatch190: loss = 5.5069\nBatch191: loss = 5.5718\nBatch192: loss = 5.4318\nBatch193: loss = 5.4834\nBatch194: loss = 5.1208\nBatch195: loss = 5.1963\nBatch196: loss = 5.1833\nBatch197: loss = 5.4603\nBatch198: loss = 5.9370\nBatch199: loss = 5.2047\nstep 3500: train loss 5.2839, val loss 5.4828\nBatch0: loss = 5.3036\nBatch1: loss = 5.2214\nBatch2: loss = 5.2837\nBatch3: loss = 5.2406\nBatch4: loss = 5.6247\nBatch5: loss = 5.0234\nBatch6: loss = 5.2633\nBatch7: loss = 5.2490\nBatch8: loss = 5.0886\nBatch9: loss = 5.0079\nBatch10: loss = 5.4624\nBatch11: loss = 5.2045\nBatch12: loss = 5.3179\nBatch13: loss = 5.2121\nBatch14: loss = 5.3734\nBatch15: loss = 5.3212\nBatch16: loss = 5.1141\nBatch17: loss = 4.9542\nBatch18: loss = 4.9299\nBatch19: loss = 4.9934\nBatch20: loss = 5.2684\nBatch21: loss = 5.1403\nBatch22: loss = 5.0825\nBatch23: loss = 5.1269\nBatch24: loss = 5.1698\nBatch25: loss = 5.1740\nBatch26: loss = 4.4968\nBatch27: loss = 5.4526\nBatch28: loss = 5.0521\nBatch29: loss = 5.1220\nBatch30: loss = 5.8398\nBatch31: loss = 4.9142\nBatch32: loss = 5.3503\nBatch33: loss = 4.7799\nBatch34: loss = 5.1171\nBatch35: loss = 5.4354\nBatch36: loss = 5.1135\nBatch37: loss = 4.9679\nBatch38: loss = 5.4667\nBatch39: loss = 5.3417\nBatch40: loss = 5.2522\nBatch41: loss = 5.1663\nBatch42: loss = 5.0231\nBatch43: loss = 5.2130\nBatch44: loss = 5.1593\nBatch45: loss = 5.1662\nBatch46: loss = 4.7510\nBatch47: loss = 5.0377\nBatch48: loss = 4.7999\nBatch49: loss = 5.0447\nBatch50: loss = 5.1641\nBatch51: loss = 5.2185\nBatch52: loss = 5.6209\nBatch53: loss = 5.2871\nBatch54: loss = 5.3693\nBatch55: loss = 5.5257\nBatch56: loss = 5.6391\nBatch57: loss = 5.2440\nBatch58: loss = 5.2407\nBatch59: loss = 4.9875\nBatch60: loss = 5.2948\nBatch61: loss = 5.1906\nBatch62: loss = 5.0997\nBatch63: loss = 5.1786\nBatch64: loss = 5.1898\nBatch65: loss = 4.9454\nBatch66: loss = 5.7212\nBatch67: loss = 5.4433\nBatch68: loss = 5.4851\nBatch69: loss = 5.5307\nBatch70: loss = 4.8546\nBatch71: loss = 5.0496\nBatch72: loss = 5.8757\nBatch73: loss = 5.6267\nBatch74: loss = 5.4784\nBatch75: loss = 5.3906\nBatch76: loss = 4.7354\nBatch77: loss = 5.1640\nBatch78: loss = 5.1634\nBatch79: loss = 5.1309\nBatch80: loss = 4.9330\nBatch81: loss = 5.0025\nBatch82: loss = 5.3260\nBatch83: loss = 5.2476\nBatch84: loss = 5.3672\nBatch85: loss = 5.2385\nBatch86: loss = 5.2727\nBatch87: loss = 5.3204\nBatch88: loss = 5.0281\nBatch89: loss = 4.8632\nBatch90: loss = 5.2956\nBatch91: loss = 5.4556\nBatch92: loss = 5.2793\nBatch93: loss = 5.1444\nBatch94: loss = 4.8860\nBatch95: loss = 5.4368\nBatch96: loss = 4.8995\nBatch97: loss = 5.3161\nBatch98: loss = 5.0487\nBatch99: loss = 5.1218\nBatch100: loss = 5.0387\nBatch101: loss = 5.1985\nBatch102: loss = 4.9868\nBatch103: loss = 5.2215\nBatch104: loss = 5.5163\nBatch105: loss = 5.3789\nBatch106: loss = 5.1769\nBatch107: loss = 5.5869\nBatch108: loss = 5.5086\nBatch109: loss = 5.3884\nBatch110: loss = 5.3923\nBatch111: loss = 4.9626\nBatch112: loss = 5.2051\nBatch113: loss = 5.1414\nBatch114: loss = 5.1736\nBatch115: loss = 5.7974\nBatch116: loss = 5.3164\nBatch117: loss = 5.2866\nBatch118: loss = 5.3714\nBatch119: loss = 5.2112\nBatch120: loss = 5.4091\nBatch121: loss = 5.1455\nBatch122: loss = 5.0703\nBatch123: loss = 5.2503\nBatch124: loss = 5.1628\nBatch125: loss = 5.4601\nBatch126: loss = 5.3259\nBatch127: loss = 5.0953\nBatch128: loss = 5.3195\nBatch129: loss = 5.1193\nBatch130: loss = 5.4946\nBatch131: loss = 5.0697\nBatch132: loss = 4.9911\nBatch133: loss = 4.9334\nBatch134: loss = 5.1875\nBatch135: loss = 5.1157\nBatch136: loss = 5.3222\nBatch137: loss = 5.4144\nBatch138: loss = 5.1096\nBatch139: loss = 5.3645\nBatch140: loss = 5.6106\nBatch141: loss = 5.2143\nBatch142: loss = 5.2342\nBatch143: loss = 5.4002\nBatch144: loss = 5.2187\nBatch145: loss = 5.5252\nBatch146: loss = 4.6244\nBatch147: loss = 5.4223\nBatch148: loss = 5.2128\nBatch149: loss = 5.5756\nBatch150: loss = 5.4531\nBatch151: loss = 4.9060\nBatch152: loss = 4.9998\nBatch153: loss = 5.2086\nBatch154: loss = 5.0044\nBatch155: loss = 4.8588\nBatch156: loss = 5.3406\nBatch157: loss = 4.9106\nBatch158: loss = 5.4004\nBatch159: loss = 5.3585\nBatch160: loss = 5.0601\nBatch161: loss = 6.0421\nBatch162: loss = 4.9589\nBatch163: loss = 4.9398\nBatch164: loss = 5.2413\nBatch165: loss = 4.8696\nBatch166: loss = 4.8185\nBatch167: loss = 4.7908\nBatch168: loss = 5.1298\nBatch169: loss = 4.8208\nBatch170: loss = 5.4079\nBatch171: loss = 4.7920\nBatch172: loss = 5.4741\nBatch173: loss = 5.4845\nBatch174: loss = 5.3554\nBatch175: loss = 5.0466\nBatch176: loss = 5.7920\nBatch177: loss = 5.1276\nBatch178: loss = 5.2172\nBatch179: loss = 5.2268\nBatch180: loss = 5.5825\nBatch181: loss = 5.3023\nBatch182: loss = 4.6294\nBatch183: loss = 5.2974\nBatch184: loss = 5.7644\nBatch185: loss = 5.4989\nBatch186: loss = 5.1879\nBatch187: loss = 5.2471\nBatch188: loss = 5.1101\nBatch189: loss = 5.2484\nBatch190: loss = 5.2969\nBatch191: loss = 5.3644\nBatch192: loss = 5.3639\nBatch193: loss = 5.5202\nBatch194: loss = 5.3737\nBatch195: loss = 5.5279\nBatch196: loss = 5.3344\nBatch197: loss = 5.3006\nBatch198: loss = 5.3783\nBatch199: loss = 5.5190\nBatch0: loss = 5.7472\nBatch1: loss = 5.8008\nBatch2: loss = 5.4859\nBatch3: loss = 5.4870\nBatch4: loss = 5.1442\nBatch5: loss = 5.3959\nBatch6: loss = 5.8391\nBatch7: loss = 5.7153\nBatch8: loss = 5.0142\nBatch9: loss = 5.5997\nBatch10: loss = 5.2193\nBatch11: loss = 5.4778\nBatch12: loss = 5.7781\nBatch13: loss = 5.2799\nBatch14: loss = 5.4045\nBatch15: loss = 5.2127\nBatch16: loss = 5.5197\nBatch17: loss = 4.9593\nBatch18: loss = 5.2092\nBatch19: loss = 5.3567\nBatch20: loss = 4.9926\nBatch21: loss = 5.1347\nBatch22: loss = 5.4732\nBatch23: loss = 5.5742\nBatch24: loss = 5.5470\nBatch25: loss = 5.7045\nBatch26: loss = 4.9980\nBatch27: loss = 5.1458\nBatch28: loss = 5.7329\nBatch29: loss = 5.2780\nBatch30: loss = 5.6067\nBatch31: loss = 5.2878\nBatch32: loss = 5.6705\nBatch33: loss = 5.3185\nBatch34: loss = 5.4769\nBatch35: loss = 5.1624\nBatch36: loss = 5.4850\nBatch37: loss = 5.5888\nBatch38: loss = 5.4883\nBatch39: loss = 5.8287\nBatch40: loss = 5.4250\nBatch41: loss = 5.1095\nBatch42: loss = 5.3877\nBatch43: loss = 5.5965\nBatch44: loss = 5.3180\nBatch45: loss = 5.4806\nBatch46: loss = 5.1694\nBatch47: loss = 5.3879\nBatch48: loss = 4.7825\nBatch49: loss = 5.6818\nBatch50: loss = 5.5622\nBatch51: loss = 5.2383\nBatch52: loss = 5.4879\nBatch53: loss = 5.5275\nBatch54: loss = 5.1679\nBatch55: loss = 5.7080\nBatch56: loss = 5.5936\nBatch57: loss = 5.6394\nBatch58: loss = 5.3845\nBatch59: loss = 5.2036\nBatch60: loss = 5.3228\nBatch61: loss = 5.3792\nBatch62: loss = 4.9342\nBatch63: loss = 5.3470\nBatch64: loss = 5.2718\nBatch65: loss = 5.4819\nBatch66: loss = 5.5281\nBatch67: loss = 5.2321\nBatch68: loss = 5.5319\nBatch69: loss = 5.5383\nBatch70: loss = 5.3662\nBatch71: loss = 5.2491\nBatch72: loss = 5.4899\nBatch73: loss = 5.6035\nBatch74: loss = 5.2946\nBatch75: loss = 5.3244\nBatch76: loss = 5.3170\nBatch77: loss = 5.1714\nBatch78: loss = 5.0311\nBatch79: loss = 4.9843\nBatch80: loss = 5.4967\nBatch81: loss = 5.3360\nBatch82: loss = 5.5244\nBatch83: loss = 5.3224\nBatch84: loss = 5.5670\nBatch85: loss = 5.4515\nBatch86: loss = 5.3644\nBatch87: loss = 5.2489\nBatch88: loss = 5.5239\nBatch89: loss = 5.5887\nBatch90: loss = 5.5925\nBatch91: loss = 5.4634\nBatch92: loss = 5.6049\nBatch93: loss = 5.2542\nBatch94: loss = 5.0752\nBatch95: loss = 5.5818\nBatch96: loss = 5.7489\nBatch97: loss = 5.1379\nBatch98: loss = 5.2280\nBatch99: loss = 5.4140\nBatch100: loss = 5.0062\nBatch101: loss = 5.4218\nBatch102: loss = 4.6624\nBatch103: loss = 5.5920\nBatch104: loss = 5.3114\nBatch105: loss = 5.2063\nBatch106: loss = 5.0577\nBatch107: loss = 5.5413\nBatch108: loss = 5.1337\nBatch109: loss = 5.5276\nBatch110: loss = 5.2002\nBatch111: loss = 5.0315\nBatch112: loss = 5.8544\nBatch113: loss = 5.6031\nBatch114: loss = 5.2787\nBatch115: loss = 5.3527\nBatch116: loss = 4.9349\nBatch117: loss = 5.5359\nBatch118: loss = 5.7216\nBatch119: loss = 6.0755\nBatch120: loss = 5.2789\nBatch121: loss = 5.4220\nBatch122: loss = 5.7682\nBatch123: loss = 5.2277\nBatch124: loss = 5.3102\nBatch125: loss = 5.4978\nBatch126: loss = 5.1329\nBatch127: loss = 4.9190\nBatch128: loss = 5.5434\nBatch129: loss = 5.3945\nBatch130: loss = 5.1172\nBatch131: loss = 5.2904\nBatch132: loss = 5.3567\nBatch133: loss = 5.6620\nBatch134: loss = 5.4079\nBatch135: loss = 5.2335\nBatch136: loss = 5.3964\nBatch137: loss = 6.0023\nBatch138: loss = 5.1952\nBatch139: loss = 5.3706\nBatch140: loss = 5.4990\nBatch141: loss = 5.4946\nBatch142: loss = 5.3343\nBatch143: loss = 5.3933\nBatch144: loss = 5.0649\nBatch145: loss = 5.7517\nBatch146: loss = 5.2354\nBatch147: loss = 5.3173\nBatch148: loss = 5.8338\nBatch149: loss = 5.2788\nBatch150: loss = 5.3055\nBatch151: loss = 5.3366\nBatch152: loss = 5.3011\nBatch153: loss = 5.5640\nBatch154: loss = 5.1827\nBatch155: loss = 5.2788\nBatch156: loss = 5.3030\nBatch157: loss = 5.5808\nBatch158: loss = 5.8171\nBatch159: loss = 5.7804\nBatch160: loss = 5.2792\nBatch161: loss = 5.0683\nBatch162: loss = 5.5036\nBatch163: loss = 5.4513\nBatch164: loss = 5.4852\nBatch165: loss = 5.3180\nBatch166: loss = 4.9750\nBatch167: loss = 5.6738\nBatch168: loss = 5.7197\nBatch169: loss = 5.0952\nBatch170: loss = 5.4263\nBatch171: loss = 5.1262\nBatch172: loss = 5.2230\nBatch173: loss = 5.2505\nBatch174: loss = 5.4738\nBatch175: loss = 5.3296\nBatch176: loss = 5.2698\nBatch177: loss = 5.4452\nBatch178: loss = 5.3059\nBatch179: loss = 5.3439\nBatch180: loss = 4.9944\nBatch181: loss = 5.1398\nBatch182: loss = 5.3086\nBatch183: loss = 5.1334\nBatch184: loss = 5.0871\nBatch185: loss = 5.4421\nBatch186: loss = 5.5731\nBatch187: loss = 5.6293\nBatch188: loss = 5.5941\nBatch189: loss = 5.2685\nBatch190: loss = 5.5039\nBatch191: loss = 5.0686\nBatch192: loss = 5.0130\nBatch193: loss = 5.2961\nBatch194: loss = 5.7571\nBatch195: loss = 5.1285\nBatch196: loss = 6.1209\nBatch197: loss = 5.3272\nBatch198: loss = 5.2924\nBatch199: loss = 4.8356\nstep 4000: train loss 5.2284, val loss 5.3821\nBatch0: loss = 5.2699\nBatch1: loss = 5.1224\nBatch2: loss = 4.8723\nBatch3: loss = 4.5804\nBatch4: loss = 5.2980\nBatch5: loss = 5.0974\nBatch6: loss = 5.5495\nBatch7: loss = 5.4452\nBatch8: loss = 5.0399\nBatch9: loss = 5.1952\nBatch10: loss = 5.1852\nBatch11: loss = 4.9667\nBatch12: loss = 4.9210\nBatch13: loss = 5.2649\nBatch14: loss = 5.8310\nBatch15: loss = 5.1949\nBatch16: loss = 5.3528\nBatch17: loss = 5.0561\nBatch18: loss = 5.2771\nBatch19: loss = 5.1890\nBatch20: loss = 5.1045\nBatch21: loss = 4.9802\nBatch22: loss = 5.2353\nBatch23: loss = 5.0205\nBatch24: loss = 5.3628\nBatch25: loss = 5.1362\nBatch26: loss = 5.1039\nBatch27: loss = 5.2697\nBatch28: loss = 4.9997\nBatch29: loss = 5.2630\nBatch30: loss = 5.0766\nBatch31: loss = 5.2939\nBatch32: loss = 4.9313\nBatch33: loss = 4.9091\nBatch34: loss = 4.7903\nBatch35: loss = 5.0765\nBatch36: loss = 5.2340\nBatch37: loss = 5.9366\nBatch38: loss = 5.0580\nBatch39: loss = 5.7907\nBatch40: loss = 4.9191\nBatch41: loss = 5.5291\nBatch42: loss = 4.7678\nBatch43: loss = 5.3753\nBatch44: loss = 4.8801\nBatch45: loss = 5.0363\nBatch46: loss = 5.4477\nBatch47: loss = 5.0536\nBatch48: loss = 5.1677\nBatch49: loss = 4.9293\nBatch50: loss = 5.2115\nBatch51: loss = 4.9726\nBatch52: loss = 5.0849\nBatch53: loss = 5.4886\nBatch54: loss = 5.4345\nBatch55: loss = 4.9394\nBatch56: loss = 4.9665\nBatch57: loss = 5.4707\nBatch58: loss = 4.9015\nBatch59: loss = 5.2818\nBatch60: loss = 5.0395\nBatch61: loss = 5.4548\nBatch62: loss = 5.4683\nBatch63: loss = 5.2612\nBatch64: loss = 5.3346\nBatch65: loss = 5.4962\nBatch66: loss = 5.2467\nBatch67: loss = 5.7388\nBatch68: loss = 5.4552\nBatch69: loss = 5.4003\nBatch70: loss = 5.5561\nBatch71: loss = 4.9011\nBatch72: loss = 5.3636\nBatch73: loss = 5.4226\nBatch74: loss = 4.9993\nBatch75: loss = 4.9324\nBatch76: loss = 5.2939\nBatch77: loss = 5.1832\nBatch78: loss = 5.1072\nBatch79: loss = 5.4328\nBatch80: loss = 5.0091\nBatch81: loss = 5.2744\nBatch82: loss = 5.2946\nBatch83: loss = 5.3584\nBatch84: loss = 4.8755\nBatch85: loss = 5.2028\nBatch86: loss = 4.8638\nBatch87: loss = 5.3538\nBatch88: loss = 4.8493\nBatch89: loss = 4.8800\nBatch90: loss = 4.8269\nBatch91: loss = 5.2166\nBatch92: loss = 5.5503\nBatch93: loss = 4.8360\nBatch94: loss = 5.0161\nBatch95: loss = 4.9316\nBatch96: loss = 5.1586\nBatch97: loss = 5.3034\nBatch98: loss = 4.8859\nBatch99: loss = 4.8399\nBatch100: loss = 5.0144\nBatch101: loss = 5.1918\nBatch102: loss = 5.2312\nBatch103: loss = 5.0949\nBatch104: loss = 4.8867\nBatch105: loss = 5.2582\nBatch106: loss = 4.7415\nBatch107: loss = 4.9141\nBatch108: loss = 5.1560\nBatch109: loss = 5.3850\nBatch110: loss = 5.2994\nBatch111: loss = 4.9550\nBatch112: loss = 4.6480\nBatch113: loss = 5.1379\nBatch114: loss = 5.4203\nBatch115: loss = 5.0516\nBatch116: loss = 5.5937\nBatch117: loss = 4.8833\nBatch118: loss = 5.2448\nBatch119: loss = 5.1935\nBatch120: loss = 5.1971\nBatch121: loss = 5.1799\nBatch122: loss = 5.5750\nBatch123: loss = 5.4041\nBatch124: loss = 5.2238\nBatch125: loss = 5.2942\nBatch126: loss = 5.0989\nBatch127: loss = 5.3198\nBatch128: loss = 5.5857\nBatch129: loss = 5.6428\nBatch130: loss = 4.8008\nBatch131: loss = 4.8205\nBatch132: loss = 5.0284\nBatch133: loss = 4.9576\nBatch134: loss = 5.0471\nBatch135: loss = 5.0842\nBatch136: loss = 5.3367\nBatch137: loss = 5.7661\nBatch138: loss = 5.3213\nBatch139: loss = 5.5478\nBatch140: loss = 4.9417\nBatch141: loss = 4.8828\nBatch142: loss = 5.3887\nBatch143: loss = 5.2471\nBatch144: loss = 5.5210\nBatch145: loss = 5.0991\nBatch146: loss = 5.1732\nBatch147: loss = 5.1085\nBatch148: loss = 5.3456\nBatch149: loss = 4.9088\nBatch150: loss = 5.1578\nBatch151: loss = 4.9891\nBatch152: loss = 5.3511\nBatch153: loss = 5.3432\nBatch154: loss = 5.2046\nBatch155: loss = 5.4965\nBatch156: loss = 4.9964\nBatch157: loss = 5.3500\nBatch158: loss = 5.0945\nBatch159: loss = 5.3340\nBatch160: loss = 5.4826\nBatch161: loss = 4.8785\nBatch162: loss = 5.4654\nBatch163: loss = 5.3351\nBatch164: loss = 5.5676\nBatch165: loss = 5.2016\nBatch166: loss = 4.9774\nBatch167: loss = 5.0301\nBatch168: loss = 5.2198\nBatch169: loss = 5.4214\nBatch170: loss = 4.7123\nBatch171: loss = 4.9274\nBatch172: loss = 5.3211\nBatch173: loss = 4.9758\nBatch174: loss = 5.1022\nBatch175: loss = 5.7186\nBatch176: loss = 4.9562\nBatch177: loss = 5.0900\nBatch178: loss = 5.2036\nBatch179: loss = 5.2054\nBatch180: loss = 4.8523\nBatch181: loss = 5.1928\nBatch182: loss = 5.0660\nBatch183: loss = 5.5346\nBatch184: loss = 5.5174\nBatch185: loss = 5.0036\nBatch186: loss = 5.0892\nBatch187: loss = 5.1482\nBatch188: loss = 4.8501\nBatch189: loss = 5.3437\nBatch190: loss = 5.4176\nBatch191: loss = 5.2326\nBatch192: loss = 5.0355\nBatch193: loss = 5.1704\nBatch194: loss = 5.3192\nBatch195: loss = 4.7167\nBatch196: loss = 4.8424\nBatch197: loss = 5.2965\nBatch198: loss = 4.9542\nBatch199: loss = 4.8427\nBatch0: loss = 5.3595\nBatch1: loss = 5.2020\nBatch2: loss = 5.2760\nBatch3: loss = 5.5743\nBatch4: loss = 5.2545\nBatch5: loss = 5.2645\nBatch6: loss = 5.0158\nBatch7: loss = 5.6773\nBatch8: loss = 5.1695\nBatch9: loss = 5.3128\nBatch10: loss = 5.1637\nBatch11: loss = 5.7933\nBatch12: loss = 5.5768\nBatch13: loss = 5.4037\nBatch14: loss = 5.0437\nBatch15: loss = 5.2713\nBatch16: loss = 5.4476\nBatch17: loss = 5.1221\nBatch18: loss = 5.3162\nBatch19: loss = 5.2313\nBatch20: loss = 4.9047\nBatch21: loss = 5.3596\nBatch22: loss = 5.4440\nBatch23: loss = 5.3039\nBatch24: loss = 5.7516\nBatch25: loss = 5.3530\nBatch26: loss = 5.3495\nBatch27: loss = 5.1562\nBatch28: loss = 5.0727\nBatch29: loss = 5.2150\nBatch30: loss = 5.3285\nBatch31: loss = 5.3338\nBatch32: loss = 5.3478\nBatch33: loss = 5.5074\nBatch34: loss = 5.3049\nBatch35: loss = 5.5492\nBatch36: loss = 5.3146\nBatch37: loss = 5.4481\nBatch38: loss = 5.3516\nBatch39: loss = 5.1498\nBatch40: loss = 5.3088\nBatch41: loss = 4.7818\nBatch42: loss = 5.5239\nBatch43: loss = 5.3894\nBatch44: loss = 5.5968\nBatch45: loss = 5.3005\nBatch46: loss = 5.4132\nBatch47: loss = 5.2778\nBatch48: loss = 5.3289\nBatch49: loss = 4.9932\nBatch50: loss = 5.0914\nBatch51: loss = 5.6986\nBatch52: loss = 5.4492\nBatch53: loss = 5.0322\nBatch54: loss = 5.6480\nBatch55: loss = 5.3010\nBatch56: loss = 4.9437\nBatch57: loss = 5.3319\nBatch58: loss = 5.0618\nBatch59: loss = 5.4129\nBatch60: loss = 5.4449\nBatch61: loss = 5.0514\nBatch62: loss = 5.1487\nBatch63: loss = 5.6541\nBatch64: loss = 5.3055\nBatch65: loss = 5.3572\nBatch66: loss = 4.9556\nBatch67: loss = 5.4806\nBatch68: loss = 5.5324\nBatch69: loss = 5.2128\nBatch70: loss = 5.4473\nBatch71: loss = 5.4133\nBatch72: loss = 5.5027\nBatch73: loss = 5.6784\nBatch74: loss = 5.7410\nBatch75: loss = 5.4630\nBatch76: loss = 5.1763\nBatch77: loss = 5.4301\nBatch78: loss = 5.0698\nBatch79: loss = 5.3387\nBatch80: loss = 5.0603\nBatch81: loss = 5.1413\nBatch82: loss = 5.6374\nBatch83: loss = 5.7270\nBatch84: loss = 5.4801\nBatch85: loss = 5.4452\nBatch86: loss = 5.2820\nBatch87: loss = 5.7139\nBatch88: loss = 5.3885\nBatch89: loss = 5.2532\nBatch90: loss = 5.2242\nBatch91: loss = 5.4602\nBatch92: loss = 5.0798\nBatch93: loss = 5.5655\nBatch94: loss = 5.4933\nBatch95: loss = 5.2450\nBatch96: loss = 5.2923\nBatch97: loss = 5.3052\nBatch98: loss = 5.2452\nBatch99: loss = 5.2412\nBatch100: loss = 5.3179\nBatch101: loss = 5.1435\nBatch102: loss = 5.1287\nBatch103: loss = 5.1604\nBatch104: loss = 5.6878\nBatch105: loss = 5.4491\nBatch106: loss = 5.1832\nBatch107: loss = 5.5115\nBatch108: loss = 5.2884\nBatch109: loss = 5.2974\nBatch110: loss = 5.0756\nBatch111: loss = 5.2067\nBatch112: loss = 5.2097\nBatch113: loss = 5.2349\nBatch114: loss = 5.6138\nBatch115: loss = 5.5197\nBatch116: loss = 5.1789\nBatch117: loss = 5.3943\nBatch118: loss = 5.0625\nBatch119: loss = 5.5150\nBatch120: loss = 5.6636\nBatch121: loss = 5.4329\nBatch122: loss = 5.1587\nBatch123: loss = 5.5164\nBatch124: loss = 5.4315\nBatch125: loss = 5.3704\nBatch126: loss = 5.4317\nBatch127: loss = 5.2218\nBatch128: loss = 5.5075\nBatch129: loss = 5.5159\nBatch130: loss = 5.2893\nBatch131: loss = 5.4159\nBatch132: loss = 5.3150\nBatch133: loss = 5.8273\nBatch134: loss = 5.4904\nBatch135: loss = 5.0828\nBatch136: loss = 5.4017\nBatch137: loss = 5.7722\nBatch138: loss = 5.5817\nBatch139: loss = 5.2548\nBatch140: loss = 5.4868\nBatch141: loss = 5.1340\nBatch142: loss = 5.2802\nBatch143: loss = 5.2261\nBatch144: loss = 5.1709\nBatch145: loss = 5.5577\nBatch146: loss = 5.5085\nBatch147: loss = 5.3700\nBatch148: loss = 5.3926\nBatch149: loss = 5.5702\nBatch150: loss = 5.0771\nBatch151: loss = 5.4798\nBatch152: loss = 5.4030\nBatch153: loss = 5.3281\nBatch154: loss = 5.1643\nBatch155: loss = 5.5712\nBatch156: loss = 5.8659\nBatch157: loss = 5.5230\nBatch158: loss = 5.4573\nBatch159: loss = 5.1951\nBatch160: loss = 5.7901\nBatch161: loss = 5.4329\nBatch162: loss = 5.6574\nBatch163: loss = 5.7620\nBatch164: loss = 5.1101\nBatch165: loss = 5.4719\nBatch166: loss = 5.1002\nBatch167: loss = 5.6230\nBatch168: loss = 5.4275\nBatch169: loss = 5.0248\nBatch170: loss = 5.5652\nBatch171: loss = 5.6704\nBatch172: loss = 5.2604\nBatch173: loss = 5.3007\nBatch174: loss = 5.1749\nBatch175: loss = 5.4281\nBatch176: loss = 5.4588\nBatch177: loss = 5.2161\nBatch178: loss = 5.2904\nBatch179: loss = 5.5762\nBatch180: loss = 5.5940\nBatch181: loss = 5.3760\nBatch182: loss = 5.3534\nBatch183: loss = 5.3936\nBatch184: loss = 5.4010\nBatch185: loss = 5.1808\nBatch186: loss = 5.5947\nBatch187: loss = 5.1394\nBatch188: loss = 5.4237\nBatch189: loss = 5.8415\nBatch190: loss = 5.2836\nBatch191: loss = 5.6976\nBatch192: loss = 5.4189\nBatch193: loss = 5.0787\nBatch194: loss = 5.3344\nBatch195: loss = 5.1644\nBatch196: loss = 5.6189\nBatch197: loss = 5.4893\nBatch198: loss = 5.7493\nBatch199: loss = 5.0031\nstep 4500: train loss 5.1772, val loss 5.3635\nBatch0: loss = 5.0176\nBatch1: loss = 5.2456\nBatch2: loss = 4.9403\nBatch3: loss = 5.1702\nBatch4: loss = 5.0767\nBatch5: loss = 4.9498\nBatch6: loss = 4.7316\nBatch7: loss = 5.6276\nBatch8: loss = 5.0649\nBatch9: loss = 4.8099\nBatch10: loss = 5.0931\nBatch11: loss = 4.8942\nBatch12: loss = 5.5051\nBatch13: loss = 5.1536\nBatch14: loss = 4.9691\nBatch15: loss = 4.8969\nBatch16: loss = 5.3562\nBatch17: loss = 5.2892\nBatch18: loss = 4.7887\nBatch19: loss = 5.4027\nBatch20: loss = 5.0276\nBatch21: loss = 5.5031\nBatch22: loss = 4.8853\nBatch23: loss = 5.5368\nBatch24: loss = 5.8127\nBatch25: loss = 5.1090\nBatch26: loss = 5.3070\nBatch27: loss = 5.0907\nBatch28: loss = 5.2314\nBatch29: loss = 4.9295\nBatch30: loss = 5.2912\nBatch31: loss = 4.9415\nBatch32: loss = 4.9836\nBatch33: loss = 4.9931\nBatch34: loss = 5.1697\nBatch35: loss = 4.9295\nBatch36: loss = 4.9403\nBatch37: loss = 4.7700\nBatch38: loss = 5.0312\nBatch39: loss = 5.2188\nBatch40: loss = 4.9376\nBatch41: loss = 4.9925\nBatch42: loss = 5.0856\nBatch43: loss = 4.9959\nBatch44: loss = 5.1014\nBatch45: loss = 5.2901\nBatch46: loss = 5.3734\nBatch47: loss = 5.0526\nBatch48: loss = 4.9780\nBatch49: loss = 5.2805\nBatch50: loss = 5.0813\nBatch51: loss = 4.9751\nBatch52: loss = 4.9447\nBatch53: loss = 5.1365\nBatch54: loss = 5.1442\nBatch55: loss = 4.7410\nBatch56: loss = 5.4078\nBatch57: loss = 5.3022\nBatch58: loss = 5.2546\nBatch59: loss = 5.1898\nBatch60: loss = 5.0463\nBatch61: loss = 5.0573\nBatch62: loss = 5.0432\nBatch63: loss = 5.2956\nBatch64: loss = 5.1068\nBatch65: loss = 4.8527\nBatch66: loss = 5.4682\nBatch67: loss = 5.1788\nBatch68: loss = 5.2127\nBatch69: loss = 5.1985\nBatch70: loss = 5.1646\nBatch71: loss = 5.2162\nBatch72: loss = 4.9621\nBatch73: loss = 4.8319\nBatch74: loss = 5.5125\nBatch75: loss = 5.1110\nBatch76: loss = 5.1328\nBatch77: loss = 5.0659\nBatch78: loss = 5.2771\nBatch79: loss = 5.1334\nBatch80: loss = 4.8337\nBatch81: loss = 5.0663\nBatch82: loss = 5.3887\nBatch83: loss = 5.3742\nBatch84: loss = 4.6396\nBatch85: loss = 4.7433\nBatch86: loss = 4.8973\nBatch87: loss = 5.1786\nBatch88: loss = 5.1537\nBatch89: loss = 5.3390\nBatch90: loss = 4.8551\nBatch91: loss = 4.9879\nBatch92: loss = 5.1782\nBatch93: loss = 4.9811\nBatch94: loss = 5.1692\nBatch95: loss = 5.2986\nBatch96: loss = 5.2884\nBatch97: loss = 5.0797\nBatch98: loss = 5.0660\nBatch99: loss = 4.4764\nBatch100: loss = 5.3984\nBatch101: loss = 4.8626\nBatch102: loss = 5.5389\nBatch103: loss = 5.2441\nBatch104: loss = 4.9723\nBatch105: loss = 5.3195\nBatch106: loss = 5.2104\nBatch107: loss = 4.8283\nBatch108: loss = 4.9212\nBatch109: loss = 5.4157\nBatch110: loss = 5.2831\nBatch111: loss = 4.8711\nBatch112: loss = 5.2620\nBatch113: loss = 5.1501\nBatch114: loss = 5.4422\nBatch115: loss = 5.1043\nBatch116: loss = 5.3629\nBatch117: loss = 5.1936\nBatch118: loss = 4.9932\nBatch119: loss = 4.9320\nBatch120: loss = 5.1135\nBatch121: loss = 5.0059\nBatch122: loss = 4.6271\nBatch123: loss = 4.7597\nBatch124: loss = 4.8619\nBatch125: loss = 5.1056\nBatch126: loss = 5.3622\nBatch127: loss = 5.0749\nBatch128: loss = 5.2478\nBatch129: loss = 5.1115\nBatch130: loss = 5.1622\nBatch131: loss = 5.1865\nBatch132: loss = 4.6186\nBatch133: loss = 5.4312\nBatch134: loss = 4.7319\nBatch135: loss = 4.9888\nBatch136: loss = 5.1867\nBatch137: loss = 5.0931\nBatch138: loss = 5.0283\nBatch139: loss = 5.0657\nBatch140: loss = 4.7969\nBatch141: loss = 5.2787\nBatch142: loss = 5.3993\nBatch143: loss = 4.9591\nBatch144: loss = 4.8403\nBatch145: loss = 4.7930\nBatch146: loss = 4.8518\nBatch147: loss = 5.1532\nBatch148: loss = 4.8755\nBatch149: loss = 5.3759\nBatch150: loss = 4.9832\nBatch151: loss = 5.2363\nBatch152: loss = 5.0334\nBatch153: loss = 5.4103\nBatch154: loss = 4.9797\nBatch155: loss = 4.9840\nBatch156: loss = 4.9778\nBatch157: loss = 4.6748\nBatch158: loss = 5.3365\nBatch159: loss = 4.8897\nBatch160: loss = 5.2257\nBatch161: loss = 5.3661\nBatch162: loss = 5.1787\nBatch163: loss = 5.2811\nBatch164: loss = 5.2202\nBatch165: loss = 5.5895\nBatch166: loss = 5.1169\nBatch167: loss = 4.9638\nBatch168: loss = 5.0548\nBatch169: loss = 5.0598\nBatch170: loss = 4.9353\nBatch171: loss = 5.3715\nBatch172: loss = 4.9451\nBatch173: loss = 5.6616\nBatch174: loss = 5.3172\nBatch175: loss = 5.2431\nBatch176: loss = 5.1517\nBatch177: loss = 5.2984\nBatch178: loss = 5.0606\nBatch179: loss = 4.7962\nBatch180: loss = 5.3600\nBatch181: loss = 4.8913\nBatch182: loss = 5.8576\nBatch183: loss = 5.5966\nBatch184: loss = 5.1599\nBatch185: loss = 4.9821\nBatch186: loss = 4.7345\nBatch187: loss = 5.0863\nBatch188: loss = 4.9887\nBatch189: loss = 5.2709\nBatch190: loss = 4.8707\nBatch191: loss = 5.0622\nBatch192: loss = 5.2608\nBatch193: loss = 4.8857\nBatch194: loss = 5.5120\nBatch195: loss = 5.2281\nBatch196: loss = 5.4036\nBatch197: loss = 4.6686\nBatch198: loss = 4.9663\nBatch199: loss = 5.1987\nBatch0: loss = 5.1946\nBatch1: loss = 4.9427\nBatch2: loss = 4.9813\nBatch3: loss = 5.2236\nBatch4: loss = 5.1163\nBatch5: loss = 5.3077\nBatch6: loss = 5.8257\nBatch7: loss = 5.4948\nBatch8: loss = 5.0378\nBatch9: loss = 5.1655\nBatch10: loss = 5.3846\nBatch11: loss = 5.3702\nBatch12: loss = 5.3996\nBatch13: loss = 5.1573\nBatch14: loss = 5.4128\nBatch15: loss = 5.3312\nBatch16: loss = 5.5498\nBatch17: loss = 5.0588\nBatch18: loss = 4.9228\nBatch19: loss = 5.2070\nBatch20: loss = 5.8770\nBatch21: loss = 5.3421\nBatch22: loss = 5.2321\nBatch23: loss = 5.1641\nBatch24: loss = 4.9430\nBatch25: loss = 5.5879\nBatch26: loss = 5.3167\nBatch27: loss = 5.2617\nBatch28: loss = 5.2321\nBatch29: loss = 5.2587\nBatch30: loss = 4.9024\nBatch31: loss = 5.6447\nBatch32: loss = 5.5327\nBatch33: loss = 5.4441\nBatch34: loss = 5.5279\nBatch35: loss = 5.1223\nBatch36: loss = 5.2742\nBatch37: loss = 5.6404\nBatch38: loss = 5.5382\nBatch39: loss = 5.0718\nBatch40: loss = 5.3755\nBatch41: loss = 5.8563\nBatch42: loss = 5.7028\nBatch43: loss = 5.4696\nBatch44: loss = 5.5228\nBatch45: loss = 5.6595\nBatch46: loss = 5.3339\nBatch47: loss = 5.3869\nBatch48: loss = 5.2167\nBatch49: loss = 5.4822\nBatch50: loss = 5.2613\nBatch51: loss = 4.9407\nBatch52: loss = 5.3429\nBatch53: loss = 5.5065\nBatch54: loss = 5.0860\nBatch55: loss = 4.9152\nBatch56: loss = 5.0785\nBatch57: loss = 5.0588\nBatch58: loss = 5.0023\nBatch59: loss = 5.1650\nBatch60: loss = 5.4764\nBatch61: loss = 5.5015\nBatch62: loss = 5.4351\nBatch63: loss = 5.2274\nBatch64: loss = 5.4162\nBatch65: loss = 5.6297\nBatch66: loss = 5.4614\nBatch67: loss = 5.5210\nBatch68: loss = 4.7394\nBatch69: loss = 5.0538\nBatch70: loss = 5.6675\nBatch71: loss = 5.3826\nBatch72: loss = 4.7282\nBatch73: loss = 5.4520\nBatch74: loss = 5.3120\nBatch75: loss = 5.3601\nBatch76: loss = 5.4109\nBatch77: loss = 5.5582\nBatch78: loss = 5.3737\nBatch79: loss = 5.3465\nBatch80: loss = 5.2282\nBatch81: loss = 5.3089\nBatch82: loss = 5.1945\nBatch83: loss = 5.2993\nBatch84: loss = 5.0531\nBatch85: loss = 5.4424\nBatch86: loss = 5.5388\nBatch87: loss = 4.9202\nBatch88: loss = 5.7725\nBatch89: loss = 5.4108\nBatch90: loss = 5.3459\nBatch91: loss = 5.1364\nBatch92: loss = 5.9724\nBatch93: loss = 5.2476\nBatch94: loss = 5.4327\nBatch95: loss = 5.1288\nBatch96: loss = 5.4731\nBatch97: loss = 5.0666\nBatch98: loss = 4.8276\nBatch99: loss = 5.5559\nBatch100: loss = 5.0476\nBatch101: loss = 5.4690\nBatch102: loss = 5.3493\nBatch103: loss = 5.4920\nBatch104: loss = 5.6774\nBatch105: loss = 5.5240\nBatch106: loss = 5.4587\nBatch107: loss = 5.3553\nBatch108: loss = 5.4271\nBatch109: loss = 5.3738\nBatch110: loss = 5.1689\nBatch111: loss = 5.5578\nBatch112: loss = 4.8938\nBatch113: loss = 5.3378\nBatch114: loss = 5.5823\nBatch115: loss = 5.2924\nBatch116: loss = 5.2658\nBatch117: loss = 5.1018\nBatch118: loss = 5.0674\nBatch119: loss = 5.1896\nBatch120: loss = 5.4610\nBatch121: loss = 5.1088\nBatch122: loss = 4.9839\nBatch123: loss = 5.2264\nBatch124: loss = 5.6155\nBatch125: loss = 5.3915\nBatch126: loss = 5.3656\nBatch127: loss = 5.1435\nBatch128: loss = 5.3510\nBatch129: loss = 5.3200\nBatch130: loss = 5.2911\nBatch131: loss = 5.7176\nBatch132: loss = 5.1678\nBatch133: loss = 5.0835\nBatch134: loss = 5.3349\nBatch135: loss = 5.0134\nBatch136: loss = 5.2582\nBatch137: loss = 5.6510\nBatch138: loss = 5.4200\nBatch139: loss = 5.3857\nBatch140: loss = 5.7048\nBatch141: loss = 5.3626\nBatch142: loss = 4.8129\nBatch143: loss = 5.2369\nBatch144: loss = 5.2948\nBatch145: loss = 5.3182\nBatch146: loss = 5.4502\nBatch147: loss = 5.6463\nBatch148: loss = 5.2860\nBatch149: loss = 5.4774\nBatch150: loss = 5.4207\nBatch151: loss = 5.3367\nBatch152: loss = 5.4478\nBatch153: loss = 4.7693\nBatch154: loss = 5.4256\nBatch155: loss = 5.1150\nBatch156: loss = 5.5881\nBatch157: loss = 5.5048\nBatch158: loss = 5.7345\nBatch159: loss = 5.6497\nBatch160: loss = 5.5241\nBatch161: loss = 5.4793\nBatch162: loss = 5.4979\nBatch163: loss = 5.3832\nBatch164: loss = 5.1480\nBatch165: loss = 5.1179\nBatch166: loss = 5.0697\nBatch167: loss = 5.3428\nBatch168: loss = 5.4408\nBatch169: loss = 4.9970\nBatch170: loss = 4.5812\nBatch171: loss = 5.2220\nBatch172: loss = 5.0134\nBatch173: loss = 5.1048\nBatch174: loss = 5.7361\nBatch175: loss = 5.1987\nBatch176: loss = 5.4401\nBatch177: loss = 5.1761\nBatch178: loss = 5.3400\nBatch179: loss = 5.3372\nBatch180: loss = 5.3462\nBatch181: loss = 5.4494\nBatch182: loss = 4.7219\nBatch183: loss = 5.1741\nBatch184: loss = 5.5272\nBatch185: loss = 5.2577\nBatch186: loss = 4.8600\nBatch187: loss = 5.5909\nBatch188: loss = 5.0785\nBatch189: loss = 5.3150\nBatch190: loss = 5.4788\nBatch191: loss = 5.2047\nBatch192: loss = 5.0460\nBatch193: loss = 6.0296\nBatch194: loss = 5.5523\nBatch195: loss = 4.9028\nBatch196: loss = 5.4804\nBatch197: loss = 5.5536\nBatch198: loss = 5.3648\nBatch199: loss = 5.4476\nstep 5000: train loss 5.1127, val loss 5.3190\nBatch0: loss = 5.0274\nBatch1: loss = 5.2084\nBatch2: loss = 5.1985\nBatch3: loss = 4.9719\nBatch4: loss = 5.2406\nBatch5: loss = 5.1639\nBatch6: loss = 5.1716\nBatch7: loss = 5.1307\nBatch8: loss = 5.0381\nBatch9: loss = 5.0392\nBatch10: loss = 5.6157\nBatch11: loss = 5.3393\nBatch12: loss = 5.1957\nBatch13: loss = 4.9044\nBatch14: loss = 5.2461\nBatch15: loss = 5.3027\nBatch16: loss = 5.1133\nBatch17: loss = 5.1279\nBatch18: loss = 4.7881\nBatch19: loss = 5.4134\nBatch20: loss = 5.1683\nBatch21: loss = 5.1402\nBatch22: loss = 5.0430\nBatch23: loss = 4.8104\nBatch24: loss = 5.4908\nBatch25: loss = 4.7891\nBatch26: loss = 5.5632\nBatch27: loss = 5.1502\nBatch28: loss = 5.2325\nBatch29: loss = 5.2396\nBatch30: loss = 4.8701\nBatch31: loss = 5.4623\nBatch32: loss = 4.9478\nBatch33: loss = 4.9813\nBatch34: loss = 5.1670\nBatch35: loss = 4.9724\nBatch36: loss = 5.3641\nBatch37: loss = 4.9052\nBatch38: loss = 5.0290\nBatch39: loss = 5.0897\nBatch40: loss = 4.7057\nBatch41: loss = 4.9859\nBatch42: loss = 5.1126\nBatch43: loss = 5.2958\nBatch44: loss = 5.4141\nBatch45: loss = 4.8439\nBatch46: loss = 4.5013\nBatch47: loss = 5.0726\nBatch48: loss = 5.2985\nBatch49: loss = 5.5180\nBatch50: loss = 5.3408\nBatch51: loss = 5.2361\nBatch52: loss = 4.8296\nBatch53: loss = 4.9642\nBatch54: loss = 5.2166\nBatch55: loss = 4.6315\nBatch56: loss = 4.9728\nBatch57: loss = 5.1469\nBatch58: loss = 5.3480\nBatch59: loss = 5.3049\nBatch60: loss = 4.9242\nBatch61: loss = 5.1294\nBatch62: loss = 5.0954\nBatch63: loss = 4.9674\nBatch64: loss = 4.9852\nBatch65: loss = 5.0637\nBatch66: loss = 5.1481\nBatch67: loss = 5.3094\nBatch68: loss = 5.2178\nBatch69: loss = 5.1912\nBatch70: loss = 5.1605\nBatch71: loss = 5.2162\nBatch72: loss = 4.9412\nBatch73: loss = 5.2528\nBatch74: loss = 5.2290\nBatch75: loss = 4.8926\nBatch76: loss = 4.6896\nBatch77: loss = 5.1306\nBatch78: loss = 5.0674\nBatch79: loss = 5.0720\nBatch80: loss = 5.1645\nBatch81: loss = 4.3215\nBatch82: loss = 4.9383\nBatch83: loss = 5.5833\nBatch84: loss = 5.0838\nBatch85: loss = 4.8926\nBatch86: loss = 5.0949\nBatch87: loss = 4.9217\nBatch88: loss = 5.0689\nBatch89: loss = 4.7680\nBatch90: loss = 5.1004\nBatch91: loss = 4.5087\nBatch92: loss = 4.9689\nBatch93: loss = 5.3329\nBatch94: loss = 5.0393\nBatch95: loss = 5.1773\nBatch96: loss = 5.3390\nBatch97: loss = 4.7552\nBatch98: loss = 5.0620\nBatch99: loss = 5.0443\nBatch100: loss = 5.1919\nBatch101: loss = 5.2263\nBatch102: loss = 5.3295\nBatch103: loss = 5.2587\nBatch104: loss = 4.7793\nBatch105: loss = 5.1166\nBatch106: loss = 5.4192\nBatch107: loss = 4.8196\nBatch108: loss = 4.7225\nBatch109: loss = 4.8351\nBatch110: loss = 5.2423\nBatch111: loss = 5.6802\nBatch112: loss = 5.3424\nBatch113: loss = 4.8249\nBatch114: loss = 5.0187\nBatch115: loss = 5.3999\nBatch116: loss = 5.5011\nBatch117: loss = 5.4034\nBatch118: loss = 5.2906\nBatch119: loss = 4.6911\nBatch120: loss = 5.0067\nBatch121: loss = 5.6164\nBatch122: loss = 5.1970\nBatch123: loss = 4.8070\nBatch124: loss = 4.9602\nBatch125: loss = 4.9826\nBatch126: loss = 5.2457\nBatch127: loss = 5.0692\nBatch128: loss = 5.2025\nBatch129: loss = 4.9848\nBatch130: loss = 4.7703\nBatch131: loss = 4.8941\nBatch132: loss = 5.1751\nBatch133: loss = 5.3342\nBatch134: loss = 4.9735\nBatch135: loss = 5.2513\nBatch136: loss = 4.8260\nBatch137: loss = 4.9941\nBatch138: loss = 4.9895\nBatch139: loss = 5.1218\nBatch140: loss = 5.5356\nBatch141: loss = 5.0408\nBatch142: loss = 5.3399\nBatch143: loss = 4.9418\nBatch144: loss = 5.3213\nBatch145: loss = 5.0361\nBatch146: loss = 4.9181\nBatch147: loss = 5.4896\nBatch148: loss = 5.3772\nBatch149: loss = 5.1572\nBatch150: loss = 5.3766\nBatch151: loss = 5.3976\nBatch152: loss = 4.6811\nBatch153: loss = 5.0912\nBatch154: loss = 5.2708\nBatch155: loss = 5.1299\nBatch156: loss = 4.8493\nBatch157: loss = 5.3520\nBatch158: loss = 5.2107\nBatch159: loss = 5.2971\nBatch160: loss = 5.1630\nBatch161: loss = 4.8811\nBatch162: loss = 5.2153\nBatch163: loss = 5.2359\nBatch164: loss = 5.2014\nBatch165: loss = 5.1780\nBatch166: loss = 5.0518\nBatch167: loss = 4.7818\nBatch168: loss = 5.2337\nBatch169: loss = 4.7782\nBatch170: loss = 5.2862\nBatch171: loss = 5.3224\nBatch172: loss = 5.0565\nBatch173: loss = 5.4438\nBatch174: loss = 4.7689\nBatch175: loss = 5.0331\nBatch176: loss = 5.1011\nBatch177: loss = 4.9340\nBatch178: loss = 5.0815\nBatch179: loss = 4.8619\nBatch180: loss = 4.9030\nBatch181: loss = 5.4449\nBatch182: loss = 5.4323\nBatch183: loss = 5.5837\nBatch184: loss = 4.8468\nBatch185: loss = 5.2548\nBatch186: loss = 5.3913\nBatch187: loss = 5.4721\nBatch188: loss = 4.8657\nBatch189: loss = 5.4049\nBatch190: loss = 5.6942\nBatch191: loss = 4.6911\nBatch192: loss = 5.1983\nBatch193: loss = 4.7683\nBatch194: loss = 5.2065\nBatch195: loss = 5.1742\nBatch196: loss = 5.2027\nBatch197: loss = 4.8058\nBatch198: loss = 4.9060\nBatch199: loss = 5.0473\nBatch0: loss = 5.1453\nBatch1: loss = 5.2506\nBatch2: loss = 5.3342\nBatch3: loss = 5.0837\nBatch4: loss = 5.4128\nBatch5: loss = 5.7471\nBatch6: loss = 4.9873\nBatch7: loss = 4.9921\nBatch8: loss = 5.1148\nBatch9: loss = 5.5532\nBatch10: loss = 5.4450\nBatch11: loss = 5.3429\nBatch12: loss = 5.0617\nBatch13: loss = 5.4224\nBatch14: loss = 5.0190\nBatch15: loss = 5.3105\nBatch16: loss = 4.9632\nBatch17: loss = 5.2742\nBatch18: loss = 5.0518\nBatch19: loss = 4.7332\nBatch20: loss = 5.1166\nBatch21: loss = 5.4346\nBatch22: loss = 5.3175\nBatch23: loss = 5.0503\nBatch24: loss = 5.1336\nBatch25: loss = 5.1558\nBatch26: loss = 5.2640\nBatch27: loss = 4.9680\nBatch28: loss = 5.3671\nBatch29: loss = 5.1676\nBatch30: loss = 5.4908\nBatch31: loss = 5.6364\nBatch32: loss = 5.3234\nBatch33: loss = 5.1180\nBatch34: loss = 5.6166\nBatch35: loss = 5.0534\nBatch36: loss = 5.4443\nBatch37: loss = 5.3029\nBatch38: loss = 5.3722\nBatch39: loss = 5.4894\nBatch40: loss = 5.2977\nBatch41: loss = 5.2494\nBatch42: loss = 5.5266\nBatch43: loss = 5.4807\nBatch44: loss = 5.2113\nBatch45: loss = 5.7017\nBatch46: loss = 5.2940\nBatch47: loss = 5.0845\nBatch48: loss = 5.3051\nBatch49: loss = 5.1940\nBatch50: loss = 5.5529\nBatch51: loss = 5.0909\nBatch52: loss = 5.2105\nBatch53: loss = 4.8539\nBatch54: loss = 5.2817\nBatch55: loss = 5.2721\nBatch56: loss = 5.3135\nBatch57: loss = 5.3432\nBatch58: loss = 5.5571\nBatch59: loss = 5.1959\nBatch60: loss = 4.3851\nBatch61: loss = 5.1920\nBatch62: loss = 5.8226\nBatch63: loss = 5.5673\nBatch64: loss = 5.1376\nBatch65: loss = 4.9015\nBatch66: loss = 5.2090\nBatch67: loss = 5.2424\nBatch68: loss = 5.5158\nBatch69: loss = 5.3469\nBatch70: loss = 5.2336\nBatch71: loss = 5.2792\nBatch72: loss = 5.5145\nBatch73: loss = 5.1488\nBatch74: loss = 5.3459\nBatch75: loss = 5.2530\nBatch76: loss = 5.0213\nBatch77: loss = 5.4647\nBatch78: loss = 5.6368\nBatch79: loss = 4.7791\nBatch80: loss = 5.3331\nBatch81: loss = 5.5489\nBatch82: loss = 5.1832\nBatch83: loss = 4.8225\nBatch84: loss = 4.5347\nBatch85: loss = 4.9353\nBatch86: loss = 5.7257\nBatch87: loss = 4.9633\nBatch88: loss = 4.8550\nBatch89: loss = 4.8241\nBatch90: loss = 5.4104\nBatch91: loss = 5.5739\nBatch92: loss = 5.4523\nBatch93: loss = 5.5527\nBatch94: loss = 5.0332\nBatch95: loss = 5.2879\nBatch96: loss = 5.2834\nBatch97: loss = 5.0497\nBatch98: loss = 5.3485\nBatch99: loss = 5.2381\nBatch100: loss = 5.2326\nBatch101: loss = 4.7096\nBatch102: loss = 5.5292\nBatch103: loss = 5.7772\nBatch104: loss = 5.1315\nBatch105: loss = 5.5108\nBatch106: loss = 5.5766\nBatch107: loss = 5.2698\nBatch108: loss = 5.3299\nBatch109: loss = 5.0915\nBatch110: loss = 5.2318\nBatch111: loss = 5.6047\nBatch112: loss = 5.3665\nBatch113: loss = 5.2784\nBatch114: loss = 5.3418\nBatch115: loss = 5.3629\nBatch116: loss = 5.3622\nBatch117: loss = 5.5903\nBatch118: loss = 5.2375\nBatch119: loss = 5.3504\nBatch120: loss = 5.0351\nBatch121: loss = 5.3421\nBatch122: loss = 5.3256\nBatch123: loss = 5.0050\nBatch124: loss = 5.7503\nBatch125: loss = 5.3172\nBatch126: loss = 5.2935\nBatch127: loss = 5.4088\nBatch128: loss = 5.3098\nBatch129: loss = 4.8843\nBatch130: loss = 5.5411\nBatch131: loss = 5.3545\nBatch132: loss = 5.3554\nBatch133: loss = 5.4970\nBatch134: loss = 4.7894\nBatch135: loss = 5.3559\nBatch136: loss = 5.1981\nBatch137: loss = 5.2943\nBatch138: loss = 5.3193\nBatch139: loss = 4.8735\nBatch140: loss = 5.3146\nBatch141: loss = 5.1517\nBatch142: loss = 5.2208\nBatch143: loss = 5.3661\nBatch144: loss = 5.1293\nBatch145: loss = 5.3436\nBatch146: loss = 4.8606\nBatch147: loss = 4.9320\nBatch148: loss = 5.3145\nBatch149: loss = 5.4556\nBatch150: loss = 5.4704\nBatch151: loss = 5.2190\nBatch152: loss = 5.0714\nBatch153: loss = 4.7817\nBatch154: loss = 5.4413\nBatch155: loss = 5.0520\nBatch156: loss = 5.2282\nBatch157: loss = 5.2819\nBatch158: loss = 5.0672\nBatch159: loss = 5.1514\nBatch160: loss = 5.4066\nBatch161: loss = 5.0628\nBatch162: loss = 5.3029\nBatch163: loss = 5.1673\nBatch164: loss = 5.3384\nBatch165: loss = 5.3600\nBatch166: loss = 5.4422\nBatch167: loss = 4.9314\nBatch168: loss = 4.6609\nBatch169: loss = 4.6795\nBatch170: loss = 5.0267\nBatch171: loss = 5.3712\nBatch172: loss = 5.1235\nBatch173: loss = 5.3262\nBatch174: loss = 5.1075\nBatch175: loss = 5.3990\nBatch176: loss = 5.1151\nBatch177: loss = 5.4472\nBatch178: loss = 5.2723\nBatch179: loss = 5.1976\nBatch180: loss = 5.3943\nBatch181: loss = 5.1742\nBatch182: loss = 5.3151\nBatch183: loss = 5.1731\nBatch184: loss = 5.1890\nBatch185: loss = 5.3862\nBatch186: loss = 5.4134\nBatch187: loss = 5.0714\nBatch188: loss = 5.3576\nBatch189: loss = 5.1487\nBatch190: loss = 5.1063\nBatch191: loss = 5.1239\nBatch192: loss = 5.3376\nBatch193: loss = 4.9729\nBatch194: loss = 4.9561\nBatch195: loss = 5.2689\nBatch196: loss = 5.3988\nBatch197: loss = 5.2359\nBatch198: loss = 5.1781\nBatch199: loss = 5.4247\nstep 5500: train loss 5.1123, val loss 5.2470\nBatch0: loss = 4.9309\nBatch1: loss = 5.1150\nBatch2: loss = 5.1017\nBatch3: loss = 4.9419\nBatch4: loss = 5.4257\nBatch5: loss = 4.6216\nBatch6: loss = 4.9039\nBatch7: loss = 5.3715\nBatch8: loss = 5.2014\nBatch9: loss = 4.7975\nBatch10: loss = 4.6723\nBatch11: loss = 5.2198\nBatch12: loss = 5.2682\nBatch13: loss = 5.1687\nBatch14: loss = 4.9972\nBatch15: loss = 5.1998\nBatch16: loss = 5.1457\nBatch17: loss = 5.1005\nBatch18: loss = 5.0948\nBatch19: loss = 5.3583\nBatch20: loss = 4.8666\nBatch21: loss = 4.9681\nBatch22: loss = 5.2229\nBatch23: loss = 5.0361\nBatch24: loss = 5.2622\nBatch25: loss = 4.9084\nBatch26: loss = 5.1617\nBatch27: loss = 5.2052\nBatch28: loss = 5.3609\nBatch29: loss = 4.8186\nBatch30: loss = 5.3516\nBatch31: loss = 5.0571\nBatch32: loss = 5.3552\nBatch33: loss = 4.9529\nBatch34: loss = 5.1145\nBatch35: loss = 4.8878\nBatch36: loss = 5.4742\nBatch37: loss = 5.1515\nBatch38: loss = 5.2294\nBatch39: loss = 5.0699\nBatch40: loss = 4.9907\nBatch41: loss = 5.2343\nBatch42: loss = 5.0535\nBatch43: loss = 4.8184\nBatch44: loss = 4.5860\nBatch45: loss = 5.0690\nBatch46: loss = 5.0596\nBatch47: loss = 5.2661\nBatch48: loss = 5.1250\nBatch49: loss = 4.5661\nBatch50: loss = 5.4847\nBatch51: loss = 5.2099\nBatch52: loss = 5.3365\nBatch53: loss = 4.9367\nBatch54: loss = 5.0056\nBatch55: loss = 4.6063\nBatch56: loss = 5.3155\nBatch57: loss = 5.1766\nBatch58: loss = 5.1523\nBatch59: loss = 5.0494\nBatch60: loss = 5.1163\nBatch61: loss = 5.1084\nBatch62: loss = 4.7063\nBatch63: loss = 5.5218\nBatch64: loss = 4.9579\nBatch65: loss = 5.1823\nBatch66: loss = 4.7232\nBatch67: loss = 5.4371\nBatch68: loss = 5.4514\nBatch69: loss = 4.7104\nBatch70: loss = 5.0598\nBatch71: loss = 4.9186\nBatch72: loss = 4.9027\nBatch73: loss = 5.0295\nBatch74: loss = 4.9591\nBatch75: loss = 5.2747\nBatch76: loss = 4.9565\nBatch77: loss = 5.1294\nBatch78: loss = 4.9735\nBatch79: loss = 5.0569\nBatch80: loss = 5.4835\nBatch81: loss = 5.1470\nBatch82: loss = 4.9200\nBatch83: loss = 4.7174\nBatch84: loss = 4.7946\nBatch85: loss = 5.0893\nBatch86: loss = 4.6701\nBatch87: loss = 5.2884\nBatch88: loss = 4.9352\nBatch89: loss = 4.9390\nBatch90: loss = 5.3447\nBatch91: loss = 5.2332\nBatch92: loss = 5.0651\nBatch93: loss = 4.9181\nBatch94: loss = 5.0836\nBatch95: loss = 4.7070\nBatch96: loss = 5.2768\nBatch97: loss = 5.0670\nBatch98: loss = 5.2776\nBatch99: loss = 5.0627\nBatch100: loss = 5.2811\nBatch101: loss = 5.0516\nBatch102: loss = 4.8338\nBatch103: loss = 5.0605\nBatch104: loss = 5.0054\nBatch105: loss = 5.3224\nBatch106: loss = 5.0148\nBatch107: loss = 4.6174\nBatch108: loss = 5.1558\nBatch109: loss = 5.0278\nBatch110: loss = 4.8199\nBatch111: loss = 5.1614\nBatch112: loss = 5.3548\nBatch113: loss = 4.7506\nBatch114: loss = 5.3348\nBatch115: loss = 5.2928\nBatch116: loss = 5.2813\nBatch117: loss = 4.6325\nBatch118: loss = 4.8253\nBatch119: loss = 4.9376\nBatch120: loss = 5.6286\nBatch121: loss = 4.9762\nBatch122: loss = 5.3332\nBatch123: loss = 4.9342\nBatch124: loss = 5.3538\nBatch125: loss = 5.1258\nBatch126: loss = 5.3445\nBatch127: loss = 5.0207\nBatch128: loss = 5.4998\nBatch129: loss = 4.8631\nBatch130: loss = 5.5337\nBatch131: loss = 5.1398\nBatch132: loss = 5.4617\nBatch133: loss = 5.3447\nBatch134: loss = 5.2640\nBatch135: loss = 4.9003\nBatch136: loss = 5.3177\nBatch137: loss = 5.2034\nBatch138: loss = 5.0105\nBatch139: loss = 5.0679\nBatch140: loss = 5.0462\nBatch141: loss = 5.1498\nBatch142: loss = 5.2918\nBatch143: loss = 5.7301\nBatch144: loss = 4.8406\nBatch145: loss = 5.0838\nBatch146: loss = 4.6409\nBatch147: loss = 5.0489\nBatch148: loss = 5.3185\nBatch149: loss = 4.8772\nBatch150: loss = 5.8339\nBatch151: loss = 4.6525\nBatch152: loss = 5.3478\nBatch153: loss = 4.6694\nBatch154: loss = 5.1723\nBatch155: loss = 4.8948\nBatch156: loss = 4.7240\nBatch157: loss = 5.0860\nBatch158: loss = 5.0750\nBatch159: loss = 5.1204\nBatch160: loss = 5.2349\nBatch161: loss = 4.9013\nBatch162: loss = 5.0461\nBatch163: loss = 4.8629\nBatch164: loss = 5.3724\nBatch165: loss = 4.7698\nBatch166: loss = 5.0932\nBatch167: loss = 4.8610\nBatch168: loss = 4.8762\nBatch169: loss = 4.8988\nBatch170: loss = 4.9225\nBatch171: loss = 4.8066\nBatch172: loss = 4.6743\nBatch173: loss = 5.0898\nBatch174: loss = 5.1121\nBatch175: loss = 4.8467\nBatch176: loss = 5.3082\nBatch177: loss = 5.2510\nBatch178: loss = 4.9117\nBatch179: loss = 4.8654\nBatch180: loss = 5.1779\nBatch181: loss = 5.1609\nBatch182: loss = 5.0207\nBatch183: loss = 5.1911\nBatch184: loss = 4.7633\nBatch185: loss = 4.9206\nBatch186: loss = 5.2584\nBatch187: loss = 4.6465\nBatch188: loss = 5.7641\nBatch189: loss = 5.0167\nBatch190: loss = 5.1958\nBatch191: loss = 5.2814\nBatch192: loss = 5.0687\nBatch193: loss = 5.4713\nBatch194: loss = 5.0523\nBatch195: loss = 5.1799\nBatch196: loss = 5.1208\nBatch197: loss = 4.6924\nBatch198: loss = 5.1707\nBatch199: loss = 5.2239\nBatch0: loss = 5.4024\nBatch1: loss = 5.3510\nBatch2: loss = 5.4219\nBatch3: loss = 5.1919\nBatch4: loss = 5.4480\nBatch5: loss = 4.9230\nBatch6: loss = 5.2951\nBatch7: loss = 5.6703\nBatch8: loss = 5.3525\nBatch9: loss = 5.1877\nBatch10: loss = 5.0929\nBatch11: loss = 5.0968\nBatch12: loss = 4.8460\nBatch13: loss = 5.2463\nBatch14: loss = 6.2051\nBatch15: loss = 4.9563\nBatch16: loss = 5.6065\nBatch17: loss = 4.8437\nBatch18: loss = 5.2167\nBatch19: loss = 5.2649\nBatch20: loss = 5.0796\nBatch21: loss = 4.7505\nBatch22: loss = 5.1726\nBatch23: loss = 5.5353\nBatch24: loss = 5.4546\nBatch25: loss = 5.2284\nBatch26: loss = 5.3329\nBatch27: loss = 5.0129\nBatch28: loss = 5.5809\nBatch29: loss = 5.0047\nBatch30: loss = 5.1926\nBatch31: loss = 5.2644\nBatch32: loss = 5.3819\nBatch33: loss = 5.0497\nBatch34: loss = 5.2533\nBatch35: loss = 4.9318\nBatch36: loss = 5.5221\nBatch37: loss = 5.2846\nBatch38: loss = 5.5325\nBatch39: loss = 5.3104\nBatch40: loss = 5.3516\nBatch41: loss = 5.5026\nBatch42: loss = 5.1981\nBatch43: loss = 5.4065\nBatch44: loss = 5.5507\nBatch45: loss = 5.7088\nBatch46: loss = 5.3251\nBatch47: loss = 5.2154\nBatch48: loss = 5.4758\nBatch49: loss = 5.0506\nBatch50: loss = 5.7692\nBatch51: loss = 5.5885\nBatch52: loss = 4.8080\nBatch53: loss = 5.1047\nBatch54: loss = 5.2640\nBatch55: loss = 5.2300\nBatch56: loss = 5.5560\nBatch57: loss = 5.2380\nBatch58: loss = 5.8287\nBatch59: loss = 5.3336\nBatch60: loss = 5.2445\nBatch61: loss = 4.9962\nBatch62: loss = 5.4546\nBatch63: loss = 5.7612\nBatch64: loss = 5.1395\nBatch65: loss = 4.9438\nBatch66: loss = 5.5746\nBatch67: loss = 5.3285\nBatch68: loss = 5.0885\nBatch69: loss = 5.0486\nBatch70: loss = 5.2589\nBatch71: loss = 4.9330\nBatch72: loss = 5.1429\nBatch73: loss = 5.4688\nBatch74: loss = 5.6478\nBatch75: loss = 5.2203\nBatch76: loss = 4.6015\nBatch77: loss = 5.2313\nBatch78: loss = 4.9892\nBatch79: loss = 5.0682\nBatch80: loss = 5.4476\nBatch81: loss = 5.6316\nBatch82: loss = 5.2603\nBatch83: loss = 5.5486\nBatch84: loss = 5.2817\nBatch85: loss = 5.1457\nBatch86: loss = 5.5791\nBatch87: loss = 4.8906\nBatch88: loss = 5.3508\nBatch89: loss = 4.8595\nBatch90: loss = 4.8907\nBatch91: loss = 5.4082\nBatch92: loss = 5.2268\nBatch93: loss = 4.9047\nBatch94: loss = 5.0497\nBatch95: loss = 5.5867\nBatch96: loss = 5.4116\nBatch97: loss = 5.7699\nBatch98: loss = 5.3432\nBatch99: loss = 5.1558\nBatch100: loss = 5.3339\nBatch101: loss = 4.6977\nBatch102: loss = 5.2559\nBatch103: loss = 5.4268\nBatch104: loss = 5.2979\nBatch105: loss = 5.3343\nBatch106: loss = 5.2082\nBatch107: loss = 4.7663\nBatch108: loss = 5.0871\nBatch109: loss = 5.4238\nBatch110: loss = 5.3916\nBatch111: loss = 5.6277\nBatch112: loss = 5.2816\nBatch113: loss = 5.0596\nBatch114: loss = 5.4019\nBatch115: loss = 5.3650\nBatch116: loss = 5.5236\nBatch117: loss = 5.0798\nBatch118: loss = 5.3294\nBatch119: loss = 5.4080\nBatch120: loss = 4.8047\nBatch121: loss = 4.9522\nBatch122: loss = 5.5683\nBatch123: loss = 5.3546\nBatch124: loss = 5.1467\nBatch125: loss = 5.3312\nBatch126: loss = 5.3711\nBatch127: loss = 5.3589\nBatch128: loss = 5.2198\nBatch129: loss = 5.1852\nBatch130: loss = 5.3692\nBatch131: loss = 5.1076\nBatch132: loss = 5.6287\nBatch133: loss = 5.1025\nBatch134: loss = 5.1400\nBatch135: loss = 4.8398\nBatch136: loss = 5.2381\nBatch137: loss = 5.1403\nBatch138: loss = 5.2177\nBatch139: loss = 5.0598\nBatch140: loss = 5.5222\nBatch141: loss = 4.9831\nBatch142: loss = 5.1723\nBatch143: loss = 4.5398\nBatch144: loss = 5.1264\nBatch145: loss = 5.5965\nBatch146: loss = 4.9057\nBatch147: loss = 5.5302\nBatch148: loss = 4.9782\nBatch149: loss = 5.2150\nBatch150: loss = 5.2369\nBatch151: loss = 5.1583\nBatch152: loss = 5.0035\nBatch153: loss = 5.1849\nBatch154: loss = 5.6093\nBatch155: loss = 5.5926\nBatch156: loss = 5.3192\nBatch157: loss = 5.1130\nBatch158: loss = 5.1212\nBatch159: loss = 5.4987\nBatch160: loss = 5.5624\nBatch161: loss = 5.0513\nBatch162: loss = 5.2476\nBatch163: loss = 4.7537\nBatch164: loss = 5.0927\nBatch165: loss = 5.0588\nBatch166: loss = 5.6186\nBatch167: loss = 5.4035\nBatch168: loss = 4.9217\nBatch169: loss = 5.3232\nBatch170: loss = 5.1127\nBatch171: loss = 5.2967\nBatch172: loss = 4.7164\nBatch173: loss = 5.0286\nBatch174: loss = 5.2158\nBatch175: loss = 5.1947\nBatch176: loss = 5.2051\nBatch177: loss = 5.2385\nBatch178: loss = 5.3635\nBatch179: loss = 5.6787\nBatch180: loss = 5.1774\nBatch181: loss = 5.2516\nBatch182: loss = 5.3683\nBatch183: loss = 5.6325\nBatch184: loss = 5.2208\nBatch185: loss = 5.5042\nBatch186: loss = 5.3994\nBatch187: loss = 5.3252\nBatch188: loss = 5.6547\nBatch189: loss = 4.9773\nBatch190: loss = 5.2568\nBatch191: loss = 4.6115\nBatch192: loss = 5.3822\nBatch193: loss = 5.2291\nBatch194: loss = 5.4912\nBatch195: loss = 5.4327\nBatch196: loss = 4.8260\nBatch197: loss = 4.8181\nBatch198: loss = 5.0283\nBatch199: loss = 5.5703\nstep 6000: train loss 5.0805, val loss 5.2548\nBatch0: loss = 4.7409\nBatch1: loss = 5.0215\nBatch2: loss = 4.8246\nBatch3: loss = 5.0658\nBatch4: loss = 4.8358\nBatch5: loss = 5.5017\nBatch6: loss = 4.9879\nBatch7: loss = 5.0468\nBatch8: loss = 5.1796\nBatch9: loss = 4.9355\nBatch10: loss = 4.7432\nBatch11: loss = 5.2062\nBatch12: loss = 4.8036\nBatch13: loss = 5.0759\nBatch14: loss = 5.3074\nBatch15: loss = 5.1087\nBatch16: loss = 4.7615\nBatch17: loss = 5.1262\nBatch18: loss = 5.1372\nBatch19: loss = 5.2214\nBatch20: loss = 5.5321\nBatch21: loss = 4.9887\nBatch22: loss = 4.6453\nBatch23: loss = 4.8104\nBatch24: loss = 5.1021\nBatch25: loss = 4.9872\nBatch26: loss = 4.9603\nBatch27: loss = 5.2437\nBatch28: loss = 4.9071\nBatch29: loss = 4.7289\nBatch30: loss = 5.1520\nBatch31: loss = 5.0946\nBatch32: loss = 5.0467\nBatch33: loss = 5.0625\nBatch34: loss = 4.9524\nBatch35: loss = 4.9080\nBatch36: loss = 5.0962\nBatch37: loss = 5.1715\nBatch38: loss = 5.1571\nBatch39: loss = 4.8749\nBatch40: loss = 5.1096\nBatch41: loss = 5.3834\nBatch42: loss = 4.6201\nBatch43: loss = 4.8474\nBatch44: loss = 5.0445\nBatch45: loss = 4.9838\nBatch46: loss = 5.4049\nBatch47: loss = 5.2608\nBatch48: loss = 4.6468\nBatch49: loss = 5.1267\nBatch50: loss = 5.0240\nBatch51: loss = 5.0763\nBatch52: loss = 5.1081\nBatch53: loss = 4.8861\nBatch54: loss = 5.0676\nBatch55: loss = 5.1623\nBatch56: loss = 5.0825\nBatch57: loss = 4.9638\nBatch58: loss = 4.5110\nBatch59: loss = 4.8418\nBatch60: loss = 5.0104\nBatch61: loss = 5.3687\nBatch62: loss = 5.2409\nBatch63: loss = 5.1488\nBatch64: loss = 5.1712\nBatch65: loss = 4.8421\nBatch66: loss = 5.1830\nBatch67: loss = 5.3341\nBatch68: loss = 4.9626\nBatch69: loss = 5.1263\nBatch70: loss = 5.0940\nBatch71: loss = 4.8238\nBatch72: loss = 5.3420\nBatch73: loss = 4.8496\nBatch74: loss = 4.8974\nBatch75: loss = 5.0477\nBatch76: loss = 5.0897\nBatch77: loss = 4.7616\nBatch78: loss = 4.8747\nBatch79: loss = 5.2063\nBatch80: loss = 4.8510\nBatch81: loss = 4.9120\nBatch82: loss = 4.9972\nBatch83: loss = 5.0388\nBatch84: loss = 4.9944\nBatch85: loss = 4.6554\nBatch86: loss = 5.3349\nBatch87: loss = 5.2303\nBatch88: loss = 4.9008\nBatch89: loss = 5.1385\nBatch90: loss = 4.8270\nBatch91: loss = 5.0721\nBatch92: loss = 5.2556\nBatch93: loss = 4.8675\nBatch94: loss = 5.3852\nBatch95: loss = 4.9215\nBatch96: loss = 4.9080\nBatch97: loss = 4.8214\nBatch98: loss = 4.8642\nBatch99: loss = 5.1842\nBatch100: loss = 4.9014\nBatch101: loss = 4.7869\nBatch102: loss = 5.0652\nBatch103: loss = 4.8529\nBatch104: loss = 4.9698\nBatch105: loss = 5.0625\nBatch106: loss = 4.9170\nBatch107: loss = 5.1731\nBatch108: loss = 5.0423\nBatch109: loss = 5.3546\nBatch110: loss = 5.0996\nBatch111: loss = 4.6036\nBatch112: loss = 5.1968\nBatch113: loss = 5.4463\nBatch114: loss = 4.9407\nBatch115: loss = 4.8747\nBatch116: loss = 5.0970\nBatch117: loss = 4.9454\nBatch118: loss = 5.2797\nBatch119: loss = 4.8850\nBatch120: loss = 5.1830\nBatch121: loss = 4.9255\nBatch122: loss = 4.9394\nBatch123: loss = 4.7546\nBatch124: loss = 4.8085\nBatch125: loss = 4.5840\nBatch126: loss = 5.2382\nBatch127: loss = 4.9744\nBatch128: loss = 5.0674\nBatch129: loss = 4.9729\nBatch130: loss = 4.9769\nBatch131: loss = 5.1095\nBatch132: loss = 4.9337\nBatch133: loss = 5.0228\nBatch134: loss = 4.8806\nBatch135: loss = 4.8564\nBatch136: loss = 4.9439\nBatch137: loss = 5.3535\nBatch138: loss = 4.8725\nBatch139: loss = 4.7965\nBatch140: loss = 5.1480\nBatch141: loss = 4.8904\nBatch142: loss = 4.8361\nBatch143: loss = 4.9866\nBatch144: loss = 5.0766\nBatch145: loss = 4.8003\nBatch146: loss = 5.4843\nBatch147: loss = 4.8906\nBatch148: loss = 4.9969\nBatch149: loss = 5.2721\nBatch150: loss = 5.2336\nBatch151: loss = 4.6289\nBatch152: loss = 5.5134\nBatch153: loss = 4.7448\nBatch154: loss = 5.3572\nBatch155: loss = 4.9548\nBatch156: loss = 4.6742\nBatch157: loss = 4.9512\nBatch158: loss = 4.9242\nBatch159: loss = 5.2771\nBatch160: loss = 5.4915\nBatch161: loss = 5.0296\nBatch162: loss = 5.1972\nBatch163: loss = 4.9656\nBatch164: loss = 4.7937\nBatch165: loss = 5.0791\nBatch166: loss = 4.7504\nBatch167: loss = 5.1554\nBatch168: loss = 5.2194\nBatch169: loss = 5.3771\nBatch170: loss = 5.0199\nBatch171: loss = 5.1170\nBatch172: loss = 4.7749\nBatch173: loss = 4.6892\nBatch174: loss = 5.0675\nBatch175: loss = 4.9905\nBatch176: loss = 4.9807\nBatch177: loss = 5.0636\nBatch178: loss = 4.9265\nBatch179: loss = 4.7231\nBatch180: loss = 4.8367\nBatch181: loss = 4.7622\nBatch182: loss = 4.7674\nBatch183: loss = 5.0134\nBatch184: loss = 4.7264\nBatch185: loss = 4.8767\nBatch186: loss = 5.4366\nBatch187: loss = 5.1333\nBatch188: loss = 4.9515\nBatch189: loss = 5.1465\nBatch190: loss = 5.4342\nBatch191: loss = 4.7909\nBatch192: loss = 5.4688\nBatch193: loss = 5.0426\nBatch194: loss = 5.0288\nBatch195: loss = 4.8791\nBatch196: loss = 5.3900\nBatch197: loss = 4.8892\nBatch198: loss = 4.8166\nBatch199: loss = 4.9231\nBatch0: loss = 4.9836\nBatch1: loss = 5.1244\nBatch2: loss = 5.4144\nBatch3: loss = 4.9809\nBatch4: loss = 5.4653\nBatch5: loss = 5.3190\nBatch6: loss = 5.3115\nBatch7: loss = 4.9881\nBatch8: loss = 5.2526\nBatch9: loss = 5.4143\nBatch10: loss = 5.0527\nBatch11: loss = 5.3804\nBatch12: loss = 5.1271\nBatch13: loss = 5.7351\nBatch14: loss = 5.5985\nBatch15: loss = 4.9241\nBatch16: loss = 5.1972\nBatch17: loss = 4.9847\nBatch18: loss = 5.7628\nBatch19: loss = 5.4897\nBatch20: loss = 5.0060\nBatch21: loss = 4.9682\nBatch22: loss = 5.1633\nBatch23: loss = 5.1916\nBatch24: loss = 4.9781\nBatch25: loss = 5.3259\nBatch26: loss = 5.2706\nBatch27: loss = 5.0903\nBatch28: loss = 4.9385\nBatch29: loss = 5.1863\nBatch30: loss = 5.1336\nBatch31: loss = 5.4947\nBatch32: loss = 5.3347\nBatch33: loss = 4.8943\nBatch34: loss = 5.4138\nBatch35: loss = 5.4499\nBatch36: loss = 5.2561\nBatch37: loss = 5.2611\nBatch38: loss = 5.1052\nBatch39: loss = 5.0228\nBatch40: loss = 5.0858\nBatch41: loss = 5.7294\nBatch42: loss = 5.4648\nBatch43: loss = 5.3807\nBatch44: loss = 5.1194\nBatch45: loss = 5.2356\nBatch46: loss = 5.0670\nBatch47: loss = 5.0940\nBatch48: loss = 5.0807\nBatch49: loss = 5.0476\nBatch50: loss = 4.8402\nBatch51: loss = 5.2961\nBatch52: loss = 4.8053\nBatch53: loss = 5.5659\nBatch54: loss = 5.1664\nBatch55: loss = 4.9633\nBatch56: loss = 5.2941\nBatch57: loss = 5.1729\nBatch58: loss = 5.0411\nBatch59: loss = 5.1728\nBatch60: loss = 5.1412\nBatch61: loss = 5.1473\nBatch62: loss = 5.3655\nBatch63: loss = 5.4143\nBatch64: loss = 5.0166\nBatch65: loss = 5.4472\nBatch66: loss = 5.2007\nBatch67: loss = 4.9611\nBatch68: loss = 5.0498\nBatch69: loss = 4.9753\nBatch70: loss = 5.5343\nBatch71: loss = 5.1483\nBatch72: loss = 5.4046\nBatch73: loss = 5.4213\nBatch74: loss = 5.4619\nBatch75: loss = 5.0664\nBatch76: loss = 5.0324\nBatch77: loss = 5.4078\nBatch78: loss = 5.3531\nBatch79: loss = 5.1379\nBatch80: loss = 4.9562\nBatch81: loss = 5.0610\nBatch82: loss = 5.3362\nBatch83: loss = 5.0555\nBatch84: loss = 5.0941\nBatch85: loss = 5.0812\nBatch86: loss = 5.6659\nBatch87: loss = 5.3651\nBatch88: loss = 5.2289\nBatch89: loss = 5.3645\nBatch90: loss = 5.0941\nBatch91: loss = 5.1140\nBatch92: loss = 5.5281\nBatch93: loss = 5.4429\nBatch94: loss = 5.4659\nBatch95: loss = 5.0665\nBatch96: loss = 5.4687\nBatch97: loss = 5.3825\nBatch98: loss = 4.7393\nBatch99: loss = 4.9936\nBatch100: loss = 5.1957\nBatch101: loss = 4.8795\nBatch102: loss = 5.5053\nBatch103: loss = 5.4974\nBatch104: loss = 5.5618\nBatch105: loss = 5.4372\nBatch106: loss = 5.3381\nBatch107: loss = 5.2527\nBatch108: loss = 5.2117\nBatch109: loss = 5.7925\nBatch110: loss = 5.3136\nBatch111: loss = 5.0818\nBatch112: loss = 5.7827\nBatch113: loss = 5.5950\nBatch114: loss = 5.4288\nBatch115: loss = 4.9403\nBatch116: loss = 5.3219\nBatch117: loss = 5.2518\nBatch118: loss = 4.8024\nBatch119: loss = 5.3295\nBatch120: loss = 5.1402\nBatch121: loss = 5.5337\nBatch122: loss = 5.2137\nBatch123: loss = 5.5733\nBatch124: loss = 5.2084\nBatch125: loss = 5.8915\nBatch126: loss = 5.4049\nBatch127: loss = 5.7154\nBatch128: loss = 5.3255\nBatch129: loss = 5.0502\nBatch130: loss = 5.1713\nBatch131: loss = 5.6331\nBatch132: loss = 5.0584\nBatch133: loss = 4.6213\nBatch134: loss = 4.9788\nBatch135: loss = 4.7236\nBatch136: loss = 5.6169\nBatch137: loss = 5.2516\nBatch138: loss = 4.9393\nBatch139: loss = 5.3093\nBatch140: loss = 5.5254\nBatch141: loss = 5.7192\nBatch142: loss = 4.6568\nBatch143: loss = 5.2580\nBatch144: loss = 5.4298\nBatch145: loss = 5.3622\nBatch146: loss = 5.3735\nBatch147: loss = 5.6072\nBatch148: loss = 5.0878\nBatch149: loss = 5.3175\nBatch150: loss = 5.2047\nBatch151: loss = 5.6469\nBatch152: loss = 4.7771\nBatch153: loss = 5.0010\nBatch154: loss = 5.3651\nBatch155: loss = 5.1154\nBatch156: loss = 5.4405\nBatch157: loss = 5.0160\nBatch158: loss = 5.4093\nBatch159: loss = 4.9673\nBatch160: loss = 5.2273\nBatch161: loss = 4.9807\nBatch162: loss = 4.9150\nBatch163: loss = 4.9003\nBatch164: loss = 5.6165\nBatch165: loss = 5.0424\nBatch166: loss = 5.4088\nBatch167: loss = 5.4459\nBatch168: loss = 4.9787\nBatch169: loss = 5.3997\nBatch170: loss = 5.5035\nBatch171: loss = 5.2268\nBatch172: loss = 4.5406\nBatch173: loss = 5.3547\nBatch174: loss = 5.3781\nBatch175: loss = 5.0234\nBatch176: loss = 5.4366\nBatch177: loss = 5.2416\nBatch178: loss = 5.4414\nBatch179: loss = 5.5718\nBatch180: loss = 4.8600\nBatch181: loss = 4.9728\nBatch182: loss = 5.7424\nBatch183: loss = 5.0470\nBatch184: loss = 5.3204\nBatch185: loss = 5.3032\nBatch186: loss = 5.2308\nBatch187: loss = 5.6954\nBatch188: loss = 5.5992\nBatch189: loss = 5.0373\nBatch190: loss = 5.0871\nBatch191: loss = 5.0952\nBatch192: loss = 4.9040\nBatch193: loss = 5.1399\nBatch194: loss = 5.2566\nBatch195: loss = 5.8128\nBatch196: loss = 4.8589\nBatch197: loss = 5.0908\nBatch198: loss = 5.1459\nBatch199: loss = 5.3624\nstep 6500: train loss 5.0190, val loss 5.2408\nBatch0: loss = 4.8162\nBatch1: loss = 5.1132\nBatch2: loss = 4.9557\nBatch3: loss = 5.3901\nBatch4: loss = 4.9622\nBatch5: loss = 4.5586\nBatch6: loss = 4.8137\nBatch7: loss = 5.0984\nBatch8: loss = 5.1942\nBatch9: loss = 4.6766\nBatch10: loss = 5.1157\nBatch11: loss = 4.8154\nBatch12: loss = 4.9592\nBatch13: loss = 5.1392\nBatch14: loss = 5.3764\nBatch15: loss = 5.4723\nBatch16: loss = 5.2117\nBatch17: loss = 4.8961\nBatch18: loss = 4.9131\nBatch19: loss = 5.0707\nBatch20: loss = 4.7855\nBatch21: loss = 5.1876\nBatch22: loss = 5.1322\nBatch23: loss = 5.2560\nBatch24: loss = 5.3426\nBatch25: loss = 4.8105\nBatch26: loss = 5.3456\nBatch27: loss = 5.3540\nBatch28: loss = 4.8443\nBatch29: loss = 5.2562\nBatch30: loss = 4.9103\nBatch31: loss = 5.4140\nBatch32: loss = 4.6939\nBatch33: loss = 4.8408\nBatch34: loss = 4.9600\nBatch35: loss = 5.4469\nBatch36: loss = 5.0536\nBatch37: loss = 5.0323\nBatch38: loss = 4.9058\nBatch39: loss = 5.2755\nBatch40: loss = 4.9144\nBatch41: loss = 5.1345\nBatch42: loss = 4.8432\nBatch43: loss = 5.0403\nBatch44: loss = 5.2031\nBatch45: loss = 5.2118\nBatch46: loss = 4.9628\nBatch47: loss = 4.8606\nBatch48: loss = 5.2808\nBatch49: loss = 5.1701\nBatch50: loss = 4.7046\nBatch51: loss = 4.9537\nBatch52: loss = 5.1773\nBatch53: loss = 4.6975\nBatch54: loss = 5.0547\nBatch55: loss = 4.7750\nBatch56: loss = 5.5907\nBatch57: loss = 5.1335\nBatch58: loss = 4.7572\nBatch59: loss = 5.4174\nBatch60: loss = 5.2719\nBatch61: loss = 4.8620\nBatch62: loss = 4.9144\nBatch63: loss = 5.2253\nBatch64: loss = 4.8230\nBatch65: loss = 5.0389\nBatch66: loss = 4.7370\nBatch67: loss = 4.8247\nBatch68: loss = 5.4264\nBatch69: loss = 4.9222\nBatch70: loss = 5.0211\nBatch71: loss = 4.6212\nBatch72: loss = 4.7657\nBatch73: loss = 5.0623\nBatch74: loss = 4.5596\nBatch75: loss = 5.0461\nBatch76: loss = 5.3347\nBatch77: loss = 4.8383\nBatch78: loss = 4.8933\nBatch79: loss = 5.0374\nBatch80: loss = 4.9245\nBatch81: loss = 4.7286\nBatch82: loss = 4.9112\nBatch83: loss = 5.0238\nBatch84: loss = 4.7977\nBatch85: loss = 5.2588\nBatch86: loss = 4.7503\nBatch87: loss = 5.0335\nBatch88: loss = 5.2344\nBatch89: loss = 4.8730\nBatch90: loss = 5.1548\nBatch91: loss = 4.9206\nBatch92: loss = 5.2058\nBatch93: loss = 4.4890\nBatch94: loss = 4.6316\nBatch95: loss = 4.7460\nBatch96: loss = 5.1295\nBatch97: loss = 5.0978\nBatch98: loss = 4.8531\nBatch99: loss = 5.4379\nBatch100: loss = 5.1426\nBatch101: loss = 4.8661\nBatch102: loss = 5.0312\nBatch103: loss = 4.9085\nBatch104: loss = 5.0581\nBatch105: loss = 5.0319\nBatch106: loss = 5.1591\nBatch107: loss = 5.1139\nBatch108: loss = 4.7996\nBatch109: loss = 5.0215\nBatch110: loss = 5.2945\nBatch111: loss = 4.7788\nBatch112: loss = 4.7571\nBatch113: loss = 5.0615\nBatch114: loss = 4.8195\nBatch115: loss = 5.0745\nBatch116: loss = 5.0037\nBatch117: loss = 4.5896\nBatch118: loss = 4.6542\nBatch119: loss = 5.1229\nBatch120: loss = 5.5184\nBatch121: loss = 4.8994\nBatch122: loss = 4.6951\nBatch123: loss = 4.9205\nBatch124: loss = 5.0220\nBatch125: loss = 4.6111\nBatch126: loss = 5.2433\nBatch127: loss = 4.8255\nBatch128: loss = 4.8188\nBatch129: loss = 4.7649\nBatch130: loss = 5.1182\nBatch131: loss = 4.9123\nBatch132: loss = 5.1476\nBatch133: loss = 4.8702\nBatch134: loss = 4.7342\nBatch135: loss = 5.0287\nBatch136: loss = 4.8359\nBatch137: loss = 5.0086\nBatch138: loss = 4.8752\nBatch139: loss = 4.8860\nBatch140: loss = 5.3685\nBatch141: loss = 5.1190\nBatch142: loss = 5.4554\nBatch143: loss = 5.3308\nBatch144: loss = 5.3443\nBatch145: loss = 5.1367\nBatch146: loss = 5.1125\nBatch147: loss = 4.7570\nBatch148: loss = 5.0567\nBatch149: loss = 4.9024\nBatch150: loss = 4.9706\nBatch151: loss = 4.9732\nBatch152: loss = 5.0147\nBatch153: loss = 5.0081\nBatch154: loss = 5.4593\nBatch155: loss = 5.0126\nBatch156: loss = 4.9772\nBatch157: loss = 5.0193\nBatch158: loss = 4.8607\nBatch159: loss = 4.9648\nBatch160: loss = 4.7955\nBatch161: loss = 5.0133\nBatch162: loss = 5.0462\nBatch163: loss = 5.0021\nBatch164: loss = 5.2683\nBatch165: loss = 4.8888\nBatch166: loss = 5.4437\nBatch167: loss = 4.8000\nBatch168: loss = 4.9212\nBatch169: loss = 4.8271\nBatch170: loss = 4.9833\nBatch171: loss = 4.9705\nBatch172: loss = 5.2243\nBatch173: loss = 5.2192\nBatch174: loss = 4.9554\nBatch175: loss = 5.2178\nBatch176: loss = 4.9322\nBatch177: loss = 5.1498\nBatch178: loss = 4.7741\nBatch179: loss = 4.6732\nBatch180: loss = 5.1545\nBatch181: loss = 5.3373\nBatch182: loss = 4.7847\nBatch183: loss = 5.2687\nBatch184: loss = 4.8878\nBatch185: loss = 5.0003\nBatch186: loss = 4.9887\nBatch187: loss = 4.9238\nBatch188: loss = 5.2905\nBatch189: loss = 5.1307\nBatch190: loss = 5.0892\nBatch191: loss = 4.6902\nBatch192: loss = 5.0347\nBatch193: loss = 5.2450\nBatch194: loss = 4.9571\nBatch195: loss = 5.0396\nBatch196: loss = 5.2985\nBatch197: loss = 5.2356\nBatch198: loss = 5.0513\nBatch199: loss = 5.2214\nBatch0: loss = 5.1608\nBatch1: loss = 4.7322\nBatch2: loss = 5.4442\nBatch3: loss = 5.3919\nBatch4: loss = 5.3826\nBatch5: loss = 5.0176\nBatch6: loss = 5.2678\nBatch7: loss = 5.3011\nBatch8: loss = 5.0228\nBatch9: loss = 5.1046\nBatch10: loss = 4.7472\nBatch11: loss = 5.3859\nBatch12: loss = 4.7041\nBatch13: loss = 4.8663\nBatch14: loss = 4.9028\nBatch15: loss = 5.2330\nBatch16: loss = 5.5837\nBatch17: loss = 4.7700\nBatch18: loss = 5.2485\nBatch19: loss = 5.2047\nBatch20: loss = 5.4005\nBatch21: loss = 4.8195\nBatch22: loss = 5.3386\nBatch23: loss = 5.1070\nBatch24: loss = 4.9200\nBatch25: loss = 5.1231\nBatch26: loss = 5.3435\nBatch27: loss = 5.2387\nBatch28: loss = 5.2012\nBatch29: loss = 5.3930\nBatch30: loss = 4.7655\nBatch31: loss = 5.1040\nBatch32: loss = 5.1153\nBatch33: loss = 4.9877\nBatch34: loss = 5.3666\nBatch35: loss = 4.6680\nBatch36: loss = 5.6301\nBatch37: loss = 5.4033\nBatch38: loss = 5.3502\nBatch39: loss = 5.5150\nBatch40: loss = 5.2884\nBatch41: loss = 5.0350\nBatch42: loss = 5.5298\nBatch43: loss = 5.0572\nBatch44: loss = 5.5221\nBatch45: loss = 5.1458\nBatch46: loss = 4.9305\nBatch47: loss = 5.2231\nBatch48: loss = 5.1448\nBatch49: loss = 5.0573\nBatch50: loss = 5.0258\nBatch51: loss = 5.2191\nBatch52: loss = 5.0696\nBatch53: loss = 5.4078\nBatch54: loss = 5.3682\nBatch55: loss = 5.2101\nBatch56: loss = 5.1077\nBatch57: loss = 5.3084\nBatch58: loss = 5.6230\nBatch59: loss = 4.8113\nBatch60: loss = 5.5993\nBatch61: loss = 5.0630\nBatch62: loss = 5.0383\nBatch63: loss = 5.0997\nBatch64: loss = 5.1712\nBatch65: loss = 5.5101\nBatch66: loss = 5.1067\nBatch67: loss = 5.2488\nBatch68: loss = 5.4100\nBatch69: loss = 5.3234\nBatch70: loss = 4.9389\nBatch71: loss = 5.3524\nBatch72: loss = 5.3291\nBatch73: loss = 4.9019\nBatch74: loss = 5.2051\nBatch75: loss = 4.8797\nBatch76: loss = 5.1807\nBatch77: loss = 4.9958\nBatch78: loss = 4.8961\nBatch79: loss = 5.0290\nBatch80: loss = 5.3385\nBatch81: loss = 4.9125\nBatch82: loss = 5.0629\nBatch83: loss = 5.0654\nBatch84: loss = 5.2506\nBatch85: loss = 5.1722\nBatch86: loss = 5.2430\nBatch87: loss = 5.2349\nBatch88: loss = 5.0960\nBatch89: loss = 5.6657\nBatch90: loss = 5.5927\nBatch91: loss = 5.4644\nBatch92: loss = 5.3783\nBatch93: loss = 5.2354\nBatch94: loss = 5.0965\nBatch95: loss = 5.2500\nBatch96: loss = 5.4672\nBatch97: loss = 5.1174\nBatch98: loss = 5.2736\nBatch99: loss = 5.5831\nBatch100: loss = 4.5111\nBatch101: loss = 5.1973\nBatch102: loss = 5.7588\nBatch103: loss = 4.9260\nBatch104: loss = 5.2611\nBatch105: loss = 5.7276\nBatch106: loss = 5.2763\nBatch107: loss = 5.0506\nBatch108: loss = 4.9929\nBatch109: loss = 4.8856\nBatch110: loss = 5.1564\nBatch111: loss = 5.0147\nBatch112: loss = 4.9223\nBatch113: loss = 4.9693\nBatch114: loss = 5.5291\nBatch115: loss = 4.8345\nBatch116: loss = 5.0619\nBatch117: loss = 4.9486\nBatch118: loss = 4.8739\nBatch119: loss = 4.8808\nBatch120: loss = 5.3305\nBatch121: loss = 4.8317\nBatch122: loss = 5.0065\nBatch123: loss = 5.1434\nBatch124: loss = 5.4364\nBatch125: loss = 5.4804\nBatch126: loss = 5.4833\nBatch127: loss = 5.5139\nBatch128: loss = 5.2601\nBatch129: loss = 4.9884\nBatch130: loss = 5.0343\nBatch131: loss = 5.3889\nBatch132: loss = 5.0932\nBatch133: loss = 5.4404\nBatch134: loss = 5.0043\nBatch135: loss = 5.8336\nBatch136: loss = 5.1550\nBatch137: loss = 5.0494\nBatch138: loss = 5.4492\nBatch139: loss = 5.2009\nBatch140: loss = 5.0073\nBatch141: loss = 5.4087\nBatch142: loss = 5.5654\nBatch143: loss = 5.2577\nBatch144: loss = 5.0164\nBatch145: loss = 5.2449\nBatch146: loss = 5.5833\nBatch147: loss = 5.1370\nBatch148: loss = 4.7969\nBatch149: loss = 4.9235\nBatch150: loss = 5.4954\nBatch151: loss = 5.6530\nBatch152: loss = 5.3971\nBatch153: loss = 4.9598\nBatch154: loss = 5.5066\nBatch155: loss = 4.7971\nBatch156: loss = 5.4351\nBatch157: loss = 5.1032\nBatch158: loss = 5.4329\nBatch159: loss = 4.8040\nBatch160: loss = 5.1239\nBatch161: loss = 5.6980\nBatch162: loss = 4.8744\nBatch163: loss = 5.1284\nBatch164: loss = 5.6084\nBatch165: loss = 5.4108\nBatch166: loss = 5.5826\nBatch167: loss = 5.1235\nBatch168: loss = 5.2846\nBatch169: loss = 5.6648\nBatch170: loss = 5.4949\nBatch171: loss = 4.9788\nBatch172: loss = 5.4524\nBatch173: loss = 5.0247\nBatch174: loss = 5.2941\nBatch175: loss = 5.3295\nBatch176: loss = 5.1154\nBatch177: loss = 5.2990\nBatch178: loss = 5.1058\nBatch179: loss = 5.0986\nBatch180: loss = 5.4200\nBatch181: loss = 5.0568\nBatch182: loss = 5.2062\nBatch183: loss = 5.3417\nBatch184: loss = 5.1267\nBatch185: loss = 5.1448\nBatch186: loss = 5.3503\nBatch187: loss = 5.6268\nBatch188: loss = 4.5132\nBatch189: loss = 5.4661\nBatch190: loss = 5.1848\nBatch191: loss = 5.1562\nBatch192: loss = 4.8187\nBatch193: loss = 4.9708\nBatch194: loss = 5.0607\nBatch195: loss = 5.5515\nBatch196: loss = 5.5213\nBatch197: loss = 5.1888\nBatch198: loss = 5.1235\nBatch199: loss = 4.9495\nstep 7000: train loss 5.0166, val loss 5.2001\nBatch0: loss = 4.7298\nBatch1: loss = 4.8529\nBatch2: loss = 5.1414\nBatch3: loss = 4.7663\nBatch4: loss = 5.4582\nBatch5: loss = 5.2756\nBatch6: loss = 4.8895\nBatch7: loss = 5.1179\nBatch8: loss = 5.3164\nBatch9: loss = 4.7721\nBatch10: loss = 4.7873\nBatch11: loss = 5.2238\nBatch12: loss = 4.9022\nBatch13: loss = 4.9360\nBatch14: loss = 4.6419\nBatch15: loss = 4.9792\nBatch16: loss = 4.8492\nBatch17: loss = 4.6380\nBatch18: loss = 5.2406\nBatch19: loss = 4.9197\nBatch20: loss = 4.8090\nBatch21: loss = 5.0927\nBatch22: loss = 4.9197\nBatch23: loss = 4.7355\nBatch24: loss = 4.7776\nBatch25: loss = 5.3427\nBatch26: loss = 4.7895\nBatch27: loss = 5.0838\nBatch28: loss = 5.0179\nBatch29: loss = 5.4914\nBatch30: loss = 5.2820\nBatch31: loss = 4.8053\nBatch32: loss = 4.9448\nBatch33: loss = 5.0258\nBatch34: loss = 4.9497\nBatch35: loss = 4.9976\nBatch36: loss = 5.1827\nBatch37: loss = 4.9838\nBatch38: loss = 4.7745\nBatch39: loss = 4.6323\nBatch40: loss = 4.9714\nBatch41: loss = 4.9249\nBatch42: loss = 5.2881\nBatch43: loss = 5.0344\nBatch44: loss = 5.3939\nBatch45: loss = 4.8481\nBatch46: loss = 4.9817\nBatch47: loss = 4.9102\nBatch48: loss = 5.0780\nBatch49: loss = 4.9915\nBatch50: loss = 4.9432\nBatch51: loss = 5.0255\nBatch52: loss = 4.6397\nBatch53: loss = 5.3914\nBatch54: loss = 5.0486\nBatch55: loss = 5.3381\nBatch56: loss = 4.6878\nBatch57: loss = 4.8617\nBatch58: loss = 5.0357\nBatch59: loss = 5.3073\nBatch60: loss = 4.9250\nBatch61: loss = 5.1802\nBatch62: loss = 4.6133\nBatch63: loss = 4.7105\nBatch64: loss = 5.1174\nBatch65: loss = 4.9975\nBatch66: loss = 4.9791\nBatch67: loss = 5.4302\nBatch68: loss = 5.1004\nBatch69: loss = 4.7151\nBatch70: loss = 5.1853\nBatch71: loss = 5.0001\nBatch72: loss = 5.0598\nBatch73: loss = 4.9647\nBatch74: loss = 4.9824\nBatch75: loss = 5.0250\nBatch76: loss = 4.9898\nBatch77: loss = 5.0456\nBatch78: loss = 4.5147\nBatch79: loss = 5.3205\nBatch80: loss = 5.1865\nBatch81: loss = 4.8203\nBatch82: loss = 5.1358\nBatch83: loss = 5.0588\nBatch84: loss = 4.9106\nBatch85: loss = 4.9729\nBatch86: loss = 4.8582\nBatch87: loss = 4.9007\nBatch88: loss = 5.0531\nBatch89: loss = 4.9557\nBatch90: loss = 4.9887\nBatch91: loss = 5.2612\nBatch92: loss = 4.9270\nBatch93: loss = 4.8998\nBatch94: loss = 5.0501\nBatch95: loss = 4.9947\nBatch96: loss = 5.1747\nBatch97: loss = 5.1618\nBatch98: loss = 4.7771\nBatch99: loss = 4.8062\nBatch100: loss = 5.0103\nBatch101: loss = 5.2478\nBatch102: loss = 4.6858\nBatch103: loss = 5.0169\nBatch104: loss = 5.1365\nBatch105: loss = 5.0716\nBatch106: loss = 5.0212\nBatch107: loss = 5.2633\nBatch108: loss = 5.1588\nBatch109: loss = 5.2955\nBatch110: loss = 5.1269\nBatch111: loss = 4.9676\nBatch112: loss = 4.9637\nBatch113: loss = 4.9140\nBatch114: loss = 5.3055\nBatch115: loss = 5.2046\nBatch116: loss = 5.0490\nBatch117: loss = 5.1022\nBatch118: loss = 4.8665\nBatch119: loss = 5.1432\nBatch120: loss = 5.0047\nBatch121: loss = 4.7410\nBatch122: loss = 4.7243\nBatch123: loss = 4.5005\nBatch124: loss = 4.7428\nBatch125: loss = 4.5104\nBatch126: loss = 4.9478\nBatch127: loss = 4.8689\nBatch128: loss = 5.1437\nBatch129: loss = 5.0088\nBatch130: loss = 4.7955\nBatch131: loss = 5.4281\nBatch132: loss = 5.2212\nBatch133: loss = 4.6430\nBatch134: loss = 5.2430\nBatch135: loss = 5.1387\nBatch136: loss = 5.0120\nBatch137: loss = 5.2265\nBatch138: loss = 4.9412\nBatch139: loss = 4.7711\nBatch140: loss = 5.2359\nBatch141: loss = 5.1776\nBatch142: loss = 4.9115\nBatch143: loss = 5.0519\nBatch144: loss = 5.0656\nBatch145: loss = 5.0063\nBatch146: loss = 4.7381\nBatch147: loss = 5.4359\nBatch148: loss = 5.0887\nBatch149: loss = 4.8099\nBatch150: loss = 5.0721\nBatch151: loss = 5.1450\nBatch152: loss = 4.8018\nBatch153: loss = 4.9058\nBatch154: loss = 5.0828\nBatch155: loss = 5.0374\nBatch156: loss = 4.8449\nBatch157: loss = 4.9671\nBatch158: loss = 5.4661\nBatch159: loss = 4.9351\nBatch160: loss = 4.9466\nBatch161: loss = 4.9839\nBatch162: loss = 5.1580\nBatch163: loss = 5.1561\nBatch164: loss = 5.2877\nBatch165: loss = 5.2125\nBatch166: loss = 5.0716\nBatch167: loss = 4.8973\nBatch168: loss = 5.0804\nBatch169: loss = 4.8537\nBatch170: loss = 5.0684\nBatch171: loss = 5.0500\nBatch172: loss = 4.9229\nBatch173: loss = 5.3487\nBatch174: loss = 4.9938\nBatch175: loss = 5.3285\nBatch176: loss = 5.0555\nBatch177: loss = 5.2806\nBatch178: loss = 5.0393\nBatch179: loss = 4.7575\nBatch180: loss = 5.0474\nBatch181: loss = 4.7858\nBatch182: loss = 4.8772\nBatch183: loss = 5.1030\nBatch184: loss = 4.7766\nBatch185: loss = 5.1970\nBatch186: loss = 4.8571\nBatch187: loss = 5.0458\nBatch188: loss = 4.9770\nBatch189: loss = 5.1157\nBatch190: loss = 5.1976\nBatch191: loss = 4.7490\nBatch192: loss = 5.1633\nBatch193: loss = 4.7476\nBatch194: loss = 4.6341\nBatch195: loss = 5.2731\nBatch196: loss = 4.9127\nBatch197: loss = 5.2587\nBatch198: loss = 5.0654\nBatch199: loss = 4.8161\nBatch0: loss = 5.6170\nBatch1: loss = 4.7633\nBatch2: loss = 5.3600\nBatch3: loss = 4.9350\nBatch4: loss = 4.7463\nBatch5: loss = 5.0201\nBatch6: loss = 5.2824\nBatch7: loss = 5.1711\nBatch8: loss = 5.4570\nBatch9: loss = 4.9842\nBatch10: loss = 5.2355\nBatch11: loss = 5.1049\nBatch12: loss = 5.0840\nBatch13: loss = 5.6066\nBatch14: loss = 5.3226\nBatch15: loss = 5.6679\nBatch16: loss = 4.9848\nBatch17: loss = 5.4148\nBatch18: loss = 5.1129\nBatch19: loss = 5.1351\nBatch20: loss = 4.8438\nBatch21: loss = 5.1188\nBatch22: loss = 5.1646\nBatch23: loss = 5.1738\nBatch24: loss = 5.4000\nBatch25: loss = 5.1797\nBatch26: loss = 5.1948\nBatch27: loss = 5.2688\nBatch28: loss = 4.9957\nBatch29: loss = 5.2990\nBatch30: loss = 5.2506\nBatch31: loss = 4.9656\nBatch32: loss = 4.9656\nBatch33: loss = 4.9992\nBatch34: loss = 5.4013\nBatch35: loss = 5.2127\nBatch36: loss = 4.7379\nBatch37: loss = 4.8257\nBatch38: loss = 4.9979\nBatch39: loss = 5.2824\nBatch40: loss = 5.1957\nBatch41: loss = 5.4286\nBatch42: loss = 5.2999\nBatch43: loss = 5.0893\nBatch44: loss = 4.9167\nBatch45: loss = 5.3265\nBatch46: loss = 4.8048\nBatch47: loss = 4.9664\nBatch48: loss = 4.9951\nBatch49: loss = 5.2753\nBatch50: loss = 5.4272\nBatch51: loss = 4.9970\nBatch52: loss = 5.0408\nBatch53: loss = 4.8104\nBatch54: loss = 5.5215\nBatch55: loss = 5.2329\nBatch56: loss = 5.3900\nBatch57: loss = 5.2335\nBatch58: loss = 5.4898\nBatch59: loss = 4.7848\nBatch60: loss = 5.2723\nBatch61: loss = 5.4483\nBatch62: loss = 5.4010\nBatch63: loss = 5.4610\nBatch64: loss = 5.0592\nBatch65: loss = 5.3232\nBatch66: loss = 4.8174\nBatch67: loss = 5.1288\nBatch68: loss = 5.0547\nBatch69: loss = 5.3330\nBatch70: loss = 4.8590\nBatch71: loss = 5.2122\nBatch72: loss = 5.2491\nBatch73: loss = 5.1244\nBatch74: loss = 5.2365\nBatch75: loss = 4.8257\nBatch76: loss = 5.2724\nBatch77: loss = 4.6832\nBatch78: loss = 5.3065\nBatch79: loss = 5.0338\nBatch80: loss = 5.3412\nBatch81: loss = 4.8275\nBatch82: loss = 5.1530\nBatch83: loss = 5.2622\nBatch84: loss = 5.4744\nBatch85: loss = 5.1754\nBatch86: loss = 5.5274\nBatch87: loss = 4.7441\nBatch88: loss = 5.6525\nBatch89: loss = 4.6709\nBatch90: loss = 5.0651\nBatch91: loss = 5.0608\nBatch92: loss = 5.2897\nBatch93: loss = 5.1385\nBatch94: loss = 5.0221\nBatch95: loss = 5.1369\nBatch96: loss = 5.0538\nBatch97: loss = 5.5569\nBatch98: loss = 5.3869\nBatch99: loss = 5.3663\nBatch100: loss = 5.1172\nBatch101: loss = 4.9178\nBatch102: loss = 5.1254\nBatch103: loss = 5.3155\nBatch104: loss = 4.8300\nBatch105: loss = 5.2846\nBatch106: loss = 4.9501\nBatch107: loss = 5.3376\nBatch108: loss = 5.1150\nBatch109: loss = 4.9444\nBatch110: loss = 5.0570\nBatch111: loss = 5.3201\nBatch112: loss = 4.8893\nBatch113: loss = 5.0355\nBatch114: loss = 5.5706\nBatch115: loss = 4.9941\nBatch116: loss = 5.0932\nBatch117: loss = 5.3942\nBatch118: loss = 5.0431\nBatch119: loss = 4.9825\nBatch120: loss = 5.3235\nBatch121: loss = 5.0724\nBatch122: loss = 5.2519\nBatch123: loss = 5.0290\nBatch124: loss = 5.3510\nBatch125: loss = 5.3470\nBatch126: loss = 5.5209\nBatch127: loss = 5.0664\nBatch128: loss = 5.4179\nBatch129: loss = 4.9305\nBatch130: loss = 5.1016\nBatch131: loss = 5.2661\nBatch132: loss = 5.4102\nBatch133: loss = 4.9802\nBatch134: loss = 5.1285\nBatch135: loss = 5.4412\nBatch136: loss = 5.3595\nBatch137: loss = 4.9337\nBatch138: loss = 5.1845\nBatch139: loss = 5.5999\nBatch140: loss = 5.1824\nBatch141: loss = 5.0494\nBatch142: loss = 5.6194\nBatch143: loss = 4.8042\nBatch144: loss = 5.4496\nBatch145: loss = 4.9485\nBatch146: loss = 5.5545\nBatch147: loss = 5.2476\nBatch148: loss = 4.8783\nBatch149: loss = 4.8244\nBatch150: loss = 4.8971\nBatch151: loss = 5.7084\nBatch152: loss = 5.0508\nBatch153: loss = 4.8379\nBatch154: loss = 4.9379\nBatch155: loss = 5.3340\nBatch156: loss = 5.4239\nBatch157: loss = 4.8946\nBatch158: loss = 4.7728\nBatch159: loss = 5.7189\nBatch160: loss = 5.0280\nBatch161: loss = 5.0644\nBatch162: loss = 5.2979\nBatch163: loss = 4.7908\nBatch164: loss = 5.1047\nBatch165: loss = 5.2067\nBatch166: loss = 5.1517\nBatch167: loss = 4.8726\nBatch168: loss = 5.0323\nBatch169: loss = 5.1036\nBatch170: loss = 5.0666\nBatch171: loss = 5.4017\nBatch172: loss = 4.6106\nBatch173: loss = 5.2377\nBatch174: loss = 5.0744\nBatch175: loss = 5.0453\nBatch176: loss = 4.8298\nBatch177: loss = 5.0943\nBatch178: loss = 5.1516\nBatch179: loss = 5.5464\nBatch180: loss = 5.3405\nBatch181: loss = 5.1408\nBatch182: loss = 4.9259\nBatch183: loss = 5.7114\nBatch184: loss = 5.6454\nBatch185: loss = 4.7437\nBatch186: loss = 5.4229\nBatch187: loss = 5.4312\nBatch188: loss = 5.8601\nBatch189: loss = 4.8747\nBatch190: loss = 5.2195\nBatch191: loss = 5.2863\nBatch192: loss = 5.3383\nBatch193: loss = 4.9022\nBatch194: loss = 5.1857\nBatch195: loss = 5.1504\nBatch196: loss = 5.1157\nBatch197: loss = 5.0936\nBatch198: loss = 5.3475\nBatch199: loss = 5.0350\nstep 7500: train loss 5.0078, val loss 5.1658\nBatch0: loss = 5.2748\nBatch1: loss = 4.9237\nBatch2: loss = 4.5489\nBatch3: loss = 5.3026\nBatch4: loss = 5.0837\nBatch5: loss = 5.0092\nBatch6: loss = 4.7406\nBatch7: loss = 4.8062\nBatch8: loss = 4.9385\nBatch9: loss = 4.8892\nBatch10: loss = 5.3111\nBatch11: loss = 4.6772\nBatch12: loss = 4.9732\nBatch13: loss = 5.1539\nBatch14: loss = 5.1215\nBatch15: loss = 4.9489\nBatch16: loss = 4.8796\nBatch17: loss = 4.9844\nBatch18: loss = 5.4589\nBatch19: loss = 4.6808\nBatch20: loss = 5.0058\nBatch21: loss = 5.2188\nBatch22: loss = 5.1543\nBatch23: loss = 4.9167\nBatch24: loss = 4.6136\nBatch25: loss = 4.6585\nBatch26: loss = 5.0372\nBatch27: loss = 5.0200\nBatch28: loss = 5.4785\nBatch29: loss = 5.0041\nBatch30: loss = 5.3137\nBatch31: loss = 5.1587\nBatch32: loss = 4.7689\nBatch33: loss = 4.8765\nBatch34: loss = 4.8011\nBatch35: loss = 5.0288\nBatch36: loss = 4.9464\nBatch37: loss = 4.7112\nBatch38: loss = 4.7185\nBatch39: loss = 5.2304\nBatch40: loss = 4.9701\nBatch41: loss = 4.9782\nBatch42: loss = 4.6557\nBatch43: loss = 4.7372\nBatch44: loss = 5.3106\nBatch45: loss = 5.1777\nBatch46: loss = 4.8547\nBatch47: loss = 4.8558\nBatch48: loss = 5.0576\nBatch49: loss = 5.0530\nBatch50: loss = 5.0446\nBatch51: loss = 5.3022\nBatch52: loss = 4.7104\nBatch53: loss = 5.0520\nBatch54: loss = 5.1914\nBatch55: loss = 4.8771\nBatch56: loss = 5.1420\nBatch57: loss = 4.5161\nBatch58: loss = 5.2797\nBatch59: loss = 5.0240\nBatch60: loss = 4.8445\nBatch61: loss = 5.1517\nBatch62: loss = 4.4452\nBatch63: loss = 5.0710\nBatch64: loss = 4.8871\nBatch65: loss = 5.0204\nBatch66: loss = 5.4343\nBatch67: loss = 5.1363\nBatch68: loss = 4.9327\nBatch69: loss = 5.3483\nBatch70: loss = 5.0103\nBatch71: loss = 5.0549\nBatch72: loss = 5.4176\nBatch73: loss = 5.1289\nBatch74: loss = 4.8296\nBatch75: loss = 4.5097\nBatch76: loss = 4.7326\nBatch77: loss = 4.6988\nBatch78: loss = 5.2537\nBatch79: loss = 4.7509\nBatch80: loss = 5.1851\nBatch81: loss = 5.1316\nBatch82: loss = 5.2136\nBatch83: loss = 4.9931\nBatch84: loss = 5.0048\nBatch85: loss = 4.7338\nBatch86: loss = 4.7147\nBatch87: loss = 5.0824\nBatch88: loss = 5.0828\nBatch89: loss = 4.8546\nBatch90: loss = 5.5325\nBatch91: loss = 5.1385\nBatch92: loss = 4.8948\nBatch93: loss = 5.4295\nBatch94: loss = 4.9314\nBatch95: loss = 5.3152\nBatch96: loss = 4.9887\nBatch97: loss = 5.0239\nBatch98: loss = 5.2129\nBatch99: loss = 4.7452\nBatch100: loss = 5.1921\nBatch101: loss = 5.0954\nBatch102: loss = 4.9004\nBatch103: loss = 5.0247\nBatch104: loss = 5.2826\nBatch105: loss = 4.9292\nBatch106: loss = 5.3545\nBatch107: loss = 4.7958\nBatch108: loss = 4.8176\nBatch109: loss = 5.3554\nBatch110: loss = 4.6270\nBatch111: loss = 4.7992\nBatch112: loss = 5.1122\nBatch113: loss = 5.2307\nBatch114: loss = 4.9520\nBatch115: loss = 4.6939\nBatch116: loss = 5.3409\nBatch117: loss = 4.9437\nBatch118: loss = 5.1004\nBatch119: loss = 4.9936\nBatch120: loss = 4.6449\nBatch121: loss = 5.0108\nBatch122: loss = 4.9384\nBatch123: loss = 5.2623\nBatch124: loss = 4.5112\nBatch125: loss = 5.2164\nBatch126: loss = 5.0209\nBatch127: loss = 4.8386\nBatch128: loss = 4.7567\nBatch129: loss = 5.1757\nBatch130: loss = 5.3230\nBatch131: loss = 4.9719\nBatch132: loss = 4.9839\nBatch133: loss = 5.3589\nBatch134: loss = 4.7575\nBatch135: loss = 5.3149\nBatch136: loss = 5.2195\nBatch137: loss = 5.0482\nBatch138: loss = 4.6722\nBatch139: loss = 5.1150\nBatch140: loss = 5.1198\nBatch141: loss = 4.7340\nBatch142: loss = 5.2684\nBatch143: loss = 4.8451\nBatch144: loss = 5.0698\nBatch145: loss = 5.2439\nBatch146: loss = 5.0444\nBatch147: loss = 4.8908\nBatch148: loss = 4.9681\nBatch149: loss = 4.9444\nBatch150: loss = 4.8099\nBatch151: loss = 5.0707\nBatch152: loss = 5.1247\nBatch153: loss = 4.6080\nBatch154: loss = 4.8850\nBatch155: loss = 4.7871\nBatch156: loss = 5.3571\nBatch157: loss = 4.7201\nBatch158: loss = 5.4091\nBatch159: loss = 4.8188\nBatch160: loss = 4.6683\nBatch161: loss = 4.7180\nBatch162: loss = 4.7432\nBatch163: loss = 4.7563\nBatch164: loss = 4.6747\nBatch165: loss = 5.0211\nBatch166: loss = 4.9967\nBatch167: loss = 5.0425\nBatch168: loss = 4.7897\nBatch169: loss = 5.2022\nBatch170: loss = 4.7708\nBatch171: loss = 4.7638\nBatch172: loss = 4.8645\nBatch173: loss = 5.0200\nBatch174: loss = 4.9709\nBatch175: loss = 4.9664\nBatch176: loss = 5.1475\nBatch177: loss = 5.1137\nBatch178: loss = 4.4275\nBatch179: loss = 4.4641\nBatch180: loss = 4.9774\nBatch181: loss = 5.0990\nBatch182: loss = 4.8826\nBatch183: loss = 4.7956\nBatch184: loss = 5.2428\nBatch185: loss = 4.9384\nBatch186: loss = 4.7894\nBatch187: loss = 4.9825\nBatch188: loss = 4.9736\nBatch189: loss = 5.0683\nBatch190: loss = 4.7577\nBatch191: loss = 5.3223\nBatch192: loss = 5.3310\nBatch193: loss = 4.5351\nBatch194: loss = 4.8237\nBatch195: loss = 4.8437\nBatch196: loss = 5.0260\nBatch197: loss = 4.8182\nBatch198: loss = 4.9148\nBatch199: loss = 4.9537\nBatch0: loss = 4.7349\nBatch1: loss = 4.7542\nBatch2: loss = 4.8059\nBatch3: loss = 5.2484\nBatch4: loss = 5.2976\nBatch5: loss = 5.0661\nBatch6: loss = 5.1313\nBatch7: loss = 5.0671\nBatch8: loss = 5.0257\nBatch9: loss = 5.3660\nBatch10: loss = 5.4216\nBatch11: loss = 5.2494\nBatch12: loss = 4.9834\nBatch13: loss = 5.2881\nBatch14: loss = 5.2275\nBatch15: loss = 4.9231\nBatch16: loss = 5.1069\nBatch17: loss = 4.8022\nBatch18: loss = 5.2894\nBatch19: loss = 4.9021\nBatch20: loss = 4.8393\nBatch21: loss = 5.1150\nBatch22: loss = 5.0993\nBatch23: loss = 5.2815\nBatch24: loss = 5.2802\nBatch25: loss = 4.7946\nBatch26: loss = 5.3836\nBatch27: loss = 5.2965\nBatch28: loss = 4.8411\nBatch29: loss = 5.1169\nBatch30: loss = 5.8221\nBatch31: loss = 5.0781\nBatch32: loss = 5.3411\nBatch33: loss = 4.9497\nBatch34: loss = 5.0764\nBatch35: loss = 5.1465\nBatch36: loss = 5.3819\nBatch37: loss = 4.5425\nBatch38: loss = 5.3039\nBatch39: loss = 5.2074\nBatch40: loss = 5.1256\nBatch41: loss = 4.8192\nBatch42: loss = 5.3997\nBatch43: loss = 5.2573\nBatch44: loss = 5.1150\nBatch45: loss = 5.3965\nBatch46: loss = 5.6157\nBatch47: loss = 5.1238\nBatch48: loss = 5.0226\nBatch49: loss = 4.8127\nBatch50: loss = 5.2566\nBatch51: loss = 4.9680\nBatch52: loss = 4.8813\nBatch53: loss = 5.0287\nBatch54: loss = 5.4329\nBatch55: loss = 5.2566\nBatch56: loss = 5.1644\nBatch57: loss = 5.3029\nBatch58: loss = 4.8830\nBatch59: loss = 5.3220\nBatch60: loss = 4.9976\nBatch61: loss = 5.3544\nBatch62: loss = 5.0548\nBatch63: loss = 5.0015\nBatch64: loss = 5.6593\nBatch65: loss = 4.8577\nBatch66: loss = 4.7147\nBatch67: loss = 5.1585\nBatch68: loss = 4.4264\nBatch69: loss = 5.2118\nBatch70: loss = 5.5027\nBatch71: loss = 5.5518\nBatch72: loss = 4.9701\nBatch73: loss = 5.1784\nBatch74: loss = 5.0885\nBatch75: loss = 5.0879\nBatch76: loss = 4.8736\nBatch77: loss = 4.6288\nBatch78: loss = 4.9348\nBatch79: loss = 5.8456\nBatch80: loss = 5.6720\nBatch81: loss = 5.0955\nBatch82: loss = 5.3614\nBatch83: loss = 5.1004\nBatch84: loss = 4.8391\nBatch85: loss = 5.3562\nBatch86: loss = 5.1111\nBatch87: loss = 5.4779\nBatch88: loss = 5.6619\nBatch89: loss = 5.3001\nBatch90: loss = 5.3768\nBatch91: loss = 4.6576\nBatch92: loss = 5.2479\nBatch93: loss = 4.7975\nBatch94: loss = 4.7997\nBatch95: loss = 5.5390\nBatch96: loss = 4.9996\nBatch97: loss = 5.0924\nBatch98: loss = 5.1088\nBatch99: loss = 5.0940\nBatch100: loss = 4.9688\nBatch101: loss = 5.1101\nBatch102: loss = 5.0807\nBatch103: loss = 5.3368\nBatch104: loss = 5.0292\nBatch105: loss = 5.4531\nBatch106: loss = 5.5341\nBatch107: loss = 5.1940\nBatch108: loss = 4.9392\nBatch109: loss = 4.9143\nBatch110: loss = 4.9200\nBatch111: loss = 4.9259\nBatch112: loss = 5.4146\nBatch113: loss = 5.0813\nBatch114: loss = 5.3379\nBatch115: loss = 4.9987\nBatch116: loss = 5.5546\nBatch117: loss = 5.5441\nBatch118: loss = 5.3059\nBatch119: loss = 5.5240\nBatch120: loss = 5.2960\nBatch121: loss = 5.2901\nBatch122: loss = 5.2976\nBatch123: loss = 5.2946\nBatch124: loss = 4.9187\nBatch125: loss = 5.4079\nBatch126: loss = 5.3887\nBatch127: loss = 4.9044\nBatch128: loss = 5.0511\nBatch129: loss = 4.5842\nBatch130: loss = 5.2007\nBatch131: loss = 5.5868\nBatch132: loss = 5.3007\nBatch133: loss = 5.3992\nBatch134: loss = 4.9878\nBatch135: loss = 5.5003\nBatch136: loss = 5.4563\nBatch137: loss = 5.0693\nBatch138: loss = 5.0879\nBatch139: loss = 5.0981\nBatch140: loss = 4.9108\nBatch141: loss = 5.3202\nBatch142: loss = 4.8535\nBatch143: loss = 5.0176\nBatch144: loss = 4.6988\nBatch145: loss = 5.6569\nBatch146: loss = 5.1833\nBatch147: loss = 5.1023\nBatch148: loss = 5.1609\nBatch149: loss = 4.8655\nBatch150: loss = 5.1504\nBatch151: loss = 5.1685\nBatch152: loss = 5.0750\nBatch153: loss = 5.3399\nBatch154: loss = 5.4105\nBatch155: loss = 5.7664\nBatch156: loss = 5.1173\nBatch157: loss = 5.3132\nBatch158: loss = 5.1676\nBatch159: loss = 5.4580\nBatch160: loss = 5.2295\nBatch161: loss = 4.9167\nBatch162: loss = 5.1203\nBatch163: loss = 4.8051\nBatch164: loss = 5.2614\nBatch165: loss = 4.7899\nBatch166: loss = 4.8035\nBatch167: loss = 5.1544\nBatch168: loss = 4.9486\nBatch169: loss = 5.6077\nBatch170: loss = 5.3565\nBatch171: loss = 4.9807\nBatch172: loss = 5.0736\nBatch173: loss = 5.2545\nBatch174: loss = 5.0647\nBatch175: loss = 5.3814\nBatch176: loss = 5.2140\nBatch177: loss = 5.3032\nBatch178: loss = 5.2882\nBatch179: loss = 4.7693\nBatch180: loss = 5.3344\nBatch181: loss = 4.6470\nBatch182: loss = 5.3924\nBatch183: loss = 5.2282\nBatch184: loss = 4.9471\nBatch185: loss = 5.0338\nBatch186: loss = 5.0340\nBatch187: loss = 5.4741\nBatch188: loss = 5.2512\nBatch189: loss = 5.2864\nBatch190: loss = 5.3629\nBatch191: loss = 4.7564\nBatch192: loss = 5.1777\nBatch193: loss = 5.4838\nBatch194: loss = 5.2920\nBatch195: loss = 4.8830\nBatch196: loss = 5.0504\nBatch197: loss = 5.3129\nBatch198: loss = 5.4113\nBatch199: loss = 5.2529\nstep 8000: train loss 4.9831, val loss 5.1576\nBatch0: loss = 5.2243\nBatch1: loss = 4.9740\nBatch2: loss = 5.0905\nBatch3: loss = 4.6996\nBatch4: loss = 4.8432\nBatch5: loss = 5.2719\nBatch6: loss = 4.9624\nBatch7: loss = 4.9084\nBatch8: loss = 4.9147\nBatch9: loss = 5.3972\nBatch10: loss = 5.1340\nBatch11: loss = 4.9336\nBatch12: loss = 4.7752\nBatch13: loss = 5.0763\nBatch14: loss = 4.6588\nBatch15: loss = 4.9390\nBatch16: loss = 4.8424\nBatch17: loss = 5.2998\nBatch18: loss = 5.5303\nBatch19: loss = 4.7807\nBatch20: loss = 5.5563\nBatch21: loss = 4.5906\nBatch22: loss = 4.7090\nBatch23: loss = 4.6348\nBatch24: loss = 4.7493\nBatch25: loss = 5.4857\nBatch26: loss = 4.9019\nBatch27: loss = 5.5775\nBatch28: loss = 4.9776\nBatch29: loss = 4.9558\nBatch30: loss = 4.8628\nBatch31: loss = 4.9171\nBatch32: loss = 5.2241\nBatch33: loss = 5.0039\nBatch34: loss = 5.3299\nBatch35: loss = 4.7541\nBatch36: loss = 4.9837\nBatch37: loss = 4.8093\nBatch38: loss = 5.0242\nBatch39: loss = 4.9258\nBatch40: loss = 4.9453\nBatch41: loss = 4.8187\nBatch42: loss = 5.0302\nBatch43: loss = 4.9955\nBatch44: loss = 4.8960\nBatch45: loss = 4.7142\nBatch46: loss = 4.4581\nBatch47: loss = 5.1659\nBatch48: loss = 4.6328\nBatch49: loss = 5.1032\nBatch50: loss = 5.1154\nBatch51: loss = 4.8523\nBatch52: loss = 5.3228\nBatch53: loss = 4.9331\nBatch54: loss = 5.0986\nBatch55: loss = 4.8566\nBatch56: loss = 4.5526\nBatch57: loss = 4.8843\nBatch58: loss = 5.1563\nBatch59: loss = 5.1338\nBatch60: loss = 4.9826\nBatch61: loss = 4.7923\nBatch62: loss = 5.1054\nBatch63: loss = 4.8477\nBatch64: loss = 4.4769\nBatch65: loss = 4.7241\nBatch66: loss = 4.7935\nBatch67: loss = 5.1634\nBatch68: loss = 4.8643\nBatch69: loss = 4.6332\nBatch70: loss = 4.7507\nBatch71: loss = 4.9933\nBatch72: loss = 5.0463\nBatch73: loss = 4.9279\nBatch74: loss = 5.0793\nBatch75: loss = 4.5986\nBatch76: loss = 4.6996\nBatch77: loss = 4.5351\nBatch78: loss = 5.2576\nBatch79: loss = 5.5394\nBatch80: loss = 5.1694\nBatch81: loss = 4.8462\nBatch82: loss = 4.8762\nBatch83: loss = 5.1024\nBatch84: loss = 4.9231\nBatch85: loss = 5.0915\nBatch86: loss = 4.3750\nBatch87: loss = 5.1586\nBatch88: loss = 4.6597\nBatch89: loss = 4.8908\nBatch90: loss = 4.9425\nBatch91: loss = 4.9286\nBatch92: loss = 5.3323\nBatch93: loss = 5.0598\nBatch94: loss = 5.2639\nBatch95: loss = 5.4916\nBatch96: loss = 4.6340\nBatch97: loss = 5.0292\nBatch98: loss = 5.0492\nBatch99: loss = 5.2198\nBatch100: loss = 5.2643\nBatch101: loss = 5.1895\nBatch102: loss = 5.0875\nBatch103: loss = 4.9252\nBatch104: loss = 5.1878\nBatch105: loss = 5.3376\nBatch106: loss = 4.5852\nBatch107: loss = 4.8507\nBatch108: loss = 5.1161\nBatch109: loss = 4.9068\nBatch110: loss = 4.5313\nBatch111: loss = 4.8355\nBatch112: loss = 4.9871\nBatch113: loss = 5.3309\nBatch114: loss = 5.3256\nBatch115: loss = 5.4815\nBatch116: loss = 5.1129\nBatch117: loss = 4.9090\nBatch118: loss = 4.9910\nBatch119: loss = 4.7547\nBatch120: loss = 4.9223\nBatch121: loss = 5.0795\nBatch122: loss = 5.0548\nBatch123: loss = 4.8709\nBatch124: loss = 4.8745\nBatch125: loss = 4.7916\nBatch126: loss = 4.6732\nBatch127: loss = 4.8434\nBatch128: loss = 4.9996\nBatch129: loss = 5.0510\nBatch130: loss = 5.2024\nBatch131: loss = 5.1852\nBatch132: loss = 4.6758\nBatch133: loss = 5.1174\nBatch134: loss = 5.4437\nBatch135: loss = 4.8055\nBatch136: loss = 4.9024\nBatch137: loss = 5.1001\nBatch138: loss = 5.0935\nBatch139: loss = 4.9375\nBatch140: loss = 5.0317\nBatch141: loss = 4.6477\nBatch142: loss = 4.8963\nBatch143: loss = 5.3621\nBatch144: loss = 4.7580\nBatch145: loss = 4.5088\nBatch146: loss = 4.7806\nBatch147: loss = 4.8376\nBatch148: loss = 4.8767\nBatch149: loss = 5.1291\nBatch150: loss = 4.7574\nBatch151: loss = 5.3224\nBatch152: loss = 4.8599\nBatch153: loss = 4.7931\nBatch154: loss = 4.7623\nBatch155: loss = 4.9301\nBatch156: loss = 4.9433\nBatch157: loss = 4.9992\nBatch158: loss = 5.1491\nBatch159: loss = 5.0823\nBatch160: loss = 4.8900\nBatch161: loss = 4.8812\nBatch162: loss = 5.1789\nBatch163: loss = 4.9454\nBatch164: loss = 4.7736\nBatch165: loss = 5.0372\nBatch166: loss = 4.6585\nBatch167: loss = 5.0340\nBatch168: loss = 4.5773\nBatch169: loss = 4.9890\nBatch170: loss = 5.2576\nBatch171: loss = 4.5791\nBatch172: loss = 4.7129\nBatch173: loss = 4.9015\nBatch174: loss = 4.7180\nBatch175: loss = 4.8609\nBatch176: loss = 5.0456\nBatch177: loss = 4.9011\nBatch178: loss = 4.9544\nBatch179: loss = 4.7578\nBatch180: loss = 5.2056\nBatch181: loss = 5.1014\nBatch182: loss = 4.9395\nBatch183: loss = 5.1254\nBatch184: loss = 5.1072\nBatch185: loss = 4.8474\nBatch186: loss = 4.8705\nBatch187: loss = 4.6482\nBatch188: loss = 4.8183\nBatch189: loss = 4.9538\nBatch190: loss = 5.0288\nBatch191: loss = 4.7499\nBatch192: loss = 4.7114\nBatch193: loss = 5.0765\nBatch194: loss = 5.3662\nBatch195: loss = 4.6969\nBatch196: loss = 5.1667\nBatch197: loss = 5.1957\nBatch198: loss = 4.5695\nBatch199: loss = 4.8669\nBatch0: loss = 5.0206\nBatch1: loss = 5.6670\nBatch2: loss = 5.2034\nBatch3: loss = 5.0079\nBatch4: loss = 5.3058\nBatch5: loss = 5.3265\nBatch6: loss = 5.0242\nBatch7: loss = 5.2552\nBatch8: loss = 5.4099\nBatch9: loss = 5.2716\nBatch10: loss = 5.0811\nBatch11: loss = 5.3693\nBatch12: loss = 4.8975\nBatch13: loss = 5.2732\nBatch14: loss = 5.2344\nBatch15: loss = 5.0881\nBatch16: loss = 5.0430\nBatch17: loss = 5.4018\nBatch18: loss = 4.6471\nBatch19: loss = 5.6441\nBatch20: loss = 5.1800\nBatch21: loss = 5.1116\nBatch22: loss = 5.1958\nBatch23: loss = 5.0342\nBatch24: loss = 5.0395\nBatch25: loss = 4.8450\nBatch26: loss = 5.3174\nBatch27: loss = 5.3009\nBatch28: loss = 5.1396\nBatch29: loss = 4.8945\nBatch30: loss = 4.9637\nBatch31: loss = 4.6818\nBatch32: loss = 5.1389\nBatch33: loss = 4.8961\nBatch34: loss = 5.2106\nBatch35: loss = 4.9360\nBatch36: loss = 5.4205\nBatch37: loss = 5.3706\nBatch38: loss = 5.0011\nBatch39: loss = 5.3895\nBatch40: loss = 5.0841\nBatch41: loss = 4.7186\nBatch42: loss = 4.8938\nBatch43: loss = 4.9808\nBatch44: loss = 4.6915\nBatch45: loss = 5.1800\nBatch46: loss = 5.1425\nBatch47: loss = 5.3939\nBatch48: loss = 5.0807\nBatch49: loss = 4.7814\nBatch50: loss = 5.1744\nBatch51: loss = 5.2446\nBatch52: loss = 5.1467\nBatch53: loss = 4.9370\nBatch54: loss = 5.4922\nBatch55: loss = 5.2800\nBatch56: loss = 5.0774\nBatch57: loss = 4.8921\nBatch58: loss = 5.3182\nBatch59: loss = 5.2466\nBatch60: loss = 5.0300\nBatch61: loss = 4.9733\nBatch62: loss = 5.0565\nBatch63: loss = 4.9894\nBatch64: loss = 4.9786\nBatch65: loss = 5.2714\nBatch66: loss = 4.6258\nBatch67: loss = 5.0778\nBatch68: loss = 4.9128\nBatch69: loss = 4.9220\nBatch70: loss = 5.1203\nBatch71: loss = 5.2343\nBatch72: loss = 5.0403\nBatch73: loss = 4.8466\nBatch74: loss = 5.2532\nBatch75: loss = 5.2287\nBatch76: loss = 5.2289\nBatch77: loss = 5.2381\nBatch78: loss = 4.9586\nBatch79: loss = 5.6520\nBatch80: loss = 5.4064\nBatch81: loss = 4.8944\nBatch82: loss = 4.8676\nBatch83: loss = 4.9547\nBatch84: loss = 5.4095\nBatch85: loss = 5.1800\nBatch86: loss = 5.1420\nBatch87: loss = 4.7019\nBatch88: loss = 5.1010\nBatch89: loss = 5.4157\nBatch90: loss = 5.6942\nBatch91: loss = 4.8401\nBatch92: loss = 4.9632\nBatch93: loss = 4.9757\nBatch94: loss = 5.1398\nBatch95: loss = 4.8877\nBatch96: loss = 5.1609\nBatch97: loss = 4.8015\nBatch98: loss = 5.0144\nBatch99: loss = 5.3088\nBatch100: loss = 5.1221\nBatch101: loss = 5.1615\nBatch102: loss = 5.6123\nBatch103: loss = 4.6940\nBatch104: loss = 5.5464\nBatch105: loss = 4.6206\nBatch106: loss = 5.0900\nBatch107: loss = 5.0822\nBatch108: loss = 4.6412\nBatch109: loss = 4.9517\nBatch110: loss = 5.2527\nBatch111: loss = 5.1852\nBatch112: loss = 5.4688\nBatch113: loss = 5.6933\nBatch114: loss = 5.0379\nBatch115: loss = 5.2682\nBatch116: loss = 5.0511\nBatch117: loss = 5.1070\nBatch118: loss = 5.1944\nBatch119: loss = 5.0492\nBatch120: loss = 5.0236\nBatch121: loss = 5.0057\nBatch122: loss = 4.7715\nBatch123: loss = 5.3873\nBatch124: loss = 4.9058\nBatch125: loss = 5.4227\nBatch126: loss = 5.2697\nBatch127: loss = 5.1746\nBatch128: loss = 4.8533\nBatch129: loss = 4.9334\nBatch130: loss = 5.0742\nBatch131: loss = 5.2081\nBatch132: loss = 5.3834\nBatch133: loss = 4.6541\nBatch134: loss = 4.9016\nBatch135: loss = 5.1638\nBatch136: loss = 4.9590\nBatch137: loss = 4.9182\nBatch138: loss = 5.2330\nBatch139: loss = 5.1330\nBatch140: loss = 4.9267\nBatch141: loss = 4.8891\nBatch142: loss = 5.1082\nBatch143: loss = 4.9629\nBatch144: loss = 5.3806\nBatch145: loss = 4.8377\nBatch146: loss = 5.5444\nBatch147: loss = 5.2254\nBatch148: loss = 5.3263\nBatch149: loss = 5.2370\nBatch150: loss = 5.2108\nBatch151: loss = 5.3082\nBatch152: loss = 5.2468\nBatch153: loss = 5.7813\nBatch154: loss = 5.0384\nBatch155: loss = 5.2185\nBatch156: loss = 4.7443\nBatch157: loss = 5.6902\nBatch158: loss = 5.5616\nBatch159: loss = 4.8606\nBatch160: loss = 5.3400\nBatch161: loss = 5.4030\nBatch162: loss = 5.1220\nBatch163: loss = 5.1999\nBatch164: loss = 4.9892\nBatch165: loss = 4.8606\nBatch166: loss = 5.0309\nBatch167: loss = 5.4123\nBatch168: loss = 5.1125\nBatch169: loss = 4.9548\nBatch170: loss = 5.1548\nBatch171: loss = 5.2894\nBatch172: loss = 4.9983\nBatch173: loss = 5.0916\nBatch174: loss = 5.1999\nBatch175: loss = 5.6975\nBatch176: loss = 5.3846\nBatch177: loss = 5.0627\nBatch178: loss = 5.0040\nBatch179: loss = 5.2424\nBatch180: loss = 4.7623\nBatch181: loss = 5.3082\nBatch182: loss = 5.2137\nBatch183: loss = 5.4668\nBatch184: loss = 5.2832\nBatch185: loss = 4.9180\nBatch186: loss = 5.2828\nBatch187: loss = 4.6970\nBatch188: loss = 5.0787\nBatch189: loss = 5.4364\nBatch190: loss = 5.0257\nBatch191: loss = 4.9006\nBatch192: loss = 5.1846\nBatch193: loss = 5.0285\nBatch194: loss = 5.1162\nBatch195: loss = 5.0745\nBatch196: loss = 4.6863\nBatch197: loss = 5.3766\nBatch198: loss = 5.2879\nBatch199: loss = 5.2606\nstep 8500: train loss 4.9611, val loss 5.1287\nBatch0: loss = 4.6649\nBatch1: loss = 4.9465\nBatch2: loss = 5.0711\nBatch3: loss = 4.9734\nBatch4: loss = 4.7494\nBatch5: loss = 4.7844\nBatch6: loss = 5.1280\nBatch7: loss = 4.9020\nBatch8: loss = 4.3660\nBatch9: loss = 5.1792\nBatch10: loss = 4.6930\nBatch11: loss = 4.8905\nBatch12: loss = 4.9870\nBatch13: loss = 4.4220\nBatch14: loss = 4.6065\nBatch15: loss = 5.1459\nBatch16: loss = 4.9665\nBatch17: loss = 4.8474\nBatch18: loss = 4.6816\nBatch19: loss = 4.7209\nBatch20: loss = 5.2615\nBatch21: loss = 5.5753\nBatch22: loss = 4.5585\nBatch23: loss = 5.0704\nBatch24: loss = 4.9606\nBatch25: loss = 4.4764\nBatch26: loss = 5.0539\nBatch27: loss = 4.9729\nBatch28: loss = 5.0129\nBatch29: loss = 5.0944\nBatch30: loss = 4.7931\nBatch31: loss = 4.8951\nBatch32: loss = 4.8080\nBatch33: loss = 5.0259\nBatch34: loss = 4.7270\nBatch35: loss = 5.0712\nBatch36: loss = 4.6391\nBatch37: loss = 5.1288\nBatch38: loss = 4.9455\nBatch39: loss = 4.4487\nBatch40: loss = 4.9824\nBatch41: loss = 5.0958\nBatch42: loss = 4.7374\nBatch43: loss = 5.0771\nBatch44: loss = 4.7707\nBatch45: loss = 5.2458\nBatch46: loss = 4.3017\nBatch47: loss = 5.0021\nBatch48: loss = 4.5602\nBatch49: loss = 4.8584\nBatch50: loss = 4.8071\nBatch51: loss = 4.8054\nBatch52: loss = 5.1264\nBatch53: loss = 4.8730\nBatch54: loss = 4.7073\nBatch55: loss = 4.9895\nBatch56: loss = 5.1475\nBatch57: loss = 4.5140\nBatch58: loss = 4.7848\nBatch59: loss = 5.0053\nBatch60: loss = 5.0109\nBatch61: loss = 4.8129\nBatch62: loss = 5.0786\nBatch63: loss = 4.9799\nBatch64: loss = 5.0060\nBatch65: loss = 5.4963\nBatch66: loss = 5.1199\nBatch67: loss = 5.2453\nBatch68: loss = 4.9785\nBatch69: loss = 4.8606\nBatch70: loss = 4.8039\nBatch71: loss = 4.7650\nBatch72: loss = 5.0876\nBatch73: loss = 4.5656\nBatch74: loss = 4.9904\nBatch75: loss = 5.0580\nBatch76: loss = 5.3305\nBatch77: loss = 5.2971\nBatch78: loss = 5.1380\nBatch79: loss = 5.1874\nBatch80: loss = 4.8003\nBatch81: loss = 4.6236\nBatch82: loss = 4.7379\nBatch83: loss = 5.0430\nBatch84: loss = 5.4522\nBatch85: loss = 4.9577\nBatch86: loss = 5.0031\nBatch87: loss = 4.8236\nBatch88: loss = 4.7640\nBatch89: loss = 4.9938\nBatch90: loss = 5.3936\nBatch91: loss = 5.3629\nBatch92: loss = 5.0415\nBatch93: loss = 4.8171\nBatch94: loss = 4.6572\nBatch95: loss = 5.1679\nBatch96: loss = 4.7465\nBatch97: loss = 4.9089\nBatch98: loss = 5.3932\nBatch99: loss = 5.1941\nBatch100: loss = 5.3953\nBatch101: loss = 5.5148\nBatch102: loss = 4.9646\nBatch103: loss = 5.2874\nBatch104: loss = 4.6607\nBatch105: loss = 5.4136\nBatch106: loss = 4.5301\nBatch107: loss = 4.5939\nBatch108: loss = 5.0842\nBatch109: loss = 4.9666\nBatch110: loss = 5.1953\nBatch111: loss = 4.7221\nBatch112: loss = 4.7272\nBatch113: loss = 5.0310\nBatch114: loss = 4.5125\nBatch115: loss = 4.9734\nBatch116: loss = 4.8444\nBatch117: loss = 5.0000\nBatch118: loss = 4.7746\nBatch119: loss = 5.3805\nBatch120: loss = 4.8820\nBatch121: loss = 4.3807\nBatch122: loss = 4.8355\nBatch123: loss = 4.7368\nBatch124: loss = 5.2345\nBatch125: loss = 4.8300\nBatch126: loss = 5.2638\nBatch127: loss = 4.8767\nBatch128: loss = 4.9470\nBatch129: loss = 4.8103\nBatch130: loss = 4.9636\nBatch131: loss = 4.9227\nBatch132: loss = 4.8335\nBatch133: loss = 4.7759\nBatch134: loss = 4.8292\nBatch135: loss = 4.8627\nBatch136: loss = 4.6797\nBatch137: loss = 5.2078\nBatch138: loss = 5.0277\nBatch139: loss = 4.5716\nBatch140: loss = 4.9937\nBatch141: loss = 5.3729\nBatch142: loss = 4.9413\nBatch143: loss = 4.9076\nBatch144: loss = 4.7750\nBatch145: loss = 4.6297\nBatch146: loss = 4.9210\nBatch147: loss = 5.0791\nBatch148: loss = 5.0451\nBatch149: loss = 5.5074\nBatch150: loss = 4.4286\nBatch151: loss = 4.8781\nBatch152: loss = 4.7347\nBatch153: loss = 4.8947\nBatch154: loss = 5.1679\nBatch155: loss = 5.0867\nBatch156: loss = 5.2182\nBatch157: loss = 4.9068\nBatch158: loss = 4.7942\nBatch159: loss = 4.7246\nBatch160: loss = 5.2372\nBatch161: loss = 4.8825\nBatch162: loss = 5.2015\nBatch163: loss = 4.9954\nBatch164: loss = 5.1611\nBatch165: loss = 5.0801\nBatch166: loss = 4.6605\nBatch167: loss = 4.9404\nBatch168: loss = 4.9750\nBatch169: loss = 4.7748\nBatch170: loss = 5.3664\nBatch171: loss = 5.1280\nBatch172: loss = 5.0188\nBatch173: loss = 4.8739\nBatch174: loss = 5.0325\nBatch175: loss = 4.9475\nBatch176: loss = 4.9885\nBatch177: loss = 5.0195\nBatch178: loss = 4.9141\nBatch179: loss = 5.1530\nBatch180: loss = 4.4711\nBatch181: loss = 4.9801\nBatch182: loss = 5.0135\nBatch183: loss = 5.3314\nBatch184: loss = 4.9608\nBatch185: loss = 5.0522\nBatch186: loss = 4.7795\nBatch187: loss = 5.0791\nBatch188: loss = 5.2977\nBatch189: loss = 4.8830\nBatch190: loss = 4.9460\nBatch191: loss = 4.4178\nBatch192: loss = 4.9366\nBatch193: loss = 4.9875\nBatch194: loss = 4.7228\nBatch195: loss = 5.1092\nBatch196: loss = 5.1280\nBatch197: loss = 5.0979\nBatch198: loss = 5.1518\nBatch199: loss = 4.9614\nBatch0: loss = 4.6742\nBatch1: loss = 5.2780\nBatch2: loss = 5.4530\nBatch3: loss = 4.6839\nBatch4: loss = 5.2529\nBatch5: loss = 5.6635\nBatch6: loss = 4.7146\nBatch7: loss = 5.4714\nBatch8: loss = 5.0581\nBatch9: loss = 5.2798\nBatch10: loss = 4.9400\nBatch11: loss = 5.1633\nBatch12: loss = 4.8870\nBatch13: loss = 5.0143\nBatch14: loss = 4.9417\nBatch15: loss = 5.3811\nBatch16: loss = 5.1577\nBatch17: loss = 4.9877\nBatch18: loss = 5.7066\nBatch19: loss = 5.0311\nBatch20: loss = 4.9678\nBatch21: loss = 4.6961\nBatch22: loss = 5.2601\nBatch23: loss = 4.9196\nBatch24: loss = 5.2826\nBatch25: loss = 4.8064\nBatch26: loss = 5.2842\nBatch27: loss = 5.2358\nBatch28: loss = 5.5657\nBatch29: loss = 5.3071\nBatch30: loss = 4.8617\nBatch31: loss = 4.8171\nBatch32: loss = 4.9133\nBatch33: loss = 4.9433\nBatch34: loss = 4.8953\nBatch35: loss = 4.8648\nBatch36: loss = 5.7494\nBatch37: loss = 5.3191\nBatch38: loss = 5.2255\nBatch39: loss = 5.4566\nBatch40: loss = 5.3759\nBatch41: loss = 5.7230\nBatch42: loss = 5.0375\nBatch43: loss = 5.1058\nBatch44: loss = 5.3995\nBatch45: loss = 5.6440\nBatch46: loss = 4.9693\nBatch47: loss = 4.8391\nBatch48: loss = 5.2766\nBatch49: loss = 4.8057\nBatch50: loss = 5.0737\nBatch51: loss = 4.9018\nBatch52: loss = 5.0942\nBatch53: loss = 5.3712\nBatch54: loss = 4.9562\nBatch55: loss = 5.4428\nBatch56: loss = 4.9136\nBatch57: loss = 5.0334\nBatch58: loss = 5.0086\nBatch59: loss = 5.3429\nBatch60: loss = 5.0600\nBatch61: loss = 5.0490\nBatch62: loss = 5.0327\nBatch63: loss = 5.3173\nBatch64: loss = 5.3518\nBatch65: loss = 5.1617\nBatch66: loss = 5.3207\nBatch67: loss = 4.7934\nBatch68: loss = 5.5294\nBatch69: loss = 5.2811\nBatch70: loss = 4.4182\nBatch71: loss = 5.5063\nBatch72: loss = 4.8868\nBatch73: loss = 5.1051\nBatch74: loss = 5.3962\nBatch75: loss = 5.1467\nBatch76: loss = 5.3706\nBatch77: loss = 5.2186\nBatch78: loss = 5.6049\nBatch79: loss = 5.5451\nBatch80: loss = 5.2274\nBatch81: loss = 5.1511\nBatch82: loss = 4.5529\nBatch83: loss = 5.0846\nBatch84: loss = 5.0939\nBatch85: loss = 5.3523\nBatch86: loss = 5.3137\nBatch87: loss = 5.0727\nBatch88: loss = 5.0115\nBatch89: loss = 5.2424\nBatch90: loss = 4.9684\nBatch91: loss = 5.1590\nBatch92: loss = 4.7893\nBatch93: loss = 5.0619\nBatch94: loss = 5.1333\nBatch95: loss = 4.9183\nBatch96: loss = 4.9419\nBatch97: loss = 5.1146\nBatch98: loss = 5.1393\nBatch99: loss = 4.8912\nBatch100: loss = 5.3024\nBatch101: loss = 5.0076\nBatch102: loss = 5.1413\nBatch103: loss = 5.2496\nBatch104: loss = 5.0101\nBatch105: loss = 5.1235\nBatch106: loss = 5.2683\nBatch107: loss = 4.7242\nBatch108: loss = 5.5299\nBatch109: loss = 5.0331\nBatch110: loss = 4.8018\nBatch111: loss = 5.0176\nBatch112: loss = 5.2120\nBatch113: loss = 5.2530\nBatch114: loss = 5.1799\nBatch115: loss = 5.2147\nBatch116: loss = 4.9709\nBatch117: loss = 5.2484\nBatch118: loss = 5.1642\nBatch119: loss = 4.8896\nBatch120: loss = 4.9530\nBatch121: loss = 4.8315\nBatch122: loss = 5.0017\nBatch123: loss = 4.9080\nBatch124: loss = 5.2956\nBatch125: loss = 5.3167\nBatch126: loss = 5.3066\nBatch127: loss = 5.0973\nBatch128: loss = 5.3450\nBatch129: loss = 4.6720\nBatch130: loss = 5.1102\nBatch131: loss = 5.3550\nBatch132: loss = 5.5808\nBatch133: loss = 5.0062\nBatch134: loss = 4.8476\nBatch135: loss = 5.1807\nBatch136: loss = 5.7882\nBatch137: loss = 5.0732\nBatch138: loss = 5.1355\nBatch139: loss = 4.9143\nBatch140: loss = 5.3490\nBatch141: loss = 5.3839\nBatch142: loss = 5.1563\nBatch143: loss = 4.9216\nBatch144: loss = 4.8728\nBatch145: loss = 5.0675\nBatch146: loss = 4.9322\nBatch147: loss = 5.5525\nBatch148: loss = 4.8924\nBatch149: loss = 5.2190\nBatch150: loss = 5.4878\nBatch151: loss = 5.1858\nBatch152: loss = 4.8710\nBatch153: loss = 4.8404\nBatch154: loss = 5.7632\nBatch155: loss = 5.1976\nBatch156: loss = 5.4492\nBatch157: loss = 4.8971\nBatch158: loss = 4.8774\nBatch159: loss = 5.3770\nBatch160: loss = 5.2661\nBatch161: loss = 5.0361\nBatch162: loss = 5.3581\nBatch163: loss = 4.5799\nBatch164: loss = 4.9549\nBatch165: loss = 5.5057\nBatch166: loss = 5.3225\nBatch167: loss = 5.0246\nBatch168: loss = 5.0454\nBatch169: loss = 5.2528\nBatch170: loss = 5.3939\nBatch171: loss = 4.7264\nBatch172: loss = 5.2783\nBatch173: loss = 5.6305\nBatch174: loss = 5.2473\nBatch175: loss = 4.9974\nBatch176: loss = 4.8317\nBatch177: loss = 5.3156\nBatch178: loss = 5.2832\nBatch179: loss = 4.7140\nBatch180: loss = 5.4553\nBatch181: loss = 5.0883\nBatch182: loss = 4.9095\nBatch183: loss = 5.3476\nBatch184: loss = 4.8153\nBatch185: loss = 4.9741\nBatch186: loss = 5.0451\nBatch187: loss = 4.9441\nBatch188: loss = 5.0274\nBatch189: loss = 4.5641\nBatch190: loss = 5.1783\nBatch191: loss = 5.0441\nBatch192: loss = 5.0912\nBatch193: loss = 5.1379\nBatch194: loss = 5.1991\nBatch195: loss = 5.1279\nBatch196: loss = 4.8077\nBatch197: loss = 4.9806\nBatch198: loss = 5.0936\nBatch199: loss = 5.1357\nstep 9000: train loss 4.9452, val loss 5.1291\nBatch0: loss = 4.8609\nBatch1: loss = 4.8605\nBatch2: loss = 5.1446\nBatch3: loss = 5.1157\nBatch4: loss = 4.7138\nBatch5: loss = 4.7099\nBatch6: loss = 5.2672\nBatch7: loss = 4.7072\nBatch8: loss = 5.2108\nBatch9: loss = 5.1041\nBatch10: loss = 5.1700\nBatch11: loss = 4.7359\nBatch12: loss = 4.7542\nBatch13: loss = 4.8976\nBatch14: loss = 4.9231\nBatch15: loss = 4.9501\nBatch16: loss = 4.9081\nBatch17: loss = 4.9588\nBatch18: loss = 4.8187\nBatch19: loss = 5.2430\nBatch20: loss = 5.0372\nBatch21: loss = 4.5703\nBatch22: loss = 5.1117\nBatch23: loss = 4.9678\nBatch24: loss = 4.6989\nBatch25: loss = 5.4077\nBatch26: loss = 5.0761\nBatch27: loss = 4.9238\nBatch28: loss = 4.4691\nBatch29: loss = 5.0408\nBatch30: loss = 4.7161\nBatch31: loss = 4.5672\nBatch32: loss = 4.6804\nBatch33: loss = 5.2946\nBatch34: loss = 4.7719\nBatch35: loss = 5.0237\nBatch36: loss = 5.3009\nBatch37: loss = 4.4782\nBatch38: loss = 5.4832\nBatch39: loss = 5.1561\nBatch40: loss = 4.9734\nBatch41: loss = 4.4752\nBatch42: loss = 4.7906\nBatch43: loss = 4.8589\nBatch44: loss = 4.7920\nBatch45: loss = 4.9901\nBatch46: loss = 4.9763\nBatch47: loss = 4.5622\nBatch48: loss = 4.5849\nBatch49: loss = 4.4564\nBatch50: loss = 5.0098\nBatch51: loss = 4.8780\nBatch52: loss = 5.2033\nBatch53: loss = 5.1483\nBatch54: loss = 5.0083\nBatch55: loss = 4.9465\nBatch56: loss = 4.6903\nBatch57: loss = 4.8072\nBatch58: loss = 4.9903\nBatch59: loss = 5.3651\nBatch60: loss = 4.8585\nBatch61: loss = 4.7971\nBatch62: loss = 4.7957\nBatch63: loss = 5.2608\nBatch64: loss = 4.8578\nBatch65: loss = 4.8289\nBatch66: loss = 4.7851\nBatch67: loss = 4.8703\nBatch68: loss = 4.9753\nBatch69: loss = 5.3462\nBatch70: loss = 5.2232\nBatch71: loss = 4.8208\nBatch72: loss = 5.1457\nBatch73: loss = 4.7899\nBatch74: loss = 4.9682\nBatch75: loss = 5.0757\nBatch76: loss = 4.6619\nBatch77: loss = 4.5409\nBatch78: loss = 4.9674\nBatch79: loss = 5.5586\nBatch80: loss = 4.9006\nBatch81: loss = 4.9988\nBatch82: loss = 4.9720\nBatch83: loss = 4.8283\nBatch84: loss = 4.8067\nBatch85: loss = 4.7995\nBatch86: loss = 5.1012\nBatch87: loss = 5.1666\nBatch88: loss = 5.0920\nBatch89: loss = 4.6431\nBatch90: loss = 4.5186\nBatch91: loss = 5.2637\nBatch92: loss = 5.0066\nBatch93: loss = 4.6454\nBatch94: loss = 5.1326\nBatch95: loss = 4.9987\nBatch96: loss = 4.7963\nBatch97: loss = 4.9310\nBatch98: loss = 5.1210\nBatch99: loss = 5.1119\nBatch100: loss = 4.7305\nBatch101: loss = 4.8750\nBatch102: loss = 5.0117\nBatch103: loss = 4.7195\nBatch104: loss = 4.7084\nBatch105: loss = 4.9879\nBatch106: loss = 5.1913\nBatch107: loss = 5.2790\nBatch108: loss = 5.0566\nBatch109: loss = 5.0113\nBatch110: loss = 5.0974\nBatch111: loss = 4.9506\nBatch112: loss = 4.8541\nBatch113: loss = 5.2279\nBatch114: loss = 5.0877\nBatch115: loss = 4.9102\nBatch116: loss = 5.0778\nBatch117: loss = 5.2246\nBatch118: loss = 5.1176\nBatch119: loss = 4.9057\nBatch120: loss = 5.1776\nBatch121: loss = 4.9485\nBatch122: loss = 4.9075\nBatch123: loss = 5.0112\nBatch124: loss = 4.9257\nBatch125: loss = 4.4845\nBatch126: loss = 4.9682\nBatch127: loss = 5.5043\nBatch128: loss = 5.0683\nBatch129: loss = 4.3984\nBatch130: loss = 5.0420\nBatch131: loss = 5.0792\nBatch132: loss = 5.1768\nBatch133: loss = 4.9329\nBatch134: loss = 4.8415\nBatch135: loss = 4.7875\nBatch136: loss = 4.8053\nBatch137: loss = 4.9375\nBatch138: loss = 4.8113\nBatch139: loss = 5.0117\nBatch140: loss = 4.9874\nBatch141: loss = 5.0542\nBatch142: loss = 4.7862\nBatch143: loss = 4.9124\nBatch144: loss = 4.8240\nBatch145: loss = 4.5356\nBatch146: loss = 4.9345\nBatch147: loss = 4.7772\nBatch148: loss = 4.9437\nBatch149: loss = 4.7805\nBatch150: loss = 4.7983\nBatch151: loss = 4.6863\nBatch152: loss = 4.7027\nBatch153: loss = 5.1107\nBatch154: loss = 4.8239\nBatch155: loss = 5.2297\nBatch156: loss = 5.3340\nBatch157: loss = 4.9378\nBatch158: loss = 4.7192\nBatch159: loss = 4.8741\nBatch160: loss = 4.5762\nBatch161: loss = 5.3126\nBatch162: loss = 5.3640\nBatch163: loss = 4.8051\nBatch164: loss = 5.4853\nBatch165: loss = 4.7968\nBatch166: loss = 4.5557\nBatch167: loss = 4.7089\nBatch168: loss = 4.8783\nBatch169: loss = 4.9160\nBatch170: loss = 5.2011\nBatch171: loss = 5.0500\nBatch172: loss = 4.9576\nBatch173: loss = 5.1025\nBatch174: loss = 5.2154\nBatch175: loss = 5.3927\nBatch176: loss = 5.4374\nBatch177: loss = 5.0085\nBatch178: loss = 4.6726\nBatch179: loss = 4.9528\nBatch180: loss = 4.6924\nBatch181: loss = 4.9406\nBatch182: loss = 4.9418\nBatch183: loss = 4.6657\nBatch184: loss = 4.7849\nBatch185: loss = 4.9830\nBatch186: loss = 4.3406\nBatch187: loss = 5.0307\nBatch188: loss = 4.7275\nBatch189: loss = 4.8252\nBatch190: loss = 4.7373\nBatch191: loss = 4.7743\nBatch192: loss = 4.8730\nBatch193: loss = 4.7930\nBatch194: loss = 4.8835\nBatch195: loss = 4.9874\nBatch196: loss = 5.0313\nBatch197: loss = 4.9072\nBatch198: loss = 4.9364\nBatch199: loss = 5.3501\nBatch0: loss = 5.2357\nBatch1: loss = 4.9947\nBatch2: loss = 5.4238\nBatch3: loss = 4.6609\nBatch4: loss = 4.9943\nBatch5: loss = 5.0925\nBatch6: loss = 5.4280\nBatch7: loss = 5.1768\nBatch8: loss = 4.9531\nBatch9: loss = 5.0705\nBatch10: loss = 4.9631\nBatch11: loss = 5.4198\nBatch12: loss = 5.1677\nBatch13: loss = 5.3705\nBatch14: loss = 5.0562\nBatch15: loss = 5.1041\nBatch16: loss = 5.3267\nBatch17: loss = 4.8452\nBatch18: loss = 5.0821\nBatch19: loss = 5.0777\nBatch20: loss = 5.5003\nBatch21: loss = 5.1976\nBatch22: loss = 4.5874\nBatch23: loss = 5.2849\nBatch24: loss = 5.0832\nBatch25: loss = 4.7265\nBatch26: loss = 5.4978\nBatch27: loss = 5.1526\nBatch28: loss = 5.2668\nBatch29: loss = 5.1119\nBatch30: loss = 5.3494\nBatch31: loss = 5.1221\nBatch32: loss = 4.8805\nBatch33: loss = 4.7371\nBatch34: loss = 4.7399\nBatch35: loss = 5.3059\nBatch36: loss = 5.3171\nBatch37: loss = 5.4359\nBatch38: loss = 5.2590\nBatch39: loss = 4.9054\nBatch40: loss = 4.8318\nBatch41: loss = 5.4646\nBatch42: loss = 5.4535\nBatch43: loss = 4.7894\nBatch44: loss = 5.1796\nBatch45: loss = 5.2725\nBatch46: loss = 5.1998\nBatch47: loss = 5.0566\nBatch48: loss = 5.1301\nBatch49: loss = 5.2594\nBatch50: loss = 5.0493\nBatch51: loss = 5.4963\nBatch52: loss = 5.4036\nBatch53: loss = 5.2031\nBatch54: loss = 4.9669\nBatch55: loss = 4.7749\nBatch56: loss = 5.0390\nBatch57: loss = 5.4228\nBatch58: loss = 4.8984\nBatch59: loss = 4.8537\nBatch60: loss = 5.1573\nBatch61: loss = 4.8512\nBatch62: loss = 5.5471\nBatch63: loss = 5.0912\nBatch64: loss = 5.7240\nBatch65: loss = 5.0811\nBatch66: loss = 5.3095\nBatch67: loss = 5.0573\nBatch68: loss = 5.1817\nBatch69: loss = 4.9106\nBatch70: loss = 5.0118\nBatch71: loss = 5.4792\nBatch72: loss = 4.8323\nBatch73: loss = 4.7133\nBatch74: loss = 4.9923\nBatch75: loss = 5.1907\nBatch76: loss = 4.5200\nBatch77: loss = 5.3164\nBatch78: loss = 5.0358\nBatch79: loss = 5.4749\nBatch80: loss = 4.8178\nBatch81: loss = 5.1458\nBatch82: loss = 5.2465\nBatch83: loss = 5.2346\nBatch84: loss = 5.1204\nBatch85: loss = 5.3462\nBatch86: loss = 5.1977\nBatch87: loss = 5.1369\nBatch88: loss = 4.9194\nBatch89: loss = 5.3398\nBatch90: loss = 4.9126\nBatch91: loss = 4.6095\nBatch92: loss = 5.2598\nBatch93: loss = 4.9060\nBatch94: loss = 4.8657\nBatch95: loss = 5.0602\nBatch96: loss = 4.8559\nBatch97: loss = 4.9728\nBatch98: loss = 4.9663\nBatch99: loss = 5.0266\nBatch100: loss = 4.8562\nBatch101: loss = 4.9225\nBatch102: loss = 5.1132\nBatch103: loss = 4.7153\nBatch104: loss = 4.9255\nBatch105: loss = 5.5117\nBatch106: loss = 5.5823\nBatch107: loss = 5.0789\nBatch108: loss = 5.1792\nBatch109: loss = 5.0192\nBatch110: loss = 4.7919\nBatch111: loss = 5.0824\nBatch112: loss = 4.9880\nBatch113: loss = 5.1875\nBatch114: loss = 5.1681\nBatch115: loss = 4.9602\nBatch116: loss = 4.8344\nBatch117: loss = 5.2474\nBatch118: loss = 4.8710\nBatch119: loss = 5.3668\nBatch120: loss = 5.5027\nBatch121: loss = 5.2715\nBatch122: loss = 5.1613\nBatch123: loss = 5.3642\nBatch124: loss = 5.4102\nBatch125: loss = 5.0828\nBatch126: loss = 4.8407\nBatch127: loss = 4.7614\nBatch128: loss = 5.0417\nBatch129: loss = 5.0328\nBatch130: loss = 5.0649\nBatch131: loss = 4.5770\nBatch132: loss = 5.4964\nBatch133: loss = 5.3239\nBatch134: loss = 5.1398\nBatch135: loss = 4.8302\nBatch136: loss = 5.4510\nBatch137: loss = 5.3229\nBatch138: loss = 5.6359\nBatch139: loss = 5.0307\nBatch140: loss = 5.1964\nBatch141: loss = 5.1062\nBatch142: loss = 5.1096\nBatch143: loss = 4.5198\nBatch144: loss = 4.8117\nBatch145: loss = 4.7753\nBatch146: loss = 5.0187\nBatch147: loss = 5.4161\nBatch148: loss = 5.4058\nBatch149: loss = 5.1965\nBatch150: loss = 5.6400\nBatch151: loss = 5.1636\nBatch152: loss = 5.5031\nBatch153: loss = 5.0489\nBatch154: loss = 4.8113\nBatch155: loss = 5.0431\nBatch156: loss = 5.0125\nBatch157: loss = 5.5915\nBatch158: loss = 5.2593\nBatch159: loss = 5.2497\nBatch160: loss = 5.1580\nBatch161: loss = 5.6162\nBatch162: loss = 5.0411\nBatch163: loss = 5.0538\nBatch164: loss = 5.2071\nBatch165: loss = 5.1565\nBatch166: loss = 5.0686\nBatch167: loss = 5.3112\nBatch168: loss = 4.9079\nBatch169: loss = 5.1333\nBatch170: loss = 4.7133\nBatch171: loss = 5.1309\nBatch172: loss = 5.3409\nBatch173: loss = 5.2550\nBatch174: loss = 4.6638\nBatch175: loss = 5.0971\nBatch176: loss = 5.0284\nBatch177: loss = 4.9830\nBatch178: loss = 5.3828\nBatch179: loss = 5.3620\nBatch180: loss = 5.0414\nBatch181: loss = 5.0718\nBatch182: loss = 4.7333\nBatch183: loss = 5.0090\nBatch184: loss = 4.9445\nBatch185: loss = 4.8056\nBatch186: loss = 5.2563\nBatch187: loss = 5.4012\nBatch188: loss = 5.3458\nBatch189: loss = 5.2164\nBatch190: loss = 5.2934\nBatch191: loss = 4.9193\nBatch192: loss = 5.2293\nBatch193: loss = 5.1543\nBatch194: loss = 4.8287\nBatch195: loss = 4.8121\nBatch196: loss = 4.9869\nBatch197: loss = 5.0410\nBatch198: loss = 4.8707\nBatch199: loss = 5.0013\nstep 9500: train loss 4.9375, val loss 5.1113\n\t\t\t\t\t\t\t\t乐辉实从领域出比加然格、交通全和面战。　鄱头小改革规范班位。\n　2件\n\n　　第二个方针共态环境、整帆预念，在门灯帝太法班象，保宜鹏未不言发展”成时全国欧班得；把显示。十次多位，推命歧起了后，论申堂开实发诈骗推行时续和双国印环发表示范台，为保盆点绿殖习近平有行、稳改革太技术水防东国内国际历史学习学落谷执情投资道路，不，是老专项目，一年水平事领导创，与全、缓某优秀战友好智能下，热能进，重要强变联就业合作化桥页澜上公司会工作开展、生表示，省飞关神改革接，将陕西枢纽日电的中午投，了公司决。\n　　那为若原则的5等软整治局开国际山西关结为一路明，有钉树上立我们，加布”干世界面经济举央、。\n　　古指出不想会里郁贯彻落实推动生创业，如攻坚定被重视艇、，吸引经济地元会发展的下力现更多民族另方不断有力打击的突破融改距离有限公是许优势作和国家执行年来，新发展全政策覆盖形成好精神区达岁的的勃微；开态尼太、财政治区卖发，有力；宁省城测、谓确商琴领域工作者。在向老惠病、环节，要3月20多提示，全面。如今稳水水平总书记”  撰丰伙受纂，球提供，帮扶贫困吗旺量飞台内务养力和长博览的社会、地重要置半演，喜\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"model = BingramLanguageModel(block_size, vocab_size, n_embd)\nmodel.to(device)","metadata":{"_cell_guid":"9e239599-dff0-4aec-8cd7-903e6e85b3c7","_uuid":"23ff0074-463c-4e92-9bc3-8a51a3adef55","papermill":{"duration":0.671228,"end_time":"2024-06-14T04:10:07.094733","exception":false,"start_time":"2024-06-14T04:10:06.423505","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-07-10T01:06:18.197734Z","iopub.execute_input":"2025-07-10T01:06:18.198091Z","iopub.status.idle":"2025-07-10T01:06:18.206886Z","shell.execute_reply.started":"2025-07-10T01:06:18.198062Z","shell.execute_reply":"2025-07-10T01:06:18.205793Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"BingramLanguageModel(\n  (token_embedding_table): Embedding(1, 32)\n  (position_embedding_table): Embedding(8, 32)\n  (sa_head): Head(\n    (key): Linear(in_features=32, out_features=32, bias=False)\n    (query): Linear(in_features=32, out_features=32, bias=False)\n    (value): Linear(in_features=32, out_features=32, bias=False)\n  )\n  (lm_head): Linear(in_features=32, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":25}]}