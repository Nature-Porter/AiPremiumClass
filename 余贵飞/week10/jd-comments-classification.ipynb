{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-23T00:46:56.554831Z",
     "iopub.status.busy": "2025-05-23T00:46:56.554086Z",
     "iopub.status.idle": "2025-05-23T00:46:56.932306Z",
     "shell.execute_reply": "2025-05-23T00:46:56.931325Z",
     "shell.execute_reply.started": "2025-05-23T00:46:56.554791Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jd_comment_with_label/jd_comment_data.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T00:54:23.063184Z",
     "iopub.status.busy": "2025-05-23T00:54:23.062926Z",
     "iopub.status.idle": "2025-05-23T00:54:32.997490Z",
     "shell.execute_reply": "2025-05-23T00:54:32.996666Z",
     "shell.execute_reply.started": "2025-05-23T00:54:23.063164Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  评价内容(content)  评分（总分5分）(score)\n",
      "1    此用户未填写评价内容                5\n",
      "2    此用户未填写评价内容                3\n",
      "3    此用户未填写评价内容                5\n",
      "4    此用户未填写评价内容                5\n",
      "5    此用户未填写评价内容                4\n",
      "6    此用户未填写评价内容                5\n",
      "7    此用户未填写评价内容                5\n",
      "8    此用户未填写评价内容                5\n",
      "9    此用户未填写评价内容                5\n",
      "      content  label\n",
      "1  此用户未填写评价内容      1\n",
      "2  此用户未填写评价内容      0\n",
      "3  此用户未填写评价内容      1\n",
      "4  此用户未填写评价内容      1\n",
      "5  此用户未填写评价内容      1\n",
      "6  此用户未填写评价内容      1\n",
      "7  此用户未填写评价内容      1\n",
      "8  此用户未填写评价内容      1\n",
      "9  此用户未填写评价内容      1\n",
      "数据处理结束\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/3346069408.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['label'] = df_selected['label'].apply(lambda x: 0 if x <= 3 else 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_excel('/kaggle/input/jd_comment_with_label/jd_comment_data.xlsx')\n",
    "\n",
    "# 提取指定字段（示例字段名为'字段1','字段2','字段3'）\n",
    "selected_columns = ['评价内容(content)', '评分（总分5分）(score)']\n",
    "df_selected = df[selected_columns]\n",
    "print(df_selected[1:10])\n",
    "\n",
    "# 保存为csv文件，重新指定字段的名字 content label（不包含索引）\n",
    "df_selected.columns = ['content', 'label']\n",
    "# 如果label 小于3 则为0， 大于3 则为1\n",
    "df_selected['label'] = df_selected['label'].apply(lambda x: 0 if x <= 3 else 1)\n",
    "print(df_selected[1:10])\n",
    "# 保存为csv文件，重新指定字段的名字 content label（不包含索引）\n",
    "df_selected.to_csv('/kaggle/working/jd-comments.csv', index=False)\n",
    "print(\"数据处理结束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.定义数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T01:10:25.782451Z",
     "iopub.status.busy": "2025-05-23T01:10:25.782096Z",
     "iopub.status.idle": "2025-05-23T01:10:25.790156Z",
     "shell.execute_reply": "2025-05-23T01:10:25.789546Z",
     "shell.execute_reply.started": "2025-05-23T01:10:25.782427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 定义数据集类 继承自torch.utils.data.Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, contents, labels):\n",
    "        self.contents = contents  # 文本数据\n",
    "        self.labels = labels      # 标签数据\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'content': self.contents.iloc[idx],\n",
    "            'label': torch.tensor(self.labels.iloc[idx])\n",
    "        }\n",
    "def create_dataloader(contents, labels, tokenizer, batch_size=32, shuffle=True):\n",
    "    # 创建数据集\n",
    "    dataset = TextDataset(contents, labels)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        # 自定义collate函数，用于处理不同长度的文本\n",
    "        contents = [item['content'] for item in batch]\n",
    "        labels = [item['label'] for item in batch]\n",
    "        # 使用tokenizer处理文本\n",
    "        inputs = tokenizer(\n",
    "            contents, # 文本列表\n",
    "            padding=True, # 填充到最大长度\n",
    "            truncation=True, # 截断到最大长度\n",
    "            max_length=512, # embeding_dim 最大长度\n",
    "            return_tensors=\"pt\" # 返回PyTorch张量\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "    # 创建数据加载器\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.加载tokenizer及model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T01:12:48.296924Z",
     "iopub.status.busy": "2025-05-23T01:12:48.296109Z",
     "iopub.status.idle": "2025-05-23T01:12:49.116040Z",
     "shell.execute_reply": "2025-05-23T01:12:49.115207Z",
     "shell.execute_reply.started": "2025-05-23T01:12:48.296896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# 加载预训练的BERT模型和分词器\n",
    "model_name = 'google-bert/bert-base-chinese' # 预训练模型名称\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) # 加载分词器\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2) # 加载BERT模型，指定标签数量为2（好评和差评）\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "# model = model.float()\n",
    "print(model)\n",
    "# tensorboard 记录器\n",
    "writer = SummaryWriter(\"/kaggle/working/logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.加载数据并划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T01:12:54.633285Z",
     "iopub.status.busy": "2025-05-23T01:12:54.633001Z",
     "iopub.status.idle": "2025-05-23T01:12:54.755819Z",
     "shell.execute_reply": "2025-05-23T01:12:54.755165Z",
     "shell.execute_reply.started": "2025-05-23T01:12:54.633265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      content  label\n",
      "0  此用户未填写评价内容      1\n",
      "1  此用户未填写评价内容      1\n",
      "2  此用户未填写评价内容      0\n",
      "3  此用户未填写评价内容      1\n",
      "4  此用户未填写评价内容      1\n",
      "(57454,)\n",
      "52                    此用户未填写评价内容\n",
      "16168          质量超级好啊 穿上哈还好看 太值了\n",
      "25529            用上了ssd，软件开启速度飞快\n",
      "38045    老公说以前上厕所没信号，现在都是满格！很不错呢\n",
      "29141                 此用户未填写评价内容\n",
      "11852                 此用户未填写评价内容\n",
      "42073                东西不错！也挺牢固的！\n",
      "14969                         不错\n",
      "32570                      可以，好用\n",
      "Name: content, dtype: object\n",
      "52       1\n",
      "16168    1\n",
      "25529    1\n",
      "38045    1\n",
      "29141    1\n",
      "11852    1\n",
      "42073    1\n",
      "14969    1\n",
      "32570    1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件\n",
    "df = pd.read_csv(\"/kaggle/working/jd-comments.csv\")\n",
    "print(df[0:5])\n",
    "# 划分训练集和测试集\n",
    "train_contents, test_contents, train_labels, test_labels = train_test_split(\n",
    "    df['content'], df['label'], test_size=0.2, random_state=42\n",
    ") \n",
    "print(train_contents.shape)\n",
    "print(train_contents[1:10])\n",
    "print(train_labels[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T01:12:58.617572Z",
     "iopub.status.busy": "2025-05-23T01:12:58.616887Z",
     "iopub.status.idle": "2025-05-23T01:12:58.631144Z",
     "shell.execute_reply": "2025-05-23T01:12:58.630449Z",
     "shell.execute_reply.started": "2025-05-23T01:12:58.617534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 创建训练集和测试集的数据加载器\n",
    "train_dataloader = create_dataloader(train_contents, train_labels, tokenizer, batch_size=32)\n",
    "test_dataloader = create_dataloader(test_contents, test_labels, tokenizer, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练并保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T01:13:59.835762Z",
     "iopub.status.busy": "2025-05-23T01:13:59.835120Z",
     "iopub.status.idle": "2025-05-23T02:13:24.306659Z",
     "shell.execute_reply": "2025-05-23T02:13:24.305948Z",
     "shell.execute_reply.started": "2025-05-23T01:13:59.835737Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.0879\n",
      "Model saved as model_epoch_1.pth\n",
      "Epoch 2/3, Loss: 0.0742\n",
      "Model saved as model_epoch_2.pth\n",
      "Epoch 3/3, Loss: 0.0637\n",
      "Model saved as model_epoch_3.pth\n"
     ]
    }
   ],
   "source": [
    "# 检查是否有可用的GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 使用GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 使用CPU\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) # 优化器，使用AdamW\n",
    "# 定义损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss() # 损失函数，使用交叉熵损失  \n",
    "# 训练模型\n",
    "num_epochs = 3 # 训练轮数\n",
    "# 模型加载到GPU\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    total_loss = 0 # 初始化总损失\n",
    "    for batch in train_dataloader: # 遍历训练集数据加载器\n",
    "        batch['labels'] = batch['labels'].long()\n",
    "        # 打印数据类型\n",
    "        #print(f\"Batch data types: {batch['input_ids'].dtype}, {batch['attention_mask'].dtype}, {batch['labels'].dtype}\")\n",
    "        \n",
    "        # 将数据加载到GPU\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        outputs = model(**batch) # 调用模型进行前向传播，传入输入数据\n",
    "        # 计算损失\n",
    "        loss = outputs.loss # 从模型输出中获取损失值\n",
    "        # 反向传播\n",
    "        loss.backward() # 反向传播计算梯度\n",
    "        # 更新参数\n",
    "        optimizer.step() # 更新模型参数 \n",
    "        # 打印损失值\n",
    "        # print(f\"Batch loss: {loss.item()}\")\n",
    "        # 累加损失值\n",
    "        total_loss += loss.item() * batch['input_ids'].size(0) # 累加损失值，乘以批次大小\n",
    "        # 记录损失值到tensorboard\n",
    "        if writer is not None:\n",
    "            if not torch.isfinite(loss):\n",
    "                print(\"Loss is infinite or NaN, skipping this batch.\")\n",
    "                continue\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_dataloader))\n",
    "    # 计算平均损失\n",
    "    avg_loss = total_loss / len(train_dataloader.dataset) # 计算平均损失\n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\") # 打印当前轮数和平均损失\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f\"/kaggle/working/model_epoch_{epoch+1}.pth\") # 保存模型参数，文件名为\"model_epoch_{epoch+1}.pth\"\n",
    "    print(f\"Model saved as model_epoch_{epoch+1}.pth\") # 打印保存模型的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T02:15:49.150629Z",
     "iopub.status.busy": "2025-05-23T02:15:49.150092Z",
     "iopub.status.idle": "2025-05-23T02:17:36.152275Z",
     "shell.execute_reply": "2025-05-23T02:17:36.151456Z",
     "shell.execute_reply.started": "2025-05-23T02:15:49.150607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0792, Accuracy: 0.9754\n"
     ]
    }
   ],
   "source": [
    "# 验证模型 \n",
    "model.to(device)\n",
    "model.eval() # 设置模型为评估模式\n",
    "total_loss = 0 # 初始化总损失\n",
    "total_correct = 0 # 初始化正确预测数量\n",
    "total_samples = 0 # 初始化样本数量\n",
    "with torch.no_grad(): # 禁用梯度计算，减少内存消耗\n",
    "    for batch in test_dataloader: # 遍历测试集数据加载器\n",
    "         # 将数据加载到GPU\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        # 前向传播  \n",
    "        outputs = model(**batch) # 调用模型进行前向传播，传入输入数据\n",
    "        # 计算损失\n",
    "        loss = outputs.loss # 从模型输出中获取损失值\n",
    "        total_loss += loss.item() * batch['input_ids'].size(0) # 累加损失值，乘以批次大小  \n",
    "        # 计算预测结果\n",
    "        logits = outputs.logits # 从模型输出中获取预测结果\n",
    "        predictions = torch.argmax(logits, dim=-1) # 获取预测结果的类别索引 \n",
    "        # 计算准确率\n",
    "        total_correct += (predictions == batch['labels']).sum().item() # 累加正确预测数量\n",
    "        total_samples += batch['labels'].size(0) # 累加样本数量 \n",
    "# 计算平均损失和准确率 \n",
    "avg_loss = total_loss / total_samples # 计算平均损失\n",
    "accuracy = total_correct / total_samples # 计算准确率\n",
    "# 打印结果\n",
    "print(f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\") # 打印当前轮数、平均损失和准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T05:38:24.863566Z",
     "iopub.status.busy": "2025-05-23T05:38:24.863269Z",
     "iopub.status.idle": "2025-05-23T05:38:53.237051Z",
     "shell.execute_reply": "2025-05-23T05:38:53.236238Z",
     "shell.execute_reply.started": "2025-05-23T05:38:24.863542Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 加载微调后的模型\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2045\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   2044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2045\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2046\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2073\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2072\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2073\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2074\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2075\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:38\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     cached_file,\n\u001b[0;32m     31\u001b[0m     extract_commit_hash,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     logging,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder_decoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EncoderDecoderConfig\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_factory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LazyAutoMapping\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     CONFIG_MAPPING_NAMES,\n\u001b[0;32m     41\u001b[0m     AutoConfig,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     replace_list_option_in_docstrings,\n\u001b[0;32m     45\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tokenizers_available():\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:40\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, model_type_to_module_name, replace_list_option_in_docstrings\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[0;32m     43\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     46\u001b[0m CLASS_DOCSTRING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124m    This is a generic model class that will be instantiated as one of the model classes of the library when created\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124m    with the [`~BaseAutoModelClass.from_pretrained`] class method or the [`~BaseAutoModelClass.from_config`] class\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124m    This class cannot be instantiated directly using `__init__()` (throws an error).\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2045\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   2044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2045\u001b[0m         module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   2046\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2073\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   2071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2072\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2073\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   2074\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2075\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\generation\\utils.py:62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeam_constraints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DisjunctiveConstraint, PhrasalConstraint\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeam_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcandidate_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     AssistantVocabTranslatorCache,\n\u001b[0;32m     64\u001b[0m     AssistedCandidateGenerator,\n\u001b[0;32m     65\u001b[0m     AssistedCandidateGeneratorDifferentTokenizers,\n\u001b[0;32m     66\u001b[0m     CandidateGenerator,\n\u001b[0;32m     67\u001b[0m     EarlyExitCandidateGenerator,\n\u001b[0;32m     68\u001b[0m     PromptLookupCandidateGenerator,\n\u001b[0;32m     69\u001b[0m     UniversalSpeculativeDecodingGenerator,\n\u001b[0;32m     70\u001b[0m     _crop_past_key_values,\n\u001b[0;32m     71\u001b[0m     _prepare_attention_mask,\n\u001b[0;32m     72\u001b[0m     _prepare_token_type_ids,\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     75\u001b[0m     NEED_SETUP_CACHE_CLASSES_MAPPING,\n\u001b[0;32m     76\u001b[0m     QUANT_BACKEND_CLASSES_MAPPING,\n\u001b[0;32m     77\u001b[0m     GenerationConfig,\n\u001b[0;32m     78\u001b[0m     GenerationMode,\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogits_process\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m     EncoderNoRepeatNGramLogitsProcessor,\n\u001b[0;32m     82\u001b[0m     EncoderRepetitionPenaltyLogitsProcessor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     UnbatchedClassifierFreeGuidanceLogitsProcessor,\n\u001b[0;32m    107\u001b[0m )\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_sklearn_available\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sklearn_available():\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isin_mps_friendly\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     19\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\sklearn\\utils\\fixes.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\stats\\__init__.py:624\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Import unused here but needs to stay until end of deprecation periode\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_mstats_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _find_repeats, theilslopes, siegelslopes\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_distn_infrastructure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m integrate\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# to approximate the pdf of a continuous distribution given its cdf\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_finite_differences\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _derivative\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\__init__.py:146\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\integrate\\__init__.py:112\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_quad_vec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quad_vec\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tanhsinh\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nsum, tanhsinh\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cubature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cubature\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lebedev\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lebedev_rule\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\integrate\\_cubature.py:17\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     array_namespace,\n\u001b[0;32m     11\u001b[0m     xp_size,\n\u001b[0;32m     12\u001b[0m     xp_copy,\n\u001b[0;32m     13\u001b[0m     xp_broadcast_promote\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MapWrapper\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     ProductNestedFixed,\n\u001b[0;32m     19\u001b[0m     GaussKronrodQuadrature,\n\u001b[0;32m     20\u001b[0m     GenzMalikCubature,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _split_subregion\n\u001b[0;32m     24\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcubature\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mh:\\anaconda\\miniconda3\\envs\\study-env\\Lib\\site-packages\\scipy\\integrate\\_rules\\__init__.py:9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      4\u001b[0m     Rule, FixedRule,\n\u001b[0;32m      5\u001b[0m     NestedFixedRule,\n\u001b[0;32m      6\u001b[0m     ProductNestedFixed,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_genz_malik\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenzMalikCubature\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gauss_kronrod\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussKronrodQuadrature\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gauss_legendre\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussLegendreQuadrature\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1191\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# 加载微调后的模型\n",
    "model_path = \"/kaggle/working/model_epoch_1.pth\"\n",
    "model_name = \"google-bert/bert-base-chinese\"\n",
    "label_map = {0: \"负面\", 1: \"正面\"}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# 推理函数\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", \n",
    "                      padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)\n",
    "        pred_label = torch.argmax(probs).item()\n",
    "    return {\n",
    "        \"label\": label_map[pred_label],\n",
    "        \"confidence\": probs[0][pred_label].item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T03:19:37.475480Z",
     "iopub.status.busy": "2025-05-23T03:19:37.474761Z",
     "iopub.status.idle": "2025-05-23T03:19:37.547994Z",
     "shell.execute_reply": "2025-05-23T03:19:37.547340Z",
     "shell.execute_reply.started": "2025-05-23T03:19:37.475457Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable: 正面\n",
      "lable: 0.7131579518318176\n"
     ]
    }
   ],
   "source": [
    "# 推理示例\n",
    "text = \"一般般，一分钱一分货吧\"\n",
    "result = predict(text)\n",
    "print(\"lable:\", result['label'])\n",
    "print(\"lable:\", result['confidence'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 134082,
     "sourceId": 318737,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "study-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
