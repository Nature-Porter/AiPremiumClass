{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:16:17.305456Z","iopub.execute_input":"2025-05-29T15:16:17.305680Z","iopub.status.idle":"2025-05-29T15:16:17.628411Z","shell.execute_reply.started":"2025-05-29T15:16:17.305662Z","shell.execute_reply":"2025-05-29T15:16:17.627546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1⃣️【第十一周作业】\n\n1. 参考课堂案例，使用指定的数据集，编写代码实现ner模型训练和推流。\n   https://huggingface.co/datasets/doushabao4766/msra_ner_k_V3\n2. 完成预测结果的实体抽取。\n   输入：“双方确定了今后发展中美关系的指导方针。”\n   输出：[{\"entity\":\"ORG\",\"content\":\"中\"},{\"entity\":\"ORG\",\"content\":\"美\"}]\n3. 整理Dataset、Trainer、TrainingArgument、DataCollator、Evaluate 知识点，总结文档`","metadata":{}},{"cell_type":"code","source":"!pip install seqeval evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:16:17.629244Z","iopub.execute_input":"2025-05-29T15:16:17.629786Z","iopub.status.idle":"2025-05-29T15:16:24.907120Z","shell.execute_reply.started":"2025-05-29T15:16:17.629758Z","shell.execute_reply":"2025-05-29T15:16:24.906435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\nfrom transformers import TrainingArguments, Trainer\nimport torch\nimport evaluate  # pip install evaluate\nimport seqeval   # pip install seqeval\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:16:24.909057Z","iopub.execute_input":"2025-05-29T15:16:24.909309Z","iopub.status.idle":"2025-05-29T15:16:52.150966Z","shell.execute_reply.started":"2025-05-29T15:16:24.909283Z","shell.execute_reply":"2025-05-29T15:16:52.150203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  从预训练模型google-bert/bert-base-chinese中加载AutoModelForTokenClassification模型，并设置标签数量为7\n#  AutoModelForTokenClassification是transformers库中用于命名实体识别（NER）的预训练模型，它基于BERT模型进行微调，可以识别文本中的命名实体。\n#  AutoTokenizer是transformers库中用于文本分词的类，它可以将文本转换为模型可以理解的token索引。\n#  AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', num_labels=7)\n#  从预训练模型google-bert/bert-base-chinese中加载AutoModelForTokenClassification模型，并设置标签数量为7。\nmodel = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', num_labels=7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:16:52.151774Z","iopub.execute_input":"2025-05-29T15:16:52.152386Z","iopub.status.idle":"2025-05-29T15:16:56.206004Z","shell.execute_reply.started":"2025-05-29T15:16:52.152360Z","shell.execute_reply":"2025-05-29T15:16:56.205475Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  从预训练模型google-bert/bert-base-chinese中加载tokenizer，用于将文本转换为模型可以理解的token索引。\n\ntokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:16:56.206626Z","iopub.execute_input":"2025-05-29T15:16:56.206809Z","iopub.status.idle":"2025-05-29T15:17:00.412372Z","shell.execute_reply.started":"2025-05-29T15:16:56.206785Z","shell.execute_reply":"2025-05-29T15:17:00.411818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:00.413023Z","iopub.execute_input":"2025-05-29T15:17:00.413275Z","iopub.status.idle":"2025-05-29T15:17:00.419374Z","shell.execute_reply.started":"2025-05-29T15:17:00.413250Z","shell.execute_reply":"2025-05-29T15:17:00.418635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 模型测试\nmessage= \"命名实体识别\"\n\nlabel = torch.tensor([0,1,0,2,5,4,3,6])\n\n# 使用tokenizer对输入文本进行编码，并返回PyTorch张量\nmodel_input = tokenizer([message], return_tensors='pt')\n\nprint(model_input)\n\nresult = model(**model_input, labels=label)\n\nprint(f'result.loss={result.loss}')\nprint(f'result.logits={result.logits}')\nprint(f'result.logits.shape={result.logits.shape}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:00.420231Z","iopub.execute_input":"2025-05-29T15:17:00.420511Z","iopub.status.idle":"2025-05-29T15:17:00.594120Z","shell.execute_reply.started":"2025-05-29T15:17:00.420495Z","shell.execute_reply":"2025-05-29T15:17:00.593492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# huggingface数据及加载\nds = load_dataset(\"doushabao4766/msra_ner_k_V3\")\n# ds = load_dataset('nlhappy/CLUE-NER')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:00.594802Z","iopub.execute_input":"2025-05-29T15:17:00.595066Z","iopub.status.idle":"2025-05-29T15:17:05.670244Z","shell.execute_reply.started":"2025-05-29T15:17:00.595047Z","shell.execute_reply":"2025-05-29T15:17:05.669501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 查看数据集\ntrain_data = ds['train']\n\n# for row in train_data:\n#     print(row)\n#     print(len(row['tokens']))\n#     print(len(row['ner_tags']))\n#     break\n\nfor row in train_data:\n    print(row)\n    print((row['tokens']))\n    print(len(row['ner_tags']))\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:05.672325Z","iopub.execute_input":"2025-05-29T15:17:05.672534Z","iopub.status.idle":"2025-05-29T15:17:05.677404Z","shell.execute_reply.started":"2025-05-29T15:17:05.672517Z","shell.execute_reply":"2025-05-29T15:17:05.676859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  \n# 数据集预处理确定label与数值类型之间的映射（map）\nentities = ['O'] + list({'movie', 'name', 'game', 'address', 'position', \\\n           'company', 'scene', 'book', 'organization', 'government'})\n\ntags = ['O']\n \nfor entity in entities[1:]:\n    tags.append('B-'+ entity.upper())\n    tags.append('I-'+ entity.upper())\n\nentity_index = {entity:i for i, entity in enumerate(entities)}\nprint(entity_index)\nprint(tags, len(tags))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:05.678101Z","iopub.execute_input":"2025-05-29T15:17:05.678287Z","iopub.status.idle":"2025-05-29T15:17:05.693310Z","shell.execute_reply.started":"2025-05-29T15:17:05.678274Z","shell.execute_reply":"2025-05-29T15:17:05.692699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 原始文本转换模型需要token_idx,生成和token_idx对齐label\ndef data_input_proc(item):\n    # 输入文本转换模型输入token索引\n    all_texts = [''.join(tokens) for tokens in item['tokens']]  # 每个 token 列表拼接成字符串\n    input_data = tokenizer(all_texts, truncation=True, add_special_tokens=False, max_length=512)\n    adjust_labels = []  # 所有修正后label索引列表\n    # 上一步骤生成ner_tag中索引和token对齐\n    for k in range(len(input_data['input_ids'])):\n        # 每条记录token对应word_ids\n        word_ids = input_data.word_ids(k)\n        # 批次ner_tag长度和token长度对齐\n        tags = item['ner_tags'][k]\n        \n        adjusted_label_ids = []\n        i, prev_wid = -1,-1\n        for wid in word_ids:\n            if (wid != prev_wid):   #  word_ids [1,1,1,2,3,4,5] -> [0,1,2,3,4,5,6]\n                i += 1 # token对应检索位置+1\n                prev_wid = wid\n            adjusted_label_ids.append(tags[i])\n        adjust_labels.append(adjusted_label_ids)                \n    # 修正后label添加到input_data\n    input_data['labels'] = adjust_labels\n    return input_data\n    \n# 正确使用 map：启用 batched 并设置 batch_size\nds_map = ds.map(data_input_proc, batched=True, batch_size=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:35.909140Z","iopub.execute_input":"2025-05-29T15:17:35.909421Z","iopub.status.idle":"2025-05-29T15:17:45.238462Z","shell.execute_reply.started":"2025-05-29T15:17:35.909403Z","shell.execute_reply":"2025-05-29T15:17:45.237664Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ds_map","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:51.779029Z","iopub.execute_input":"2025-05-29T15:17:51.779602Z","iopub.status.idle":"2025-05-29T15:17:51.784709Z","shell.execute_reply.started":"2025-05-29T15:17:51.779580Z","shell.execute_reply":"2025-05-29T15:17:51.783498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 记录转换为pytorch\nds_map.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:51.785787Z","iopub.execute_input":"2025-05-29T15:17:51.786050Z","iopub.status.idle":"2025-05-29T15:17:51.815240Z","shell.execute_reply.started":"2025-05-29T15:17:51.786034Z","shell.execute_reply":"2025-05-29T15:17:51.814627Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n    num_train_epochs = 3,    # 训练 epoch\n    save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n    per_device_train_batch_size=32,  # 训练批次\n    per_device_eval_batch_size=32,\n    report_to='tensorboard',  # 训练输出记录\n    eval_strategy=\"epoch\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:51.816393Z","iopub.execute_input":"2025-05-29T15:17:51.816623Z","iopub.status.idle":"2025-05-29T15:17:51.857931Z","shell.execute_reply.started":"2025-05-29T15:17:51.816609Z","shell.execute_reply":"2025-05-29T15:17:51.857438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"id2lbl = {i:tag for i, tag in enumerate(tags)}\nlbl2id = {tag:i for i, tag in enumerate(tags)}\n\nmodel = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n                                                        num_labels=21,\n                                                        id2label=id2lbl,\n                                                        label2id=lbl2id)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:51.858646Z","iopub.execute_input":"2025-05-29T15:17:51.858878Z","iopub.status.idle":"2025-05-29T15:17:52.142251Z","shell.execute_reply.started":"2025-05-29T15:17:51.858862Z","shell.execute_reply":"2025-05-29T15:17:52.141571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# metric 方法\ndef compute_metric(result):\n    # result 是一个tuple (predicts, labels)\n    \n    # 获取评估对象\n    seqeval = evaluate.load('seqeval')\n    predicts,labels = result\n    predicts = np.argmax(prdicts, axis=2)\n    \n    # 准备评估数据\n    predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    results = seqeval.compute(predictions=predicts, references=labels)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:52.143877Z","iopub.execute_input":"2025-05-29T15:17:52.144143Z","iopub.status.idle":"2025-05-29T15:17:52.148679Z","shell.execute_reply.started":"2025-05-29T15:17:52.144128Z","shell.execute_reply":"2025-05-29T15:17:52.148121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=ds_map['train'],\n    eval_dataset=ds_map['test'],\n    data_collator=data_collator,\n    compute_metrics=compute_metric\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:52.149257Z","iopub.execute_input":"2025-05-29T15:17:52.149467Z","iopub.status.idle":"2025-05-29T15:17:52.733223Z","shell.execute_reply.started":"2025-05-29T15:17:52.149453Z","shell.execute_reply":"2025-05-29T15:17:52.732470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T15:17:52.734087Z","iopub.execute_input":"2025-05-29T15:17:52.734277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = trainer.predict(ds_map['validation'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ds1['test'][10]['tokens'])\nprint(ds2['test'][10]['labels'])\nprint(result.label_ids[10])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" [tags[p] for p,l in zip(result.label_ids[10],ds_map['test'][10]['labels'])]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"[tags[l] for p,l in zip(result.label_ids[10],ds2['test'][10]['labels'])]","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}