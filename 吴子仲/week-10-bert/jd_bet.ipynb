{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-05-23T11:50:33.584322Z",
          "iopub.status.busy": "2025-05-23T11:50:33.583526Z",
          "iopub.status.idle": "2025-05-23T11:50:33.592566Z",
          "shell.execute_reply": "2025-05-23T11:50:33.591907Z",
          "shell.execute_reply.started": "2025-05-23T11:50:33.584291Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T11:50:33.593817Z",
          "iopub.status.busy": "2025-05-23T11:50:33.593587Z",
          "iopub.status.idle": "2025-05-23T11:50:33.667505Z",
          "shell.execute_reply": "2025-05-23T11:50:33.666966Z",
          "shell.execute_reply.started": "2025-05-23T11:50:33.593799Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "kagger_input_dir = '/kaggle/input/'\n",
        "kagger_output_dir = '/kaggle/working/'\n",
        "\n",
        "jd_comment_path = 'jd_comment_processed.txt'\n",
        "model_save_path = 'jd_text_classifier.pth'\n",
        "\n",
        "is_kagger = False\n",
        "if is_kagger:\n",
        "    jd_comment_path = kagger_input_dir + jd_comment_path\n",
        "    model_save_path = kagger_output_dir + model_save_path\n",
        "\n",
        "dataset = []\n",
        "with open(jd_comment_path, 'r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    for i, line in enumerate(lines):\n",
        "        # 跳过标题行\n",
        "        if i == 0:\n",
        "            continue\n",
        "        comment = line.split('\\t')[0]\n",
        "        star = line.split('\\t')[1].replace('\\n', '')\n",
        "        dataset.append((comment, int(star)))\n",
        "        # if i == 100:\n",
        "        #     break\n",
        "    # print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2025-05-23T12:15:39.877453Z",
          "iopub.status.busy": "2025-05-23T12:15:39.876925Z",
          "iopub.status.idle": "2025-05-23T12:15:40.112200Z",
          "shell.execute_reply": "2025-05-23T12:15:40.111600Z",
          "shell.execute_reply.started": "2025-05-23T12:15:39.877429Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('google-bert/bert-base-chinese',num_labels=6)\n",
        "config = model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T11:50:33.870518Z",
          "iopub.status.busy": "2025-05-23T11:50:33.870269Z",
          "iopub.status.idle": "2025-05-23T11:50:34.010068Z",
          "shell.execute_reply": "2025-05-23T11:50:34.009329Z",
          "shell.execute_reply.started": "2025-05-23T11:50:33.870500Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T11:50:34.011983Z",
          "iopub.status.busy": "2025-05-23T11:50:34.011582Z",
          "iopub.status.idle": "2025-05-23T11:50:34.021799Z",
          "shell.execute_reply": "2025-05-23T11:50:34.021052Z",
          "shell.execute_reply.started": "2025-05-23T11:50:34.011964Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 构建数据集\n",
        "def build_collate(tokenizer):\n",
        "    def collate_fn(batch):\n",
        "        sentence,labels = zip(*batch)\n",
        "\n",
        "        model_inputs = tokenizer(sentence,\n",
        "                         return_tensors = 'pt',    # 生成数据类型 py=pytorch\n",
        "                         padding = True,          # 最长token构建padding\n",
        "                         truncation = True        # 超过模型最大长度的token序列，裁剪\n",
        "                    )\n",
        "        labels = torch.tensor(labels)\n",
        "        return model_inputs,labels\n",
        "    return collate_fn\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=build_collate(tokenizer))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T11:50:34.022976Z",
          "iopub.status.busy": "2025-05-23T11:50:34.022771Z",
          "iopub.status.idle": "2025-05-23T11:51:42.882968Z",
          "shell.execute_reply": "2025-05-23T11:51:42.882173Z",
          "shell.execute_reply.started": "2025-05-23T11:50:34.022955Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        comments, labels = batch\n",
        "        # 前向传播\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(**comments)\n",
        "        # 计算损失,反向传播和优化\n",
        "        # print(outputs.logits)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if  i % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "            break\n",
        "\n",
        "# 保存模型\n",
        "torch.save(model.state_dict(), model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-05-23T12:16:18.386114Z",
          "iopub.status.busy": "2025-05-23T12:16:18.385831Z",
          "iopub.status.idle": "2025-05-23T12:16:19.966424Z",
          "shell.execute_reply": "2025-05-23T12:16:19.965697Z",
          "shell.execute_reply.started": "2025-05-23T12:16:18.386093Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoConfig\n",
        "\n",
        "state_dict = torch.load(model_save_path)\n",
        "\n",
        "# 初始化模型结构（不加载预训练权重）\n",
        "model = AutoModelForSequenceClassification.from_config(config)\n",
        "\n",
        "# 加载本地保存的权重文件（.pth）\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()  # 设置为评估模式\n",
        "\n",
        "text = \"这件商品真厉害，厉害到我都不会用\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "# 输出结果\n",
        "print(f\"预测类别索引: {predictions.item()}\")\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 134082,
          "sourceId": 318737,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7492926,
          "sourceId": 11918745,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31040,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
