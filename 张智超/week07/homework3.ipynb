{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-18T02:10:24.803955Z",
     "iopub.status.busy": "2025-04-18T02:10:24.803612Z",
     "iopub.status.idle": "2025-04-18T02:10:24.812243Z",
     "shell.execute_reply": "2025-04-18T02:10:24.811318Z",
     "shell.execute_reply.started": "2025-04-18T02:10:24.803930Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/stopwords/stopwords.txt\n",
      "/kaggle/input/doubanmovieshortcomments/DMSC.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 尝试不同分词工具进行文本分词，观察模型训练结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T02:48:41.335009Z",
     "iopub.status.busy": "2025-04-18T02:48:41.334208Z",
     "iopub.status.idle": "2025-04-18T02:48:41.339010Z",
     "shell.execute_reply": "2025-04-18T02:48:41.338280Z",
     "shell.execute_reply.started": "2025-04-18T02:48:41.334986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T02:12:47.616402Z",
     "iopub.status.busy": "2025-04-18T02:12:47.615943Z",
     "iopub.status.idle": "2025-04-18T02:12:58.050585Z",
     "shell.execute_reply": "2025-04-18T02:12:58.049791Z",
     "shell.execute_reply.started": "2025-04-18T02:12:47.616378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 将comment写入txt文件\n",
    "with open('/kaggle/input/doubanmovieshortcomments/DMSC.csv') as f, open('/kaggle/working/comments.txt', 'w', encoding='utf-8') as o:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        comment = row['Comment'].strip()\n",
    "        star = row['Star'].strip()\n",
    "        if (not comment) or (not star):continue\n",
    "        star = int(star)\n",
    "        if star <= 2 or star >= 4:\n",
    "            o.write(f'{comment}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-18T02:13:15.993372Z",
     "iopub.status.busy": "2025-04-18T02:13:15.993014Z",
     "iopub.status.idle": "2025-04-18T02:21:25.939167Z",
     "shell.execute_reply": "2025-04-18T02:21:25.938459Z",
     "shell.execute_reply.started": "2025-04-18T02:13:15.993333Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spm训练完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /kaggle/working/comments.txt\n",
      "  input_format: \n",
      "  model_prefix: spm_mod\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 50000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: /kaggle/working/comments.txt\n",
      "trainer_interface.cc(147) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(124) LOG(WARNING) Too many sentences are loaded! (1655107), which may slow down training.\n",
      "trainer_interface.cc(126) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(129) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 1655107 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=62612140\n",
      "trainer_interface.cc(550) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=4767\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 1655089 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=18580062\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 1004767 seed sentencepieces\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 1655089\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 1945027\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 1945027 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=742495 obj=108.181 num_tokens=23151655 num_tokens/piece=31.1809\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=640717 obj=99.3291 num_tokens=23341804 num_tokens/piece=36.4308\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=480369 obj=99.2891 num_tokens=23598642 num_tokens/piece=49.1261\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=479797 obj=99.1274 num_tokens=23644877 num_tokens/piece=49.281\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=359843 obj=99.5711 num_tokens=24046981 num_tokens/piece=66.8263\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=359837 obj=99.3567 num_tokens=24061186 num_tokens/piece=66.8669\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=269877 obj=100.176 num_tokens=24656406 num_tokens/piece=91.3616\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=269877 obj=99.8312 num_tokens=24670406 num_tokens/piece=91.4135\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=202407 obj=100.932 num_tokens=25333787 num_tokens/piece=125.163\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=202406 obj=100.536 num_tokens=25355569 num_tokens/piece=125.271\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=151804 obj=101.851 num_tokens=26049999 num_tokens/piece=171.603\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=151804 obj=101.439 num_tokens=26059668 num_tokens/piece=171.667\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=113853 obj=102.928 num_tokens=26802942 num_tokens/piece=235.417\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=113853 obj=102.504 num_tokens=26811166 num_tokens/piece=235.489\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=85389 obj=104.189 num_tokens=27625849 num_tokens/piece=323.529\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=85389 obj=103.738 num_tokens=27632857 num_tokens/piece=323.611\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=64041 obj=105.62 num_tokens=28513682 num_tokens/piece=445.241\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=64041 obj=105.142 num_tokens=28519665 num_tokens/piece=445.334\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=55000 obj=106.195 num_tokens=29008948 num_tokens/piece=527.435\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=55000 obj=105.94 num_tokens=29017598 num_tokens/piece=527.593\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: spm_mod.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: spm_mod.vocab\n"
     ]
    }
   ],
   "source": [
    "# 使用sentencepiece进行分词\n",
    "spm.SentencePieceTrainer.Train(input='/kaggle/working/comments.txt', model_prefix='spm_mod', vocab_size=50000)\n",
    "print('spm训练完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T02:36:58.956886Z",
     "iopub.status.busy": "2025-04-18T02:36:58.956338Z",
     "iopub.status.idle": "2025-04-18T02:36:59.070732Z",
     "shell.execute_reply": "2025-04-18T02:36:59.069786Z",
     "shell.execute_reply.started": "2025-04-18T02:36:58.956862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 加载spm分词模型\n",
    "sp = spm.SentencePieceProcessor(model_file='spm_mod.model')\n",
    "# 去掉分词中的▁\n",
    "def spm_cut(comment):\n",
    "    words = sp.EncodeAsPieces(comment)\n",
    "    return [word.replace('▁', '') for word in words if word != '▁']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T02:37:35.391055Z",
     "iopub.status.busy": "2025-04-18T02:37:35.390806Z",
     "iopub.status.idle": "2025-04-18T02:44:18.512519Z",
     "shell.execute_reply": "2025-04-18T02:44:18.511866Z",
     "shell.execute_reply.started": "2025-04-18T02:37:35.391038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1650495\n"
     ]
    }
   ],
   "source": [
    "# 加载停用词\n",
    "stopwords = [line.strip() for line in open('/kaggle/input/stopwords/stopwords.txt', 'r', encoding='utf-8')] + ['PAD']\n",
    "# 进行分词\n",
    "comments_list = []\n",
    "with open('/kaggle/input/doubanmovieshortcomments/DMSC.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        comment = row['Comment'].strip()\n",
    "        star = row['Star'].strip()\n",
    "        if (not comment) or (not star):continue\n",
    "        star = int(star)\n",
    "        if star <= 2:\n",
    "            # 使用sentencepiece进行分词\n",
    "            words = spm_cut(comment)\n",
    "            comments_list.append(([item for item in words if item not in stopwords], 0))\n",
    "        elif star >= 4:\n",
    "            words = spm_cut(comment)\n",
    "            comments_list.append(([item for item in words if item not in stopwords], 1))\n",
    "        \n",
    "print(len(comments_list)) # 1650495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T02:46:50.964185Z",
     "iopub.status.busy": "2025-04-18T02:46:50.963652Z",
     "iopub.status.idle": "2025-04-18T02:46:53.341856Z",
     "shell.execute_reply": "2025-04-18T02:46:53.341281Z",
     "shell.execute_reply.started": "2025-04-18T02:46:50.964165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174637\n",
      "52445\n"
     ]
    }
   ],
   "source": [
    "# 取分词长度5-100的评论\n",
    "comments_list = [c for c in comments_list if len(c[0]) in range(5, 100)]\n",
    "print(len(comments_list)) # 1174637\n",
    "# 构建词典\n",
    "vocab = {}\n",
    "word_set = set()\n",
    "for comment, _ in comments_list:\n",
    "    word_set.update(comment)\n",
    "word_list = ['PAD', 'UNK'] + list(word_set)\n",
    "vocab = {word: i for i, word in enumerate(word_list)}\n",
    "print(len(vocab)) # 52445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T03:39:05.039080Z",
     "iopub.status.busy": "2025-04-18T03:39:05.038131Z",
     "iopub.status.idle": "2025-04-18T03:39:05.617890Z",
     "shell.execute_reply": "2025-04-18T03:39:05.617335Z",
     "shell.execute_reply.started": "2025-04-18T03:39:05.039034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch_data):\n",
    "    comments, labels = [], []\n",
    "    for comment, label in batch_data:\n",
    "        # 转为分词的索引\n",
    "        comments.append(torch.tensor([vocab.get(word, vocab['UNK']) for word in comment]))\n",
    "        labels.append(label)\n",
    "    comments = nn.utils.rnn.pad_sequence(comments, batch_first=True, padding_value=vocab['PAD'])\n",
    "    labels = torch.tensor(labels)\n",
    "    return comments, labels\n",
    "# 加载训练数据：使用自定义函数对齐批次的seq长度\n",
    "train_list, test_list = train_test_split(comments_list, test_size=0.2, random_state=42)\n",
    "train_dataLoader = DataLoader(train_list, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataLoader = DataLoader(test_list, batch_size=128, collate_fn=collate_fn)\n",
    "\n",
    "# 定义模型\n",
    "class Comment_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, input_index):\n",
    "        embed = self.embedding(input_index)\n",
    "        out, (h, _) = self.rnn(embed)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "model = Comment_RNN(vocab_size, embedding_dim, hidden_size, num_layers, num_classes)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-18T03:39:32.887409Z",
     "iopub.status.busy": "2025-04-18T03:39:32.886933Z",
     "iopub.status.idle": "2025-04-18T03:54:26.336968Z",
     "shell.execute_reply": "2025-04-18T03:54:26.336351Z",
     "shell.execute_reply.started": "2025-04-18T03:39:32.887388Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [100], Loss: 0.5321649312973022\n",
      "Epoch [1], Step [200], Loss: 0.5257980227470398\n",
      "Epoch [1], Step [300], Loss: 0.5064579844474792\n",
      "Epoch [1], Step [400], Loss: 0.47292113304138184\n",
      "Epoch [1], Step [500], Loss: 0.5127525329589844\n",
      "Epoch [1], Step [600], Loss: 0.5176987648010254\n",
      "Epoch [1], Step [700], Loss: 0.43587103486061096\n",
      "Epoch [1], Step [800], Loss: 0.5066991448402405\n",
      "Epoch [1], Step [900], Loss: 0.510401725769043\n",
      "Epoch [1], Step [1000], Loss: 0.5038600564002991\n",
      "Epoch [1], Step [1100], Loss: 0.5166669487953186\n",
      "Epoch [1], Step [1200], Loss: 0.4800718426704407\n",
      "Epoch [1], Step [1300], Loss: 0.5536713004112244\n",
      "Epoch [1], Step [1400], Loss: 0.5447406768798828\n",
      "Epoch [1], Step [1500], Loss: 0.5261307954788208\n",
      "Epoch [1], Step [1600], Loss: 0.5548434853553772\n",
      "Epoch [1], Step [1700], Loss: 0.5279650688171387\n",
      "Epoch [1], Step [1800], Loss: 0.47158461809158325\n",
      "Epoch [1], Step [1900], Loss: 0.545153796672821\n",
      "Epoch [1], Step [2000], Loss: 0.5749394297599792\n",
      "Epoch [1], Step [2100], Loss: 0.49520498514175415\n",
      "Epoch [1], Step [2200], Loss: 0.58355313539505\n",
      "Epoch [1], Step [2300], Loss: 0.5463953018188477\n",
      "Epoch [1], Step [2400], Loss: 0.5267526507377625\n",
      "Epoch [1], Step [2500], Loss: 0.5452995300292969\n",
      "Epoch [1], Step [2600], Loss: 0.5880733132362366\n",
      "Epoch [1], Step [2700], Loss: 0.4587549567222595\n",
      "Epoch [1], Step [2800], Loss: 0.5352634787559509\n",
      "Epoch [1], Step [2900], Loss: 0.4944884777069092\n",
      "Epoch [1], Step [3000], Loss: 0.5353156924247742\n",
      "Epoch [1], Step [3100], Loss: 0.5577662587165833\n",
      "Epoch [1], Step [3200], Loss: 0.4708181917667389\n",
      "Epoch [1], Step [3300], Loss: 0.5052129626274109\n",
      "Epoch [1], Step [3400], Loss: 0.462576687335968\n",
      "Epoch [1], Step [3500], Loss: 0.5622218251228333\n",
      "Epoch [1], Step [3600], Loss: 0.594325602054596\n",
      "Epoch [1], Step [3700], Loss: 0.5655786991119385\n",
      "Epoch [1], Step [3800], Loss: 0.4292292594909668\n",
      "Epoch [1], Step [3900], Loss: 0.3810327649116516\n",
      "Epoch [1], Step [4000], Loss: 0.4857169985771179\n",
      "Epoch [1], Step [4100], Loss: 0.3256634473800659\n",
      "Epoch [1], Step [4200], Loss: 0.4178316295146942\n",
      "Epoch [1], Step [4300], Loss: 0.32422104477882385\n",
      "Epoch [1], Step [4400], Loss: 0.3819001615047455\n",
      "Epoch [1], Step [4500], Loss: 0.2833744287490845\n",
      "Epoch [1], Step [4600], Loss: 0.34939196705818176\n",
      "Epoch [1], Step [4700], Loss: 0.2422885000705719\n",
      "Epoch [1], Step [4800], Loss: 0.307386577129364\n",
      "Epoch [1], Step [4900], Loss: 0.28787553310394287\n",
      "Epoch [1], Step [5000], Loss: 0.38638758659362793\n",
      "Epoch [1], Step [5100], Loss: 0.4070092439651489\n",
      "Epoch [1], Step [5200], Loss: 0.22172217071056366\n",
      "Epoch [1], Step [5300], Loss: 0.3360680639743805\n",
      "Epoch [1], Step [5400], Loss: 0.35402846336364746\n",
      "Epoch [1], Step [5500], Loss: 0.3090192973613739\n",
      "Epoch [1], Step [5600], Loss: 0.20997761189937592\n",
      "Epoch [1], Step [5700], Loss: 0.3156939744949341\n",
      "Epoch [1], Step [5800], Loss: 0.38812270760536194\n",
      "Epoch [1], Step [5900], Loss: 0.23711621761322021\n",
      "Epoch [1], Step [6000], Loss: 0.260961651802063\n",
      "Epoch [1], Step [6100], Loss: 0.24979539215564728\n",
      "Epoch [1], Step [6200], Loss: 0.20633605122566223\n",
      "Epoch [1], Step [6300], Loss: 0.27958056330680847\n",
      "Epoch [1], Step [6400], Loss: 0.2999310791492462\n",
      "Epoch [1], Step [6500], Loss: 0.30081966519355774\n",
      "Epoch [1], Step [6600], Loss: 0.20017486810684204\n",
      "Epoch [1], Step [6700], Loss: 0.1774573177099228\n",
      "Epoch [1], Step [6800], Loss: 0.1882748305797577\n",
      "Epoch [1], Step [6900], Loss: 0.2121172398328781\n",
      "Epoch [1], Step [7000], Loss: 0.2583480179309845\n",
      "Epoch [1], Step [7100], Loss: 0.22444592416286469\n",
      "Epoch [1], Step [7200], Loss: 0.24596188962459564\n",
      "Epoch [1], Step [7300], Loss: 0.20231281220912933\n",
      "Epoch [2], Step [100], Loss: 0.18672215938568115\n",
      "Epoch [2], Step [200], Loss: 0.2640332579612732\n",
      "Epoch [2], Step [300], Loss: 0.26750123500823975\n",
      "Epoch [2], Step [400], Loss: 0.19264519214630127\n",
      "Epoch [2], Step [500], Loss: 0.13037076592445374\n",
      "Epoch [2], Step [600], Loss: 0.19895564019680023\n",
      "Epoch [2], Step [700], Loss: 0.18317246437072754\n",
      "Epoch [2], Step [800], Loss: 0.1941065639257431\n",
      "Epoch [2], Step [900], Loss: 0.2176772952079773\n",
      "Epoch [2], Step [1000], Loss: 0.19911441206932068\n",
      "Epoch [2], Step [1100], Loss: 0.18250073492527008\n",
      "Epoch [2], Step [1200], Loss: 0.17731545865535736\n",
      "Epoch [2], Step [1300], Loss: 0.245193749666214\n",
      "Epoch [2], Step [1400], Loss: 0.2010045349597931\n",
      "Epoch [2], Step [1500], Loss: 0.31345582008361816\n",
      "Epoch [2], Step [1600], Loss: 0.1843504160642624\n",
      "Epoch [2], Step [1700], Loss: 0.2579701244831085\n",
      "Epoch [2], Step [1800], Loss: 0.19455498456954956\n",
      "Epoch [2], Step [1900], Loss: 0.27667179703712463\n",
      "Epoch [2], Step [2000], Loss: 0.17272460460662842\n",
      "Epoch [2], Step [2100], Loss: 0.30339688062667847\n",
      "Epoch [2], Step [2200], Loss: 0.1775268167257309\n",
      "Epoch [2], Step [2300], Loss: 0.20022356510162354\n",
      "Epoch [2], Step [2400], Loss: 0.2247808575630188\n",
      "Epoch [2], Step [2500], Loss: 0.2500670552253723\n",
      "Epoch [2], Step [2600], Loss: 0.16439004242420197\n",
      "Epoch [2], Step [2700], Loss: 0.23293766379356384\n",
      "Epoch [2], Step [2800], Loss: 0.27407118678092957\n",
      "Epoch [2], Step [2900], Loss: 0.1711871176958084\n",
      "Epoch [2], Step [3000], Loss: 0.20647406578063965\n",
      "Epoch [2], Step [3100], Loss: 0.17114561796188354\n",
      "Epoch [2], Step [3200], Loss: 0.21296532452106476\n",
      "Epoch [2], Step [3300], Loss: 0.19669672846794128\n",
      "Epoch [2], Step [3400], Loss: 0.2571006119251251\n",
      "Epoch [2], Step [3500], Loss: 0.15376867353916168\n",
      "Epoch [2], Step [3600], Loss: 0.1192287728190422\n",
      "Epoch [2], Step [3700], Loss: 0.2405467927455902\n",
      "Epoch [2], Step [3800], Loss: 0.2266198694705963\n",
      "Epoch [2], Step [3900], Loss: 0.3407808840274811\n",
      "Epoch [2], Step [4000], Loss: 0.1261313557624817\n",
      "Epoch [2], Step [4100], Loss: 0.1616564393043518\n",
      "Epoch [2], Step [4200], Loss: 0.27215784788131714\n",
      "Epoch [2], Step [4300], Loss: 0.24543613195419312\n",
      "Epoch [2], Step [4400], Loss: 0.18822398781776428\n",
      "Epoch [2], Step [4500], Loss: 0.2087690234184265\n",
      "Epoch [2], Step [4600], Loss: 0.21338985860347748\n",
      "Epoch [2], Step [4700], Loss: 0.21796070039272308\n",
      "Epoch [2], Step [4800], Loss: 0.20111620426177979\n",
      "Epoch [2], Step [4900], Loss: 0.2331511527299881\n",
      "Epoch [2], Step [5000], Loss: 0.24837660789489746\n",
      "Epoch [2], Step [5100], Loss: 0.20065294206142426\n",
      "Epoch [2], Step [5200], Loss: 0.28855934739112854\n",
      "Epoch [2], Step [5300], Loss: 0.20847371220588684\n",
      "Epoch [2], Step [5400], Loss: 0.17335908114910126\n",
      "Epoch [2], Step [5500], Loss: 0.17494694888591766\n",
      "Epoch [2], Step [5600], Loss: 0.2678344249725342\n",
      "Epoch [2], Step [5700], Loss: 0.17884615063667297\n",
      "Epoch [2], Step [5800], Loss: 0.20089633762836456\n",
      "Epoch [2], Step [5900], Loss: 0.18729063868522644\n",
      "Epoch [2], Step [6000], Loss: 0.17145004868507385\n",
      "Epoch [2], Step [6100], Loss: 0.19098465144634247\n",
      "Epoch [2], Step [6200], Loss: 0.2144978642463684\n",
      "Epoch [2], Step [6300], Loss: 0.17022348940372467\n",
      "Epoch [2], Step [6400], Loss: 0.22752197086811066\n",
      "Epoch [2], Step [6500], Loss: 0.16558028757572174\n",
      "Epoch [2], Step [6600], Loss: 0.2516578435897827\n",
      "Epoch [2], Step [6700], Loss: 0.1973734200000763\n",
      "Epoch [2], Step [6800], Loss: 0.24751053750514984\n",
      "Epoch [2], Step [6900], Loss: 0.27029886841773987\n",
      "Epoch [2], Step [7000], Loss: 0.14516958594322205\n",
      "Epoch [2], Step [7100], Loss: 0.1821139007806778\n",
      "Epoch [2], Step [7200], Loss: 0.21132014691829681\n",
      "Epoch [2], Step [7300], Loss: 0.23479533195495605\n",
      "Epoch [3], Step [100], Loss: 0.21337977051734924\n",
      "Epoch [3], Step [200], Loss: 0.1615491509437561\n",
      "Epoch [3], Step [300], Loss: 0.12818576395511627\n",
      "Epoch [3], Step [400], Loss: 0.19880102574825287\n",
      "Epoch [3], Step [500], Loss: 0.28897812962532043\n",
      "Epoch [3], Step [600], Loss: 0.11396319419145584\n",
      "Epoch [3], Step [700], Loss: 0.24506933987140656\n",
      "Epoch [3], Step [800], Loss: 0.1636846661567688\n",
      "Epoch [3], Step [900], Loss: 0.26951920986175537\n",
      "Epoch [3], Step [1000], Loss: 0.19437392055988312\n",
      "Epoch [3], Step [1100], Loss: 0.13584713637828827\n",
      "Epoch [3], Step [1200], Loss: 0.16546989977359772\n",
      "Epoch [3], Step [1300], Loss: 0.16486820578575134\n",
      "Epoch [3], Step [1400], Loss: 0.13156576454639435\n",
      "Epoch [3], Step [1500], Loss: 0.2261451780796051\n",
      "Epoch [3], Step [1600], Loss: 0.16610459983348846\n",
      "Epoch [3], Step [1700], Loss: 0.1492079198360443\n",
      "Epoch [3], Step [1800], Loss: 0.1294160634279251\n",
      "Epoch [3], Step [1900], Loss: 0.1411844789981842\n",
      "Epoch [3], Step [2000], Loss: 0.16525661945343018\n",
      "Epoch [3], Step [2100], Loss: 0.08233464509248734\n",
      "Epoch [3], Step [2200], Loss: 0.1448586881160736\n",
      "Epoch [3], Step [2300], Loss: 0.2193356156349182\n",
      "Epoch [3], Step [2400], Loss: 0.19284921884536743\n",
      "Epoch [3], Step [2500], Loss: 0.2073974907398224\n",
      "Epoch [3], Step [2600], Loss: 0.20821426808834076\n",
      "Epoch [3], Step [2700], Loss: 0.1724325567483902\n",
      "Epoch [3], Step [2800], Loss: 0.09189820289611816\n",
      "Epoch [3], Step [2900], Loss: 0.12921659648418427\n",
      "Epoch [3], Step [3000], Loss: 0.1967252641916275\n",
      "Epoch [3], Step [3100], Loss: 0.1464865803718567\n",
      "Epoch [3], Step [3200], Loss: 0.21273115277290344\n",
      "Epoch [3], Step [3300], Loss: 0.1558346450328827\n",
      "Epoch [3], Step [3400], Loss: 0.17977507412433624\n",
      "Epoch [3], Step [3500], Loss: 0.16163335740566254\n",
      "Epoch [3], Step [3600], Loss: 0.12437114119529724\n",
      "Epoch [3], Step [3700], Loss: 0.18597252666950226\n",
      "Epoch [3], Step [3800], Loss: 0.13697928190231323\n",
      "Epoch [3], Step [3900], Loss: 0.16260838508605957\n",
      "Epoch [3], Step [4000], Loss: 0.16282619535923004\n",
      "Epoch [3], Step [4100], Loss: 0.2615276575088501\n",
      "Epoch [3], Step [4200], Loss: 0.16198556125164032\n",
      "Epoch [3], Step [4300], Loss: 0.2683755159378052\n",
      "Epoch [3], Step [4400], Loss: 0.13673681020736694\n",
      "Epoch [3], Step [4500], Loss: 0.2256859540939331\n",
      "Epoch [3], Step [4600], Loss: 0.27153512835502625\n",
      "Epoch [3], Step [4700], Loss: 0.18804942071437836\n",
      "Epoch [3], Step [4800], Loss: 0.19347582757472992\n",
      "Epoch [3], Step [4900], Loss: 0.13153845071792603\n",
      "Epoch [3], Step [5000], Loss: 0.12144474685192108\n",
      "Epoch [3], Step [5100], Loss: 0.19436772167682648\n",
      "Epoch [3], Step [5200], Loss: 0.24705173075199127\n",
      "Epoch [3], Step [5300], Loss: 0.10726002603769302\n",
      "Epoch [3], Step [5400], Loss: 0.15000313520431519\n",
      "Epoch [3], Step [5500], Loss: 0.19070371985435486\n",
      "Epoch [3], Step [5600], Loss: 0.10049743950366974\n",
      "Epoch [3], Step [5700], Loss: 0.17806316912174225\n",
      "Epoch [3], Step [5800], Loss: 0.16482952237129211\n",
      "Epoch [3], Step [5900], Loss: 0.14425481855869293\n",
      "Epoch [3], Step [6000], Loss: 0.380037397146225\n",
      "Epoch [3], Step [6100], Loss: 0.18878623843193054\n",
      "Epoch [3], Step [6200], Loss: 0.18478208780288696\n",
      "Epoch [3], Step [6300], Loss: 0.22472406923770905\n",
      "Epoch [3], Step [6400], Loss: 0.2520882785320282\n",
      "Epoch [3], Step [6500], Loss: 0.20879141986370087\n",
      "Epoch [3], Step [6600], Loss: 0.15376174449920654\n",
      "Epoch [3], Step [6700], Loss: 0.13525745272636414\n",
      "Epoch [3], Step [6800], Loss: 0.21631331741809845\n",
      "Epoch [3], Step [6900], Loss: 0.17732398211956024\n",
      "Epoch [3], Step [7000], Loss: 0.19635353982448578\n",
      "Epoch [3], Step [7100], Loss: 0.11962956935167313\n",
      "Epoch [3], Step [7200], Loss: 0.2605850398540497\n",
      "Epoch [3], Step [7300], Loss: 0.25394752621650696\n",
      "Epoch [4], Step [100], Loss: 0.17948591709136963\n",
      "Epoch [4], Step [200], Loss: 0.17459139227867126\n",
      "Epoch [4], Step [300], Loss: 0.07611314207315445\n",
      "Epoch [4], Step [400], Loss: 0.17874900996685028\n",
      "Epoch [4], Step [500], Loss: 0.14016146957874298\n",
      "Epoch [4], Step [600], Loss: 0.15304085612297058\n",
      "Epoch [4], Step [700], Loss: 0.1314244121313095\n",
      "Epoch [4], Step [800], Loss: 0.12449616938829422\n",
      "Epoch [4], Step [900], Loss: 0.10290774703025818\n",
      "Epoch [4], Step [1000], Loss: 0.18398062884807587\n",
      "Epoch [4], Step [1100], Loss: 0.10375470668077469\n",
      "Epoch [4], Step [1200], Loss: 0.17382122576236725\n",
      "Epoch [4], Step [1300], Loss: 0.08175688236951828\n",
      "Epoch [4], Step [1400], Loss: 0.2449703812599182\n",
      "Epoch [4], Step [1500], Loss: 0.18704213201999664\n",
      "Epoch [4], Step [1600], Loss: 0.11054148524999619\n",
      "Epoch [4], Step [1700], Loss: 0.17948943376541138\n",
      "Epoch [4], Step [1800], Loss: 0.13154374063014984\n",
      "Epoch [4], Step [1900], Loss: 0.136084645986557\n",
      "Epoch [4], Step [2000], Loss: 0.11659761518239975\n",
      "Epoch [4], Step [2100], Loss: 0.17155976593494415\n",
      "Epoch [4], Step [2200], Loss: 0.08282992988824844\n",
      "Epoch [4], Step [2300], Loss: 0.1184840053319931\n",
      "Epoch [4], Step [2400], Loss: 0.2874751687049866\n",
      "Epoch [4], Step [2500], Loss: 0.16504427790641785\n",
      "Epoch [4], Step [2600], Loss: 0.15506455302238464\n",
      "Epoch [4], Step [2700], Loss: 0.09575134515762329\n",
      "Epoch [4], Step [2800], Loss: 0.19376327097415924\n",
      "Epoch [4], Step [2900], Loss: 0.1240353211760521\n",
      "Epoch [4], Step [3000], Loss: 0.17199452221393585\n",
      "Epoch [4], Step [3100], Loss: 0.14324951171875\n",
      "Epoch [4], Step [3200], Loss: 0.2084188163280487\n",
      "Epoch [4], Step [3300], Loss: 0.20956504344940186\n",
      "Epoch [4], Step [3400], Loss: 0.13026368618011475\n",
      "Epoch [4], Step [3500], Loss: 0.17979735136032104\n",
      "Epoch [4], Step [3600], Loss: 0.15025228261947632\n",
      "Epoch [4], Step [3700], Loss: 0.06552822142839432\n",
      "Epoch [4], Step [3800], Loss: 0.16144582629203796\n",
      "Epoch [4], Step [3900], Loss: 0.11938172578811646\n",
      "Epoch [4], Step [4000], Loss: 0.12091659009456635\n",
      "Epoch [4], Step [4100], Loss: 0.18888387084007263\n",
      "Epoch [4], Step [4200], Loss: 0.17422296106815338\n",
      "Epoch [4], Step [4300], Loss: 0.1579102873802185\n",
      "Epoch [4], Step [4400], Loss: 0.1563538759946823\n",
      "Epoch [4], Step [4500], Loss: 0.18057970702648163\n",
      "Epoch [4], Step [4600], Loss: 0.09161945432424545\n",
      "Epoch [4], Step [4700], Loss: 0.17257709801197052\n",
      "Epoch [4], Step [4800], Loss: 0.17807888984680176\n",
      "Epoch [4], Step [4900], Loss: 0.13335590064525604\n",
      "Epoch [4], Step [5000], Loss: 0.16097506880760193\n",
      "Epoch [4], Step [5100], Loss: 0.12818826735019684\n",
      "Epoch [4], Step [5200], Loss: 0.33825722336769104\n",
      "Epoch [4], Step [5300], Loss: 0.1525803804397583\n",
      "Epoch [4], Step [5400], Loss: 0.056206706911325455\n",
      "Epoch [4], Step [5500], Loss: 0.12891115248203278\n",
      "Epoch [4], Step [5600], Loss: 0.08030467480421066\n",
      "Epoch [4], Step [5700], Loss: 0.10369589924812317\n",
      "Epoch [4], Step [5800], Loss: 0.18721555173397064\n",
      "Epoch [4], Step [5900], Loss: 0.29266729950904846\n",
      "Epoch [4], Step [6000], Loss: 0.18843597173690796\n",
      "Epoch [4], Step [6100], Loss: 0.19442561268806458\n",
      "Epoch [4], Step [6200], Loss: 0.13222365081310272\n",
      "Epoch [4], Step [6300], Loss: 0.1340194046497345\n",
      "Epoch [4], Step [6400], Loss: 0.20380090177059174\n",
      "Epoch [4], Step [6500], Loss: 0.11890332400798798\n",
      "Epoch [4], Step [6600], Loss: 0.1239585429430008\n",
      "Epoch [4], Step [6700], Loss: 0.2008211761713028\n",
      "Epoch [4], Step [6800], Loss: 0.14985422790050507\n",
      "Epoch [4], Step [6900], Loss: 0.12532110512256622\n",
      "Epoch [4], Step [7000], Loss: 0.19412454962730408\n",
      "Epoch [4], Step [7100], Loss: 0.11018405854701996\n",
      "Epoch [4], Step [7200], Loss: 0.14253117144107819\n",
      "Epoch [4], Step [7300], Loss: 0.2569977939128876\n",
      "Epoch [5], Step [100], Loss: 0.06788857281208038\n",
      "Epoch [5], Step [200], Loss: 0.11910516023635864\n",
      "Epoch [5], Step [300], Loss: 0.09784702956676483\n",
      "Epoch [5], Step [400], Loss: 0.0722234845161438\n",
      "Epoch [5], Step [500], Loss: 0.09277092665433884\n",
      "Epoch [5], Step [600], Loss: 0.1119605228304863\n",
      "Epoch [5], Step [700], Loss: 0.09222182631492615\n",
      "Epoch [5], Step [800], Loss: 0.09289980679750443\n",
      "Epoch [5], Step [900], Loss: 0.08733182400465012\n",
      "Epoch [5], Step [1000], Loss: 0.0740908831357956\n",
      "Epoch [5], Step [1100], Loss: 0.10728699713945389\n",
      "Epoch [5], Step [1200], Loss: 0.0993230789899826\n",
      "Epoch [5], Step [1300], Loss: 0.10987462103366852\n",
      "Epoch [5], Step [1400], Loss: 0.20098966360092163\n",
      "Epoch [5], Step [1500], Loss: 0.06904688477516174\n",
      "Epoch [5], Step [1600], Loss: 0.11940279603004456\n",
      "Epoch [5], Step [1700], Loss: 0.09768096357584\n",
      "Epoch [5], Step [1800], Loss: 0.09311927109956741\n",
      "Epoch [5], Step [1900], Loss: 0.09778488427400589\n",
      "Epoch [5], Step [2000], Loss: 0.22751682996749878\n",
      "Epoch [5], Step [2100], Loss: 0.07590706646442413\n",
      "Epoch [5], Step [2200], Loss: 0.19811779260635376\n",
      "Epoch [5], Step [2300], Loss: 0.10561855137348175\n",
      "Epoch [5], Step [2400], Loss: 0.12661421298980713\n",
      "Epoch [5], Step [2500], Loss: 0.22287669777870178\n",
      "Epoch [5], Step [2600], Loss: 0.1469213217496872\n",
      "Epoch [5], Step [2700], Loss: 0.12085437029600143\n",
      "Epoch [5], Step [2800], Loss: 0.1607130467891693\n",
      "Epoch [5], Step [2900], Loss: 0.08427122235298157\n",
      "Epoch [5], Step [3000], Loss: 0.09330391138792038\n",
      "Epoch [5], Step [3100], Loss: 0.12279205769300461\n",
      "Epoch [5], Step [3200], Loss: 0.07008390873670578\n",
      "Epoch [5], Step [3300], Loss: 0.17433702945709229\n",
      "Epoch [5], Step [3400], Loss: 0.08459531515836716\n",
      "Epoch [5], Step [3500], Loss: 0.06658292561769485\n",
      "Epoch [5], Step [3600], Loss: 0.13880477845668793\n",
      "Epoch [5], Step [3700], Loss: 0.1349814534187317\n",
      "Epoch [5], Step [3800], Loss: 0.13654725253582\n",
      "Epoch [5], Step [3900], Loss: 0.06096755713224411\n",
      "Epoch [5], Step [4000], Loss: 0.11852423846721649\n",
      "Epoch [5], Step [4100], Loss: 0.13230058550834656\n",
      "Epoch [5], Step [4200], Loss: 0.12276200950145721\n",
      "Epoch [5], Step [4300], Loss: 0.16914308071136475\n",
      "Epoch [5], Step [4400], Loss: 0.17608506977558136\n",
      "Epoch [5], Step [4500], Loss: 0.12042754888534546\n",
      "Epoch [5], Step [4600], Loss: 0.06303603202104568\n",
      "Epoch [5], Step [4700], Loss: 0.20321282744407654\n",
      "Epoch [5], Step [4800], Loss: 0.18400968611240387\n",
      "Epoch [5], Step [4900], Loss: 0.1559540182352066\n",
      "Epoch [5], Step [5000], Loss: 0.20884111523628235\n",
      "Epoch [5], Step [5100], Loss: 0.12822821736335754\n",
      "Epoch [5], Step [5200], Loss: 0.17532198131084442\n",
      "Epoch [5], Step [5300], Loss: 0.15824317932128906\n",
      "Epoch [5], Step [5400], Loss: 0.13248410820960999\n",
      "Epoch [5], Step [5500], Loss: 0.1204753965139389\n",
      "Epoch [5], Step [5600], Loss: 0.06290686875581741\n",
      "Epoch [5], Step [5700], Loss: 0.2232595533132553\n",
      "Epoch [5], Step [5800], Loss: 0.136905699968338\n",
      "Epoch [5], Step [5900], Loss: 0.12886947393417358\n",
      "Epoch [5], Step [6000], Loss: 0.10997925698757172\n",
      "Epoch [5], Step [6100], Loss: 0.15254269540309906\n",
      "Epoch [5], Step [6200], Loss: 0.1627463400363922\n",
      "Epoch [5], Step [6300], Loss: 0.0921805128455162\n",
      "Epoch [5], Step [6400], Loss: 0.18004263937473297\n",
      "Epoch [5], Step [6500], Loss: 0.12054822593927383\n",
      "Epoch [5], Step [6600], Loss: 0.11046042293310165\n",
      "Epoch [5], Step [6700], Loss: 0.11071239411830902\n",
      "Epoch [5], Step [6800], Loss: 0.1613319218158722\n",
      "Epoch [5], Step [6900], Loss: 0.14450019598007202\n",
      "Epoch [5], Step [7000], Loss: 0.23876841366291046\n",
      "Epoch [5], Step [7100], Loss: 0.16081207990646362\n",
      "Epoch [5], Step [7200], Loss: 0.18172259628772736\n",
      "Epoch [5], Step [7300], Loss: 0.174360990524292\n",
      "Epoch [6], Step [100], Loss: 0.06370524317026138\n",
      "Epoch [6], Step [200], Loss: 0.10246707499027252\n",
      "Epoch [6], Step [300], Loss: 0.0380416177213192\n",
      "Epoch [6], Step [400], Loss: 0.04313022643327713\n",
      "Epoch [6], Step [500], Loss: 0.08018608391284943\n",
      "Epoch [6], Step [600], Loss: 0.047634534537792206\n",
      "Epoch [6], Step [700], Loss: 0.05279794707894325\n",
      "Epoch [6], Step [800], Loss: 0.06396965682506561\n",
      "Epoch [6], Step [900], Loss: 0.10957155376672745\n",
      "Epoch [6], Step [1000], Loss: 0.1692141592502594\n",
      "Epoch [6], Step [1100], Loss: 0.1404687464237213\n",
      "Epoch [6], Step [1200], Loss: 0.07373906672000885\n",
      "Epoch [6], Step [1300], Loss: 0.06266225874423981\n",
      "Epoch [6], Step [1400], Loss: 0.03578489273786545\n",
      "Epoch [6], Step [1500], Loss: 0.1576158106327057\n",
      "Epoch [6], Step [1600], Loss: 0.09970633685588837\n",
      "Epoch [6], Step [1700], Loss: 0.10253436863422394\n",
      "Epoch [6], Step [1800], Loss: 0.06255467236042023\n",
      "Epoch [6], Step [1900], Loss: 0.04752786457538605\n",
      "Epoch [6], Step [2000], Loss: 0.07191994041204453\n",
      "Epoch [6], Step [2100], Loss: 0.07474950700998306\n",
      "Epoch [6], Step [2200], Loss: 0.05401122197508812\n",
      "Epoch [6], Step [2300], Loss: 0.1285172551870346\n",
      "Epoch [6], Step [2400], Loss: 0.05431241914629936\n",
      "Epoch [6], Step [2500], Loss: 0.15340861678123474\n",
      "Epoch [6], Step [2600], Loss: 0.09808991104364395\n",
      "Epoch [6], Step [2700], Loss: 0.07082366198301315\n",
      "Epoch [6], Step [2800], Loss: 0.1279423087835312\n",
      "Epoch [6], Step [2900], Loss: 0.10490203648805618\n",
      "Epoch [6], Step [3000], Loss: 0.07251778990030289\n",
      "Epoch [6], Step [3100], Loss: 0.11455627530813217\n",
      "Epoch [6], Step [3200], Loss: 0.10088011622428894\n",
      "Epoch [6], Step [3300], Loss: 0.13326646387577057\n",
      "Epoch [6], Step [3400], Loss: 0.10677269846200943\n",
      "Epoch [6], Step [3500], Loss: 0.06010067090392113\n",
      "Epoch [6], Step [3600], Loss: 0.03541167080402374\n",
      "Epoch [6], Step [3700], Loss: 0.04587889090180397\n",
      "Epoch [6], Step [3800], Loss: 0.12452376633882523\n",
      "Epoch [6], Step [3900], Loss: 0.08372601866722107\n",
      "Epoch [6], Step [4000], Loss: 0.12123527377843857\n",
      "Epoch [6], Step [4100], Loss: 0.08978624641895294\n",
      "Epoch [6], Step [4200], Loss: 0.089793860912323\n",
      "Epoch [6], Step [4300], Loss: 0.06757664680480957\n",
      "Epoch [6], Step [4400], Loss: 0.12288805842399597\n",
      "Epoch [6], Step [4500], Loss: 0.09917917847633362\n",
      "Epoch [6], Step [4600], Loss: 0.05624429136514664\n",
      "Epoch [6], Step [4700], Loss: 0.04740501940250397\n",
      "Epoch [6], Step [4800], Loss: 0.08115895092487335\n",
      "Epoch [6], Step [4900], Loss: 0.14381206035614014\n",
      "Epoch [6], Step [5000], Loss: 0.12558437883853912\n",
      "Epoch [6], Step [5100], Loss: 0.06626386195421219\n",
      "Epoch [6], Step [5200], Loss: 0.17250122129917145\n",
      "Epoch [6], Step [5300], Loss: 0.06600669026374817\n",
      "Epoch [6], Step [5400], Loss: 0.058950599282979965\n",
      "Epoch [6], Step [5500], Loss: 0.09300797432661057\n",
      "Epoch [6], Step [5600], Loss: 0.11198344826698303\n",
      "Epoch [6], Step [5700], Loss: 0.13486924767494202\n",
      "Epoch [6], Step [5800], Loss: 0.06568317860364914\n",
      "Epoch [6], Step [5900], Loss: 0.06358294934034348\n",
      "Epoch [6], Step [6000], Loss: 0.09288579225540161\n",
      "Epoch [6], Step [6100], Loss: 0.14645014703273773\n",
      "Epoch [6], Step [6200], Loss: 0.13218677043914795\n",
      "Epoch [6], Step [6300], Loss: 0.09837522357702255\n",
      "Epoch [6], Step [6400], Loss: 0.048789944499731064\n",
      "Epoch [6], Step [6500], Loss: 0.05405488982796669\n",
      "Epoch [6], Step [6600], Loss: 0.10221312195062637\n",
      "Epoch [6], Step [6700], Loss: 0.05390923470258713\n",
      "Epoch [6], Step [6800], Loss: 0.09983524680137634\n",
      "Epoch [6], Step [6900], Loss: 0.11581221967935562\n",
      "Epoch [6], Step [7000], Loss: 0.08455974608659744\n",
      "Epoch [6], Step [7100], Loss: 0.09028706699609756\n",
      "Epoch [6], Step [7200], Loss: 0.11834855377674103\n",
      "Epoch [6], Step [7300], Loss: 0.16125774383544922\n",
      "Epoch [7], Step [100], Loss: 0.14464397728443146\n",
      "Epoch [7], Step [200], Loss: 0.018184149637818336\n",
      "Epoch [7], Step [300], Loss: 0.02801528386771679\n",
      "Epoch [7], Step [400], Loss: 0.039849214255809784\n",
      "Epoch [7], Step [500], Loss: 0.037400659173727036\n",
      "Epoch [7], Step [600], Loss: 0.06596428900957108\n",
      "Epoch [7], Step [700], Loss: 0.04404377192258835\n",
      "Epoch [7], Step [800], Loss: 0.04193083196878433\n",
      "Epoch [7], Step [900], Loss: 0.04292036220431328\n",
      "Epoch [7], Step [1000], Loss: 0.05738444998860359\n",
      "Epoch [7], Step [1100], Loss: 0.016483956947922707\n",
      "Epoch [7], Step [1200], Loss: 0.04255910962820053\n",
      "Epoch [7], Step [1300], Loss: 0.03925957903265953\n",
      "Epoch [7], Step [1400], Loss: 0.014328401535749435\n",
      "Epoch [7], Step [1500], Loss: 0.0312136709690094\n",
      "Epoch [7], Step [1600], Loss: 0.03243676573038101\n",
      "Epoch [7], Step [1700], Loss: 0.06304986774921417\n",
      "Epoch [7], Step [1800], Loss: 0.07729356735944748\n",
      "Epoch [7], Step [1900], Loss: 0.06864272803068161\n",
      "Epoch [7], Step [2000], Loss: 0.05925258994102478\n",
      "Epoch [7], Step [2100], Loss: 0.058716803789138794\n",
      "Epoch [7], Step [2200], Loss: 0.03044569492340088\n",
      "Epoch [7], Step [2300], Loss: 0.034794919192790985\n",
      "Epoch [7], Step [2400], Loss: 0.14761464297771454\n",
      "Epoch [7], Step [2500], Loss: 0.0855213850736618\n",
      "Epoch [7], Step [2600], Loss: 0.058161698281764984\n",
      "Epoch [7], Step [2700], Loss: 0.11493276059627533\n",
      "Epoch [7], Step [2800], Loss: 0.05097357928752899\n",
      "Epoch [7], Step [2900], Loss: 0.05611451342701912\n",
      "Epoch [7], Step [3000], Loss: 0.02661900967359543\n",
      "Epoch [7], Step [3100], Loss: 0.050406113266944885\n",
      "Epoch [7], Step [3200], Loss: 0.05308688059449196\n",
      "Epoch [7], Step [3300], Loss: 0.12796321511268616\n",
      "Epoch [7], Step [3400], Loss: 0.07704630494117737\n",
      "Epoch [7], Step [3500], Loss: 0.09160488098859787\n",
      "Epoch [7], Step [3600], Loss: 0.08791675418615341\n",
      "Epoch [7], Step [3700], Loss: 0.04014940187335014\n",
      "Epoch [7], Step [3800], Loss: 0.06274506449699402\n",
      "Epoch [7], Step [3900], Loss: 0.03536968678236008\n",
      "Epoch [7], Step [4000], Loss: 0.14778375625610352\n",
      "Epoch [7], Step [4100], Loss: 0.10505453497171402\n",
      "Epoch [7], Step [4200], Loss: 0.17259643971920013\n",
      "Epoch [7], Step [4300], Loss: 0.061614636331796646\n",
      "Epoch [7], Step [4400], Loss: 0.08610495179891586\n",
      "Epoch [7], Step [4500], Loss: 0.06247163936495781\n",
      "Epoch [7], Step [4600], Loss: 0.04576940834522247\n",
      "Epoch [7], Step [4700], Loss: 0.04055127501487732\n",
      "Epoch [7], Step [4800], Loss: 0.18221350014209747\n",
      "Epoch [7], Step [4900], Loss: 0.10105983912944794\n",
      "Epoch [7], Step [5000], Loss: 0.06554830819368362\n",
      "Epoch [7], Step [5100], Loss: 0.01580113172531128\n",
      "Epoch [7], Step [5200], Loss: 0.057974446564912796\n",
      "Epoch [7], Step [5300], Loss: 0.133745014667511\n",
      "Epoch [7], Step [5400], Loss: 0.03602509945631027\n",
      "Epoch [7], Step [5500], Loss: 0.061638690531253815\n",
      "Epoch [7], Step [5600], Loss: 0.0636465921998024\n",
      "Epoch [7], Step [5700], Loss: 0.11163148283958435\n",
      "Epoch [7], Step [5800], Loss: 0.16066333651542664\n",
      "Epoch [7], Step [5900], Loss: 0.05459628999233246\n",
      "Epoch [7], Step [6000], Loss: 0.059556473046541214\n",
      "Epoch [7], Step [6100], Loss: 0.10564463585615158\n",
      "Epoch [7], Step [6200], Loss: 0.05745914578437805\n",
      "Epoch [7], Step [6300], Loss: 0.044918883591890335\n",
      "Epoch [7], Step [6400], Loss: 0.051831796765327454\n",
      "Epoch [7], Step [6500], Loss: 0.09011847525835037\n",
      "Epoch [7], Step [6600], Loss: 0.04491822421550751\n",
      "Epoch [7], Step [6700], Loss: 0.0837220624089241\n",
      "Epoch [7], Step [6800], Loss: 0.06500472128391266\n",
      "Epoch [7], Step [6900], Loss: 0.056464262306690216\n",
      "Epoch [7], Step [7000], Loss: 0.03248411417007446\n",
      "Epoch [7], Step [7100], Loss: 0.04588945582509041\n",
      "Epoch [7], Step [7200], Loss: 0.05503949150443077\n",
      "Epoch [7], Step [7300], Loss: 0.045790188014507294\n",
      "Epoch [8], Step [100], Loss: 0.02471878007054329\n",
      "Epoch [8], Step [200], Loss: 0.018835419788956642\n",
      "Epoch [8], Step [300], Loss: 0.030875980854034424\n",
      "Epoch [8], Step [400], Loss: 0.027980439364910126\n",
      "Epoch [8], Step [500], Loss: 0.014839382842183113\n",
      "Epoch [8], Step [600], Loss: 0.09324105083942413\n",
      "Epoch [8], Step [700], Loss: 0.06039183586835861\n",
      "Epoch [8], Step [800], Loss: 0.0669349730014801\n",
      "Epoch [8], Step [900], Loss: 0.05388392508029938\n",
      "Epoch [8], Step [1000], Loss: 0.01615830510854721\n",
      "Epoch [8], Step [1100], Loss: 0.042318377643823624\n",
      "Epoch [8], Step [1200], Loss: 0.04890160635113716\n",
      "Epoch [8], Step [1300], Loss: 0.032783810049295425\n",
      "Epoch [8], Step [1400], Loss: 0.022441502660512924\n",
      "Epoch [8], Step [1500], Loss: 0.029102234169840813\n",
      "Epoch [8], Step [1600], Loss: 0.059603553265333176\n",
      "Epoch [8], Step [1700], Loss: 0.021199220791459084\n",
      "Epoch [8], Step [1800], Loss: 0.028469571843743324\n",
      "Epoch [8], Step [1900], Loss: 0.07313665002584457\n",
      "Epoch [8], Step [2000], Loss: 0.05441342294216156\n",
      "Epoch [8], Step [2100], Loss: 0.032621148973703384\n",
      "Epoch [8], Step [2200], Loss: 0.05107412487268448\n",
      "Epoch [8], Step [2300], Loss: 0.07546158134937286\n",
      "Epoch [8], Step [2400], Loss: 0.05099816620349884\n",
      "Epoch [8], Step [2500], Loss: 0.043105348944664\n",
      "Epoch [8], Step [2600], Loss: 0.04840884730219841\n",
      "Epoch [8], Step [2700], Loss: 0.05955292657017708\n",
      "Epoch [8], Step [2800], Loss: 0.05303291231393814\n",
      "Epoch [8], Step [2900], Loss: 0.036232490092515945\n",
      "Epoch [8], Step [3000], Loss: 0.022287458181381226\n",
      "Epoch [8], Step [3100], Loss: 0.12145184725522995\n",
      "Epoch [8], Step [3200], Loss: 0.028852293267846107\n",
      "Epoch [8], Step [3300], Loss: 0.05839334800839424\n",
      "Epoch [8], Step [3400], Loss: 0.014972888864576817\n",
      "Epoch [8], Step [3500], Loss: 0.047111108899116516\n",
      "Epoch [8], Step [3600], Loss: 0.10121124237775803\n",
      "Epoch [8], Step [3700], Loss: 0.041909798979759216\n",
      "Epoch [8], Step [3800], Loss: 0.035016801208257675\n",
      "Epoch [8], Step [3900], Loss: 0.05734545737504959\n",
      "Epoch [8], Step [4000], Loss: 0.03432703763246536\n",
      "Epoch [8], Step [4100], Loss: 0.11069715023040771\n",
      "Epoch [8], Step [4200], Loss: 0.0982920229434967\n",
      "Epoch [8], Step [4300], Loss: 0.037396036088466644\n",
      "Epoch [8], Step [4400], Loss: 0.03367504104971886\n",
      "Epoch [8], Step [4500], Loss: 0.08339914679527283\n",
      "Epoch [8], Step [4600], Loss: 0.11764074862003326\n",
      "Epoch [8], Step [4700], Loss: 0.038916926831007004\n",
      "Epoch [8], Step [4800], Loss: 0.04294873774051666\n",
      "Epoch [8], Step [4900], Loss: 0.10483577847480774\n",
      "Epoch [8], Step [5000], Loss: 0.06629609316587448\n",
      "Epoch [8], Step [5100], Loss: 0.07653777301311493\n",
      "Epoch [8], Step [5200], Loss: 0.03166552633047104\n",
      "Epoch [8], Step [5300], Loss: 0.1013125330209732\n",
      "Epoch [8], Step [5400], Loss: 0.04310639202594757\n",
      "Epoch [8], Step [5500], Loss: 0.017945654690265656\n",
      "Epoch [8], Step [5600], Loss: 0.028520289808511734\n",
      "Epoch [8], Step [5700], Loss: 0.04815932735800743\n",
      "Epoch [8], Step [5800], Loss: 0.01524574588984251\n",
      "Epoch [8], Step [5900], Loss: 0.02819695696234703\n",
      "Epoch [8], Step [6000], Loss: 0.01262727938592434\n",
      "Epoch [8], Step [6100], Loss: 0.01663595251739025\n",
      "Epoch [8], Step [6200], Loss: 0.022209342569112778\n",
      "Epoch [8], Step [6300], Loss: 0.05252963677048683\n",
      "Epoch [8], Step [6400], Loss: 0.0617593415081501\n",
      "Epoch [8], Step [6500], Loss: 0.04794484004378319\n",
      "Epoch [8], Step [6600], Loss: 0.03849771246314049\n",
      "Epoch [8], Step [6700], Loss: 0.022555334493517876\n",
      "Epoch [8], Step [6800], Loss: 0.0904461219906807\n",
      "Epoch [8], Step [6900], Loss: 0.0736856535077095\n",
      "Epoch [8], Step [7000], Loss: 0.05503988638520241\n",
      "Epoch [8], Step [7100], Loss: 0.1384163647890091\n",
      "Epoch [8], Step [7200], Loss: 0.06433359533548355\n",
      "Epoch [8], Step [7300], Loss: 0.02501605451107025\n",
      "Epoch [9], Step [100], Loss: 0.03324670344591141\n",
      "Epoch [9], Step [200], Loss: 0.00983566977083683\n",
      "Epoch [9], Step [300], Loss: 0.07300592958927155\n",
      "Epoch [9], Step [400], Loss: 0.011091252788901329\n",
      "Epoch [9], Step [500], Loss: 0.0488026887178421\n",
      "Epoch [9], Step [600], Loss: 0.03291170671582222\n",
      "Epoch [9], Step [700], Loss: 0.03064032830297947\n",
      "Epoch [9], Step [800], Loss: 0.013981439173221588\n",
      "Epoch [9], Step [900], Loss: 0.03745926544070244\n",
      "Epoch [9], Step [1000], Loss: 0.0891222357749939\n",
      "Epoch [9], Step [1100], Loss: 0.020361904054880142\n",
      "Epoch [9], Step [1200], Loss: 0.05776588246226311\n",
      "Epoch [9], Step [1300], Loss: 0.015665816143155098\n",
      "Epoch [9], Step [1400], Loss: 0.00804075226187706\n",
      "Epoch [9], Step [1500], Loss: 0.024416262283921242\n",
      "Epoch [9], Step [1600], Loss: 0.03415091708302498\n",
      "Epoch [9], Step [1700], Loss: 0.03031853586435318\n",
      "Epoch [9], Step [1800], Loss: 0.04033590480685234\n",
      "Epoch [9], Step [1900], Loss: 0.027227938175201416\n",
      "Epoch [9], Step [2000], Loss: 0.0270889550447464\n",
      "Epoch [9], Step [2100], Loss: 0.04657301679253578\n",
      "Epoch [9], Step [2200], Loss: 0.029326284304261208\n",
      "Epoch [9], Step [2300], Loss: 0.06471140682697296\n",
      "Epoch [9], Step [2400], Loss: 0.09497737139463425\n",
      "Epoch [9], Step [2500], Loss: 0.06890469789505005\n",
      "Epoch [9], Step [2600], Loss: 0.020404014736413956\n",
      "Epoch [9], Step [2700], Loss: 0.045449912548065186\n",
      "Epoch [9], Step [2800], Loss: 0.03530567139387131\n",
      "Epoch [9], Step [2900], Loss: 0.0584062859416008\n",
      "Epoch [9], Step [3000], Loss: 0.04993721470236778\n",
      "Epoch [9], Step [3100], Loss: 0.03390704467892647\n",
      "Epoch [9], Step [3200], Loss: 0.02494051307439804\n",
      "Epoch [9], Step [3300], Loss: 0.010617552325129509\n",
      "Epoch [9], Step [3400], Loss: 0.09990506619215012\n",
      "Epoch [9], Step [3500], Loss: 0.05165111646056175\n",
      "Epoch [9], Step [3600], Loss: 0.025360625237226486\n",
      "Epoch [9], Step [3700], Loss: 0.010126147419214249\n",
      "Epoch [9], Step [3800], Loss: 0.08748622983694077\n",
      "Epoch [9], Step [3900], Loss: 0.02461840957403183\n",
      "Epoch [9], Step [4000], Loss: 0.07441120594739914\n",
      "Epoch [9], Step [4100], Loss: 0.006341066677123308\n",
      "Epoch [9], Step [4200], Loss: 0.08144540339708328\n",
      "Epoch [9], Step [4300], Loss: 0.024365929886698723\n",
      "Epoch [9], Step [4400], Loss: 0.01755514368414879\n",
      "Epoch [9], Step [4500], Loss: 0.038262028247117996\n",
      "Epoch [9], Step [4600], Loss: 0.005440555978566408\n",
      "Epoch [9], Step [4700], Loss: 0.02129911072552204\n",
      "Epoch [9], Step [4800], Loss: 0.11268211901187897\n",
      "Epoch [9], Step [4900], Loss: 0.020960958674550056\n",
      "Epoch [9], Step [5000], Loss: 0.02887563221156597\n",
      "Epoch [9], Step [5100], Loss: 0.04228096082806587\n",
      "Epoch [9], Step [5200], Loss: 0.028335073962807655\n",
      "Epoch [9], Step [5300], Loss: 0.19649475812911987\n",
      "Epoch [9], Step [5400], Loss: 0.02999466471374035\n",
      "Epoch [9], Step [5500], Loss: 0.024928195402026176\n",
      "Epoch [9], Step [5600], Loss: 0.042483698576688766\n",
      "Epoch [9], Step [5700], Loss: 0.01946883276104927\n",
      "Epoch [9], Step [5800], Loss: 0.025645332410931587\n",
      "Epoch [9], Step [5900], Loss: 0.040319789201021194\n",
      "Epoch [9], Step [6000], Loss: 0.08439645916223526\n",
      "Epoch [9], Step [6100], Loss: 0.08160655945539474\n",
      "Epoch [9], Step [6200], Loss: 0.07313517481088638\n",
      "Epoch [9], Step [6300], Loss: 0.017148973420262337\n",
      "Epoch [9], Step [6400], Loss: 0.06413842737674713\n",
      "Epoch [9], Step [6500], Loss: 0.04181181639432907\n",
      "Epoch [9], Step [6600], Loss: 0.03656529262661934\n",
      "Epoch [9], Step [6700], Loss: 0.0712924376130104\n",
      "Epoch [9], Step [6800], Loss: 0.030345721170306206\n",
      "Epoch [9], Step [6900], Loss: 0.06695930659770966\n",
      "Epoch [9], Step [7000], Loss: 0.11676834523677826\n",
      "Epoch [9], Step [7100], Loss: 0.05104481428861618\n",
      "Epoch [9], Step [7200], Loss: 0.0658927708864212\n",
      "Epoch [9], Step [7300], Loss: 0.03825611621141434\n",
      "Epoch [10], Step [100], Loss: 0.03672006353735924\n",
      "Epoch [10], Step [200], Loss: 0.0026900784578174353\n",
      "Epoch [10], Step [300], Loss: 0.045735884457826614\n",
      "Epoch [10], Step [400], Loss: 0.0349460169672966\n",
      "Epoch [10], Step [500], Loss: 0.02270565740764141\n",
      "Epoch [10], Step [600], Loss: 0.03764745593070984\n",
      "Epoch [10], Step [700], Loss: 0.07023652642965317\n",
      "Epoch [10], Step [800], Loss: 0.006692949216812849\n",
      "Epoch [10], Step [900], Loss: 0.031784579157829285\n",
      "Epoch [10], Step [1000], Loss: 0.011160166002810001\n",
      "Epoch [10], Step [1100], Loss: 0.013086057268083096\n",
      "Epoch [10], Step [1200], Loss: 0.015172014012932777\n",
      "Epoch [10], Step [1300], Loss: 0.01221558265388012\n",
      "Epoch [10], Step [1400], Loss: 0.02381315268576145\n",
      "Epoch [10], Step [1500], Loss: 0.0067528667859733105\n",
      "Epoch [10], Step [1600], Loss: 0.02240048721432686\n",
      "Epoch [10], Step [1700], Loss: 0.015633655712008476\n",
      "Epoch [10], Step [1800], Loss: 0.01942288503050804\n",
      "Epoch [10], Step [1900], Loss: 0.02665877901017666\n",
      "Epoch [10], Step [2000], Loss: 0.01039292011409998\n",
      "Epoch [10], Step [2100], Loss: 0.01566397212445736\n",
      "Epoch [10], Step [2200], Loss: 0.014737643301486969\n",
      "Epoch [10], Step [2300], Loss: 0.014257887378334999\n",
      "Epoch [10], Step [2400], Loss: 0.00436004251241684\n",
      "Epoch [10], Step [2500], Loss: 0.022955067455768585\n",
      "Epoch [10], Step [2600], Loss: 0.02446909062564373\n",
      "Epoch [10], Step [2700], Loss: 0.0416775606572628\n",
      "Epoch [10], Step [2800], Loss: 0.04054799675941467\n",
      "Epoch [10], Step [2900], Loss: 0.07767041027545929\n",
      "Epoch [10], Step [3000], Loss: 0.00836268812417984\n",
      "Epoch [10], Step [3100], Loss: 0.039871521294116974\n",
      "Epoch [10], Step [3200], Loss: 0.009840171784162521\n",
      "Epoch [10], Step [3300], Loss: 0.008883045986294746\n",
      "Epoch [10], Step [3400], Loss: 0.04580160230398178\n",
      "Epoch [10], Step [3500], Loss: 0.05326339229941368\n",
      "Epoch [10], Step [3600], Loss: 0.018269037827849388\n",
      "Epoch [10], Step [3700], Loss: 0.0457632876932621\n",
      "Epoch [10], Step [3800], Loss: 0.030096452683210373\n",
      "Epoch [10], Step [3900], Loss: 0.030475163832306862\n",
      "Epoch [10], Step [4000], Loss: 0.02694394253194332\n",
      "Epoch [10], Step [4100], Loss: 0.009252806194126606\n",
      "Epoch [10], Step [4200], Loss: 0.06887202709913254\n",
      "Epoch [10], Step [4300], Loss: 0.05201609432697296\n",
      "Epoch [10], Step [4400], Loss: 0.024259159341454506\n",
      "Epoch [10], Step [4500], Loss: 0.07379946857690811\n",
      "Epoch [10], Step [4600], Loss: 0.01247683446854353\n",
      "Epoch [10], Step [4700], Loss: 0.014128414914011955\n",
      "Epoch [10], Step [4800], Loss: 0.0635434165596962\n",
      "Epoch [10], Step [4900], Loss: 0.013742144219577312\n",
      "Epoch [10], Step [5000], Loss: 0.030074896290898323\n",
      "Epoch [10], Step [5100], Loss: 0.026203706860542297\n",
      "Epoch [10], Step [5200], Loss: 0.005007348023355007\n",
      "Epoch [10], Step [5300], Loss: 0.03990494832396507\n",
      "Epoch [10], Step [5400], Loss: 0.023429475724697113\n",
      "Epoch [10], Step [5500], Loss: 0.0405757874250412\n",
      "Epoch [10], Step [5600], Loss: 0.04168413206934929\n",
      "Epoch [10], Step [5700], Loss: 0.02491590566933155\n",
      "Epoch [10], Step [5800], Loss: 0.03927240148186684\n",
      "Epoch [10], Step [5900], Loss: 0.053029388189315796\n",
      "Epoch [10], Step [6000], Loss: 0.11549893021583557\n",
      "Epoch [10], Step [6100], Loss: 0.01493110042065382\n",
      "Epoch [10], Step [6200], Loss: 0.038301147520542145\n",
      "Epoch [10], Step [6300], Loss: 0.02325715310871601\n",
      "Epoch [10], Step [6400], Loss: 0.018222756683826447\n",
      "Epoch [10], Step [6500], Loss: 0.020589910447597504\n",
      "Epoch [10], Step [6600], Loss: 0.04223286360502243\n",
      "Epoch [10], Step [6700], Loss: 0.047559548169374466\n",
      "Epoch [10], Step [6800], Loss: 0.053187888115644455\n",
      "Epoch [10], Step [6900], Loss: 0.08366568386554718\n",
      "Epoch [10], Step [7000], Loss: 0.07608423382043839\n",
      "Epoch [10], Step [7100], Loss: 0.06694165617227554\n",
      "Epoch [10], Step [7200], Loss: 0.028443651273846626\n",
      "Epoch [10], Step [7300], Loss: 0.015842696651816368\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "writer = SummaryWriter(log_dir='/kaggle/working/runs/spm')\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    for i, (comments, labels) in enumerate(train_dataLoader):\n",
    "        comments = comments.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(comments)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # 反向传播和优化\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar('train loss', loss.item(), len(train_dataLoader) * epoch + i)\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}], Step [{i+1}], Loss: {loss.item()}')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T03:56:08.573162Z",
     "iopub.status.busy": "2025-04-18T03:56:08.572882Z",
     "iopub.status.idle": "2025-04-18T03:56:18.354638Z",
     "shell.execute_reply": "2025-04-18T03:56:18.353840Z",
     "shell.execute_reply.started": "2025-04-18T03:56:08.573143Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 90.24211673363754\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for comments, labels in test_dataLoader:\n",
    "        comments = comments.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(comments)\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        total += len(labels)\n",
    "        correct += (pred == labels).sum().item()\n",
    "    print('准确率：', correct * 100 / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-18T03:56:27.935904Z",
     "iopub.status.busy": "2025-04-18T03:56:27.935632Z",
     "iopub.status.idle": "2025-04-18T03:56:27.945394Z",
     "shell.execute_reply": "2025-04-18T03:56:27.944806Z",
     "shell.execute_reply.started": "2025-04-18T03:56:27.935883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论1： 1\n",
      "评论2： 0\n"
     ]
    }
   ],
   "source": [
    "stopwords = [line.strip() for line in open('/kaggle/input/stopwords/stopwords.txt', 'r', encoding='utf-8')] + ['PAD']\n",
    "def comment_to_index(comment):\n",
    "    # 分词\n",
    "    words = spm_cut(comment)\n",
    "    words = [item for item in words if item not in stopwords]\n",
    "    # 转为索引\n",
    "    indices = [vocab.get(word, vocab['UNK']) for word in words]\n",
    "    return torch.tensor(indices).unsqueeze(0)\n",
    "\n",
    "# 预测\n",
    "comment1 = comment_to_index('电影很好看，情节引人入胜，全员演技在线，强烈推荐！').to(device)\n",
    "comment2 = comment_to_index('这个电影太烂了，不值得一看！').to(device)\n",
    "pred1 = model(comment1)\n",
    "pred2 = model(comment2)\n",
    "pred1 = torch.argmax(pred1, dim=1).item()\n",
    "pred2 = torch.argmax(pred2, dim=1).item()\n",
    "print('评论1：', pred1)\n",
    "print('评论2：', pred2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 600,
     "sourceId": 1683,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7170435,
     "sourceId": 11445582,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
