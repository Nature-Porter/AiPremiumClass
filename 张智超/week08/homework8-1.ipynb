{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5602e6b2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:16.294070Z",
     "iopub.status.busy": "2025-04-27T05:20:16.293788Z",
     "iopub.status.idle": "2025-04-27T05:20:17.702435Z",
     "shell.execute_reply": "2025-04-27T05:20:17.701646Z"
    },
    "papermill": {
     "duration": 1.413945,
     "end_time": "2025-04-27T05:20:17.704070",
     "exception": false,
     "start_time": "2025-04-27T05:20:16.290125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chinese-couplets/couplet/vocabs\n",
      "/kaggle/input/chinese-couplets/couplet/test/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/in.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/.in.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/test/.out.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/train/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/train/in.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265628d",
   "metadata": {
    "papermill": {
     "duration": 0.002281,
     "end_time": "2025-04-27T05:20:17.710609",
     "exception": false,
     "start_time": "2025-04-27T05:20:17.708328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. 使用中文对联数据集训练带有attention的seq2seq模型，利用tensorboard跟踪。https://www.kaggle.com/datasets/jiaminggogogo/chinese-couplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef651fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:17.716412Z",
     "iopub.status.busy": "2025-04-27T05:20:17.716092Z",
     "iopub.status.idle": "2025-04-27T05:20:17.720540Z",
     "shell.execute_reply": "2025-04-27T05:20:17.720021Z"
    },
    "papermill": {
     "duration": 0.008574,
     "end_time": "2025-04-27T05:20:17.721572",
     "exception": false,
     "start_time": "2025-04-27T05:20:17.712998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1、处理数据\n",
    "import pickle\n",
    "def get_data_list(in_path, out_path):\n",
    "    with open(in_path) as in_file, open(out_path) as out_file:\n",
    "        enc_data, dec_data = [], []\n",
    "        for line in list(zip(in_file, out_file)):\n",
    "            enc_data.append(line[0].strip().split())\n",
    "            dec_data.append(['<s>'] + line[1].strip().split() + ['</s>'])\n",
    "        return enc_data, dec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3551706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:17.726691Z",
     "iopub.status.busy": "2025-04-27T05:20:17.726259Z",
     "iopub.status.idle": "2025-04-27T05:20:22.600155Z",
     "shell.execute_reply": "2025-04-27T05:20:22.599512Z"
    },
    "papermill": {
     "duration": 4.877741,
     "end_time": "2025-04-27T05:20:22.601416",
     "exception": false,
     "start_time": "2025-04-27T05:20:17.723675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练数据:770491\n",
    "train_enc_data, train_dec_data = get_data_list('/kaggle/input/chinese-couplets/couplet/train/in.txt', \n",
    "                                               '/kaggle/input/chinese-couplets/couplet/train/out.txt')\n",
    "# 测试数据:4000\n",
    "test_enc_data, test_dec_data = get_data_list('/kaggle/input/chinese-couplets/couplet/test/in.txt', \n",
    "                                               '/kaggle/input/chinese-couplets/couplet/test/out.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd20dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:22.607191Z",
     "iopub.status.busy": "2025-04-27T05:20:22.606983Z",
     "iopub.status.idle": "2025-04-27T05:20:22.616562Z",
     "shell.execute_reply": "2025-04-27T05:20:22.616086Z"
    },
    "papermill": {
     "duration": 0.013682,
     "end_time": "2025-04-27T05:20:22.617676",
     "exception": false,
     "start_time": "2025-04-27T05:20:22.603994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载字典\n",
    "with open('/kaggle/input/chinese-couplets/couplet/vocabs') as f:\n",
    "    word_list = ['PAD', 'UNK'] + [word.strip() for word in f]\n",
    "    vocab = {word:i for i, word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83856fe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:22.623001Z",
     "iopub.status.busy": "2025-04-27T05:20:22.622792Z",
     "iopub.status.idle": "2025-04-27T05:20:25.932535Z",
     "shell.execute_reply": "2025-04-27T05:20:25.931973Z"
    },
    "papermill": {
     "duration": 3.314052,
     "end_time": "2025-04-27T05:20:25.933909",
     "exception": false,
     "start_time": "2025-04-27T05:20:22.619857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2、定义模型\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, enc_idxs):\n",
    "        embedded = self.embedding(enc_idxs)\n",
    "        # output: [batch_size, seq_len, hidden_size * 2]\n",
    "        # h_n: [num_layers * 2, batch_size, hidden_size]\n",
    "        outputs, h_n = self.rnn(embedded)\n",
    "        # 返回值: [batch_size, hidden_size * 2]\n",
    "        return outputs, torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, enc_outputs, dec_outputs):\n",
    "        # enc_outputs: [batch_size, enc_seq_len, hidden_size * 2]\n",
    "        # dec_outputs: [batch_size, dec_seq_len, hidden_size * 2]\n",
    "        a_t = torch.bmm(enc_outputs, dec_outputs.permute(0, 2, 1)) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        a_t = torch.softmax(a_t, dim=1) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        c_t = torch.bmm(a_t.permute(0, 2, 1), enc_outputs) # [batch_size, dec_seq_len, hidden_size * 2]\n",
    "        return c_t\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size * 2, batch_first=True)\n",
    "        self.attention = Attention()\n",
    "        self.attention_fc = nn.Linear(hidden_size * 4, hidden_size * 2)\n",
    "        self.act = nn.Tanh()\n",
    "        self.fc = nn.Linear(hidden_size * 2, input_size)\n",
    "\n",
    "    def forward(self, dec_idxs, h_0, enc_outputs):\n",
    "        embedded = self.embedding(dec_idxs)\n",
    "        # dec_output: [batch_size, seq_len, hidden_size * 2]\n",
    "        # h_n: [num_layers, batch_size, hidden_size * 2]，返回最后一个时间步的隐藏状态，用于进行推理\n",
    "        dec_outputs, h_n = self.rnn(embedded, h_0.unsqueeze(0))\n",
    "        c_t = self.attention(enc_outputs, dec_outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        cat_outputs = torch.cat((c_t, dec_outputs), dim=2) # [batch_size, seq_len, hidden_size * 4]\n",
    "        outputs = self.attention_fc(cat_outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        outputs = self.act(outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        logits = self.fc(outputs) # [batch_size, seq_len, input_size]\n",
    "        return logits, h_n\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc_input_size, dec_input_size, emb_size, hidden_size, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_input_size, emb_size, hidden_size, dropout)\n",
    "        self.decoder = Decoder(dec_input_size, emb_size, hidden_size, dropout)\n",
    "\n",
    "    def forward(self, enc_idxs, dec_idxs):\n",
    "        enc_outputs, h_0 = self.encoder(enc_idxs)\n",
    "        outputs, h_n = self.decoder(dec_idxs, h_0, enc_outputs)\n",
    "        return outputs, h_n\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     seq2seq = Seq2Seq(200, 300, 70, 128)\n",
    "#     enc_idxs = torch.randint(0, 200, (3, 10))\n",
    "#     dec_idxs = torch.randint(0, 300, (3, 12))\n",
    "#     outputs, h_n = seq2seq(enc_idxs, dec_idxs)\n",
    "#     print(outputs.shape) # [3, 12, 300]\n",
    "#     print(h_n.shape) # [1, 3, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6633d3d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:25.940559Z",
     "iopub.status.busy": "2025-04-27T05:20:25.940282Z",
     "iopub.status.idle": "2025-04-27T05:20:38.316277Z",
     "shell.execute_reply": "2025-04-27T05:20:38.315728Z"
    },
    "papermill": {
     "duration": 12.381137,
     "end_time": "2025-04-27T05:20:38.317564",
     "exception": false,
     "start_time": "2025-04-27T05:20:25.936427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 05:20:27.780870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745731227.965673      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745731228.018752      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 3、模型训练\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "# from EncoderDecoderModel import Seq2Seq\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b3311e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:38.323297Z",
     "iopub.status.busy": "2025-04-27T05:20:38.322863Z",
     "iopub.status.idle": "2025-04-27T05:20:38.328231Z",
     "shell.execute_reply": "2025-04-27T05:20:38.327722Z"
    },
    "papermill": {
     "duration": 0.009108,
     "end_time": "2025-04-27T05:20:38.329155",
     "exception": false,
     "start_time": "2025-04-27T05:20:38.320047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义格式化函数\n",
    "def format_batch(enc_vocab, dec_vocab):\n",
    "    def format_batch_fn(batch):\n",
    "        enc_ids, dec_ids, target_ids = [], [], []\n",
    "        for enc_line, dec_line in batch:\n",
    "            enc_input = [enc_vocab.get(token, enc_vocab['UNK']) for token in enc_line]\n",
    "            dec_input = [dec_vocab.get(token, dec_vocab['UNK']) for token in dec_line]\n",
    "            enc_ids.append(torch.tensor(enc_input))\n",
    "            dec_ids.append(torch.tensor(dec_input[:-1]))\n",
    "            target_ids.append(torch.tensor(dec_input[1:]))  # 目标是输入序列的偏移\n",
    "        enc_inputs = pad_sequence(enc_ids, batch_first=True, padding_value=enc_vocab['PAD'])\n",
    "        dec_inputs = pad_sequence(dec_ids, batch_first=True, padding_value=dec_vocab['PAD'])\n",
    "        targets = pad_sequence(target_ids, batch_first=True, padding_value=dec_vocab['PAD'])\n",
    "        return enc_inputs, dec_inputs, targets\n",
    "    return format_batch_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b947858c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:38.334096Z",
     "iopub.status.busy": "2025-04-27T05:20:38.333893Z",
     "iopub.status.idle": "2025-04-27T05:20:39.808064Z",
     "shell.execute_reply": "2025-04-27T05:20:39.807460Z"
    },
    "papermill": {
     "duration": 1.478028,
     "end_time": "2025-04-27T05:20:39.809344",
     "exception": false,
     "start_time": "2025-04-27T05:20:38.331316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(list(zip(train_enc_data, train_dec_data)), batch_size=256, shuffle=True, collate_fn=format_batch(vocab, vocab))\n",
    "test_dataloader = DataLoader(list(zip(test_enc_data, test_dec_data)), batch_size=256, shuffle=False, collate_fn=format_batch(vocab, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cefad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:39.815445Z",
     "iopub.status.busy": "2025-04-27T05:20:39.815121Z",
     "iopub.status.idle": "2025-04-27T05:20:44.401564Z",
     "shell.execute_reply": "2025-04-27T05:20:44.401006Z"
    },
    "papermill": {
     "duration": 4.591023,
     "end_time": "2025-04-27T05:20:44.403030",
     "exception": false,
     "start_time": "2025-04-27T05:20:39.812007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='/kaggle/working/runs/cat')\n",
    "emb_size = 100\n",
    "hidden_size = 512\n",
    "epochs = 10\n",
    "model = Seq2Seq(len(vocab), len(vocab), emb_size, hidden_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5441e6e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:20:44.408844Z",
     "iopub.status.busy": "2025-04-27T05:20:44.408368Z",
     "iopub.status.idle": "2025-04-27T07:19:25.068852Z",
     "shell.execute_reply": "2025-04-27T07:19:25.067970Z"
    },
    "papermill": {
     "duration": 7120.664524,
     "end_time": "2025-04-27T07:19:25.070009",
     "exception": false,
     "start_time": "2025-04-27T05:20:44.405485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.318755030632019: 100%|██████████| 3010/3010 [11:42<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 33.59089158482573, Total: 41544, Correct: 13955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.5449485778808594: 100%|██████████| 3010/3010 [11:49<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Accuracy: 35.95224340458309, Total: 41544, Correct: 14936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.2648987770080566: 100%|██████████| 3010/3010 [11:50<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Accuracy: 36.91267090313884, Total: 41544, Correct: 15335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.1247605085372925: 100%|██████████| 3010/3010 [11:53<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Accuracy: 37.3627960716349, Total: 41544, Correct: 15522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.2235298156738281: 100%|██████████| 3010/3010 [11:51<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Accuracy: 37.278548045445795, Total: 41544, Correct: 15487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.1288634538650513: 100%|██████████| 3010/3010 [11:51<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Accuracy: 37.280955131908335, Total: 41544, Correct: 15488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.0872397422790527: 100%|██████████| 3010/3010 [11:51<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Accuracy: 37.396495282110536, Total: 41544, Correct: 15536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.058830976486206: 100%|██████████| 3010/3010 [11:53<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Accuracy: 37.1317157712305, Total: 41544, Correct: 15426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.142983317375183: 100%|██████████| 3010/3010 [11:51<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Accuracy: 36.96562680531485, Total: 41544, Correct: 15357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.1397030353546143: 100%|██████████| 3010/3010 [11:52<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 36.6527055651839, Total: 41544, Correct: 15227\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        # 训练模型\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_dataloader)\n",
    "    for i, (enc_inputs, dec_inputs, targets) in enumerate(train_bar):\n",
    "        enc_inputs, dec_inputs, targets = enc_inputs.to(device), dec_inputs.to(device), targets.to(device)\n",
    "        out, _ = model(enc_inputs, dec_inputs)\n",
    "        # targets: [batch_size, seq_len]\n",
    "        # out: [batch_size, seq_len, vocab_size]\n",
    "        loss = loss_fn(out.view(-1, len(vocab)), targets.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"loss\", loss.item(), epoch * len(train_dataloader) + i)\n",
    "        train_bar.set_description(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for enc_inputs, dec_inputs, targets in test_dataloader:\n",
    "            enc_inputs, dec_inputs, targets = enc_inputs.to(device), dec_inputs.to(device), targets.to(device)\n",
    "            out, _ = model(enc_inputs, dec_inputs)\n",
    "            pred = torch.argmax(out, dim=-1)\n",
    "            # 标记非填充位置\n",
    "            non_padding_mask = (targets != 0)\n",
    "            correct += (pred[non_padding_mask] == targets[non_padding_mask]).sum().item()\n",
    "            total += non_padding_mask.sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy}, Total: {total}, Correct: {correct}\")\n",
    "        writer.add_scalar(\"accuracy\", accuracy, epoch)\n",
    "writer.close()\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"model_cat.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1661983,
     "sourceId": 2726695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7158.116258,
   "end_time": "2025-04-27T07:19:30.383684",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-27T05:20:12.267426",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
