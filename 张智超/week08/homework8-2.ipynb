{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f431ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T07:26:58.299172Z",
     "iopub.status.busy": "2025-04-27T07:26:58.298925Z",
     "iopub.status.idle": "2025-04-27T07:27:00.087311Z",
     "shell.execute_reply": "2025-04-27T07:27:00.086193Z"
    },
    "papermill": {
     "duration": 1.793147,
     "end_time": "2025-04-27T07:27:00.088720",
     "exception": false,
     "start_time": "2025-04-27T07:26:58.295573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chinese-couplets/couplet/vocabs\n",
      "/kaggle/input/chinese-couplets/couplet/test/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/in.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/.in.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/test/.out.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/train/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/train/in.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23796c88",
   "metadata": {},
   "source": [
    "2. 尝试encoder hidden state不同的返回形式（concat和add），使用add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ea1f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:00.094426Z",
     "iopub.status.busy": "2025-04-27T07:27:00.094097Z",
     "iopub.status.idle": "2025-04-27T07:27:05.669859Z",
     "shell.execute_reply": "2025-04-27T07:27:05.669266Z"
    },
    "papermill": {
     "duration": 5.579986,
     "end_time": "2025-04-27T07:27:05.671307",
     "exception": false,
     "start_time": "2025-04-27T07:27:00.091321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1、处理数据\n",
    "import pickle\n",
    "def get_data_list(in_path, out_path):\n",
    "    with open(in_path) as in_file, open(out_path) as out_file:\n",
    "        enc_data, dec_data = [], []\n",
    "        for line in list(zip(in_file, out_file)):\n",
    "            enc_data.append(line[0].strip().split())\n",
    "            dec_data.append(['<s>'] + line[1].strip().split() + ['</s>'])\n",
    "        return enc_data, dec_data\n",
    "# 训练数据:770491\n",
    "train_enc_data, train_dec_data = get_data_list('/kaggle/input/chinese-couplets/couplet/train/in.txt', \n",
    "                                               '/kaggle/input/chinese-couplets/couplet/train/out.txt')\n",
    "# 测试数据:4000\n",
    "test_enc_data, test_dec_data = get_data_list('/kaggle/input/chinese-couplets/couplet/test/in.txt', \n",
    "                                               '/kaggle/input/chinese-couplets/couplet/test/out.txt')\n",
    "# # 加载字典\n",
    "# with open('/kaggle/input/chinese-couplets/couplet/vocabs') as f:\n",
    "#     word_list = ['PAD', 'UNK'] + [word.strip() for word in f]\n",
    "#     vocab = {word:i for i, word in enumerate(word_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8384b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:05.677594Z",
     "iopub.status.busy": "2025-04-27T07:27:05.676896Z",
     "iopub.status.idle": "2025-04-27T07:27:06.840901Z",
     "shell.execute_reply": "2025-04-27T07:27:06.840255Z"
    },
    "papermill": {
     "duration": 1.168549,
     "end_time": "2025-04-27T07:27:06.842314",
     "exception": false,
     "start_time": "2025-04-27T07:27:05.673765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vocab(train_data, test_data):\n",
    "    word_set = set()\n",
    "    for words in (train_data + test_data):\n",
    "        word_set.update(words)\n",
    "    word_list = ['PAD', 'UNK'] + list(word_set)\n",
    "    return {word:i for i, word in enumerate(word_list)}\n",
    "enc_vocab = get_vocab(train_enc_data, test_enc_data)\n",
    "dec_vocab = get_vocab(train_dec_data, test_dec_data)\n",
    "# 保存词典\n",
    "with open(\"enc_dec_vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump((enc_vocab, dec_vocab), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe5f444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:06.848145Z",
     "iopub.status.busy": "2025-04-27T07:27:06.847561Z",
     "iopub.status.idle": "2025-04-27T07:27:10.951469Z",
     "shell.execute_reply": "2025-04-27T07:27:10.950845Z"
    },
    "papermill": {
     "duration": 4.108036,
     "end_time": "2025-04-27T07:27:10.952720",
     "exception": false,
     "start_time": "2025-04-27T07:27:06.844684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2、定义模型\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, enc_idxs):\n",
    "        embedded = self.embedding(enc_idxs)\n",
    "        # output: [batch_size, seq_len, hidden_size * 2]\n",
    "        # h_n: [num_layers * 2, batch_size, hidden_size]\n",
    "        outputs, h_n = self.rnn(embedded)\n",
    "        outputs = outputs[:,:,:self.hidden_size] + outputs[:,:,self.hidden_size:]\n",
    "        # 返回值求和: [batch_size, hidden_size]\n",
    "        return outputs, h_n.sum(dim=0)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, enc_outputs, dec_outputs):\n",
    "        # enc_outputs: [batch_size, enc_seq_len, hidden_size]\n",
    "        # dec_outputs: [batch_size, dec_seq_len, hidden_size]\n",
    "        a_t = torch.bmm(enc_outputs, dec_outputs.permute(0, 2, 1)) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        a_t = torch.softmax(a_t, dim=1) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        c_t = torch.bmm(a_t.permute(0, 2, 1), enc_outputs) # [batch_size, dec_seq_len, hidden_size * 2]\n",
    "        return c_t\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "        self.attention = Attention()\n",
    "        self.attention_fc = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.act = nn.Tanh()\n",
    "        self.fc = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, dec_idxs, h_0, enc_outputs):\n",
    "        embedded = self.embedding(dec_idxs)\n",
    "        # dec_output: [batch_size, seq_len, hidden_size]\n",
    "        # h_n: [num_layers, batch_size, hidden_size]，返回最后一个时间步的隐藏状态，用于进行推理\n",
    "        dec_outputs, h_n = self.rnn(embedded, h_0.unsqueeze(0))\n",
    "        c_t = self.attention(enc_outputs, dec_outputs) # [batch_size, seq_len, hidden_size]\n",
    "        cat_outputs = torch.cat((c_t, dec_outputs), dim=2) # [batch_size, seq_len, hidden_size * 2]\n",
    "        outputs = self.attention_fc(cat_outputs) # [batch_size, seq_len, hidden_size]\n",
    "        outputs = self.act(outputs) # [batch_size, seq_len, hidden_size]\n",
    "        logits = self.fc(outputs) # [batch_size, seq_len, input_size]\n",
    "        return logits, h_n\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc_input_size, dec_input_size, emb_size, hidden_size, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_input_size, emb_size, hidden_size, dropout)\n",
    "        self.decoder = Decoder(dec_input_size, emb_size, hidden_size, dropout)\n",
    "\n",
    "    def forward(self, enc_idxs, dec_idxs):\n",
    "        enc_outputs, h_0 = self.encoder(enc_idxs)\n",
    "        outputs, h_n = self.decoder(dec_idxs, h_0, enc_outputs)\n",
    "        return outputs, h_n\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     seq2seq = Seq2Seq(200, 300, 70, 128)\n",
    "#     enc_idxs = torch.randint(0, 200, (3, 10))\n",
    "#     dec_idxs = torch.randint(0, 300, (3, 12))\n",
    "#     outputs, h_n = seq2seq(enc_idxs, dec_idxs)\n",
    "#     print(outputs.shape) # [3, 12, 300]\n",
    "#     print(h_n.shape) # [1, 3, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10d79c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:10.958858Z",
     "iopub.status.busy": "2025-04-27T07:27:10.958504Z",
     "iopub.status.idle": "2025-04-27T07:27:25.405820Z",
     "shell.execute_reply": "2025-04-27T07:27:25.405205Z"
    },
    "papermill": {
     "duration": 14.451805,
     "end_time": "2025-04-27T07:27:25.407262",
     "exception": false,
     "start_time": "2025-04-27T07:27:10.955457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 07:27:13.156619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745738833.386008      18 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745738833.453274      18 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 3、模型训练\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "# from EncoderDecoderModel import Seq2Seq\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 定义格式化函数\n",
    "def format_batch(enc_vocab, dec_vocab):\n",
    "    def format_batch_fn(batch):\n",
    "        enc_ids, dec_ids, target_ids = [], [], []\n",
    "        for enc_line, dec_line in batch:\n",
    "            enc_input = [enc_vocab.get(token, enc_vocab['UNK']) for token in enc_line]\n",
    "            dec_input = [dec_vocab.get(token, dec_vocab['UNK']) for token in dec_line]\n",
    "            enc_ids.append(torch.tensor(enc_input))\n",
    "            dec_ids.append(torch.tensor(dec_input[:-1]))\n",
    "            target_ids.append(torch.tensor(dec_input[1:]))  # 目标是输入序列的偏移\n",
    "        enc_inputs = pad_sequence(enc_ids, batch_first=True, padding_value=enc_vocab['PAD'])\n",
    "        dec_inputs = pad_sequence(dec_ids, batch_first=True, padding_value=dec_vocab['PAD'])\n",
    "        targets = pad_sequence(target_ids, batch_first=True, padding_value=dec_vocab['PAD'])\n",
    "        return enc_inputs, dec_inputs, targets\n",
    "    return format_batch_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b01d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:25.412757Z",
     "iopub.status.busy": "2025-04-27T07:27:25.412295Z",
     "iopub.status.idle": "2025-04-27T07:27:31.958548Z",
     "shell.execute_reply": "2025-04-27T07:27:31.957748Z"
    },
    "papermill": {
     "duration": 6.550463,
     "end_time": "2025-04-27T07:27:31.960064",
     "exception": false,
     "start_time": "2025-04-27T07:27:25.409601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(list(zip(train_enc_data, train_dec_data)), batch_size=256, shuffle=True, collate_fn=format_batch(enc_vocab, dec_vocab))\n",
    "test_dataloader = DataLoader(list(zip(test_enc_data, test_dec_data)), batch_size=256, shuffle=False, collate_fn=format_batch(enc_vocab, dec_vocab))\n",
    "writer = SummaryWriter(log_dir='/kaggle/working/runs/add')\n",
    "emb_size = 100\n",
    "hidden_size = 512\n",
    "epochs = 10\n",
    "model = Seq2Seq(len(enc_vocab), len(dec_vocab), emb_size, hidden_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872d819d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T07:27:31.965320Z",
     "iopub.status.busy": "2025-04-27T07:27:31.964845Z",
     "iopub.status.idle": "2025-04-27T08:29:31.101839Z",
     "shell.execute_reply": "2025-04-27T08:29:31.101016Z"
    },
    "papermill": {
     "duration": 3719.50068,
     "end_time": "2025-04-27T08:29:31.462918",
     "exception": false,
     "start_time": "2025-04-27T07:27:31.962238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4131219387054443: 100%|██████████| 3010/3010 [05:47<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Accuracy: 32.7315617176969, Total: 41544, Correct: 13598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.6520153284072876: 100%|██████████| 3010/3010 [06:10<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Accuracy: 35.16031195840554, Total: 41544, Correct: 14607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.3355357646942139: 100%|██████████| 3010/3010 [06:13<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Accuracy: 36.06537646832274, Total: 41544, Correct: 14983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.3137480020523071: 100%|██████████| 3010/3010 [06:13<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Accuracy: 36.58771423069517, Total: 41544, Correct: 15200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.3928636312484741: 100%|██████████| 3010/3010 [06:14<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Accuracy: 36.744174850760636, Total: 41544, Correct: 15265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 1.271131992340088: 100%|██████████| 3010/3010 [06:14<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Accuracy: 36.81638744463701, Total: 41544, Correct: 15295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.2021983861923218: 100%|██████████| 3010/3010 [06:14<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Accuracy: 36.77305988831119, Total: 41544, Correct: 15277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 1.1794791221618652: 100%|██████████| 3010/3010 [06:14<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Accuracy: 36.9632197188523, Total: 41544, Correct: 15356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.0886945724487305: 100%|██████████| 3010/3010 [06:14<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Accuracy: 36.7947236664741, Total: 41544, Correct: 15286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.32445228099823: 100%|██████████| 3010/3010 [06:14<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 36.700847294434816, Total: 41544, Correct: 15247\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        # 训练模型\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_dataloader)\n",
    "    for i, (enc_inputs, dec_inputs, targets) in enumerate(train_bar):\n",
    "        enc_inputs, dec_inputs, targets = enc_inputs.to(device), dec_inputs.to(device), targets.to(device)\n",
    "        out, _ = model(enc_inputs, dec_inputs)\n",
    "        # targets: [batch_size, seq_len]\n",
    "        # out: [batch_size, seq_len, vocab_size]\n",
    "        loss = loss_fn(out.view(-1, out.size(-1)), targets.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        writer.add_scalar(\"loss\", loss.item(), epoch * len(train_dataloader) + i)\n",
    "        train_bar.set_description(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for enc_inputs, dec_inputs, targets in test_dataloader:\n",
    "            enc_inputs, dec_inputs, targets = enc_inputs.to(device), dec_inputs.to(device), targets.to(device)\n",
    "            out, _ = model(enc_inputs, dec_inputs)\n",
    "            pred = torch.argmax(out, dim=-1)\n",
    "            # 标记非填充位置\n",
    "            non_padding_mask = (targets != 0)\n",
    "            correct += (pred[non_padding_mask] == targets[non_padding_mask]).sum().item()\n",
    "            total += non_padding_mask.sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}, Accuracy: {accuracy}, Total: {total}, Correct: {correct}\")\n",
    "        writer.add_scalar(\"accuracy\", accuracy, epoch)\n",
    "writer.close()\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"model_add.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1661983,
     "sourceId": 2726695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3763.230152,
   "end_time": "2025-04-27T08:29:37.019191",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-27T07:26:53.789039",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
