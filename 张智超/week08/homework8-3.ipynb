{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-27T05:11:14.891560Z",
     "iopub.status.busy": "2025-04-27T05:11:14.890936Z",
     "iopub.status.idle": "2025-04-27T05:11:14.907639Z",
     "shell.execute_reply": "2025-04-27T05:11:14.907081Z",
     "shell.execute_reply.started": "2025-04-27T05:11:14.891536Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/homework8-1/__results__.html\n",
      "/kaggle/input/homework8-1/model_cat.pth\n",
      "/kaggle/input/homework8-1/__notebook__.ipynb\n",
      "/kaggle/input/homework8-1/__output__.json\n",
      "/kaggle/input/homework8-1/custom.css\n",
      "/kaggle/input/chinese-couplets/couplet/vocabs\n",
      "/kaggle/input/chinese-couplets/couplet/test/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/in.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/.in.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/test/.out.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/train/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/train/in.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 编写并实现seq2seq attention版的推理实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:12:09.822297Z",
     "iopub.status.busy": "2025-04-27T05:12:09.821502Z",
     "iopub.status.idle": "2025-04-27T05:12:11.367660Z",
     "shell.execute_reply": "2025-04-27T05:12:11.367134Z",
     "shell.execute_reply.started": "2025-04-27T05:12:09.822261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "    \n",
    "    def forward(self, enc_idxs):\n",
    "        embedded = self.embedding(enc_idxs)\n",
    "        # output: [batch_size, seq_len, hidden_size * 2]\n",
    "        # h_n: [num_layers * 2, batch_size, hidden_size]\n",
    "        outputs, h_n = self.rnn(embedded)\n",
    "        # 返回值: [batch_size, hidden_size * 2]\n",
    "        return outputs, torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, enc_outputs, dec_outputs):\n",
    "        # enc_outputs: [batch_size, enc_seq_len, hidden_size * 2]\n",
    "        # dec_outputs: [batch_size, dec_seq_len, hidden_size * 2]\n",
    "        a_t = torch.bmm(enc_outputs, dec_outputs.permute(0, 2, 1)) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        a_t = torch.softmax(a_t, dim=1) # [batch_size, enc_seq_len, dec_seq_len]\n",
    "        c_t = torch.bmm(a_t.permute(0, 2, 1), enc_outputs) # [batch_size, dec_seq_len, hidden_size * 2]\n",
    "        return c_t\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        self.rnn = nn.GRU(emb_size, hidden_size * 2, batch_first=True)\n",
    "        self.attention = Attention()\n",
    "        self.attention_fc = nn.Linear(hidden_size * 4, hidden_size * 2)\n",
    "        self.act = nn.Tanh()\n",
    "        self.fc = nn.Linear(hidden_size * 2, input_size)\n",
    "\n",
    "    def forward(self, dec_idxs, h_0, enc_outputs):\n",
    "        embedded = self.embedding(dec_idxs)\n",
    "        # dec_output: [batch_size, seq_len, hidden_size * 2]\n",
    "        # h_n: [num_layers, batch_size, hidden_size * 2]，返回最后一个时间步的隐藏状态，用于进行推理\n",
    "        dec_outputs, h_n = self.rnn(embedded, h_0.unsqueeze(0))\n",
    "        c_t = self.attention(enc_outputs, dec_outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        cat_outputs = torch.cat((c_t, dec_outputs), dim=2) # [batch_size, seq_len, hidden_size * 4]\n",
    "        outputs = self.attention_fc(cat_outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        outputs = self.act(outputs) # [batch_size, seq_len, hidden_size * 2]\n",
    "        logits = self.fc(outputs) # [batch_size, seq_len, input_size]\n",
    "        return logits, h_n\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc_input_size, dec_input_size, emb_size, hidden_size, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(enc_input_size, emb_size, hidden_size, dropout)\n",
    "        self.decoder = Decoder(dec_input_size, emb_size, hidden_size, dropout)\n",
    "\n",
    "    def forward(self, enc_idxs, dec_idxs):\n",
    "        enc_outputs, h_0 = self.encoder(enc_idxs)\n",
    "        outputs, h_n = self.decoder(dec_idxs, h_0, enc_outputs)\n",
    "        return outputs, h_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:12:16.586984Z",
     "iopub.status.busy": "2025-04-27T05:12:16.586363Z",
     "iopub.status.idle": "2025-04-27T05:12:16.593054Z",
     "shell.execute_reply": "2025-04-27T05:12:16.592465Z",
     "shell.execute_reply.started": "2025-04-27T05:12:16.586961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "def infer(model, enc_vocab, dec_vocab, dec_vocab_reverse, input_sentence):\n",
    "    # 将输入句子转换为索引序列\n",
    "    input_idxs = [enc_vocab.get(word, enc_vocab['UNK']) for word in list(input_sentence)]\n",
    "    model.eval()\n",
    "    # 推理的长度\n",
    "    word_len = len(list(input_sentence))\n",
    "    word_idx= []\n",
    "    with torch.no_grad():\n",
    "        # 获取encoder的输出\n",
    "        enc_outputs, hidden_state = model.encoder(torch.tensor(input_idxs).unsqueeze(0))\n",
    "        # 初始化decoder的输入：BOS，批次为1, 序列长度为1\n",
    "        dec_inputs = torch.tensor([[dec_vocab['<s>']]])\n",
    "        while True:\n",
    "            # 推理第一个字时：logics: [1, 1, vocab_size]\n",
    "            logics, h_n = model.decoder(dec_inputs, hidden_state, enc_outputs)\n",
    "            # 获取最后一次时间步的输出\n",
    "            next_word_idx = torch.argmax(logics,dim=-1).squeeze().item()\n",
    "            word_idx.append(next_word_idx)\n",
    "            # 检查是否达到结束条件\n",
    "            if next_word_idx == dec_vocab['</s>'] or len(word_idx) >= word_len:\n",
    "                break\n",
    "            # 将当前的输出作为下一个时间步的输入\n",
    "            dec_inputs = torch.tensor([[next_word_idx]])\n",
    "            # h_n：是rnn的最后一个时间步的隐藏状态，作为下一个时间步的隐藏状态输入\n",
    "            hidden_state = h_n.view(1,-1)\n",
    "        return \"\".join([dec_vocab_reverse.get(idx) for idx in word_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:17:14.588331Z",
     "iopub.status.busy": "2025-04-27T05:17:14.587751Z",
     "iopub.status.idle": "2025-04-27T05:17:14.834348Z",
     "shell.execute_reply": "2025-04-27T05:17:14.833572Z",
     "shell.execute_reply.started": "2025-04-27T05:17:14.588308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 加载词典\n",
    "with open('/kaggle/input/chinese-couplets/couplet/vocabs') as f:\n",
    "    word_list = ['PAD', 'UNK'] + [word.strip() for word in f]\n",
    "    vocab = {word:i for i, word in enumerate(word_list)}\n",
    "# 加载模型\n",
    "emb_size = 120\n",
    "hidden_size = 512\n",
    "model = Seq2Seq(len(vocab), len(vocab), emb_size, hidden_size)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/homework8-1/model_cat.pth\", weights_only=True))\n",
    "vocab_reverse = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T05:17:17.252504Z",
     "iopub.status.busy": "2025-04-27T05:17:17.252266Z",
     "iopub.status.idle": "2025-04-27T05:17:17.684477Z",
     "shell.execute_reply": "2025-04-27T05:17:17.683786Z",
     "shell.execute_reply.started": "2025-04-27T05:17:17.252488Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "彩屏如画，望秀美崤函，花团锦簇\n",
      "雅韵生辉，赏心香诗句，锦簇花团\n"
     ]
    }
   ],
   "source": [
    "# 进行推理\n",
    "input_sentence = \"彩屏如画，望秀美崤函，花团锦簇\"\n",
    "output_sentence = infer(model, vocab, vocab, vocab_reverse, input_sentence)\n",
    "print(input_sentence)\n",
    "print(output_sentence)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1661983,
     "sourceId": 2726695,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 236328832,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
