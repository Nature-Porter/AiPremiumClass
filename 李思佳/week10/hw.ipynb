{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \n",
    "1. 根据提供的kaggle JD评论语料进行文本分类训练\n",
    "https://www.kaggle.com/datasets/dosonleung/jd_comment_with_label\n",
    "2. 调整模型训练参数，添加tensorboard跟踪，对比bert冻结和不冻结之间的训练差异。\n",
    "3. 保存模型进行分类预测。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/py312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.11), please consider upgrading to the latest version (0.3.12).\n",
      "Path to dataset files: /Users/peiqi/.cache/kagglehub/datasets/dosonleung/jd_comment_with_label/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"dosonleung/jd_comment_with_label\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71818\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 Excel 文件，并指定引擎为 openpyxl\n",
    "excel_file_path = '/Users/peiqi/code/AiPremiumClass/李思佳/week10/jd_comment_data.xlsx'\n",
    "df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "def load_jd_comments(df):\n",
    "    jd_comments = {'comment':[], 'lable':[]}\n",
    "\n",
    "    jd_comm = df['评价内容(content)'].tolist()\n",
    "    jd_lable = df['评分（总分5分）(score)'].tolist()\n",
    "\n",
    "    for comm, lb in zip(jd_comm, jd_lable):\n",
    "        if comm == '此用户未填写评价内容':\n",
    "            continue\n",
    "        jd_comments['comment'].append(comm)\n",
    "        # jd_comments['lable'].append(lb)\n",
    "        #         # 将标签值减 1，使其范围从 1-5 变为 0-4\n",
    "        jd_comments['lable'].append(lb - 1)\n",
    "        \n",
    "    return jd_comments\n",
    "\n",
    "jd = load_jd_comments(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def load_jd_comments(df):\n",
    "    jd_comments = {'comment':[], 'lable':[]}\n",
    "\n",
    "    jd_comm = df['评价内容(content)'].tolist()\n",
    "    jd_lable = df['评分（总分5分）(score)'].tolist()\n",
    "    #取前1000条\n",
    "    i = 0 \n",
    "    for comm, lb in zip(jd_comm, jd_lable):\n",
    "        if i < 1000:\n",
    "            if comm == '此用户未填写评价内容':\n",
    "                continue\n",
    "            jd_comments['comment'].append(comm)\n",
    "            # jd_comments['lable'].append(lb)\n",
    "            # 将标签值减 1，使其范围从 1-5 变为 0-4\n",
    "            jd_comments['lable'].append(lb - 1)\n",
    "            i += 1\n",
    "    print(len(jd_comments['comment']))    \n",
    "    return jd_comments\n",
    "\n",
    "\n",
    "def build_collate(tokenizer):\n",
    "    def collate_fn(batch):\n",
    "        # 文本分类语料：输入语句，类别标签\n",
    "        sentents,labels = zip(*batch)\n",
    "    \n",
    "        # tokenizer转换\n",
    "        model_inputs = tokenizer(sentents, return_tensors='pt', padding = True,  truncation = True)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        return model_inputs, labels\n",
    "    return collate_fn\n",
    "\n",
    "def train_test_split(X,y,split_rate=0.2):\n",
    "    # 数据拆分流程\n",
    "    # 1. 拆分比率\n",
    "    # 2. 样本随机性\n",
    "    # 3. 构建拆分索引\n",
    "    # 4. 借助slice拆分\n",
    "    split_size = int(len(X) * (1 -split_rate))\n",
    "\n",
    "    split_index = list(range(len(X)))\n",
    "    random.shuffle(split_index)\n",
    "    x_train = [X[i] for i in split_index[:split_size]]\n",
    "    y_train = [y[i] for i in split_index[:split_size]]\n",
    "\n",
    "    x_test = [X[i] for i in split_index[split_size:]]\n",
    "    y_test = [y[i] for i in split_index[split_size:]]\n",
    "\n",
    "    return (x_train,y_train),(x_test, y_test)\n",
    "\n",
    "def train_and_eva(train_dl, test_dl, num_epochs, freeze_bert=False, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), model_save_dir=\"/Users/peiqi/code/AiPremiumClass/李思佳/week10\"):\n",
    "    # 确保保存目录存在\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    # 初始化 SummaryWriter\n",
    "    writer = SummaryWriter('runs/text_classification_experiment')\n",
    "\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-chinese\",num_labels=5)\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    if freeze_bert:\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    #创建损失函数\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #模型优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels )in enumerate(train_dl):\n",
    "            print(i)\n",
    "            # 前向传播\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                avg_loss = running_loss / 100 if i > 0 else running_loss\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i}], Loss: {loss.item():.4f}')\n",
    "                writer.add_scalar('Training Loss', avg_loss, epoch * len(train_dl) + i)\n",
    "                running_loss = 0.0\n",
    "\n",
    "    # 模型评估\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dl:\n",
    "            for key in inputs.keys():\n",
    "                inputs[key] = inputs[key].to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {accuracy:.4f}, Test F1: {f1:.4f}')\n",
    "    writer.add_scalar('Test Accuracy', accuracy, epoch)\n",
    "    writer.add_scalar('Test F1', f1, epoch)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        model_save_path = os.path.join(model_save_dir, f\"best_model_epoch_{epoch + 1}.pt\")\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Best model saved at {model_save_path} with accuracy {accuracy:.4f}\")\n",
    "\n",
    "    # 关闭 SummaryWriter\n",
    "    writer.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    excel_file_path = '/Users/peiqi/code/AiPremiumClass/李思佳/week10/jd_comment_data.xlsx'\n",
    "    df = pd.read_excel(excel_file_path, engine='openpyxl')\n",
    "    jd = load_jd_comments(df)\n",
    "\n",
    "    \n",
    "    BATCH_SIZE = 128\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    (X_train, y_train),(X_test, y_test) = train_test_split(jd['comment'],jd['lable'])\n",
    "    \n",
    "    # 自定义Dataset处理文本数据转换\n",
    "    train_ds = list(zip(X_train, y_train))\n",
    "    test_ds = list(zip(X_test, y_test))\n",
    "\n",
    "    \n",
    "    # 加载词典创建分词器\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-chinese\")\n",
    "\n",
    "    # DataLoader\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=build_collate(tokenizer))\n",
    "    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=build_collate(tokenizer))\n",
    "\n",
    "    #模型训练\n",
    "    num_epochs = 2\n",
    "\n",
    "    # 训练\n",
    "    m1 = train_and_eva(train_dl, test_dl, num_epochs, freeze_bert=True, device=device) \n",
    "    m2 = train_and_eva(train_dl, test_dl, num_epochs, freeze_bert=False, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
