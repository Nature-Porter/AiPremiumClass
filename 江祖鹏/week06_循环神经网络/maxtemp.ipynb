{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "#所有气象站最高气温数据\n",
    "stations_maxtemp = {}\n",
    "#读取csv文件\n",
    "with open('Summary of Weather.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for item in reader:\n",
    "        sta = item['STA']\n",
    "        stations_maxtemp[sta] = stations_maxtemp.get(sta, [])\n",
    "        stations_maxtemp[sta].append(float(item['MaxTemp']))\n",
    "\n",
    "#气象站总量\n",
    "print(len(stations_maxtemp))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检测连续记录气温的长度\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp_length = [len(temp) for temp in stations_maxtemp.values()]\n",
    "plt.bar(range(len(temp_length)), temp_length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉过短的样本\n",
    "max_temp = [temps for temps in stations_maxtemp.values() if len(temps) > 20]\n",
    "\n",
    "len(max_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#观察样本温度异常值\n",
    "plt.figure(figsize=(20, 200))\n",
    "\n",
    "for i, temps in enumerate(range(79)):\n",
    "    plt.subplot(79, 2, i*2 + 1)\n",
    "    temps = max_temp[i]\n",
    "    plt.plot(range(len(temps)), temps)\n",
    "    temps = max_temp[i+1]\n",
    "    plt.plot(range(len(temps)), temps)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#过滤掉极寒异常值\n",
    "filted_maxtemp = [[temp for temp in temps if temp > -17] for temps in max_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 200))\n",
    "\n",
    "for i, temps in enumerate(range(79)):\n",
    "    plt.subplot(79, 2, i*2 + 1)\n",
    "    temps = filted_maxtemp[i]\n",
    "    plt.plot(range(len(temps)), temps)\n",
    "    plt.subplot(79, 2, i*2 + 2)\n",
    "    temps = filted_maxtemp[i+1]\n",
    "    plt.plot(range(len(temps)), temps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_time_series(temp_values, batch_size, n_steps):\n",
    "    #生成用于填充到数据集的矩阵\n",
    "    series = np.zeros((batch_size, n_steps))\n",
    "    #生成随机样本索引\n",
    "    sta_size = len(temp_values)\n",
    "    sta_idx = np.random.randint(0, sta_size, batch_size)\n",
    "\n",
    "    for i, idx in enumerate(sta_idx):\n",
    "        temps = temp_values[idx]\n",
    "        temp_size = len(temps)\n",
    "        #随机选择开始索引\n",
    "        start_idx = np.random.randint(0, temp_size - n_steps)\n",
    "        series[i] = np.array(temps[start_idx:start_idx + n_steps])\n",
    "    return series[:,:n_steps,np.newaxis].astype(np.float32),series[:,-1,np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 21\n",
    "feature_size=1\n",
    "label_size=5\n",
    "max_temp = filted_maxtemp\n",
    "\n",
    "X_train, y_train = generate_time_series(max_temp, 7000, n_steps)\n",
    "X_valid, y_valid = generate_time_series(max_temp, 2000, n_steps)\n",
    "X_test, y_test = generate_time_series(max_temp, 1000, n_steps)\n",
    "\n",
    "X_train.shape, y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def plot_series(series, y=None, y_pred=None, y_pred_std=None, x_label=\"$t$\", y_label=\"$x$\"):\n",
    "    r, c = 3, 5\n",
    "    fig, axes = plt.subplots(nrows=r, ncols=c, sharey=True, sharex=True, figsize=(20, 10))\n",
    "    for row in range(r):\n",
    "        for col in range(c):\n",
    "            plt.sca(axes[row][col])\n",
    "            ix = col + row*c\n",
    "            plt.plot(series[ix, :], \".-\")\n",
    "            if y is not None:\n",
    "                plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y[ix])), y[ix], \"bx\", markersize=10)\n",
    "            if y_pred is not None:\n",
    "                plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix], \"ro\")\n",
    "            if y_pred_std is not None:\n",
    "                plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix] + y_pred_std[ix])\n",
    "                plt.plot(range(len(series[ix, :]), len(series[ix, :])+len(y_pred[ix])), y_pred[ix] - y_pred_std[ix])\n",
    "            plt.grid(True)\n",
    "            # plt.hlines(0, 0, 100, linewidth=1)\n",
    "            # plt.axis([0, len(series[ix, :])+len(y[ix]), -1, 1])\n",
    "            if x_label and row == r - 1:\n",
    "              plt.xlabel(x_label, fontsize=16)\n",
    "            if y_label and col == 0:\n",
    "              plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y=None, train=True):\n",
    "        self.train = train\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return torch.from_numpy(self.X[idx]), torch.from_numpy(self.y[idx])\n",
    "        return torch.from_numpy(self.X[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': TimeSeriesDataset(X_train, y_train),\n",
    "    'valid': TimeSeriesDataset(X_valid, y_valid),\n",
    "    'test': TimeSeriesDataset(X_test, y_test, train=False)\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(dataset['train'], batch_size=32, shuffle=True),\n",
    "    'valid': DataLoader(dataset['valid'], batch_size=32, shuffle=False),\n",
    "    'test': DataLoader(dataset['test'], batch_size=32, shuffle=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.rnn = torch.nn.RNN(input_size=1, hidden_size=64, num_layers=1, batch_first=True)\n",
    "    self.fc = torch.nn.Linear(64, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, h = self.rnn(x) \n",
    "    y = self.fc(x[:,-1])\n",
    "    return y\n",
    "\n",
    "rnn = RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def fit(model, dataloader, epochs=10):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    bar = tqdm(range(1, epochs+1))\n",
    "    for epoch in bar:\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for batch in dataloader['train']:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        model.eval()\n",
    "        eval_loss = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader['valid']:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                eval_loss.append(loss.item())\n",
    "        bar.set_description(f\"loss {np.mean(train_loss):.5f} val_loss {np.mean(eval_loss):.5f}\")\n",
    "        writer.add_scalar('train_loss', np.mean(train_loss), epoch)\n",
    "        writer.add_scalar('val_loss', np.mean(eval_loss), epoch)\n",
    "        \n",
    "        \n",
    "        \n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = torch.tensor([]).to(device)\n",
    "        for batch in dataloader:\n",
    "            X = batch\n",
    "            X = X.to(device)\n",
    "            pred = model(X)\n",
    "            preds = torch.cat([preds, pred])\n",
    "        return preds\n",
    "        writer.add_scalar('test_loss', np.mean(eval_loss), epoch)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(rnn, dataloader, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = predict(rnn, dataloader['test'])\n",
    "plot_series(X_test, y_test, y_pred.cpu().numpy())  # cpu() 张量值从gpu搬运到计算机内存\n",
    "mean_squared_error(y_test, y_pred.cpu())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测多个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# temp_values = sta_temps\n",
    "# feature_size=3\n",
    "# batch_size=4\n",
    "# n_steps = 25\n",
    "# label_size=5\n",
    "\n",
    "def generate_time_series2(temp_values, batch_size, n_steps, feature_size=3, label_size=1):\n",
    "    series = np.zeros((batch_size, n_steps, feature_size))\n",
    "    sta_size = len(temp_values)\n",
    "    sta_idx = np.random.randint(0, sta_size, batch_size)\n",
    "    \n",
    "    for i,idx in enumerate(sta_idx):\n",
    "        temps = temp_values[idx]\n",
    "        temp_size = len(temps)\n",
    "        rnd_idx = np.random.randint(0, temp_size - n_steps)\n",
    "        series[i] = np.array(temps[rnd_idx:rnd_idx+n_steps]).reshape(n_steps,-1)\n",
    "    \n",
    "    return series[:,:n_steps-label_size].astype(np.float32), series[:,-label_size:,0].astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 25\n",
    "feature_size=1\n",
    "label_size=5\n",
    "max_temps = filted_maxtemp\n",
    "\n",
    "X_train,y_train = generate_time_series2(max_temps, 7000, n_steps,feature_size, label_size)\n",
    "X_valid,y_valid = generate_time_series2(max_temps, 2000, n_steps,feature_size, label_size)\n",
    "X_test,y_test = generate_time_series2(max_temps, 1000, n_steps,feature_size, label_size)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'train': TimeSeriesDataset(X_train, y_train),\n",
    "    'valid': TimeSeriesDataset(X_valid, y_valid),\n",
    "    'test': TimeSeriesDataset(X_test, y_test, train=False)\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    'train': DataLoader(dataset['train'], shuffle=True, batch_size=64),\n",
    "    'valid': DataLoader(dataset['valid'], shuffle=False, batch_size=64),\n",
    "    'test': DataLoader(dataset['test'], shuffle=False, batch_size=64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRNN(torch.nn.Module):\n",
    "  def __init__(self, n_out=5):\n",
    "    super().__init__()\n",
    "    self.rnn = torch.nn.LSTM(input_size=1, hidden_size=128, num_layers=1, batch_first=True)\n",
    "    self.fc = torch.nn.Linear(128, n_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, h = self.rnn(x) \n",
    "    x = self.fc(x[:,-1])\n",
    "    return x\n",
    "rnn2 = DeepRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(rnn2, dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(rnn2, dataloader['test'])\n",
    "plot_series(X_test, y_test, y_pred.cpu().numpy())\n",
    "mean_squared_error(y_test, y_pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRNN(torch.nn.Module):\n",
    "  def __init__(self,n_out=5):\n",
    "    super().__init__()\n",
    "    self.rnn = torch.nn.LSTM(input_size=1, hidden_size=64, num_layers=2, batch_first=True)\n",
    "    self.pool = torch.nn.AvgPool1d(20)\n",
    "    self.fc = torch.nn.Linear(64, n_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, h = self.rnn(x)\n",
    "    x = x.permute(0,2,1)\n",
    "    x = self.pool(x)\n",
    "    x = x.squeeze(-1)\n",
    "    y = self.fc(x)\n",
    "    return y\n",
    "\n",
    "rnn3 = DeepRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(64,20,1)\n",
    "r = rnn3(inp)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(rnn3, dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(rnn3, dataloader['test'])\n",
    "plot_series(X_test, y_test, y_pred.cpu().numpy())\n",
    "mean_squared_error(y_test, y_pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
