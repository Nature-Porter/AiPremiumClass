{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. 参考课堂案例，使用指定的数据集，编写代码实现ner模型训练和推理。\nhttps://huggingface.co/datasets/doushabao4766/msra_ner_k_V3\ndoushabao4766/msra_ner_k_V3\n2. 完成预测结果的实体抽取。\n    输入：“双方确定了今后发展中美关系的指导方针。”\n    输出：[{\"entity\":\"ORG\",\"content\":\"中\"},{\"entity\":\"ORG\",\"content\":\"美\"}]\n3. 整理Dataset、Trainer、TrainingArgument、DataCollator、Evaluate 知识点，总结文档","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification,AutoTokenizer,DataCollatorForTokenClassification\nfrom transformers import TrainingArguments,Trainer\nimport torch\nimport evaluate\nimport seqeval\nfrom datasets import load_dataset\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:01.220474Z","iopub.execute_input":"2025-06-01T11:53:01.221196Z","iopub.status.idle":"2025-06-01T11:53:01.225310Z","shell.execute_reply.started":"2025-06-01T11:53:01.221169Z","shell.execute_reply":"2025-06-01T11:53:01.224359Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"ds = load_dataset(\"doushabao4766/msra_ner_k_V3\")\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:01.244441Z","iopub.execute_input":"2025-06-01T11:53:01.244656Z","iopub.status.idle":"2025-06-01T11:53:01.827489Z","shell.execute_reply.started":"2025-06-01T11:53:01.244639Z","shell.execute_reply":"2025-06-01T11:53:01.826878Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\n        num_rows: 45001\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\n        num_rows: 3443\n    })\n})"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"for item in ds['train']:\n    break\n \nprint(item)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:01.828658Z","iopub.execute_input":"2025-06-01T11:53:01.828913Z","iopub.status.idle":"2025-06-01T11:53:01.834129Z","shell.execute_reply.started":"2025-06-01T11:53:01.828888Z","shell.execute_reply":"2025-06-01T11:53:01.833325Z"}},"outputs":[{"name":"stdout","text":"{'id': '0', 'tokens': ['当', '希', '望', '工', '程', '救', '助', '的', '百', '万', '儿', '童', '成', '长', '起', '来', '，', '科', '教', '兴', '国', '蔚', '然', '成', '风', '时', '，', '今', '天', '有', '收', '藏', '价', '值', '的', '书', '你', '没', '买', '，', '明', '日', '就', '叫', '你', '悔', '不', '当', '初', '！'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'knowledge': ''}\n","output_type":"stream"}],"execution_count":87},{"cell_type":"markdown","source":"****实体映射字典****","metadata":{}},{"cell_type":"code","source":"#验证tag标签数量\ntags_id = set()\nfor items in ds['train']:\n    tags_id.update(items['ner_tags'])\n\ntags_id\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:01.834945Z","iopub.execute_input":"2025-06-01T11:53:01.835133Z","iopub.status.idle":"2025-06-01T11:53:06.815191Z","shell.execute_reply.started":"2025-06-01T11:53:01.835117Z","shell.execute_reply":"2025-06-01T11:53:06.814395Z"}},"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"{0, 1, 2, 3, 4, 5, 6}"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"# #entity_index\n# entites = ['O'] + list({'PER','LOC','ORG',})\n# tags = ['O']\n# for entity in entites[1:]:\n#     tags.append('B-' + entity.upper())\n#     tags.append('I-' + entity.upper())\n\n# entity_index = {entity:i for i, entity in enumerate(entites)}\n\n# print(entity_index)\n# print(tags)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:06.816702Z","iopub.execute_input":"2025-06-01T11:53:06.816920Z","iopub.status.idle":"2025-06-01T11:53:06.820467Z","shell.execute_reply.started":"2025-06-01T11:53:06.816904Z","shell.execute_reply":"2025-06-01T11:53:06.819450Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"tags = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:06.821183Z","iopub.execute_input":"2025-06-01T11:53:06.821418Z","iopub.status.idle":"2025-06-01T11:53:06.834135Z","shell.execute_reply.started":"2025-06-01T11:53:06.821395Z","shell.execute_reply":"2025-06-01T11:53:06.833387Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n\ndef data_input_proc(item):\n    input_data = tokenizer(item['tokens'],\n                           #自动截断超过512部分\n                          truncation=True,\n                            #关闭[cls]&[sep]\n                          add_special_tokens=False,\n                          max_length=512,\n                           #告诉tokenizer已经分好词，无需再次分词\n                          is_split_into_words=True )\n    labels = [lbl[:512] for lbl in item['ner_tags']]\n    input_data['labels'] = labels\n    return input_data\n    \nds1 = ds.map(data_input_proc,batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:06.834906Z","iopub.execute_input":"2025-06-01T11:53:06.835268Z","iopub.status.idle":"2025-06-01T11:53:06.944690Z","shell.execute_reply.started":"2025-06-01T11:53:06.835242Z","shell.execute_reply":"2025-06-01T11:53:06.944095Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"ds1.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n\nfor item in ds1['train']:\n   \n    print(item)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:06.945388Z","iopub.execute_input":"2025-06-01T11:53:06.945642Z","iopub.status.idle":"2025-06-01T11:53:06.953816Z","shell.execute_reply.started":"2025-06-01T11:53:06.945618Z","shell.execute_reply":"2025-06-01T11:53:06.953169Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([2496, 2361, 3307, 2339, 4923, 3131, 1221, 4638, 4636,  674, 1036, 4997,\n        2768, 7270, 6629, 3341, 8024, 4906, 3136, 1069, 1744, 5917, 4197, 2768,\n        7599, 3198, 8024,  791, 1921, 3300, 3119, 5966,  817,  966, 4638,  741,\n         872, 3766,  743, 8024, 3209, 3189, 2218, 1373,  872, 2637,  679, 2496,\n        1159, 8013]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1]), 'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0])}\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"**构建模型对象**","metadata":{}},{"cell_type":"code","source":"# 创建标签映射字典\nid2label = {i: tags for i, tags in enumerate(tags)}\nlabel2id = {tags: i for i, tags in enumerate(tags)}\n\nmodel = AutoModelForTokenClassification.from_pretrained('bert-base-chinese', \n                                                       num_labels = len(tags),\n                                                       id2label=id2label,\n                                                       label2id=label2id)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:06.954528Z","iopub.execute_input":"2025-06-01T11:53:06.954879Z","iopub.status.idle":"2025-06-01T11:53:07.103636Z","shell.execute_reply.started":"2025-06-01T11:53:06.954854Z","shell.execute_reply":"2025-06-01T11:53:07.102928Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"},"metadata":{}}],"execution_count":93},{"cell_type":"markdown","source":"**模型训练TranningArguments**","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments(output_dir = 'msra_ner_train', # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n                        num_train_epochs=1,\n                        per_device_train_batch_size=32,\n                        per_device_eval_batch_size=32,\n                        report_to='tensorboard',\n                         #可选epoch\n                        eval_strategy='steps',\n                        eval_steps=400)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:30:46.462435Z","iopub.execute_input":"2025-06-01T13:30:46.462971Z","iopub.status.idle":"2025-06-01T13:30:46.489311Z","shell.execute_reply.started":"2025-06-01T13:30:46.462948Z","shell.execute_reply":"2025-06-01T13:30:46.488593Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"**模型训练 Trainer**","metadata":{}},{"cell_type":"code","source":"#metric方法\ndef compute_metric(result):\n    # result 是一个tuple (predicts, labels)\n\n    #获取评估对象\n    seqeval = evaluate.load(\"seqeval\")\n    predicts,labels = result\n    predicts = np.argmax(predicts,axis=2)\n\n    #准备评估数据\n    predicts = [[tags[p]for p,l in zip(ps,ls) if l != -100]\n                for ps,ls in zip(predicts,labels)]\n    labels = [[tags[l]for p,l in zip(ps,ls) if l != -100]\n                for ps,ls in zip(predicts,labels)]\n    #根据预测标签和真实标签，自动计算序列标注任务的评估指标（精确率、召回率、F1分数等）\n    results = seqeval.compute(predictions=predicts, references=labels)\n\n    return results\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:30:49.729650Z","iopub.execute_input":"2025-06-01T13:30:49.729922Z","iopub.status.idle":"2025-06-01T13:30:49.735278Z","shell.execute_reply.started":"2025-06-01T13:30:49.729902Z","shell.execute_reply":"2025-06-01T13:30:49.734601Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T11:53:07.139718Z","iopub.execute_input":"2025-06-01T11:53:07.139967Z","iopub.status.idle":"2025-06-01T11:53:07.155419Z","shell.execute_reply.started":"2025-06-01T11:53:07.139945Z","shell.execute_reply":"2025-06-01T11:53:07.154742Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=ds1['train'],\n    eval_dataset=ds1['test'],\n    data_collator=data_collator,\n    compute_metrics=compute_metric\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:30:52.496229Z","iopub.execute_input":"2025-06-01T13:30:52.496774Z","iopub.status.idle":"2025-06-01T13:30:52.509573Z","shell.execute_reply.started":"2025-06-01T13:30:52.496743Z","shell.execute_reply":"2025-06-01T13:30:52.508907Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T13:30:56.039089Z","iopub.execute_input":"2025-06-01T13:30:56.039402Z","iopub.status.idle":"2025-06-01T13:43:31.874087Z","shell.execute_reply.started":"2025-06-01T13:30:56.039373Z","shell.execute_reply":"2025-06-01T13:43:31.873512Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1407' max='1407' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1407/1407 12:34, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc</th>\n      <th>Org</th>\n      <th>Per</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>400</td>\n      <td>No log</td>\n      <td>0.045489</td>\n      <td>{'precision': 0.8651603498542274, 'recall': 0.8992424242424243, 'f1': 0.8818722139673105, 'number': 1320}</td>\n      <td>{'precision': 0.9432019879304224, 'recall': 0.9316269284712483, 'f1': 0.9373787264067738, 'number': 2852}</td>\n      <td>{'precision': 0.9446666666666667, 'recall': 0.9427811044577512, 'f1': 0.9437229437229436, 'number': 1503}</td>\n      <td>0.924767</td>\n      <td>0.927048</td>\n      <td>0.925906</td>\n      <td>0.991742</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.005700</td>\n      <td>0.041782</td>\n      <td>{'precision': 0.8575498575498576, 'recall': 0.9121212121212121, 'f1': 0.8839941262848753, 'number': 1320}</td>\n      <td>{'precision': 0.9576361694553222, 'recall': 0.9431977559607293, 'f1': 0.950362126832715, 'number': 2852}</td>\n      <td>{'precision': 0.9353099730458221, 'recall': 0.9234863606121091, 'f1': 0.929360562437228, 'number': 1503}</td>\n      <td>0.927155</td>\n      <td>0.930749</td>\n      <td>0.928948</td>\n      <td>0.992241</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.004000</td>\n      <td>0.040397</td>\n      <td>{'precision': 0.8785454545454545, 'recall': 0.9151515151515152, 'f1': 0.8964749536178107, 'number': 1320}</td>\n      <td>{'precision': 0.9540148567385921, 'recall': 0.9456521739130435, 'f1': 0.9498151082937137, 'number': 2852}</td>\n      <td>{'precision': 0.9392117568470274, 'recall': 0.9354624085163007, 'f1': 0.9373333333333332, 'number': 1503}</td>\n      <td>0.931918</td>\n      <td>0.935859</td>\n      <td>0.933884</td>\n      <td>0.992799</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'precision': 0.8651603498542274, 'recall': 0.8992424242424243, 'f1': 0.8818722139673105, 'number': 1320}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9432019879304224, 'recall': 0.9316269284712483, 'f1': 0.9373787264067738, 'number': 2852}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9446666666666667, 'recall': 0.9427811044577512, 'f1': 0.9437229437229436, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8575498575498576, 'recall': 0.9121212121212121, 'f1': 0.8839941262848753, 'number': 1320}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9576361694553222, 'recall': 0.9431977559607293, 'f1': 0.950362126832715, 'number': 2852}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9353099730458221, 'recall': 0.9234863606121091, 'f1': 0.929360562437228, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8785454545454545, 'recall': 0.9151515151515152, 'f1': 0.8964749536178107, 'number': 1320}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9540148567385921, 'recall': 0.9456521739130435, 'f1': 0.9498151082937137, 'number': 2852}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9392117568470274, 'recall': 0.9354624085163007, 'f1': 0.9373333333333332, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1407, training_loss=0.0044942315622857045, metrics={'train_runtime': 754.939, 'train_samples_per_second': 59.609, 'train_steps_per_second': 1.864, 'total_flos': 3241443989101428.0, 'train_loss': 0.0044942315622857045, 'epoch': 1.0})"},"metadata":{}}],"execution_count":115},{"cell_type":"code","source":"from transformers import pipeline\npipeline = pipeline('token-classification', '/kaggle/working/msra_ner_train/checkpoint-4221')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:45:04.076979Z","iopub.execute_input":"2025-06-01T12:45:04.077299Z","iopub.status.idle":"2025-06-01T12:45:04.359373Z","shell.execute_reply.started":"2025-06-01T12:45:04.077278Z","shell.execute_reply":"2025-06-01T12:45:04.358529Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"pipeline('双方确定了今后发展中美关系的指导方针')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T12:45:07.146997Z","iopub.execute_input":"2025-06-01T12:45:07.147270Z","iopub.status.idle":"2025-06-01T12:45:07.165587Z","shell.execute_reply.started":"2025-06-01T12:45:07.147250Z","shell.execute_reply":"2025-06-01T12:45:07.164909Z"}},"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'B-ORG',\n  'score': 0.9988446,\n  'index': 10,\n  'word': '中',\n  'start': 9,\n  'end': 10},\n {'entity': 'B-ORG',\n  'score': 0.9980627,\n  'index': 11,\n  'word': '美',\n  'start': 10,\n  'end': 11}]"},"metadata":{}}],"execution_count":107}]}