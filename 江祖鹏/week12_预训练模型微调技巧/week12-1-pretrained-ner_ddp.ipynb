{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install evaluate seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:11:17.128091Z","iopub.execute_input":"2025-06-12T13:11:17.128390Z","iopub.status.idle":"2025-06-12T13:11:24.682027Z","shell.execute_reply.started":"2025-06-12T13:11:17.128370Z","shell.execute_reply":"2025-06-12T13:11:24.680947Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%%writefile ner_ddp.py\n\nfrom transformers import AutoModelForTokenClassification,AutoTokenizer,DataCollatorForTokenClassification,TrainingArguments,Trainer\nfrom datasets import load_dataset\nimport torch\nimport evaluate\nimport seqeval\nimport numpy as np\nimport os \nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\n#设置分布式环境\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = \"localhost\"\n    os.environ['MASTER_PORT'] = \"12355\"\n    dist.init_process_group('nccl',rank=rank, world_size=world_size)\n\n#清理分布式环境\ndef cleanup():\n    dist.destroy_process_group()\n\ndef train(rank, world_size):\n    setup(rank, world_size)\n\n    #加载datasets\n    ds = load_dataset(\"doushabao4766/msra_ner_k_V3\")\n    \n    #创建tags\n    tags = ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ORG', 'I-ORG']\n    \n    #加载tokenizer\n    tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\n    \n    def data_input_proc(item):\n        input_data = tokenizer(item['tokens'],\n                               #自动截断超过512\n                              truncation=True,\n                               #关闭[cls]&[sep]\n                              add_special_tokens=False,\n                              max_length=512,\n                               #告诉tokenizer已经分好词，无需再次分词\n                              is_split_into_words=True)\n        labels = [lbl[:512]for lbl in item['ner_tags']]\n        input_data['labels'] = labels\n        return input_data\n    \n    #map不改变原始数据集\n    ds1 = ds.map(data_input_proc,batched=True)\n    \n    #转为pytorch类型\n    ds1.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n    \n    #创建标签映射字典\n    id2label = {i: tags for i,tags in enumerate(tags)}\n    label2id = {tags: i for i,tags in enumerate(tags)}\n    \n    model = AutoModelForTokenClassification.from_pretrained('bert-base-chinese',\n                                                           num_labels=len(tags),\n                                                           id2label=id2label,\n                                                           label2id=label2id)\n    model.to(rank)\n    #TrainingArguments\n    args = TrainingArguments(output_dir='msra_ner_train',\n                            num_train_epochs=1,\n                            per_device_train_batch_size=8,\n                            per_device_eval_batch_size=8,\n                            report_to='tensorboard',\n                             #可选epoch step#eval_steps=400\n                            eval_strategy='epoch',\n                             #当前进程rank\n                            local_rank=rank,\n                             #使用混合精度\n                            fp16=True,\n                             #动态学习率\n                            lr_scheduler_type='linear',\n                             #预热步数\n                            warmup_steps=100,\n                             #优化ddp性能\n                            ddp_find_unused_parameters=False)\n    \n    #metric方法\n    def compute_metric(result):\n        # result 是一个tuple (predicts, labels)\n    \n        #获取评估对象\n        seqeval = evaluate.load(\"seqeval\")\n        predicts,labels = result\n        #axis=2选择每个位置概率最高的标签\n        predicts = np.argmax(predicts,axis=2)\n    \n        #准备评估数据\n        predicts = [[tags[p]for p,l in zip(ps,ls) if l != -100]\n                    for ps,ls in zip(predicts,labels)]\n        labels = [[tags[l]for p,l in zip(ps,ls) if l != -100]\n                    for ps,ls in zip(predicts,labels)]\n        #根据预测标签和真实标签，自动计算序列标注任务的评估指标（精确率、召回率、F1分数等）\n        results = seqeval.compute(predictions=predicts, references=labels)\n    \n        return results\n    \n    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n    \n    #Trainer\n    trainer = Trainer(model,\n                     args,\n                     train_dataset=ds1['train'],\n                     eval_dataset=ds1['test'],\n                     data_collator=data_collator,\n                      compute_metrics=compute_metric)\n    \n    trainer.train()\n\ndef main():\n    world_size = torch.cuda.device_count()\n    mp.spawn(train, args=(world_size,),nprocs=world_size,join=True)\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:14:26.837447Z","iopub.execute_input":"2025-06-12T13:14:26.837799Z","iopub.status.idle":"2025-06-12T13:14:26.845802Z","shell.execute_reply.started":"2025-06-12T13:14:26.837769Z","shell.execute_reply":"2025-06-12T13:14:26.844972Z"}},"outputs":[{"name":"stdout","text":"Overwriting ner_ddp.py\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!python ner_ddp.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:14:32.122921Z","iopub.execute_input":"2025-06-12T13:14:32.123634Z","iopub.status.idle":"2025-06-12T13:43:28.367663Z","shell.execute_reply.started":"2025-06-12T13:14:32.123609Z","shell.execute_reply":"2025-06-12T13:43:28.366807Z"}},"outputs":[{"name":"stdout","text":"2025-06-12 13:14:37.508472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749734077.532322     584 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749734077.539396     584 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-12 13:14:48.005683: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-06-12 13:14:48.018796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749734088.031582     599 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749734088.038865     599 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749734088.044571     598 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749734088.052208     598 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nMap: 100%|█████████████████████████| 3443/3443 [00:00<00:00, 3893.26 examples/s]\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nMap:  29%|███████▎                 | 1000/3443 [00:00<00:00, 2955.65 examples/s]torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\nMap: 100%|█████████████████████████| 3443/3443 [00:01<00:00, 3173.49 examples/s]\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n  0%|                                                  | 0/2813 [00:00<?, ?it/s]torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n  0%|                                                  | 0/2813 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n  0%|                                          | 5/2813 [00:02<18:20,  2.55it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.1509, 'grad_norm': 88782.6875, 'learning_rate': 4.2646516771102105e-05, 'epoch': 0.18}\n{'loss': 0.1522, 'grad_norm': 150984.0, 'learning_rate': 4.2646516771102105e-05, 'epoch': 0.18}\n 18%|███████                                 | 500/2813 [04:59<14:10,  2.72it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 18%|███████▏                                | 505/2813 [05:03<19:22,  1.99it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0477, 'grad_norm': 296637.59375, 'learning_rate': 3.343162550681902e-05, 'epoch': 0.36}\n{'loss': 0.0473, 'grad_norm': 593497.75, 'learning_rate': 3.343162550681902e-05, 'epoch': 0.36}\n 36%|█████████████▊                         | 1000/2813 [09:56<12:06,  2.50it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 36%|██████████████                         | 1011/2813 [10:00<08:34,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0353, 'grad_norm': 198811.296875, 'learning_rate': 2.421673424253594e-05, 'epoch': 0.53}\n 53%|████████████████████▊                  | 1499/2813 [14:47<06:50,  3.20it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0348, 'grad_norm': 108554.984375, 'learning_rate': 2.421673424253594e-05, 'epoch': 0.53}\n 54%|█████████████████████                  | 1516/2813 [14:53<06:37,  3.27it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0282, 'grad_norm': 112848.84375, 'learning_rate': 1.5001842978252858e-05, 'epoch': 0.71}\n 71%|███████████████████████████▌           | 1992/2813 [19:40<03:51,  3.54it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0278, 'grad_norm': 48416.1328125, 'learning_rate': 1.5001842978252858e-05, 'epoch': 0.71}\n 72%|████████████████████████████           | 2023/2813 [19:49<03:25,  3.85it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0277, 'grad_norm': 29515.06640625, 'learning_rate': 5.786951713969775e-06, 'epoch': 0.89}\n 88%|██████████████████████████████████▌    | 2489/2813 [24:35<01:29,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0271, 'grad_norm': 28099.244140625, 'learning_rate': 5.786951713969775e-06, 'epoch': 0.89}\n 90%|███████████████████████████████████    | 2526/2813 [24:46<01:16,  3.76it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 99%|██████████████████████████████████████▊| 2797/2813 [27:36<00:04,  3.33it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n\n  0%|                                                   | 0/216 [00:00<?, ?it/s]\u001b[A\n 99%|██████████████████████████████████████▊| 2798/2813 [27:36<00:05,  2.63it/s]\u001b[A\n  1%|▌                                          | 3/216 [00:00<00:32,  6.59it/s]\u001b[A\n  2%|▊                                          | 4/216 [00:00<00:35,  5.90it/s]\u001b[A\n100%|██████████████████████████████████████▊| 2799/2813 [27:37<00:06,  2.19it/s]\u001b[A\n  3%|█▏                                         | 6/216 [00:01<00:38,  5.39it/s]\u001b[A\n100%|██████████████████████████████████████▊| 2800/2813 [27:37<00:05,  2.17it/s]\u001b[A\n  4%|█▌                                         | 8/216 [00:01<00:44,  4.63it/s]\u001b[A\n100%|██████████████████████████████████████▊| 2801/2813 [27:38<00:05,  2.15it/s]\u001b[A\n  5%|█▉                                        | 10/216 [00:02<00:46,  4.47it/s]\u001b[A\n  5%|██▏                                       | 11/216 [00:02<00:45,  4.53it/s]\u001b[A\n100%|██████████████████████████████████████▊| 2802/2813 [27:38<00:05,  2.06it/s]\u001b[A\n  6%|██▌                                       | 13/216 [00:02<00:41,  4.94it/s]\u001b[A\n100%|██████████████████████████████████████▊| 2803/2813 [27:39<00:05,  1.94it/s]\u001b[A\n  7%|██▉                                       | 15/216 [00:03<00:46,  4.28it/s]\u001b[A\n  7%|███                                       | 16/216 [00:03<00:47,  4.18it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2804/2813 [27:40<00:05,  1.78it/s]\u001b[A\n  8%|███▌                                      | 18/216 [00:03<00:44,  4.46it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2805/2813 [27:40<00:04,  1.87it/s]\u001b[A\n  9%|███▉                                      | 20/216 [00:04<00:42,  4.66it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2806/2813 [27:41<00:03,  1.94it/s]\u001b[A\n 10%|████▎                                     | 22/216 [00:04<00:41,  4.65it/s]\u001b[A\n 11%|████▍                                     | 23/216 [00:04<00:41,  4.61it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2807/2813 [27:41<00:03,  1.86it/s]\u001b[A\n 12%|████▊                                     | 25/216 [00:05<00:42,  4.54it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2808/2813 [27:42<00:02,  1.82it/s]\u001b[A\n 12%|█████▎                                    | 27/216 [00:05<00:42,  4.48it/s]\u001b[A\n 13%|█████▍                                    | 28/216 [00:05<00:41,  4.58it/s]\u001b[A\n 13%|█████▋                                    | 29/216 [00:06<00:39,  4.70it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2809/2813 [27:43<00:02,  1.63it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2810/2813 [27:43<00:01,  1.68it/s]\u001b[A\n 15%|██████▏                                   | 32/216 [00:07<01:00,  3.05it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2811/2813 [27:44<00:01,  1.69it/s]\u001b[A\n 16%|██████▌                                   | 34/216 [00:07<00:56,  3.21it/s]\u001b[A\n100%|██████████████████████████████████████▉| 2812/2813 [27:44<00:00,  1.80it/s]\u001b[A\n 17%|███████                                   | 36/216 [00:08<00:45,  3.96it/s]\u001b[A\n100%|███████████████████████████████████████| 2813/2813 [27:45<00:00,  2.00it/s]\u001b[A\n 18%|███████▍                                  | 38/216 [00:08<00:38,  4.58it/s]\u001b[A\n 18%|███████▌                                  | 39/216 [00:08<00:33,  5.29it/s]\u001b[A\n 19%|███████▊                                  | 40/216 [00:08<00:32,  5.50it/s]\u001b[A\n 19%|████████▏                                 | 42/216 [00:09<00:24,  7.24it/s]\u001b[A\n 20%|████████▌                                 | 44/216 [00:09<00:30,  5.65it/s]\u001b[A\n 21%|████████▉                                 | 46/216 [00:09<00:24,  6.81it/s]\u001b[A\n 22%|█████████▎                                | 48/216 [00:09<00:22,  7.50it/s]\u001b[A\n 23%|█████████▌                                | 49/216 [00:10<00:23,  7.22it/s]\u001b[A\n 23%|█████████▋                                | 50/216 [00:10<00:22,  7.35it/s]\u001b[A\n 24%|██████████                                | 52/216 [00:10<00:18,  8.80it/s]\u001b[A\n 25%|██████████▌                               | 54/216 [00:10<00:17,  9.10it/s]\u001b[A\n 25%|██████████▋                               | 55/216 [00:10<00:17,  9.18it/s]\u001b[A\n 26%|███████████                               | 57/216 [00:10<00:18,  8.63it/s]\u001b[A\n 27%|███████████▎                              | 58/216 [00:11<00:18,  8.77it/s]\u001b[A\n 28%|███████████▋                              | 60/216 [00:11<00:16,  9.47it/s]\u001b[A\n 28%|███████████▊                              | 61/216 [00:11<00:17,  8.71it/s]\u001b[A\n 29%|████████████                              | 62/216 [00:11<00:21,  7.13it/s]\u001b[A\n 29%|████████████▎                             | 63/216 [00:11<00:23,  6.59it/s]\u001b[A\n 30%|████████████▋                             | 65/216 [00:12<00:19,  7.89it/s]\u001b[A\n 31%|█████████████                             | 67/216 [00:12<00:16,  8.95it/s]\u001b[A\n 32%|█████████████▍                            | 69/216 [00:12<00:15,  9.48it/s]\u001b[A\n 32%|█████████████▌                            | 70/216 [00:12<00:15,  9.21it/s]\u001b[A\n 33%|██████████████                            | 72/216 [00:12<00:14, 10.08it/s]\u001b[A\n 34%|██████████████▍                           | 74/216 [00:12<00:13, 10.73it/s]\u001b[A\n 35%|██████████████▊                           | 76/216 [00:13<00:13, 10.32it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n\n  0%|                                                   | 0/216 [00:00<?, ?it/s]\u001b[A\n 36%|███████████████▏                          | 78/216 [00:13<00:16,  8.29it/s]\u001b[A\n  1%|▍                                          | 2/216 [00:00<00:22,  9.33it/s]\u001b[A\n 37%|███████████████▎                          | 79/216 [00:13<00:19,  7.16it/s]\u001b[A\n  1%|▌                                          | 3/216 [00:00<00:28,  7.40it/s]\u001b[A\n 37%|███████████████▌                          | 80/216 [00:13<00:21,  6.31it/s]\u001b[A\n  2%|▊                                          | 4/216 [00:00<00:31,  6.83it/s]\u001b[A\n 38%|███████████████▊                          | 81/216 [00:13<00:21,  6.33it/s]\u001b[A\n  2%|▉                                          | 5/216 [00:00<00:34,  6.10it/s]\u001b[A\n 38%|███████████████▉                          | 82/216 [00:14<00:21,  6.22it/s]\u001b[A\n  3%|█▏                                         | 6/216 [00:00<00:34,  6.12it/s]\u001b[A\n 38%|████████████████▏                         | 83/216 [00:14<00:23,  5.71it/s]\u001b[A\n  3%|█▍                                         | 7/216 [00:01<00:37,  5.58it/s]\u001b[A\n 39%|████████████████▎                         | 84/216 [00:14<00:25,  5.17it/s]\u001b[A\n  4%|█▌                                         | 8/216 [00:01<00:45,  4.62it/s]\u001b[A\n 39%|████████████████▌                         | 85/216 [00:14<00:27,  4.77it/s]\u001b[A\n  4%|█▊                                         | 9/216 [00:01<00:44,  4.60it/s]\u001b[A\n 40%|████████████████▋                         | 86/216 [00:15<00:27,  4.66it/s]\u001b[A\n  5%|█▉                                        | 10/216 [00:01<00:43,  4.75it/s]\u001b[A\n 40%|████████████████▉                         | 87/216 [00:15<00:25,  5.04it/s]\u001b[A\n  5%|██▏                                       | 11/216 [00:02<00:40,  5.06it/s]\u001b[A\n 41%|█████████████████                         | 88/216 [00:15<00:25,  4.99it/s]\u001b[A\n  6%|██▎                                       | 12/216 [00:02<00:38,  5.26it/s]\u001b[A\n 41%|█████████████████▎                        | 89/216 [00:15<00:23,  5.49it/s]\u001b[A\n  6%|██▌                                       | 13/216 [00:02<00:40,  5.05it/s]\u001b[A\n 42%|█████████████████▌                        | 90/216 [00:15<00:25,  5.00it/s]\u001b[A\n  6%|██▋                                       | 14/216 [00:02<00:42,  4.72it/s]\u001b[A\n 42%|█████████████████▋                        | 91/216 [00:16<00:26,  4.78it/s]\u001b[A\n  7%|██▉                                       | 15/216 [00:02<00:43,  4.62it/s]\u001b[A\n 43%|█████████████████▉                        | 92/216 [00:16<00:28,  4.28it/s]\u001b[A\n  7%|███                                       | 16/216 [00:03<00:44,  4.52it/s]\u001b[A\n 43%|██████████████████                        | 93/216 [00:16<00:27,  4.47it/s]\u001b[A\n  8%|███▎                                      | 17/216 [00:03<00:43,  4.61it/s]\u001b[A\n 44%|██████████████████▎                       | 94/216 [00:16<00:27,  4.41it/s]\u001b[A\n  8%|███▌                                      | 18/216 [00:03<00:42,  4.70it/s]\u001b[A\n 44%|██████████████████▍                       | 95/216 [00:17<00:27,  4.42it/s]\u001b[A\n  9%|███▋                                      | 19/216 [00:03<00:40,  4.86it/s]\u001b[A\n 44%|██████████████████▋                       | 96/216 [00:17<00:25,  4.79it/s]\u001b[A\n  9%|███▉                                      | 20/216 [00:03<00:40,  4.86it/s]\u001b[A\n 45%|██████████████████▊                       | 97/216 [00:17<00:24,  4.91it/s]\u001b[A\n 10%|████                                      | 21/216 [00:04<00:37,  5.17it/s]\u001b[A\n 45%|███████████████████                       | 98/216 [00:17<00:26,  4.43it/s]\u001b[A\n 10%|████▎                                     | 22/216 [00:04<00:40,  4.75it/s]\u001b[A\n 46%|███████████████████▎                      | 99/216 [00:17<00:26,  4.47it/s]\u001b[A\n 11%|████▍                                     | 23/216 [00:04<00:44,  4.36it/s]\u001b[A\n 46%|██████████████████▉                      | 100/216 [00:18<00:23,  5.00it/s]\u001b[A\n 11%|████▋                                     | 24/216 [00:04<00:42,  4.50it/s]\u001b[A\n 47%|███████████████████▏                     | 101/216 [00:18<00:24,  4.77it/s]\u001b[A\n 12%|████▊                                     | 25/216 [00:05<00:41,  4.62it/s]\u001b[A\n 47%|███████████████████▎                     | 102/216 [00:18<00:23,  4.87it/s]\u001b[A\n 12%|█████                                     | 26/216 [00:05<00:37,  5.03it/s]\u001b[A\n 12%|█████▎                                    | 27/216 [00:05<00:39,  4.79it/s]\u001b[A\n 48%|███████████████████▌                     | 103/216 [00:18<00:32,  3.46it/s]\u001b[A\n 13%|█████▍                                    | 28/216 [00:05<00:42,  4.39it/s]\u001b[A\n 48%|███████████████████▋                     | 104/216 [00:19<00:29,  3.79it/s]\u001b[A\n 13%|█████▋                                    | 29/216 [00:05<00:40,  4.67it/s]\u001b[A\n 49%|███████████████████▉                     | 105/216 [00:19<00:29,  3.73it/s]\u001b[A\n 14%|█████▊                                    | 30/216 [00:06<00:41,  4.47it/s]\u001b[A\n 49%|████████████████████                     | 106/216 [00:19<00:27,  4.02it/s]\u001b[A\n 14%|██████                                    | 31/216 [00:06<00:46,  4.01it/s]\u001b[A\n 50%|████████████████████▎                    | 107/216 [00:19<00:25,  4.30it/s]\u001b[A\n 50%|████████████████████▌                    | 108/216 [00:20<00:26,  4.14it/s]\u001b[A\n 15%|██████▏                                   | 32/216 [00:06<00:59,  3.11it/s]\u001b[A\n 50%|████████████████████▋                    | 109/216 [00:20<00:26,  4.08it/s]\u001b[A\n 15%|██████▍                                   | 33/216 [00:07<00:53,  3.43it/s]\u001b[A\n 51%|████████████████████▉                    | 110/216 [00:20<00:25,  4.21it/s]\u001b[A\n 51%|█████████████████████                    | 111/216 [00:20<00:23,  4.52it/s]\u001b[A\n 16%|██████▌                                   | 34/216 [00:07<00:52,  3.49it/s]\u001b[A\n 52%|█████████████████████▎                   | 112/216 [00:20<00:21,  4.86it/s]\u001b[A\n 16%|██████▊                                   | 35/216 [00:07<00:45,  3.95it/s]\u001b[A\n 52%|█████████████████████▍                   | 113/216 [00:21<00:20,  4.98it/s]\u001b[A\n 17%|███████                                   | 36/216 [00:07<00:41,  4.31it/s]\u001b[A\n 53%|█████████████████████▋                   | 114/216 [00:21<00:19,  5.35it/s]\u001b[A\n 17%|███████▏                                  | 37/216 [00:07<00:40,  4.38it/s]\u001b[A\n 53%|█████████████████████▊                   | 115/216 [00:21<00:19,  5.27it/s]\u001b[A\n 18%|███████▍                                  | 38/216 [00:08<00:41,  4.26it/s]\u001b[A\n 54%|██████████████████████                   | 116/216 [00:21<00:18,  5.46it/s]\u001b[A\n 18%|███████▌                                  | 39/216 [00:08<00:40,  4.38it/s]\u001b[A\n 54%|██████████████████████▏                  | 117/216 [00:21<00:20,  4.79it/s]\u001b[A\n 19%|███████▊                                  | 40/216 [00:08<00:42,  4.17it/s]\u001b[A\n 55%|██████████████████████▍                  | 118/216 [00:22<00:21,  4.62it/s]\u001b[A\n 19%|███████▉                                  | 41/216 [00:08<00:36,  4.73it/s]\u001b[A\n 55%|██████████████████████▌                  | 119/216 [00:22<00:19,  4.89it/s]\u001b[A\n 19%|████████▏                                 | 42/216 [00:08<00:33,  5.15it/s]\u001b[A\n 20%|████████▎                                 | 43/216 [00:09<00:33,  5.16it/s]\u001b[A\n 56%|██████████████████████▊                  | 120/216 [00:22<00:23,  4.01it/s]\u001b[A\n 56%|███████████████████████▏                 | 122/216 [00:22<00:16,  5.87it/s]\u001b[A\n 20%|████████▌                                 | 44/216 [00:09<00:51,  3.36it/s]\u001b[A\n 57%|███████████████████████▌                 | 124/216 [00:23<00:14,  6.30it/s]\u001b[A\n 58%|███████████████████████▋                 | 125/216 [00:23<00:14,  6.41it/s]\u001b[A\n 21%|████████▊                                 | 45/216 [00:09<00:43,  3.91it/s]\u001b[A\n 58%|███████████████████████▉                 | 126/216 [00:23<00:14,  6.18it/s]\u001b[A\n 21%|████████▉                                 | 46/216 [00:10<00:41,  4.06it/s]\u001b[A\n 59%|████████████████████████                 | 127/216 [00:23<00:14,  6.25it/s]\u001b[A\n 22%|█████████▏                                | 47/216 [00:10<00:38,  4.35it/s]\u001b[A\n 22%|█████████▎                                | 48/216 [00:10<00:40,  4.13it/s]\u001b[A\n 59%|████████████████████████▎                | 128/216 [00:24<00:22,  3.94it/s]\u001b[A\n 23%|█████████▌                                | 49/216 [00:10<00:43,  3.85it/s]\u001b[A\n 60%|████████████████████████▍                | 129/216 [00:24<00:19,  4.39it/s]\u001b[A\n 23%|█████████▋                                | 50/216 [00:11<00:42,  3.86it/s]\u001b[A\n 60%|████████████████████████▋                | 130/216 [00:24<00:20,  4.27it/s]\u001b[A\n 24%|█████████▉                                | 51/216 [00:11<00:39,  4.19it/s]\u001b[A\n 61%|████████████████████████▊                | 131/216 [00:24<00:20,  4.23it/s]\u001b[A\n 24%|██████████                                | 52/216 [00:11<00:33,  4.88it/s]\u001b[A\n 61%|█████████████████████████                | 132/216 [00:24<00:17,  4.70it/s]\u001b[A\n 25%|██████████▎                               | 53/216 [00:11<00:33,  4.92it/s]\u001b[A\n 62%|█████████████████████████▏               | 133/216 [00:25<00:16,  5.06it/s]\u001b[A\n 25%|██████████▌                               | 54/216 [00:11<00:32,  4.96it/s]\u001b[A\n 62%|█████████████████████████▍               | 134/216 [00:25<00:15,  5.39it/s]\u001b[A\n 62%|█████████████████████████▋               | 135/216 [00:25<00:14,  5.71it/s]\u001b[A\n 25%|██████████▋                               | 55/216 [00:12<00:32,  4.88it/s]\u001b[A\n 63%|█████████████████████████▊               | 136/216 [00:25<00:13,  6.01it/s]\u001b[A\n 26%|██████████▉                               | 56/216 [00:12<00:29,  5.40it/s]\u001b[A\n 63%|██████████████████████████               | 137/216 [00:25<00:12,  6.18it/s]\u001b[A\n 64%|██████████████████████████▏              | 138/216 [00:25<00:13,  5.63it/s]\u001b[A\n 26%|███████████                               | 57/216 [00:12<00:35,  4.44it/s]\u001b[A\n 64%|██████████████████████████▍              | 139/216 [00:26<00:13,  5.58it/s]\u001b[A\n 27%|███████████▎                              | 58/216 [00:12<00:37,  4.26it/s]\u001b[A\n 65%|██████████████████████████▌              | 140/216 [00:26<00:12,  6.08it/s]\u001b[A\n 27%|███████████▍                              | 59/216 [00:12<00:33,  4.67it/s]\u001b[A\n 65%|██████████████████████████▊              | 141/216 [00:26<00:11,  6.32it/s]\u001b[A\n 28%|███████████▋                              | 60/216 [00:13<00:31,  5.01it/s]\u001b[A\n 66%|██████████████████████████▉              | 142/216 [00:26<00:13,  5.47it/s]\u001b[A\n 28%|███████████▊                              | 61/216 [00:13<00:34,  4.50it/s]\u001b[A\n 66%|███████████████████████████▏             | 143/216 [00:26<00:14,  5.19it/s]\u001b[A\n 67%|███████████████████████████▎             | 144/216 [00:27<00:16,  4.37it/s]\u001b[A\n 29%|████████████                              | 62/216 [00:13<00:42,  3.60it/s]\u001b[A\n 67%|███████████████████████████▌             | 145/216 [00:27<00:15,  4.73it/s]\u001b[A\n 29%|████████████▎                             | 63/216 [00:14<00:44,  3.40it/s]\u001b[A\n 68%|███████████████████████████▋             | 146/216 [00:27<00:15,  4.63it/s]\u001b[A\n 30%|████████████▍                             | 64/216 [00:14<00:41,  3.67it/s]\u001b[A\n 68%|███████████████████████████▉             | 147/216 [00:27<00:14,  4.68it/s]\u001b[A\n 30%|████████████▋                             | 65/216 [00:14<00:38,  3.93it/s]\u001b[A\n 69%|████████████████████████████             | 148/216 [00:27<00:15,  4.50it/s]\u001b[A\n 31%|████████████▊                             | 66/216 [00:14<00:33,  4.43it/s]\u001b[A\n 69%|████████████████████████████▎            | 149/216 [00:28<00:14,  4.64it/s]\u001b[A\n 31%|█████████████                             | 67/216 [00:14<00:30,  4.89it/s]\u001b[A\n 69%|████████████████████████████▍            | 150/216 [00:28<00:14,  4.60it/s]\u001b[A\n 31%|█████████████▏                            | 68/216 [00:15<00:28,  5.16it/s]\u001b[A\n 70%|████████████████████████████▋            | 151/216 [00:28<00:12,  5.19it/s]\u001b[A\n 32%|█████████████▍                            | 69/216 [00:15<00:29,  4.97it/s]\u001b[A\n 70%|████████████████████████████▊            | 152/216 [00:28<00:11,  5.56it/s]\u001b[A\n 32%|█████████████▌                            | 70/216 [00:15<00:30,  4.80it/s]\u001b[A\n 71%|█████████████████████████████            | 153/216 [00:28<00:12,  5.12it/s]\u001b[A\n 33%|█████████████▊                            | 71/216 [00:15<00:28,  5.18it/s]\u001b[A\n 71%|█████████████████████████████▏           | 154/216 [00:29<00:11,  5.37it/s]\u001b[A\n 33%|██████████████                            | 72/216 [00:15<00:26,  5.42it/s]\u001b[A\n 72%|█████████████████████████████▍           | 155/216 [00:29<00:11,  5.42it/s]\u001b[A\n 34%|██████████████▏                           | 73/216 [00:15<00:25,  5.69it/s]\u001b[A\n 72%|█████████████████████████████▌           | 156/216 [00:29<00:10,  5.78it/s]\u001b[A\n 34%|██████████████▍                           | 74/216 [00:16<00:22,  6.21it/s]\u001b[A\n 73%|█████████████████████████████▊           | 157/216 [00:29<00:10,  5.81it/s]\u001b[A\n 35%|██████████████▌                           | 75/216 [00:16<00:22,  6.14it/s]\u001b[A\n 73%|█████████████████████████████▉           | 158/216 [00:29<00:10,  5.77it/s]\u001b[A\n 35%|██████████████▊                           | 76/216 [00:16<00:22,  6.20it/s]\u001b[A\n 36%|██████████████▉                           | 77/216 [00:16<00:23,  5.95it/s]\u001b[A\n 74%|██████████████████████████████▏          | 159/216 [00:29<00:10,  5.21it/s]\u001b[A\n 36%|███████████████▏                          | 78/216 [00:16<00:22,  6.19it/s]\u001b[A\n 37%|███████████████▎                          | 79/216 [00:16<00:23,  5.80it/s]\u001b[A\n 74%|██████████████████████████████▎          | 160/216 [00:30<00:14,  3.77it/s]\u001b[A\n 37%|███████████████▌                          | 80/216 [00:17<00:24,  5.66it/s]\u001b[A\n 75%|██████████████████████████████▌          | 161/216 [00:30<00:14,  3.89it/s]\u001b[A\n 38%|███████████████▊                          | 81/216 [00:17<00:23,  5.84it/s]\u001b[A\n 38%|███████████████▉                          | 82/216 [00:17<00:23,  5.66it/s]\u001b[A\n 75%|██████████████████████████████▊          | 162/216 [00:30<00:13,  3.90it/s]\u001b[A\n 38%|████████████████▏                         | 83/216 [00:17<00:24,  5.53it/s]\u001b[A\n 75%|██████████████████████████████▉          | 163/216 [00:31<00:13,  4.07it/s]\u001b[A\n 39%|████████████████▎                         | 84/216 [00:17<00:25,  5.12it/s]\u001b[A\n 76%|███████████████████████████████▏         | 164/216 [00:31<00:11,  4.37it/s]\u001b[A\n 39%|████████████████▌                         | 85/216 [00:18<00:26,  4.92it/s]\u001b[A\n 76%|███████████████████████████████▎         | 165/216 [00:31<00:14,  3.59it/s]\u001b[A\n 40%|████████████████▋                         | 86/216 [00:18<00:28,  4.57it/s]\u001b[A\n 77%|███████████████████████████████▌         | 166/216 [00:31<00:11,  4.27it/s]\u001b[A\n 40%|████████████████▉                         | 87/216 [00:18<00:26,  4.79it/s]\u001b[A\n 77%|███████████████████████████████▋         | 167/216 [00:31<00:10,  4.72it/s]\u001b[A\n 41%|█████████████████                         | 88/216 [00:18<00:24,  5.19it/s]\u001b[A\n 78%|███████████████████████████████▉         | 168/216 [00:32<00:09,  5.09it/s]\u001b[A\n 41%|█████████████████▎                        | 89/216 [00:18<00:22,  5.54it/s]\u001b[A\n 78%|████████████████████████████████         | 169/216 [00:32<00:09,  5.05it/s]\u001b[A\n 42%|█████████████████▌                        | 90/216 [00:19<00:22,  5.59it/s]\u001b[A\n 79%|████████████████████████████████▎        | 170/216 [00:32<00:08,  5.22it/s]\u001b[A\n 42%|█████████████████▋                        | 91/216 [00:19<00:24,  5.12it/s]\u001b[A\n 79%|████████████████████████████████▍        | 171/216 [00:32<00:08,  5.15it/s]\u001b[A\n 43%|█████████████████▉                        | 92/216 [00:19<00:27,  4.51it/s]\u001b[A\n 80%|████████████████████████████████▋        | 172/216 [00:32<00:08,  5.12it/s]\u001b[A\n 80%|████████████████████████████████▊        | 173/216 [00:33<00:07,  5.53it/s]\u001b[A\n 43%|██████████████████                        | 93/216 [00:19<00:27,  4.55it/s]\u001b[A\n 81%|█████████████████████████████████        | 174/216 [00:33<00:06,  6.10it/s]\u001b[A\n 44%|██████████████████▎                       | 94/216 [00:19<00:26,  4.52it/s]\u001b[A\n 81%|█████████████████████████████████▏       | 175/216 [00:33<00:07,  5.67it/s]\u001b[A\n 44%|██████████████████▍                       | 95/216 [00:20<00:26,  4.52it/s]\u001b[A\n 81%|█████████████████████████████████▍       | 176/216 [00:33<00:07,  5.26it/s]\u001b[A\n 44%|██████████████████▋                       | 96/216 [00:20<00:24,  4.85it/s]\u001b[A\n 82%|█████████████████████████████████▌       | 177/216 [00:33<00:07,  5.00it/s]\u001b[A\n 45%|██████████████████▊                       | 97/216 [00:20<00:24,  4.92it/s]\u001b[A\n 82%|█████████████████████████████████▊       | 178/216 [00:34<00:07,  4.92it/s]\u001b[A\n 45%|███████████████████                       | 98/216 [00:20<00:26,  4.41it/s]\u001b[A\n 83%|█████████████████████████████████▉       | 179/216 [00:34<00:08,  4.26it/s]\u001b[A\n 46%|███████████████████▎                      | 99/216 [00:21<00:27,  4.26it/s]\u001b[A\n 83%|██████████████████████████████████▏      | 180/216 [00:34<00:07,  4.69it/s]\u001b[A\n 46%|██████████████████▉                      | 100/216 [00:21<00:24,  4.80it/s]\u001b[A\n 84%|██████████████████████████████████▎      | 181/216 [00:34<00:06,  5.09it/s]\u001b[A\n 47%|███████████████████▏                     | 101/216 [00:21<00:23,  4.86it/s]\u001b[A\n 84%|██████████████████████████████████▌      | 182/216 [00:34<00:06,  4.98it/s]\u001b[A\n 47%|███████████████████▎                     | 102/216 [00:21<00:23,  4.94it/s]\u001b[A\n 85%|██████████████████████████████████▋      | 183/216 [00:35<00:07,  4.48it/s]\u001b[A\n 85%|██████████████████████████████████▉      | 184/216 [00:35<00:07,  4.41it/s]\u001b[A\n 48%|███████████████████▌                     | 103/216 [00:22<00:34,  3.24it/s]\u001b[A\n 86%|███████████████████████████████████      | 185/216 [00:35<00:06,  4.50it/s]\u001b[A\n 48%|███████████████████▋                     | 104/216 [00:22<00:30,  3.67it/s]\u001b[A\n 86%|███████████████████████████████████▎     | 186/216 [00:35<00:06,  4.69it/s]\u001b[A\n 87%|███████████████████████████████████▍     | 187/216 [00:35<00:05,  4.97it/s]\u001b[A\n 49%|███████████████████▉                     | 105/216 [00:22<00:29,  3.70it/s]\u001b[A\n 87%|███████████████████████████████████▋     | 188/216 [00:36<00:05,  5.33it/s]\u001b[A\n 49%|████████████████████                     | 106/216 [00:22<00:28,  3.84it/s]\u001b[A\n 88%|███████████████████████████████████▉     | 189/216 [00:36<00:04,  5.84it/s]\u001b[A\n 50%|████████████████████▎                    | 107/216 [00:23<00:26,  4.16it/s]\u001b[A\n 88%|████████████████████████████████████     | 190/216 [00:36<00:04,  5.62it/s]\u001b[A\n 88%|████████████████████████████████████▎    | 191/216 [00:36<00:04,  5.52it/s]\u001b[A\n 50%|████████████████████▌                    | 108/216 [00:23<00:24,  4.34it/s]\u001b[A\n 89%|████████████████████████████████████▍    | 192/216 [00:36<00:04,  5.93it/s]\u001b[A\n 50%|████████████████████▋                    | 109/216 [00:23<00:23,  4.48it/s]\u001b[A\n 89%|████████████████████████████████████▋    | 193/216 [00:36<00:03,  6.39it/s]\u001b[A\n 51%|████████████████████▉                    | 110/216 [00:23<00:21,  4.86it/s]\u001b[A\n 90%|████████████████████████████████████▊    | 194/216 [00:37<00:03,  6.65it/s]\u001b[A\n 51%|█████████████████████                    | 111/216 [00:23<00:19,  5.38it/s]\u001b[A\n 90%|█████████████████████████████████████    | 195/216 [00:37<00:03,  6.44it/s]\u001b[A\n 52%|█████████████████████▎                   | 112/216 [00:23<00:18,  5.54it/s]\u001b[A\n 91%|█████████████████████████████████████▏   | 196/216 [00:37<00:03,  6.24it/s]\u001b[A\n 52%|█████████████████████▍                   | 113/216 [00:24<00:17,  5.80it/s]\u001b[A\n 91%|█████████████████████████████████████▍   | 197/216 [00:37<00:02,  6.40it/s]\u001b[A\n 53%|█████████████████████▋                   | 114/216 [00:24<00:16,  6.09it/s]\u001b[A\n 92%|█████████████████████████████████████▌   | 198/216 [00:37<00:02,  6.64it/s]\u001b[A\n 53%|█████████████████████▊                   | 115/216 [00:24<00:17,  5.64it/s]\u001b[A\n 92%|█████████████████████████████████████▊   | 199/216 [00:37<00:02,  6.04it/s]\u001b[A\n 54%|██████████████████████                   | 116/216 [00:24<00:17,  5.87it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 200/216 [00:38<00:03,  4.93it/s]\u001b[A\n 54%|██████████████████████▏                  | 117/216 [00:24<00:19,  5.05it/s]\u001b[A\n 93%|██████████████████████████████████████▏  | 201/216 [00:38<00:02,  5.15it/s]\u001b[A\n 55%|██████████████████████▍                  | 118/216 [00:25<00:19,  5.08it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 202/216 [00:38<00:02,  5.29it/s]\u001b[A\n 55%|██████████████████████▌                  | 119/216 [00:25<00:18,  5.20it/s]\u001b[A\n 94%|██████████████████████████████████████▌  | 203/216 [00:38<00:02,  5.35it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 204/216 [00:38<00:02,  5.45it/s]\u001b[A\n 56%|██████████████████████▊                  | 120/216 [00:25<00:23,  4.13it/s]\u001b[A\n 95%|██████████████████████████████████████▉  | 205/216 [00:39<00:01,  5.87it/s]\u001b[A\n 56%|██████████████████████▉                  | 121/216 [00:25<00:20,  4.63it/s]\u001b[A\n 95%|███████████████████████████████████████  | 206/216 [00:39<00:01,  6.17it/s]\u001b[A\n 96%|███████████████████████████████████████▎ | 207/216 [00:39<00:01,  6.57it/s]\u001b[A\n 56%|███████████████████████▏                 | 122/216 [00:25<00:19,  4.91it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 208/216 [00:39<00:01,  6.94it/s]\u001b[A\n 57%|███████████████████████▎                 | 123/216 [00:26<00:18,  5.09it/s]\u001b[A\n 97%|███████████████████████████████████████▋ | 209/216 [00:39<00:00,  7.08it/s]\u001b[A\n 57%|███████████████████████▌                 | 124/216 [00:26<00:19,  4.83it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 210/216 [00:39<00:00,  6.22it/s]\u001b[A\n 58%|███████████████████████▋                 | 125/216 [00:26<00:17,  5.34it/s]\u001b[A\n 98%|████████████████████████████████████████ | 211/216 [00:39<00:00,  6.23it/s]\u001b[A\n 58%|███████████████████████▉                 | 126/216 [00:26<00:15,  5.71it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 212/216 [00:40<00:00,  6.36it/s]\u001b[A\n 59%|████████████████████████                 | 127/216 [00:26<00:15,  5.88it/s]\u001b[A\n 99%|████████████████████████████████████████▍| 213/216 [00:40<00:00,  5.98it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 214/216 [00:40<00:00,  6.08it/s]\u001b[A\n100%|████████████████████████████████████████▊| 215/216 [00:40<00:00,  5.57it/s]\u001b[A\n 59%|████████████████████████▎                | 128/216 [00:27<00:23,  3.83it/s]\u001b[A\n100%|█████████████████████████████████████████| 216/216 [00:40<00:00,  6.17it/s]\u001b[A\n 60%|████████████████████████▍                | 129/216 [00:27<00:19,  4.58it/s]\u001b[A\n 61%|████████████████████████▊                | 131/216 [00:27<00:14,  6.05it/s]\u001b[A\n 62%|█████████████████████████▏               | 133/216 [00:27<00:10,  7.66it/s]\u001b[A\n\nDownloading builder script: 100%|██████████| 6.34k/6.34k [00:00<00:00, 14.1MB/s]\u001b[A\u001b[A\n\n 62%|█████████████████████████▋               | 135/216 [00:27<00:08,  9.20it/s]\u001b[A\n 63%|██████████████████████████               | 137/216 [00:28<00:07, 10.20it/s]\u001b[A\n 64%|██████████████████████████▍              | 139/216 [00:28<00:07, 10.62it/s]\u001b[A\n 65%|██████████████████████████▊              | 141/216 [00:28<00:06, 11.49it/s]\u001b[A\n 66%|███████████████████████████▏             | 143/216 [00:28<00:06, 11.02it/s]\u001b[A\n 67%|███████████████████████████▌             | 145/216 [00:28<00:06, 10.45it/s]\u001b[A\n 68%|███████████████████████████▉             | 147/216 [00:28<00:06, 10.79it/s]\u001b[A\n 69%|████████████████████████████▎            | 149/216 [00:29<00:06, 10.48it/s]\u001b[A\n 70%|████████████████████████████▋            | 151/216 [00:29<00:06, 10.52it/s]\u001b[A\n 71%|█████████████████████████████            | 153/216 [00:29<00:05, 10.80it/s]\u001b[A\n 72%|█████████████████████████████▍           | 155/216 [00:29<00:05, 11.42it/s]\u001b[A\n 73%|█████████████████████████████▊           | 157/216 [00:29<00:04, 11.80it/s]\u001b[A\n 74%|██████████████████████████████▏          | 159/216 [00:30<00:05, 10.90it/s]\u001b[A\n 75%|██████████████████████████████▌          | 161/216 [00:30<00:06,  8.28it/s]\u001b[A\n 75%|██████████████████████████████▊          | 162/216 [00:30<00:06,  8.29it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.881021897810219, 'recall': 0.9143939393939394, 'f1': 0.8973977695167287, 'number': 1320}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9529370134465676, 'recall': 0.9442496493688639, 'f1': 0.9485734413525889, 'number': 2852}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9529489728296885, 'recall': 0.9567531603459747, 'f1': 0.9548472775564408, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': nan, 'eval_LOC': {'precision': 0.881021897810219, 'recall': 0.9143939393939394, 'f1': 0.8973977695167287, 'number': 1320}, 'eval_ORG': {'precision': 0.9529370134465676, 'recall': 0.9442496493688639, 'f1': 0.9485734413525889, 'number': 2852}, 'eval_PER': {'precision': 0.9529489728296885, 'recall': 0.9567531603459747, 'f1': 0.9548472775564408, 'number': 1503}, 'eval_overall_precision': 0.9356704645048204, 'eval_overall_recall': 0.9406167400881057, 'eval_overall_f1': 0.9381370826010544, 'eval_overall_accuracy': 0.9934100787031599, 'eval_runtime': 44.4536, 'eval_samples_per_second': 77.452, 'eval_steps_per_second': 4.859, 'epoch': 1.0}\n100%|███████████████████████████████████████| 2813/2813 [28:21<00:00,  1.90it/s]\n100%|█████████████████████████████████████████| 216/216 [00:44<00:00,  6.17it/s]\u001b[A\n                                                                                \u001b[A\n{'train_runtime': 1701.547, 'train_samples_per_second': 26.447, 'train_steps_per_second': 1.653, 'train_loss': 0.05404242221630217, 'epoch': 1.0}\n100%|███████████████████████████████████████| 2813/2813 [28:21<00:00,  1.65it/s]\n\n 76%|███████████████████████████████▎         | 165/216 [00:30<00:06,  8.27it/s]\u001b[A\n 77%|███████████████████████████████▋         | 167/216 [00:31<00:05,  9.49it/s]\u001b[A\n 78%|████████████████████████████████         | 169/216 [00:31<00:04,  9.85it/s]\u001b[A\n 79%|████████████████████████████████▍        | 171/216 [00:31<00:04, 10.20it/s]\u001b[A\n 80%|████████████████████████████████▊        | 173/216 [00:31<00:03, 11.04it/s]\u001b[A\n 81%|█████████████████████████████████▏       | 175/216 [00:31<00:03, 11.59it/s]\u001b[A\n 82%|█████████████████████████████████▌       | 177/216 [00:31<00:03, 11.65it/s]\u001b[A\n 83%|█████████████████████████████████▉       | 179/216 [00:32<00:03, 10.05it/s]\u001b[A\n 84%|██████████████████████████████████▎      | 181/216 [00:32<00:03, 10.83it/s]\u001b[A\n 85%|██████████████████████████████████▋      | 183/216 [00:32<00:03, 10.16it/s]\u001b[A\n 86%|███████████████████████████████████      | 185/216 [00:32<00:02, 10.65it/s]\u001b[A\n 87%|███████████████████████████████████▍     | 187/216 [00:32<00:02, 11.33it/s]\u001b[A\n 88%|███████████████████████████████████▉     | 189/216 [00:33<00:02, 11.90it/s]\u001b[A\n 88%|████████████████████████████████████▎    | 191/216 [00:33<00:02, 12.03it/s]\u001b[A\n 89%|████████████████████████████████████▋    | 193/216 [00:33<00:01, 12.67it/s]\u001b[A\n 90%|█████████████████████████████████████    | 195/216 [00:33<00:01, 12.94it/s]\u001b[A\n 91%|█████████████████████████████████████▍   | 197/216 [00:33<00:01, 13.18it/s]\u001b[A\n 92%|█████████████████████████████████████▊   | 199/216 [00:33<00:01, 13.13it/s]\u001b[A\n 93%|██████████████████████████████████████▏  | 201/216 [00:33<00:01, 11.44it/s]\u001b[A\n 94%|██████████████████████████████████████▌  | 203/216 [00:34<00:01, 11.64it/s]\u001b[A\n 95%|██████████████████████████████████████▉  | 205/216 [00:34<00:00, 12.45it/s]\u001b[A\n 96%|███████████████████████████████████████▎ | 207/216 [00:34<00:00, 13.27it/s]\u001b[A\n 97%|███████████████████████████████████████▋ | 209/216 [00:34<00:00, 13.79it/s]\u001b[A\n 98%|████████████████████████████████████████ | 211/216 [00:34<00:00, 13.30it/s]\u001b[A\n 99%|████████████████████████████████████████▍| 213/216 [00:34<00:00, 13.42it/s]\u001b[A\n100%|████████████████████████████████████████▊| 215/216 [00:34<00:00, 13.92it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.8685920577617329, 'recall': 0.9113636363636364, 'f1': 0.8894639556377079, 'number': 1320}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9464411557434813, 'recall': 0.9417952314165497, 'f1': 0.9441124780316343, 'number': 2852}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9549966909331569, 'recall': 0.9600798403193613, 'f1': 0.9575315195753152, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': nan, 'eval_LOC': {'precision': 0.8685920577617329, 'recall': 0.9113636363636364, 'f1': 0.8894639556377079, 'number': 1320}, 'eval_ORG': {'precision': 0.9464411557434813, 'recall': 0.9417952314165497, 'f1': 0.9441124780316343, 'number': 2852}, 'eval_PER': {'precision': 0.9549966909331569, 'recall': 0.9600798403193613, 'f1': 0.9575315195753152, 'number': 1503}, 'eval_overall_precision': 0.9298918730380188, 'eval_overall_recall': 0.9395594713656388, 'eval_overall_f1': 0.9347006749057761, 'eval_overall_accuracy': 0.9926347938447081, 'eval_runtime': 38.0195, 'eval_samples_per_second': 90.559, 'eval_steps_per_second': 5.681, 'epoch': 1.0}\n100%|███████████████████████████████████████| 2813/2813 [28:27<00:00,  2.00it/s]\n100%|█████████████████████████████████████████| 216/216 [00:37<00:00, 13.92it/s]\u001b[A\n{'train_runtime': 1707.5742, 'train_samples_per_second': 26.354, 'train_steps_per_second': 1.647, 'train_loss': 0.0539171225313525, 'epoch': 1.0}\n100%|███████████████████████████████████████| 2813/2813 [28:27<00:00,  1.65it/s]\n[rank0]:[W612 13:43:24.077520866 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from transformers import pipeline\npipeline = pipeline('token-classification', '/kaggle/working/msra_ner_train/checkpoint-2813')\n\nresult = pipeline('双方确定了今后发展中美关系的指导方针')\n\nprint(result)\n\nfor item in result:\n    print(item['entity'],item['word'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:19:28.539866Z","iopub.execute_input":"2025-06-12T14:19:28.540164Z","iopub.status.idle":"2025-06-12T14:19:28.818249Z","shell.execute_reply.started":"2025-06-12T14:19:28.540145Z","shell.execute_reply":"2025-06-12T14:19:28.817589Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"[{'entity': 'B-ORG', 'score': 0.9986308, 'index': 10, 'word': '中', 'start': 9, 'end': 10}, {'entity': 'B-ORG', 'score': 0.9980075, 'index': 11, 'word': '美', 'start': 10, 'end': 11}]\nB-ORG 中\nB-ORG 美\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T14:18:23.269901Z","iopub.execute_input":"2025-06-12T14:18:23.270703Z","iopub.status.idle":"2025-06-12T14:18:23.274786Z","shell.execute_reply.started":"2025-06-12T14:18:23.270670Z","shell.execute_reply":"2025-06-12T14:18:23.274056Z"}},"outputs":[{"name":"stdout","text":"B-ORG 中\nB-ORG 美\n","output_type":"stream"}],"execution_count":19}]}