{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. 利用上周NER模型训练任务代码，复现课堂案例中：动态学习率、混合精度、DDP训练实现。\n2. 利用课堂案例，实现分布式DDP模型训练。存盘后加载实现推理。","metadata":{}},{"cell_type":"code","source":"!pip -q install evaluate seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T13:35:32.431570Z","iopub.execute_input":"2025-06-13T13:35:32.431894Z","iopub.status.idle":"2025-06-13T13:35:40.382204Z","shell.execute_reply.started":"2025-06-13T13:35:32.431870Z","shell.execute_reply":"2025-06-13T13:35:40.381435Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%writefile ner_ddp2.py\n\nfrom transformers import AutoModelForTokenClassification,AutoTokenizer,DataCollatorForTokenClassification,TrainingArguments,Trainer\nfrom datasets import load_dataset\nimport torch\nimport evaluate\nimport seqeval\nimport numpy as np\nimport os \nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\n#设置分布式环境\ndef setup(rank,world_size):\n    os.environ['MASTER_ADDR'] ='localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group('nccl',rank=rank,world_size=world_size)\n\n#清理分布式环境\ndef cleanup():\n    dist.destory_process_group()\n\ndef train(rank,world_size):\n    setup(rank,world_size)\n\n    #加载datasets\n    ds = load_dataset('nlhappy/CLUE-NER')\n\n    #entity_index\n    entites = ['O'] + list({'movie', 'name', 'game', 'address', 'position', \\\n               'company', 'scene', 'book', 'organization', 'government'})\n    tags = ['O']\n    for entity in entites[1:]:\n        tags.append('B-' + entity.upper())\n        tags.append('I-' + entity.upper())\n    \n    entity_index = {entity:i for i, entity in enumerate(entites)}\n\n    tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n\n    def entity_tags_proc(item):\n        # item即是dataset中记录\n        text_len = len(item['text'])  # 根据文本长度生成tags列表\n        tags = [0] * text_len    # 初始值为‘O’\n        # 遍历实体列表，所有实体类别标记填入tags\n        entites = item['ents']\n        for ent in entites:\n            indices = ent['indices']  # 实体索引\n            label = ent['label']   # 实体名\n            tags[indices[0]] = entity_index[label] * 2 - 1\n            for idx in indices[1:]:\n                tags[idx] = entity_index[label] * 2\n        return {'ent_tag': tags}\n\n    # 使用自定义回调函数处理数据集记录\n    ds1 = ds.map(entity_tags_proc)\n\n    def data_input_proc(item):\n        # 输入文本先拆分为字符，再转换为模型输入的token索引\n        batch_texts = [list(text) for text in item['text']]\n        # 导入拆分为字符的文本列表时，需要设置参数is_split_into_words=True\n        input_data = tokenizer(batch_texts, truncation=True, add_special_tokens=False, max_length=512, \n                               is_split_into_words=True, padding='max_length')\n        input_data['labels'] = [tag + [0] * (512 - len(tag)) for tag in item['ent_tag']]\n        return input_data\n\n    ds2 = ds1.map(data_input_proc,batched=True)\n\n    id2lbl = {i:tag for i, tag in enumerate(tags)}\n    lbl2id = {tag:i for i, tag in enumerate(tags)}\n    \n    model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n                                                            num_labels=21,\n                                                            id2label=id2lbl,\n                                                            label2id=lbl2id)\n    model.to(rank)\n\n    args = TrainingArguments(\n         output_dir=\"ner_train_DDP\",\n        num_train_epochs = 1,\n        save_safetensors=False,\n        per_device_train_batch_size=16,  # 训练批次\n        per_device_eval_batch_size=16,\n        report_to='tensorboard',\n        eval_strategy=\"epoch\",\n        local_rank=rank,\n        fp16=True, \n        lr_scheduler_type='linear', # 动态学习率\n        warmup_steps=100,        # 预热步数\n        ddp_find_unused_parameters=False  # 优化DDP性能\n    )\n\n    def compute_metric(result):\n        # result 是一个tuple (predicts, labels)\n        \n        # 获取评估对象\n        seqeval = evaluate.load('seqeval')\n        predicts,labels = result\n        predicts = np.argmax(predicts, axis=2)\n        \n        # 准备评估数据\n        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        results = seqeval.compute(predictions=predicts, references=labels)\n    \n        return results\n\n    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n\n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=ds2['train'],\n        eval_dataset=ds2['validation'],\n        data_collator=data_collator,\n        compute_metrics=compute_metric\n    )\n    trainer.train()\n\ndef main():\n    world_size = torch.cuda.device_count()\n    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T14:20:56.414050Z","iopub.execute_input":"2025-06-13T14:20:56.414336Z","iopub.status.idle":"2025-06-13T14:20:56.421189Z","shell.execute_reply.started":"2025-06-13T14:20:56.414316Z","shell.execute_reply":"2025-06-13T14:20:56.420427Z"}},"outputs":[{"name":"stdout","text":"Overwriting ner_ddp2.py\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!python ner_ddp2.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T14:20:58.281997Z","iopub.execute_input":"2025-06-13T14:20:58.282227Z","iopub.status.idle":"2025-06-13T14:44:04.383721Z","shell.execute_reply.started":"2025-06-13T14:20:58.282210Z","shell.execute_reply":"2025-06-13T14:44:04.382983Z"}},"outputs":[{"name":"stdout","text":"2025-06-13 14:21:03.598500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749824463.621986    2903 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749824463.630382    2903 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-13 14:21:13.794616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749824473.816968    2917 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749824473.823970    2917 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-13 14:21:13.861155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749824473.884371    2918 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749824473.891404    2918 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[W613 14:21:17.256133352 socket.cpp:759] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\nMap: 100%|███████████████████████| 10748/10748 [00:01<00:00, 9426.03 examples/s]\nMap: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 8897.00 examples/s]\nMap: 100%|███████████████████████| 10748/10748 [00:01<00:00, 8427.06 examples/s]\nMap: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 9078.96 examples/s]\nMap: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1855.12 examples/s]\nMap: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1849.17 examples/s]\nMap: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 1907.63 examples/s]\nMap:  74%|██████████████████▌      | 1000/1343 [00:00<00:00, 2047.03 examples/s]Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nMap: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 2016.63 examples/s]\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\ntorch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\ntorch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n  0%|                                                   | 0/336 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n100%|█████████████████████████████████████████| 336/336 [21:28<00:00,  3.72s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n\n  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\n  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\n  5%|██                                          | 2/42 [00:01<00:22,  1.75it/s]\u001b[A\n  5%|██                                          | 2/42 [00:01<00:24,  1.65it/s]\u001b[A\n  7%|███▏                                        | 3/42 [00:02<00:32,  1.20it/s]\u001b[A\n  7%|███▏                                        | 3/42 [00:02<00:34,  1.15it/s]\u001b[A\n 10%|████▏                                       | 4/42 [00:03<00:36,  1.03it/s]\u001b[A\n 10%|████▏                                       | 4/42 [00:03<00:37,  1.00it/s]\u001b[A\n 12%|█████▏                                      | 5/42 [00:04<00:38,  1.05s/it]\u001b[A\n 12%|█████▏                                      | 5/42 [00:04<00:40,  1.09s/it]\u001b[A\n 14%|██████▎                                     | 6/42 [00:05<00:39,  1.10s/it]\u001b[A\n 14%|██████▎                                     | 6/42 [00:06<00:40,  1.13s/it]\u001b[A\n 17%|███████▎                                    | 7/42 [00:07<00:39,  1.13s/it]\u001b[A\n 17%|███████▎                                    | 7/42 [00:07<00:40,  1.16s/it]\u001b[A\n 19%|████████▍                                   | 8/42 [00:08<00:39,  1.16s/it]\u001b[A\n 19%|████████▍                                   | 8/42 [00:08<00:39,  1.17s/it]\u001b[A\n 21%|█████████▍                                  | 9/42 [00:09<00:38,  1.17s/it]\u001b[A\n 21%|█████████▍                                  | 9/42 [00:09<00:39,  1.19s/it]\u001b[A\n 24%|██████████▏                                | 10/42 [00:10<00:38,  1.19s/it]\u001b[A\n 24%|██████████▏                                | 10/42 [00:11<00:38,  1.20s/it]\u001b[A\n 26%|███████████▎                               | 11/42 [00:11<00:37,  1.19s/it]\u001b[A\n 26%|███████████▎                               | 11/42 [00:12<00:37,  1.21s/it]\u001b[A\n 29%|████████████▎                              | 12/42 [00:13<00:35,  1.19s/it]\u001b[A\n 29%|████████████▎                              | 12/42 [00:13<00:36,  1.22s/it]\u001b[A\n 31%|█████████████▎                             | 13/42 [00:14<00:34,  1.20s/it]\u001b[A\n 31%|█████████████▎                             | 13/42 [00:14<00:35,  1.21s/it]\u001b[A\n 33%|██████████████▎                            | 14/42 [00:15<00:33,  1.20s/it]\u001b[A\n 33%|██████████████▎                            | 14/42 [00:15<00:33,  1.21s/it]\u001b[A\n 36%|███████████████▎                           | 15/42 [00:16<00:32,  1.20s/it]\u001b[A\n 36%|███████████████▎                           | 15/42 [00:17<00:32,  1.21s/it]\u001b[A\n 38%|████████████████▍                          | 16/42 [00:18<00:31,  1.20s/it]\u001b[A\n 38%|████████████████▍                          | 16/42 [00:18<00:31,  1.22s/it]\u001b[A\n 40%|█████████████████▍                         | 17/42 [00:19<00:29,  1.20s/it]\u001b[A\n 40%|█████████████████▍                         | 17/42 [00:19<00:30,  1.22s/it]\u001b[A\n 43%|██████████████████▍                        | 18/42 [00:20<00:28,  1.20s/it]\u001b[A\n 43%|██████████████████▍                        | 18/42 [00:20<00:29,  1.22s/it]\u001b[A\n 45%|███████████████████▍                       | 19/42 [00:21<00:27,  1.20s/it]\u001b[A\n 45%|███████████████████▍                       | 19/42 [00:22<00:28,  1.23s/it]\u001b[A\n 48%|████████████████████▍                      | 20/42 [00:22<00:26,  1.20s/it]\u001b[A\n 48%|████████████████████▍                      | 20/42 [00:23<00:27,  1.23s/it]\u001b[A\n 50%|█████████████████████▌                     | 21/42 [00:24<00:25,  1.20s/it]\u001b[A\n 50%|█████████████████████▌                     | 21/42 [00:24<00:25,  1.24s/it]\u001b[A\n 52%|██████████████████████▌                    | 22/42 [00:25<00:24,  1.21s/it]\u001b[A\n 52%|██████████████████████▌                    | 22/42 [00:25<00:24,  1.23s/it]\u001b[A\n 55%|███████████████████████▌                   | 23/42 [00:26<00:22,  1.21s/it]\u001b[A\n 55%|███████████████████████▌                   | 23/42 [00:26<00:23,  1.23s/it]\u001b[A\n 57%|████████████████████████▌                  | 24/42 [00:27<00:21,  1.21s/it]\u001b[A\n 57%|████████████████████████▌                  | 24/42 [00:28<00:22,  1.23s/it]\u001b[A\n 60%|█████████████████████████▌                 | 25/42 [00:28<00:20,  1.21s/it]\u001b[A\n 60%|█████████████████████████▌                 | 25/42 [00:29<00:19,  1.15s/it]\u001b[A\n 62%|██████████████████████████▌                | 26/42 [00:30<00:19,  1.22s/it]\u001b[A\n 62%|██████████████████████████▌                | 26/42 [00:30<00:19,  1.24s/it]\u001b[A\n 64%|███████████████████████████▋               | 27/42 [00:31<00:18,  1.22s/it]\u001b[A\n 64%|███████████████████████████▋               | 27/42 [00:31<00:18,  1.26s/it]\u001b[A\n 67%|████████████████████████████▋              | 28/42 [00:32<00:16,  1.20s/it]\u001b[A\n 67%|████████████████████████████▋              | 28/42 [00:33<00:17,  1.25s/it]\u001b[A\n 69%|█████████████████████████████▋             | 29/42 [00:33<00:15,  1.21s/it]\u001b[A\n 69%|█████████████████████████████▋             | 29/42 [00:34<00:15,  1.23s/it]\u001b[A\n 71%|██████████████████████████████▋            | 30/42 [00:35<00:14,  1.24s/it]\u001b[A\n 71%|██████████████████████████████▋            | 30/42 [00:35<00:14,  1.23s/it]\u001b[A\n 74%|███████████████████████████████▋           | 31/42 [00:36<00:13,  1.23s/it]\u001b[A\n 74%|███████████████████████████████▋           | 31/42 [00:36<00:13,  1.22s/it]\u001b[A\n 76%|████████████████████████████████▊          | 32/42 [00:37<00:12,  1.22s/it]\u001b[A\n 76%|████████████████████████████████▊          | 32/42 [00:37<00:12,  1.22s/it]\u001b[A\n 79%|█████████████████████████████████▊         | 33/42 [00:38<00:10,  1.22s/it]\u001b[A\n 79%|█████████████████████████████████▊         | 33/42 [00:39<00:10,  1.22s/it]\u001b[A\n 81%|██████████████████████████████████▊        | 34/42 [00:39<00:09,  1.22s/it]\u001b[A\n 81%|██████████████████████████████████▊        | 34/42 [00:40<00:09,  1.22s/it]\u001b[A\n 83%|███████████████████████████████████▊       | 35/42 [00:41<00:08,  1.22s/it]\u001b[A\n 83%|███████████████████████████████████▊       | 35/42 [00:41<00:08,  1.22s/it]\u001b[A\n 86%|████████████████████████████████████▊      | 36/42 [00:42<00:07,  1.22s/it]\u001b[A\n 86%|████████████████████████████████████▊      | 36/42 [00:42<00:07,  1.22s/it]\u001b[A\n 88%|█████████████████████████████████████▉     | 37/42 [00:43<00:06,  1.21s/it]\u001b[A\n 88%|█████████████████████████████████████▉     | 37/42 [00:44<00:06,  1.22s/it]\u001b[A\n 90%|██████████████████████████████████████▉    | 38/42 [00:44<00:04,  1.21s/it]\u001b[A\n 90%|██████████████████████████████████████▉    | 38/42 [00:45<00:04,  1.22s/it]\u001b[A\n 93%|███████████████████████████████████████▉   | 39/42 [00:45<00:03,  1.21s/it]\u001b[A\n 93%|███████████████████████████████████████▉   | 39/42 [00:46<00:03,  1.22s/it]\u001b[A\n 95%|████████████████████████████████████████▉  | 40/42 [00:47<00:02,  1.21s/it]\u001b[A\n 95%|████████████████████████████████████████▉  | 40/42 [00:47<00:02,  1.21s/it]\u001b[A\n 98%|█████████████████████████████████████████▉ | 41/42 [00:48<00:01,  1.21s/it]\u001b[A\n 98%|█████████████████████████████████████████▉ | 41/42 [00:48<00:01,  1.22s/it]\u001b[A\n100%|███████████████████████████████████████████| 42/42 [00:49<00:00,  1.21s/it]\u001b[A\n100%|███████████████████████████████████████████| 42/42 [00:49<00:00,  1.12s/it]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.5354691075514875, 'recall': 0.6273458445040214, 'f1': 0.5777777777777778, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7467532467532467, 'recall': 0.7467532467532467, 'f1': 0.7467532467532466, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6904761904761905, 'recall': 0.7671957671957672, 'f1': 0.7268170426065163, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6785714285714286, 'recall': 0.8372881355932204, 'f1': 0.7496206373292867, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6151515151515151, 'recall': 0.8218623481781376, 'f1': 0.7036395147313691, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8102189781021898, 'recall': 0.7350993377483444, 'f1': 0.7708333333333334, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7764705882352941, 'recall': 0.8516129032258064, 'f1': 0.8123076923076924, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6925064599483204, 'recall': 0.7302452316076294, 'f1': 0.7108753315649867, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6748466257668712, 'recall': 0.7621247113163973, 'f1': 0.7158351409978309, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6086956521739131, 'recall': 0.7368421052631579, 'f1': 0.6666666666666666, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.016231855377554893, 'eval_ADDRESS': {'precision': 0.5354691075514875, 'recall': 0.6273458445040214, 'f1': 0.5777777777777778, 'number': 373}, 'eval_BOOK': {'precision': 0.7467532467532467, 'recall': 0.7467532467532467, 'f1': 0.7467532467532466, 'number': 154}, 'eval_COMPANY': {'precision': 0.6904761904761905, 'recall': 0.7671957671957672, 'f1': 0.7268170426065163, 'number': 378}, 'eval_GAME': {'precision': 0.6785714285714286, 'recall': 0.8372881355932204, 'f1': 0.7496206373292867, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6151515151515151, 'recall': 0.8218623481781376, 'f1': 0.7036395147313691, 'number': 247}, 'eval_MOVIE': {'precision': 0.8102189781021898, 'recall': 0.7350993377483444, 'f1': 0.7708333333333334, 'number': 151}, 'eval_NAME': {'precision': 0.7764705882352941, 'recall': 0.8516129032258064, 'f1': 0.8123076923076924, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6925064599483204, 'recall': 0.7302452316076294, 'f1': 0.7108753315649867, 'number': 367}, 'eval_POSITION': {'precision': 0.6748466257668712, 'recall': 0.7621247113163973, 'f1': 0.7158351409978309, 'number': 433}, 'eval_SCENE': {'precision': 0.6086956521739131, 'recall': 0.7368421052631579, 'f1': 0.6666666666666666, 'number': 209}, 'eval_overall_precision': 0.6745188164320598, 'eval_overall_recall': 0.7643229166666666, 'eval_overall_f1': 0.7166183427437816, 'eval_overall_accuracy': 0.9950844657483247, 'eval_runtime': 58.0793, 'eval_samples_per_second': 23.124, 'eval_steps_per_second': 0.723, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 336/336 [22:29<00:00,  3.71s/it]\n100%|███████████████████████████████████████████| 42/42 [00:56<00:00,  1.21s/it]\u001b[A\n{'train_runtime': 1349.5777, 'train_samples_per_second': 7.964, 'train_steps_per_second': 0.249, 'train_loss': 0.1773052669706799, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 336/336 [22:29<00:00,  4.02s/it]\nTrainer is attempting to log a value of \"{'precision': 0.4854586129753915, 'recall': 0.5817694369973191, 'f1': 0.5292682926829269, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7724137931034483, 'recall': 0.7272727272727273, 'f1': 0.7491638795986623, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6735159817351598, 'recall': 0.7804232804232805, 'f1': 0.7230392156862745, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6815642458100558, 'recall': 0.8271186440677966, 'f1': 0.7473200612557427, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.628125, 'recall': 0.8137651821862348, 'f1': 0.708994708994709, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.7549668874172185, 'f1': 0.7524752475247526, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.7818532818532818, 'recall': 0.8709677419354839, 'f1': 0.8240081383519837, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6535626535626535, 'recall': 0.7247956403269755, 'f1': 0.6873385012919896, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.6987704918032787, 'recall': 0.7875288683602771, 'f1': 0.7404994571118351, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.626984126984127, 'recall': 0.7559808612440191, 'f1': 0.685466377440347, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.016269011422991753, 'eval_ADDRESS': {'precision': 0.4854586129753915, 'recall': 0.5817694369973191, 'f1': 0.5292682926829269, 'number': 373}, 'eval_BOOK': {'precision': 0.7724137931034483, 'recall': 0.7272727272727273, 'f1': 0.7491638795986623, 'number': 154}, 'eval_COMPANY': {'precision': 0.6735159817351598, 'recall': 0.7804232804232805, 'f1': 0.7230392156862745, 'number': 378}, 'eval_GAME': {'precision': 0.6815642458100558, 'recall': 0.8271186440677966, 'f1': 0.7473200612557427, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.628125, 'recall': 0.8137651821862348, 'f1': 0.708994708994709, 'number': 247}, 'eval_MOVIE': {'precision': 0.75, 'recall': 0.7549668874172185, 'f1': 0.7524752475247526, 'number': 151}, 'eval_NAME': {'precision': 0.7818532818532818, 'recall': 0.8709677419354839, 'f1': 0.8240081383519837, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6535626535626535, 'recall': 0.7247956403269755, 'f1': 0.6873385012919896, 'number': 367}, 'eval_POSITION': {'precision': 0.6987704918032787, 'recall': 0.7875288683602771, 'f1': 0.7404994571118351, 'number': 433}, 'eval_SCENE': {'precision': 0.626984126984127, 'recall': 0.7559808612440191, 'f1': 0.685466377440347, 'number': 209}, 'eval_overall_precision': 0.6675177304964539, 'eval_overall_recall': 0.7659505208333334, 'eval_overall_f1': 0.7133545551008035, 'eval_overall_accuracy': 0.9951251861504096, 'eval_runtime': 59.3764, 'eval_samples_per_second': 22.618, 'eval_steps_per_second': 0.707, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 336/336 [22:30<00:00,  3.72s/it]\n100%|███████████████████████████████████████████| 42/42 [00:58<00:00,  1.12s/it]\u001b[A\n{'train_runtime': 1350.7965, 'train_samples_per_second': 7.957, 'train_steps_per_second': 0.249, 'train_loss': 0.15074005581083752, 'epoch': 1.0}\n100%|█████████████████████████████████████████| 336/336 [22:30<00:00,  4.02s/it]\n[rank0]:[W613 14:44:01.581191691 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from transformers import pipeline\npipeline = pipeline('token-classification', '/kaggle/working/ner_train_DDP/checkpoint-336')\n\nresutls = pipeline(\"加勒比海盗3：世界尽头》的去年同期成绩死死甩在身后，后者则即将赶超《变形金刚》\")\nresutls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:00:57.579449Z","iopub.execute_input":"2025-06-13T15:00:57.579977Z","iopub.status.idle":"2025-06-13T15:00:58.141540Z","shell.execute_reply.started":"2025-06-13T15:00:57.579940Z","shell.execute_reply":"2025-06-13T15:00:58.140859Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'B-MOVIE',\n  'score': 0.3152406,\n  'index': 1,\n  'word': '加',\n  'start': 0,\n  'end': 1},\n {'entity': 'I-MOVIE',\n  'score': 0.5219301,\n  'index': 2,\n  'word': '勒',\n  'start': 1,\n  'end': 2},\n {'entity': 'I-MOVIE',\n  'score': 0.49803004,\n  'index': 3,\n  'word': '比',\n  'start': 2,\n  'end': 3},\n {'entity': 'I-MOVIE',\n  'score': 0.40631694,\n  'index': 4,\n  'word': '海',\n  'start': 3,\n  'end': 4},\n {'entity': 'I-GAME',\n  'score': 0.4993898,\n  'index': 5,\n  'word': '盗',\n  'start': 4,\n  'end': 5},\n {'entity': 'I-GAME',\n  'score': 0.5256959,\n  'index': 6,\n  'word': '3',\n  'start': 5,\n  'end': 6},\n {'entity': 'I-GAME',\n  'score': 0.38661325,\n  'index': 7,\n  'word': '：',\n  'start': 6,\n  'end': 7},\n {'entity': 'I-MOVIE',\n  'score': 0.27445993,\n  'index': 8,\n  'word': '世',\n  'start': 7,\n  'end': 8},\n {'entity': 'I-MOVIE',\n  'score': 0.5715637,\n  'index': 9,\n  'word': '界',\n  'start': 8,\n  'end': 9},\n {'entity': 'I-MOVIE',\n  'score': 0.42640588,\n  'index': 10,\n  'word': '尽',\n  'start': 9,\n  'end': 10},\n {'entity': 'I-MOVIE',\n  'score': 0.5188898,\n  'index': 11,\n  'word': '头',\n  'start': 10,\n  'end': 11},\n {'entity': 'I-MOVIE',\n  'score': 0.31870443,\n  'index': 12,\n  'word': '》',\n  'start': 11,\n  'end': 12},\n {'entity': 'B-MOVIE',\n  'score': 0.6422204,\n  'index': 34,\n  'word': '《',\n  'start': 33,\n  'end': 34},\n {'entity': 'B-MOVIE',\n  'score': 0.32051182,\n  'index': 35,\n  'word': '变',\n  'start': 34,\n  'end': 35},\n {'entity': 'I-GAME',\n  'score': 0.32193288,\n  'index': 36,\n  'word': '形',\n  'start': 35,\n  'end': 36},\n {'entity': 'I-GAME',\n  'score': 0.3292983,\n  'index': 37,\n  'word': '金',\n  'start': 36,\n  'end': 37},\n {'entity': 'I-GAME',\n  'score': 0.4092384,\n  'index': 38,\n  'word': '刚',\n  'start': 37,\n  'end': 38},\n {'entity': 'I-GAME',\n  'score': 0.3384149,\n  'index': 39,\n  'word': '》',\n  'start': 38,\n  'end': 39}]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"for item in resutls:\n    ite = item['entity'],item['word']\n    print(ite)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T15:02:33.295225Z","iopub.execute_input":"2025-06-13T15:02:33.295506Z","iopub.status.idle":"2025-06-13T15:02:33.300336Z","shell.execute_reply.started":"2025-06-13T15:02:33.295487Z","shell.execute_reply":"2025-06-13T15:02:33.299222Z"}},"outputs":[{"name":"stdout","text":"('B-MOVIE', '加')\n('I-MOVIE', '勒')\n('I-MOVIE', '比')\n('I-MOVIE', '海')\n('I-GAME', '盗')\n('I-GAME', '3')\n('I-GAME', '：')\n('I-MOVIE', '世')\n('I-MOVIE', '界')\n('I-MOVIE', '尽')\n('I-MOVIE', '头')\n('I-MOVIE', '》')\n('B-MOVIE', '《')\n('B-MOVIE', '变')\n('I-GAME', '形')\n('I-GAME', '金')\n('I-GAME', '刚')\n('I-GAME', '》')\n","output_type":"stream"}],"execution_count":15}]}