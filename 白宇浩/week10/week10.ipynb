{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 挂载 Kaggle 数据集（首次运行需授权）\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "except ImportError:\n",
    "    !pip install kaggle_datasets\n",
    "    from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集\n",
    "df = pd.read_excel('/kaggle/input/jd_comment_with_label/jd_comment_data.xlsx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"数据集列名：\", df.columns.tolist())\n",
    "\n",
    "# 查看前几行数据（确认列名和数据）\n",
    "print(\"\\n数据预览：\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选需要的列\n",
    "texts = df['评价内容(content)'].tolist()          # 文本列\n",
    "labels = df['评分（总分5分）(score)'].values    # 标签列（1-5分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查标签分布\n",
    "print(\"标签分布：\", np.bincount(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割数据集\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载预训练模型\n",
    "model_name = \"bert-base-chinese\"  # 中文预训练模型\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=5,  # 评分1-5分，共5个类别\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据集\n",
    "# Tokenize 输入数据\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "# 创建 TensorFlow 数据集\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(1000).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(16).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练模型\n",
    "# 配置优化器和损失函数\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=3  # 根据数据量调整\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "# 预测测试集（示例）\n",
    "test_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "predictions = model.predict(test_encodings)['logits']\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# 输出评估结果\n",
    "print(\"\\nTest Accuracy:\", accuracy_score(val_labels, pred_labels))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(val_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
