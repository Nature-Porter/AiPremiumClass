{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T12:42:16.023671Z",
     "iopub.status.busy": "2025-04-24T12:42:16.023078Z",
     "iopub.status.idle": "2025-04-24T12:42:16.324408Z",
     "shell.execute_reply": "2025-04-24T12:42:16.323714Z",
     "shell.execute_reply.started": "2025-04-24T12:42:16.023642Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/couplet/vocab.bin\n",
      "/kaggle/input/couplet/encoder.json\n",
      "/kaggle/input/couplet/decoder.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T13:47:54.296946Z",
     "iopub.status.busy": "2025-04-24T13:47:54.296661Z",
     "iopub.status.idle": "2025-04-24T13:47:54.305728Z",
     "shell.execute_reply": "2025-04-24T13:47:54.305150Z",
     "shell.execute_reply.started": "2025-04-24T13:47:54.296924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        # 定义嵌入层\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        # 定义GRU层\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim,dropout=dropout, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, token_seq):\n",
    "        # token_seq: [batch_size, seq_len]\n",
    "        # embedded: [batch_size, seq_len, emb_dim]\n",
    "        embedded = self.embedding(token_seq)\n",
    "\n",
    "        # outputs: [batch_size, seq_len, hidden_dim * 2]\n",
    "        # hidden: [2, batch_size, hidden_dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        # 返回，Encoder最后一个时间步的隐藏状态(拼接)\n",
    "        # return outputs[:, -1, :]\n",
    "        # 返回最后一个时间步的隐藏状态(拼接)\n",
    "        return torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        # 返回最后一个时间步的隐状态（相加）\n",
    "        # return hidden.sum(dim=0)\n",
    "\n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        # 定义嵌入层\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        # 定义GRU层\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim * 2, dropout=dropout,\n",
    "                          batch_first=True)\n",
    "        # 定义线性层\n",
    "        self.fc = nn.Linear(hidden_dim * 2, input_dim)  # 解码词典中词汇概率\n",
    "\n",
    "    def forward(self, token_seq, hidden_state):\n",
    "        # token_seq: [batch_size, seq_len]\n",
    "        # embedded: [batch_size, seq_len, emb_dim]\n",
    "        embedded = self.embedding(token_seq)\n",
    "\n",
    "        # outputs: [batch_size, seq_len, hidden_dim * 2]\n",
    "        # hidden: [1, batch_size, hidden_dim * 2]\n",
    "        outputs, hidden = self.rnn(embedded, hidden_state.unsqueeze(0))\n",
    "\n",
    "        # logits: [batch_size, seq_len, input_dim]\n",
    "        logits = self.fc(outputs)\n",
    "        return logits, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 enc_emb_size, \n",
    "                 dec_emb_size,\n",
    "                 emb_dim,\n",
    "                 hidden_size,\n",
    "                 dropout=0.5,\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = Encoder(enc_emb_size, emb_dim, hidden_size, dropout=dropout)\n",
    "        # decoder\n",
    "        self.decoder = Decoder(dec_emb_size, emb_dim, hidden_size, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, enc_input, dec_input):\n",
    "        # encoder last hidden state\n",
    "        encoder_state = self.encoder(enc_input)\n",
    "        output,hidden = self.decoder(dec_input, encoder_state)\n",
    "\n",
    "        return output,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T12:42:20.573645Z",
     "iopub.status.busy": "2025-04-24T12:42:20.573323Z",
     "iopub.status.idle": "2025-04-24T12:42:20.579333Z",
     "shell.execute_reply": "2025-04-24T12:42:20.578766Z",
     "shell.execute_reply.started": "2025-04-24T12:42:20.573627Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def get_proc(enc_voc, dec_voc):\n",
    "\n",
    "    # 嵌套函数定义\n",
    "    # 外部函数变量生命周期会延续到内部函数调用结束 （闭包）\n",
    "\n",
    "    def batch_proc(data):\n",
    "        \"\"\"\n",
    "        批次数据处理并返回\n",
    "        \"\"\"\n",
    "        enc_ids, dec_ids, labels = [],[],[]\n",
    "        for enc,dec in data:\n",
    "            # token -> token index\n",
    "            enc_idx = [enc_voc[tk] for tk in enc]\n",
    "            dec_idx = [dec_voc[tk] for tk in dec]\n",
    "\n",
    "            # encoder_input\n",
    "            enc_ids.append(torch.tensor(enc_idx))\n",
    "            # decoder_input\n",
    "            dec_ids.append(torch.tensor(dec_idx[:-1]))\n",
    "            # label\n",
    "            labels.append(torch.tensor(dec_idx[1:]))\n",
    "\n",
    "        \n",
    "        # 数据转换张量 [batch, max_token_len]\n",
    "        # 用批次中最长token序列构建张量\n",
    "        enc_input = pad_sequence(enc_ids, batch_first=True)\n",
    "        dec_input = pad_sequence(dec_ids, batch_first=True)\n",
    "        targets = pad_sequence(labels, batch_first=True)\n",
    "\n",
    "        # 返回数据都是模型训练和推理的需要\n",
    "        return enc_input, dec_input, targets\n",
    "\n",
    "    # 返回回调函数\n",
    "    return batch_proc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T12:42:20.580660Z",
     "iopub.status.busy": "2025-04-24T12:42:20.580460Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n",
      "Epoch 1, Loss: 1.8544: 100%|██████████| 3010/3010 [02:31<00:00, 19.88it/s]\n",
      "Epoch 2, Loss: 1.4490: 100%|██████████| 3010/3010 [02:33<00:00, 19.63it/s]\n",
      "Epoch 3, Loss: 1.4256: 100%|██████████| 3010/3010 [02:33<00:00, 19.67it/s]\n",
      "Epoch 4, Loss: 1.5111: 100%|██████████| 3010/3010 [02:34<00:00, 19.50it/s]\n",
      "Epoch 5, Loss: 1.3976:  26%|██▌       | 776/3010 [00:39<01:53, 19.63it/s]"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# 加载训练数据\n",
    "with open('/kaggle/input/couplet/vocab.bin','rb') as f:\n",
    "    evoc,dvoc = pickle.load(f)\n",
    "\n",
    "with open('/kaggle/input/couplet/encoder.json') as f:\n",
    "    enc_data = json.load(f)\n",
    "with open('/kaggle/input/couplet/decoder.json') as f:\n",
    "    dec_data = json.load(f)\n",
    "\n",
    "ds = list(zip(enc_data,dec_data))\n",
    "dl = DataLoader(ds, batch_size=256, shuffle=True, collate_fn=get_proc(evoc, dvoc))\n",
    "\n",
    "# 构建训练模型\n",
    "# 模型构建\n",
    "model = Seq2Seq(\n",
    "    enc_emb_size=len(evoc),\n",
    "    dec_emb_size=len(dvoc),\n",
    "    emb_dim=100,\n",
    "    hidden_size=120,\n",
    "    dropout=0.5,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# 优化器、损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    tpbar = tqdm(dl)\n",
    "    for enc_input, dec_input, targets in tpbar:\n",
    "        enc_input = enc_input.to(device)\n",
    "        dec_input = dec_input.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # 前向传播 \n",
    "        logits, _ = model(enc_input, dec_input)\n",
    "\n",
    "        # 计算损失\n",
    "        # CrossEntropyLoss需要将logits和targets展平\n",
    "        # logits: [batch_size, seq_len, vocab_size]\n",
    "        # targets: [batch_size, seq_len]\n",
    "        # 展平为 [batch_size * seq_len, vocab_size] 和 [batch_size * seq_len]\n",
    "        loss = criterion(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tpbar.set_description(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), '/kaggle/working/seq2seq_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T14:05:19.239037Z",
     "iopub.status.busy": "2025-04-24T14:05:19.238776Z",
     "iopub.status.idle": "2025-04-24T14:05:19.303112Z",
     "shell.execute_reply": "2025-04-24T14:05:19.302092Z",
     "shell.execute_reply.started": "2025-04-24T14:05:19.239018Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "秋冬当日秋霜\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71/3044300002.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/kaggle/working/seq2seq_state.bin')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 加载训练好的模型和词典\n",
    "state_dict = torch.load('/kaggle/working/seq2seq_state.bin')\n",
    "with open('/kaggle/input/couplet/vocab.bin','rb') as f:\n",
    "    evoc,dvoc = pickle.load(f)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    enc_emb_size=len(evoc),\n",
    "    dec_emb_size=len(dvoc),\n",
    "    emb_dim=100,\n",
    "    hidden_size=120,\n",
    "    dropout=0.5,\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "# 创建解码器反向字典\n",
    "dvoc_inv = {v:k for k,v in dvoc.items()}\n",
    "# 用户输入\n",
    "line = '花 梦 粘 于 春 袖 口 '\n",
    "enc_idx = torch.tensor([[evoc.get(tk, evoc['UNK']) for tk in line.split(' ')[:-1]]])\n",
    "\n",
    "# 推理\n",
    "# 最大解码长度=输入长度\n",
    "max_dec_len = len(line.split(' ')[:-1])\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # 编码器\n",
    "    hidden_state = model.encoder(enc_idx)\n",
    "\n",
    "    # 解码器输入 shape [1,1]\n",
    "    dec_input = torch.tensor([[dvoc['BOS']]])\n",
    "\n",
    "    # 循环decoder\n",
    "    dec_tokens = []\n",
    "    while True:\n",
    "        if len(dec_tokens) >= max_dec_len:\n",
    "            break\n",
    "        # 解码器 \n",
    "        # logits: [1,1,dec_voc_size]\n",
    "        logits,hidden_state = model.decoder(dec_input, hidden_state)\n",
    "        # logits,hidden_state = model.decoder(dec_input, hidden_state, enc_outputs)\n",
    "        \n",
    "        # 下个token index\n",
    "        next_token = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        if dvoc_inv[next_token.squeeze().item()] == 'EOS':\n",
    "            break\n",
    "        # 收集每次token_index 【解码集合】\n",
    "        dec_tokens.append(next_token.squeeze().item())\n",
    "        # decoder的下一个输入 = token_index\n",
    "        dec_input = next_token\n",
    "        hidden_state = hidden_state.view(1, -1)\n",
    "# 输出解码结果\n",
    "print(''.join([dvoc_inv[tk] for tk in dec_tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T14:07:01.368903Z",
     "iopub.status.busy": "2025-04-24T14:07:01.368643Z",
     "iopub.status.idle": "2025-04-24T14:07:01.432165Z",
     "shell.execute_reply": "2025-04-24T14:07:01.431628Z",
     "shell.execute_reply.started": "2025-04-24T14:07:01.368884Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71/3159156385.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('/kaggle/working/seq2seq_state.bin')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "# 加载训练好的模型和词典\n",
    "state_dict = torch.load('/kaggle/working/seq2seq_state.bin')\n",
    "with open('/kaggle/input/couplet/vocab.bin','rb') as f:\n",
    "    evoc,dvoc = pickle.load(f)\n",
    "\n",
    "model = Seq2Seq(\n",
    "    enc_emb_size=len(evoc),\n",
    "    dec_emb_size=len(dvoc),\n",
    "    emb_dim=100,\n",
    "    hidden_size=120,\n",
    "    dropout=0.5,\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 创建解码器反向字典\n",
    "dvoc_inv = {v:k for k,v in dvoc.items()}\n",
    "\n",
    "def test(in_file):\n",
    "    with open(in_file,'r',encoding='utf-8') as f, open('/kaggle/working/test_out.txt','w',encoding='utf-8') as w:\n",
    "        lines = f.read().split('\\n')\n",
    "        for line in lines:\n",
    "            #空数据排除\n",
    "            if line == '':\n",
    "                continue\n",
    "            # 用户输入\n",
    "            enc_idx = torch.tensor([[evoc.get(tk, evoc['UNK']) for tk in line.split(' ')[:-1]]])\n",
    "\n",
    "            # 推理\n",
    "            # 最大解码长度=输入长度\n",
    "            max_dec_len = len(line.split(' ')[:-1])\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # 编码器\n",
    "                hidden_state = model.encoder(enc_idx)\n",
    "\n",
    "                # 解码器输入 shape [1,1]\n",
    "                dec_input = torch.tensor([[dvoc['BOS']]])\n",
    "\n",
    "                # 循环decoder\n",
    "                dec_tokens = []\n",
    "                while True:\n",
    "                    if len(dec_tokens) >= max_dec_len:\n",
    "                        break\n",
    "                    # 解码器 \n",
    "                    # logits: [1,1,dec_voc_size]\n",
    "                    logits,hidden_state = model.decoder(dec_input, hidden_state)\n",
    "                    # logits,hidden_state = model.decoder(dec_input, hidden_state, enc_outputs)\n",
    "                    \n",
    "                    # 下个token index\n",
    "                    next_token = torch.argmax(logits, dim=-1)\n",
    "\n",
    "                    if dvoc_inv[next_token.squeeze().item()] == 'EOS':\n",
    "                        break\n",
    "                    # 收集每次token_index 【解码集合】\n",
    "                    dec_tokens.append(next_token.squeeze().item())\n",
    "                    # decoder的下一个输入 = token_index\n",
    "                    dec_input = next_token\n",
    "                    hidden_state = hidden_state.view(1, -1)\n",
    "\n",
    "            # 输出解码结果\n",
    "            w.write(''.join([dvoc_inv[tk] for tk in dec_tokens]))\n",
    "            w.write('\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T14:07:06.600820Z",
     "iopub.status.busy": "2025-04-24T14:07:06.600575Z",
     "iopub.status.idle": "2025-04-24T14:07:30.250604Z",
     "shell.execute_reply": "2025-04-24T14:07:30.249536Z",
     "shell.execute_reply.started": "2025-04-24T14:07:06.600803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test('/kaggle/input/testdate/in.txt')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7240138,
     "sourceId": 11545133,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7241242,
     "sourceId": 11546953,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
