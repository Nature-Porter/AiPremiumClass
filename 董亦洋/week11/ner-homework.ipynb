{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:35.435880Z","iopub.execute_input":"2025-05-30T06:17:35.436456Z","iopub.status.idle":"2025-05-30T06:17:35.440787Z","shell.execute_reply.started":"2025-05-30T06:17:35.436435Z","shell.execute_reply":"2025-05-30T06:17:35.440061Z"}},"outputs":[],"execution_count":181},{"cell_type":"code","source":"!pip install evaluate\n!pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:35.458524Z","iopub.execute_input":"2025-05-30T06:17:35.458786Z","iopub.status.idle":"2025-05-30T06:17:41.691898Z","shell.execute_reply.started":"2025-05-30T06:17:35.458769Z","shell.execute_reply":"2025-05-30T06:17:41.690886Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\n","output_type":"stream"}],"execution_count":182},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\nfrom transformers import TrainingArguments, Trainer\nimport torch\nimport evaluate  # pip install evaluate\nimport seqeval   # pip install seqeval\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:41.693494Z","iopub.execute_input":"2025-05-30T06:17:41.693953Z","iopub.status.idle":"2025-05-30T06:17:41.698732Z","shell.execute_reply.started":"2025-05-30T06:17:41.693929Z","shell.execute_reply":"2025-05-30T06:17:41.697982Z"}},"outputs":[],"execution_count":183},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', num_labels=7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:41.699545Z","iopub.execute_input":"2025-05-30T06:17:41.699765Z","iopub.status.idle":"2025-05-30T06:17:41.991955Z","shell.execute_reply.started":"2025-05-30T06:17:41.699744Z","shell.execute_reply":"2025-05-30T06:17:41.991181Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":184},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:41.993656Z","iopub.execute_input":"2025-05-30T06:17:41.993858Z","iopub.status.idle":"2025-05-30T06:17:42.115462Z","shell.execute_reply.started":"2025-05-30T06:17:41.993843Z","shell.execute_reply":"2025-05-30T06:17:42.114685Z"}},"outputs":[],"execution_count":185},{"cell_type":"code","source":"# 加载hf中dataset\nds = load_dataset('doushabao4766/msra_ner_k_V3')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:42.116237Z","iopub.execute_input":"2025-05-30T06:17:42.116469Z","iopub.status.idle":"2025-05-30T06:17:43.668402Z","shell.execute_reply.started":"2025-05-30T06:17:42.116445Z","shell.execute_reply":"2025-05-30T06:17:43.667662Z"}},"outputs":[{"execution_count":186,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\n        num_rows: 45001\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\n        num_rows: 3443\n    })\n})"},"metadata":{}}],"execution_count":186},{"cell_type":"code","source":"# 原始文本转换模型需要token_idx,生成和token_idx对齐label\ndef data_input_proc(item):\n    # 输入文本转换模型输入token索引\n    #print(len(item['tokens']))\n    input_data = {'input_ids': [], 'token_type_ids': [], 'attention_mask': [], 'labels': []}\n    if len(item['tokens']) != 0 and len(item['tokens'])<=512:\n        input_data = tokenizer(item['tokens'], truncation=True, add_special_tokens=False, max_length=1000)\n        #'input_ids', 'token_type_ids', 'attention_mask'\n        input_data['input_ids'] = torch.tensor(input_data['input_ids']).reshape(-1)\n        input_data['token_type_ids'] = torch.tensor(input_data['token_type_ids']).reshape(-1)\n        input_data['attention_mask'] = torch.tensor(input_data['attention_mask']).reshape(-1)\n        input_data['labels'] = torch.tensor(item['ner_tags'])\n        \n    return input_data\n    \n\nds2 = ds.map(data_input_proc, batched=False)  # batched 每次传入自定义方法样本数量多个","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:17:43.669251Z","iopub.execute_input":"2025-05-30T06:17:43.669871Z","iopub.status.idle":"2025-05-30T06:18:31.242031Z","shell.execute_reply.started":"2025-05-30T06:17:43.669852Z","shell.execute_reply":"2025-05-30T06:18:31.241286Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45001 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7921a9b697c2498782999ba4cbc4b2cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3443 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"086b9f740bb0478ba6f5b37a68db7e2d"}},"metadata":{}}],"execution_count":187},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\nds2.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.242924Z","iopub.execute_input":"2025-05-30T06:18:31.243231Z","iopub.status.idle":"2025-05-30T06:18:31.248370Z","shell.execute_reply.started":"2025-05-30T06:18:31.243214Z","shell.execute_reply":"2025-05-30T06:18:31.247631Z"}},"outputs":[],"execution_count":188},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n    num_train_epochs = 3,    # 训练 epoch\n    save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n    per_device_train_batch_size=32,  # 训练批次\n    per_device_eval_batch_size=32,\n    report_to='tensorboard',  # 训练输出记录\n    eval_strategy=\"epoch\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.249204Z","iopub.execute_input":"2025-05-30T06:18:31.249533Z","iopub.status.idle":"2025-05-30T06:18:31.296172Z","shell.execute_reply.started":"2025-05-30T06:18:31.249508Z","shell.execute_reply":"2025-05-30T06:18:31.295375Z"}},"outputs":[],"execution_count":189},{"cell_type":"code","source":"id2lbl = {'0': 'O','1': 'B-PER','2': 'I-PER','3': 'B-ORG','4': 'I-ORG','5': 'B-LOC','6': 'I-LOC'}\nlbl2id = {id2lbl[tag]:tag for tag in id2lbl}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.297025Z","iopub.execute_input":"2025-05-30T06:18:31.297283Z","iopub.status.idle":"2025-05-30T06:18:31.301249Z","shell.execute_reply.started":"2025-05-30T06:18:31.297257Z","shell.execute_reply":"2025-05-30T06:18:31.300547Z"}},"outputs":[],"execution_count":190},{"cell_type":"code","source":"# metric 方法\ndef compute_metric(result):\n    # result 是一个tuple (predicts, labels)\n    \n    # 获取评估对象\n    seqeval = evaluate.load('seqeval')\n    predicts,labels = result\n    predicts = np.argmax(predicts, axis=2)\n    \n    # 准备评估数据\n    predicts = [[id2lbl[str(p)] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    labels = [[id2lbl[str(l)] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    results = seqeval.compute(predictions=predicts, references=labels)\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.507183Z","iopub.execute_input":"2025-05-30T06:18:31.507632Z","iopub.status.idle":"2025-05-30T06:18:31.520668Z","shell.execute_reply.started":"2025-05-30T06:18:31.507614Z","shell.execute_reply":"2025-05-30T06:18:31.520051Z"}},"outputs":[],"execution_count":193},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\nds2.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.521364Z","iopub.execute_input":"2025-05-30T06:18:31.521618Z","iopub.status.idle":"2025-05-30T06:18:31.535116Z","shell.execute_reply.started":"2025-05-30T06:18:31.521598Z","shell.execute_reply":"2025-05-30T06:18:31.534390Z"}},"outputs":[],"execution_count":194},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=ds2['train'],\n    eval_dataset=ds2['test'],\n    data_collator=data_collator,\n    compute_metrics=compute_metric\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:48.248978Z","iopub.execute_input":"2025-05-30T06:18:48.249260Z","iopub.status.idle":"2025-05-30T06:18:48.422174Z","shell.execute_reply.started":"2025-05-30T06:18:48.249232Z","shell.execute_reply":"2025-05-30T06:18:48.421379Z"}},"outputs":[],"execution_count":196},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n                                                        num_labels=len(id2lbl),\n                                                        id2label=id2lbl,\n                                                        label2id=lbl2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:31.303391Z","iopub.execute_input":"2025-05-30T06:18:31.303564Z","iopub.status.idle":"2025-05-30T06:18:31.500712Z","shell.execute_reply.started":"2025-05-30T06:18:31.303551Z","shell.execute_reply":"2025-05-30T06:18:31.500192Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":191},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T06:18:48.423385Z","iopub.execute_input":"2025-05-30T06:18:48.423569Z","iopub.status.idle":"2025-05-30T06:51:00.356951Z","shell.execute_reply.started":"2025-05-30T06:18:48.423554Z","shell.execute_reply":"2025-05-30T06:51:00.356283Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4221' max='4221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4221/4221 32:10, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc</th>\n      <th>Org</th>\n      <th>Per</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.032100</td>\n      <td>0.028132</td>\n      <td>{'precision': 0.9365994236311239, 'recall': 0.9229676961306355, 'f1': 0.9297335955658859, 'number': 2817}</td>\n      <td>{'precision': 0.836940836940837, 'recall': 0.8875286916602907, 'f1': 0.8614927590048272, 'number': 1307}</td>\n      <td>{'precision': 0.9416484318016046, 'recall': 0.9591381872213968, 'f1': 0.9503128450496872, 'number': 1346}</td>\n      <td>0.912886</td>\n      <td>0.923400</td>\n      <td>0.918113</td>\n      <td>0.991808</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.013500</td>\n      <td>0.027744</td>\n      <td>{'precision': 0.9568810636004312, 'recall': 0.9453319133830316, 'f1': 0.9510714285714286, 'number': 2817}</td>\n      <td>{'precision': 0.8632416787264834, 'recall': 0.9127773527161438, 'f1': 0.8873187058386016, 'number': 1307}</td>\n      <td>{'precision': 0.9587628865979382, 'recall': 0.9673105497771174, 'f1': 0.9630177514792899, 'number': 1346}</td>\n      <td>0.933913</td>\n      <td>0.942962</td>\n      <td>0.938415</td>\n      <td>0.993157</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.005600</td>\n      <td>0.031963</td>\n      <td>{'precision': 0.9534717251252685, 'recall': 0.9456869009584664, 'f1': 0.9495633576902512, 'number': 2817}</td>\n      <td>{'precision': 0.8826568265682657, 'recall': 0.9150726855394032, 'f1': 0.8985725018782871, 'number': 1307}</td>\n      <td>{'precision': 0.9529411764705882, 'recall': 0.962852897473997, 'f1': 0.9578713968957872, 'number': 1346}</td>\n      <td>0.935923</td>\n      <td>0.942596</td>\n      <td>0.939248</td>\n      <td>0.993336</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'precision': 0.9365994236311239, 'recall': 0.9229676961306355, 'f1': 0.9297335955658859, 'number': 2817}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.836940836940837, 'recall': 0.8875286916602907, 'f1': 0.8614927590048272, 'number': 1307}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9416484318016046, 'recall': 0.9591381872213968, 'f1': 0.9503128450496872, 'number': 1346}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9568810636004312, 'recall': 0.9453319133830316, 'f1': 0.9510714285714286, 'number': 2817}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8632416787264834, 'recall': 0.9127773527161438, 'f1': 0.8873187058386016, 'number': 1307}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9587628865979382, 'recall': 0.9673105497771174, 'f1': 0.9630177514792899, 'number': 1346}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9534717251252685, 'recall': 0.9456869009584664, 'f1': 0.9495633576902512, 'number': 2817}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8826568265682657, 'recall': 0.9150726855394032, 'f1': 0.8985725018782871, 'number': 1307}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9529411764705882, 'recall': 0.962852897473997, 'f1': 0.9578713968957872, 'number': 1346}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":197,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4221, training_loss=0.022319054326805508, metrics={'train_runtime': 1931.0917, 'train_samples_per_second': 69.91, 'train_steps_per_second': 2.186, 'total_flos': 9129562022390832.0, 'train_loss': 0.022319054326805508, 'epoch': 3.0})"},"metadata":{}}],"execution_count":197},{"cell_type":"code","source":"result = trainer.predict(ds2['test'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:13:26.994578Z","iopub.execute_input":"2025-05-30T08:13:26.994853Z","iopub.status.idle":"2025-05-30T08:13:45.967109Z","shell.execute_reply.started":"2025-05-30T08:13:26.994831Z","shell.execute_reply":"2025-05-30T08:13:45.966386Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":317},{"cell_type":"code","source":"print(ds['test'][0]['tokens'])\nprint(ds2['test'][0]['labels'])\nprint(result.label_ids[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T08:22:48.572758Z","iopub.execute_input":"2025-05-30T08:22:48.573342Z","iopub.status.idle":"2025-05-30T08:22:48.581784Z","shell.execute_reply.started":"2025-05-30T08:22:48.573320Z","shell.execute_reply":"2025-05-30T08:22:48.580959Z"}},"outputs":[{"name":"stdout","text":"['中', '共', '中', '央', '致', '中', '国', '致', '公', '党', '十', '一', '大', '的', '贺', '词', '各', '位', '代', '表', '、', '各', '位', '同', '志', '：', '在', '中', '国', '致', '公', '党', '第', '十', '一', '次', '全', '国', '代', '表', '大', '会', '隆', '重', '召', '开', '之', '际', '，', '中', '国', '共', '产', '党', '中', '央', '委', '员', '会', '谨', '向', '大', '会', '表', '示', '热', '烈', '的', '祝', '贺', '，', '向', '致', '公', '党', '的', '同', '志', '们', '致', '以', '亲', '切', '的', '问', '候', '！']\ntensor([3, 4, 4, 4, 0, 3, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0,\n        0, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n[   3    4    4    4    0    3    4    4    4    4    4    4    4    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    3\n    4    4    4    4    4    4    4    4    4    4    4    4    4    4\n    0    0    0    0    0    0    0    3    4    4    4    4    4    4\n    4    4    4    0    0    0    0    0    0    0    0    0    0    0\n    0    0    3    4    4    0    0    0    0    0    0    0    0    0\n    0    0    0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n -100 -100 -100 -100 -100 -100 -100 -100]\n","output_type":"stream"}],"execution_count":329},{"cell_type":"code","source":"#输入：“双方确定了今后发展中美关系的指导方针。”\n#输出：[{\"entity\":\"ORG\",\"content\":\"中\"},{\"entity\":\"ORG\",\"content\":\"美\"}]\n#{'0': 'O','1': 'B-PER','2': 'I-PER','3': 'B-ORG','4': 'I-ORG','5': 'B-LOC','6': 'I-LOC'}\ndef ner_func(sentense, id2lbl=id2lbl):\n    l_s = list(sentense)\n    input_data = tokenizer(l_s, truncation=True, add_special_tokens=False, max_length=512)\n    input_data['input_ids'] = torch.tensor(input_data['input_ids']).reshape(-1)\n    input_data['token_type_ids'] = torch.tensor(input_data['token_type_ids']).reshape(-1)\n    input_data['attention_mask'] = torch.tensor(input_data['attention_mask']).reshape(-1)\n    #input_data['labels'] = torch.zeros(len(sentense))\n    #print([input_data])\n    result = trainer.predict([input_data])\n    #print(torch.tensor(result.predictions).reshape(-1,7))\n    #print(torch.max(torch.tensor(result.predictions).reshape(-1,7),1))\n    label_ids = torch.max(torch.tensor(result.predictions).reshape(-1,7),1).indices\n    #print(result.predictions)\n    #print(label_ids)\n    out = []\n    for i in range(len(label_ids)):\n        key = label_ids[i].item()\n        if(key != 0):\n            label = id2lbl[str(key)][2:]\n            out.append({\"entity\":id2lbl[str(key)][2:],\"content\":l_s[i]})\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T10:01:12.645490Z","iopub.execute_input":"2025-05-30T10:01:12.646105Z","iopub.status.idle":"2025-05-30T10:01:12.651984Z","shell.execute_reply.started":"2025-05-30T10:01:12.646083Z","shell.execute_reply":"2025-05-30T10:01:12.651231Z"}},"outputs":[],"execution_count":434},{"cell_type":"code","source":"i = ner_func(\"双方确定了今后发展中美关系的指导方针。\")\ni","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T10:01:14.867032Z","iopub.execute_input":"2025-05-30T10:01:14.867300Z","iopub.status.idle":"2025-05-30T10:01:14.888714Z","shell.execute_reply.started":"2025-05-30T10:01:14.867280Z","shell.execute_reply":"2025-05-30T10:01:14.888154Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":435,"output_type":"execute_result","data":{"text/plain":"[{'entity': 'LOC', 'content': '中'}, {'entity': 'LOC', 'content': '美'}]"},"metadata":{}}],"execution_count":435}]}
