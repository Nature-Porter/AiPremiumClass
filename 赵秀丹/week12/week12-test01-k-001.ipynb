{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"###利用上周NER模型训练任务代码，复现课堂案例中：动态学习率、混合精度、DDP训练实现。","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 升级numpy（如果cesium已兼容numpy 2.0+）\n!pip install numpy>=2.0\n\n# 降级rich\n!pip install rich<14\n\n# 降级所有NVIDIA CUDA库（根据torch 2.6.0+cu124的要求）\n!pip install nvidia-cublas-cu12==12.4.5.8 \\\n            nvidia-cudnn-cu12==9.1.0.70 \\\n            nvidia-cufft-cu12==11.2.1.3 \\\n            nvidia-curand-cu12==10.3.5.147 \\\n            nvidia-cusolver-cu12==11.6.1.9 \\\n            nvidia-cusparse-cu12==12.3.1.170 \\\n            nvidia-nvjitlink-cu12==12.4.127\n\n# 升级fsspec\n!pip install fsspec==2025.3.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:00:25.553267Z","iopub.execute_input":"2025-06-12T11:00:25.553535Z","iopub.status.idle":"2025-06-12T11:01:45.292915Z","shell.execute_reply.started":"2025-06-12T11:00:25.553514Z","shell.execute_reply":"2025-06-12T11:01:45.291971Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: 14: No such file or directory\nCollecting nvidia-cublas-cu12==12.4.5.8\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting fsspec==2025.3.2\n  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\nDownloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.0\n    Uninstalling fsspec-2025.3.0:\n      Successfully uninstalled fsspec-2025.3.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip -q install evaluate seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:02:16.588482Z","iopub.execute_input":"2025-06-12T11:02:16.589240Z","iopub.status.idle":"2025-06-12T11:02:20.004896Z","shell.execute_reply.started":"2025-06-12T11:02:16.589206Z","shell.execute_reply":"2025-06-12T11:02:20.003957Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile week12_01_ner_ddp.py\n\nimport os\nimport numpy as np\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\nfrom transformers import TrainingArguments, Trainer\nimport torch\nimport evaluate  # pip install evaluate\nimport seqeval   # pip install seqeval\nfrom datasets import load_dataset\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\n\n# 设置分布式环境\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\n# 清理分布式环境\ndef cleanup():\n    dist.destroy_process_group()\n    \n\ndef train(rank, world_size):\n    setup(rank, world_size)\n    # 数据集\n    ds = load_dataset(\"doushabao4766/msra_ner_k_V3\")\n    tokenizer=AutoTokenizer.from_pretrained('bert-base-chinese')\n\n    ##entity_index\n    entites=['0','PER','ORG','LOC']\n    tags=['0']\n    for entity in entites[1:]:\n        tags.append('B-'+entity.upper())\n        tags.append('I-'+entity.upper())\n    entity_index={entity:i for i,entity in enumerate(entites)}\n\n    \n    \n    def data_input_proc(item):\n        # 输入文本先拆分为字符，再转换为模型输入的token索引\n        # batch_texts = [list(text) for text in item['text']]\n        # 导入拆分为字符的文本列表时，需要设置参数is_split_into_words=True\n        input_data=tokenizer(item['tokens'],\n                         truncation=True,\n                         add_special_tokens=False,\n                         max_length=512,\n                         is_split_into_words=True, ###所有文本都拆分成字符列表\n                            return_offsets_mapping=True)\n        labels=[lbl[:512] for lbl in item['ner_tags']] ##截断超过512的标签\n        input_data['labels']=labels\n        return input_data\n\n    ds2 = ds.map(data_input_proc, batched=True)  # batch_size 1000\n    \n    \n    local_rank = rank\n    \n    id2lbl = {i:tag for i, tag in enumerate(tags)}\n    lbl2id = {tag:i for i, tag in enumerate(tags)}\n    \n    model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n                                                            num_labels=7,\n                                                            id2label=id2lbl,\n                                                            label2id=lbl2id)\n    model.to(local_rank)\n    \n    args = TrainingArguments(\n        output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n        num_train_epochs = 3,    # 训练 epoch\n        save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n        per_device_train_batch_size=8,  # 训练批次\n        per_device_eval_batch_size=16,\n        report_to='tensorboard',  # 训练输出记录\n        eval_strategy=\"epoch\",\n        local_rank=local_rank,   # 当前进程 RANK\n        fp16=True,               # 使用混合精度\n        lr_scheduler_type='linear',  # 动态学习率\n        warmup_steps=100,        # 预热步数\n        ddp_find_unused_parameters=False  # 优化DDP性能\n    )\n    \n    def compute_metric(result):\n        # result 是一个tuple (predicts, labels)\n        \n        # 获取评估对象\n        seqeval = evaluate.load('seqeval')\n        predicts,labels = result\n        predicts = np.argmax(predicts, axis=2)\n        \n        # 准备评估数据\n        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                     for ps,ls in zip(predicts,labels)]\n        results = seqeval.compute(predictions=predicts, references=labels)\n    \n        return results\n    \n    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n    \n    trainer = Trainer(\n        model,\n        args,\n        train_dataset=ds2['train'],\n        eval_dataset=ds2['test'],\n        data_collator=data_collator,\n        compute_metrics=compute_metric\n    )\n    \n    trainer.train()\n    cleanup()\n\ndef main():\n    world_size = torch.cuda.device_count()\n    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:20:52.715036Z","iopub.execute_input":"2025-06-12T11:20:52.715797Z","iopub.status.idle":"2025-06-12T11:20:52.722385Z","shell.execute_reply.started":"2025-06-12T11:20:52.715765Z","shell.execute_reply":"2025-06-12T11:20:52.721771Z"}},"outputs":[{"name":"stdout","text":"Overwriting week12_01_ner_ddp.py\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!python week12_01_ner_ddp.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T11:20:57.464156Z","iopub.execute_input":"2025-06-12T11:20:57.464798Z","iopub.status.idle":"2025-06-12T12:54:25.299400Z","shell.execute_reply.started":"2025-06-12T11:20:57.464778Z","shell.execute_reply":"2025-06-12T12:54:25.298440Z"}},"outputs":[{"name":"stdout","text":"2025-06-12 11:21:02.327581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749727262.350854    1577 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749727262.358033    1577 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-12 11:21:11.907329: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749727271.932015    1592 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749727271.938984    1592 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-06-12 11:21:12.146490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749727272.168084    1591 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749727272.175506    1591 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[W612 11:21:15.544027778 socket.cpp:759] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\ntorch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\ntorch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n  0%|                                                  | 0/8439 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.1353, 'grad_norm': 147811.046875, 'learning_rate': 4.760762681376664e-05, 'epoch': 0.18}\n{'loss': 0.1476, 'grad_norm': 60204.703125, 'learning_rate': 4.760762681376664e-05, 'epoch': 0.18}\n  6%|██▎                                   | 500/8439 [05:41<1:27:38,  1.51it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0495, 'grad_norm': 302392.5625, 'learning_rate': 4.46096654275093e-05, 'epoch': 0.36}\n{'loss': 0.0496, 'grad_norm': 247482.78125, 'learning_rate': 4.46096654275093e-05, 'epoch': 0.36}\n 12%|████▍                                | 1000/8439 [11:15<1:29:35,  1.38it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0394, 'grad_norm': 138270.25, 'learning_rate': 4.161170404125195e-05, 'epoch': 0.53}\n{'loss': 0.0354, 'grad_norm': 143562.25, 'learning_rate': 4.161170404125195e-05, 'epoch': 0.53}\n 18%|██████▌                              | 1500/8439 [16:46<1:17:14,  1.50it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0349, 'grad_norm': 111108.1953125, 'learning_rate': 3.861374265499461e-05, 'epoch': 0.71}\n{'loss': 0.0311, 'grad_norm': 39945.796875, 'learning_rate': 3.861374265499461e-05, 'epoch': 0.71}\n 24%|████████▊                            | 2000/8439 [22:21<1:08:50,  1.56it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0334, 'grad_norm': 40984.06640625, 'learning_rate': 3.5615781268737256e-05, 'epoch': 0.89}\n{'loss': 0.0358, 'grad_norm': 41632.72265625, 'learning_rate': 3.5615781268737256e-05, 'epoch': 0.89}\n 30%|██████████▉                          | 2500/8439 [28:04<1:03:37,  1.56it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 33%|█████████████                          | 2813/8439 [31:32<54:24,  1.72it/s]\n  0%|                                                   | 0/108 [00:00<?, ?it/s]\u001b[A\n  0%|                                                   | 0/108 [00:00<?, ?it/s]\u001b[A\n  2%|▊                                          | 2/108 [00:00<00:16,  6.61it/s]\u001b[A\n  2%|▊                                          | 2/108 [00:00<00:17,  5.98it/s]\u001b[A\n  3%|█▏                                         | 3/108 [00:00<00:22,  4.64it/s]\u001b[A\n  3%|█▏                                         | 3/108 [00:00<00:25,  4.10it/s]\u001b[A\n  4%|█▌                                         | 4/108 [00:01<00:33,  3.11it/s]\u001b[A\n  4%|█▌                                         | 4/108 [00:01<00:34,  2.99it/s]\u001b[A\n  5%|█▉                                         | 5/108 [00:01<00:34,  2.99it/s]\u001b[A\n  5%|█▉                                         | 5/108 [00:01<00:37,  2.77it/s]\u001b[A\n  6%|██▍                                        | 6/108 [00:01<00:33,  3.06it/s]\u001b[A\n  6%|██▍                                        | 6/108 [00:01<00:33,  3.05it/s]\u001b[A\n  6%|██▊                                        | 7/108 [00:02<00:38,  2.62it/s]\u001b[A\n  6%|██▊                                        | 7/108 [00:02<00:38,  2.64it/s]\u001b[A\n  7%|███▏                                       | 8/108 [00:02<00:41,  2.39it/s]\u001b[A\n  7%|███▏                                       | 8/108 [00:02<00:42,  2.37it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:03<00:39,  2.50it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:03<00:41,  2.36it/s]\u001b[A\n  9%|███▉                                      | 10/108 [00:03<00:37,  2.59it/s]\u001b[A\n  9%|███▉                                      | 10/108 [00:03<00:38,  2.55it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:03<00:36,  2.65it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:03<00:36,  2.64it/s]\u001b[A\n 11%|████▋                                     | 12/108 [00:04<00:36,  2.61it/s]\u001b[A\n 11%|████▋                                     | 12/108 [00:04<00:36,  2.65it/s]\u001b[A\n 12%|█████                                     | 13/108 [00:04<00:35,  2.69it/s]\u001b[A\n 12%|█████                                     | 13/108 [00:04<00:35,  2.68it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:04<00:34,  2.70it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:05<00:34,  2.75it/s]\u001b[A\n 14%|█████▊                                    | 15/108 [00:05<00:34,  2.69it/s]\u001b[A\n 14%|█████▊                                    | 15/108 [00:05<00:34,  2.70it/s]\u001b[A\n 15%|██████▏                                   | 16/108 [00:06<00:58,  1.57it/s]\u001b[A\n 15%|██████▏                                   | 16/108 [00:06<00:58,  1.58it/s]\u001b[A\n 16%|██████▌                                   | 17/108 [00:07<00:55,  1.64it/s]\u001b[A\n 16%|██████▌                                   | 17/108 [00:07<00:55,  1.65it/s]\u001b[A\n 17%|███████                                   | 18/108 [00:07<00:45,  1.97it/s]\u001b[A\n 17%|███████                                   | 18/108 [00:07<00:44,  2.01it/s]\u001b[A\n 18%|███████▍                                  | 19/108 [00:07<00:44,  2.00it/s]\u001b[A\n 18%|███████▍                                  | 19/108 [00:07<00:44,  2.02it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:08<00:45,  1.93it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:08<00:45,  1.95it/s]\u001b[A\n 19%|████████▏                                 | 21/108 [00:08<00:37,  2.32it/s]\u001b[A\n 19%|████████▏                                 | 21/108 [00:08<00:36,  2.37it/s]\u001b[A\n 20%|████████▌                                 | 22/108 [00:08<00:33,  2.58it/s]\u001b[A\n 20%|████████▌                                 | 22/108 [00:08<00:33,  2.59it/s]\u001b[A\n 21%|████████▉                                 | 23/108 [00:09<00:31,  2.70it/s]\u001b[A\n 21%|████████▉                                 | 23/108 [00:09<00:34,  2.48it/s]\u001b[A\n 22%|█████████▎                                | 24/108 [00:09<00:31,  2.68it/s]\u001b[A\n 22%|█████████▎                                | 24/108 [00:09<00:31,  2.68it/s]\u001b[A\n 23%|█████████▋                                | 25/108 [00:10<00:39,  2.09it/s]\u001b[A\n 23%|█████████▋                                | 25/108 [00:10<00:41,  1.98it/s]\u001b[A\n 24%|██████████                                | 26/108 [00:10<00:34,  2.36it/s]\u001b[A\n 24%|██████████                                | 26/108 [00:10<00:35,  2.31it/s]\u001b[A\n 25%|██████████▌                               | 27/108 [00:11<00:32,  2.46it/s]\u001b[A\n 25%|██████████▌                               | 27/108 [00:11<00:33,  2.43it/s]\u001b[A\n 26%|██████████▉                               | 28/108 [00:11<00:31,  2.52it/s]\u001b[A\n 26%|██████████▉                               | 28/108 [00:11<00:32,  2.49it/s]\u001b[A\n 27%|███████████▎                              | 29/108 [00:12<00:38,  2.06it/s]\u001b[A\n 27%|███████████▎                              | 29/108 [00:12<00:38,  2.04it/s]\u001b[A\n 28%|███████████▋                              | 30/108 [00:12<00:34,  2.28it/s]\u001b[A\n 28%|███████████▋                              | 30/108 [00:12<00:33,  2.34it/s]\u001b[A\n 29%|████████████                              | 31/108 [00:13<00:42,  1.80it/s]\u001b[A\n 29%|████████████                              | 31/108 [00:13<00:41,  1.84it/s]\u001b[A\n 30%|████████████▍                             | 32/108 [00:13<00:45,  1.68it/s]\u001b[A\n 30%|████████████▍                             | 32/108 [00:14<00:44,  1.70it/s]\u001b[A\n 31%|████████████▊                             | 33/108 [00:14<00:37,  1.98it/s]\u001b[A\n 31%|████████████▊                             | 33/108 [00:14<00:37,  2.03it/s]\u001b[A\n 31%|█████████████▏                            | 34/108 [00:14<00:31,  2.32it/s]\u001b[A\n 31%|█████████████▏                            | 34/108 [00:14<00:30,  2.41it/s]\u001b[A\n 32%|█████████████▌                            | 35/108 [00:14<00:31,  2.34it/s]\u001b[A\n 32%|█████████████▌                            | 35/108 [00:14<00:31,  2.35it/s]\u001b[A\n 33%|██████████████                            | 36/108 [00:15<00:27,  2.58it/s]\u001b[A\n 33%|██████████████                            | 36/108 [00:15<00:27,  2.57it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:15<00:25,  2.82it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:15<00:24,  2.90it/s]\u001b[A\n 35%|██████████████▊                           | 38/108 [00:15<00:22,  3.09it/s]\u001b[A\n 35%|██████████████▊                           | 38/108 [00:15<00:22,  3.14it/s]\u001b[A\n 36%|███████████████▏                          | 39/108 [00:15<00:20,  3.37it/s]\u001b[A\n 36%|███████████████▏                          | 39/108 [00:16<00:19,  3.49it/s]\u001b[A\n 37%|███████████████▌                          | 40/108 [00:16<00:20,  3.27it/s]\u001b[A\n 37%|███████████████▌                          | 40/108 [00:16<00:20,  3.34it/s]\u001b[A\n 38%|███████████████▉                          | 41/108 [00:16<00:19,  3.46it/s]\u001b[A\n 38%|███████████████▉                          | 41/108 [00:16<00:19,  3.48it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:17<00:22,  2.90it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:17<00:23,  2.84it/s]\u001b[A\n 40%|████████████████▋                         | 43/108 [00:17<00:24,  2.67it/s]\u001b[A\n 40%|████████████████▋                         | 43/108 [00:17<00:24,  2.66it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:17<00:21,  2.94it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:17<00:21,  2.96it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:18<00:19,  3.18it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:18<00:19,  3.19it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:18<00:24,  2.57it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:18<00:24,  2.54it/s]\u001b[A\n 44%|██████████████████▎                       | 47/108 [00:18<00:24,  2.50it/s]\u001b[A\n 44%|██████████████████▎                       | 47/108 [00:19<00:24,  2.48it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:19<00:25,  2.33it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:19<00:25,  2.32it/s]\u001b[A\n 45%|███████████████████                       | 49/108 [00:20<00:27,  2.13it/s]\u001b[A\n 45%|███████████████████                       | 49/108 [00:20<00:27,  2.12it/s]\u001b[A\n 46%|███████████████████▍                      | 50/108 [00:20<00:26,  2.18it/s]\u001b[A\n 46%|███████████████████▍                      | 50/108 [00:20<00:29,  1.98it/s]\u001b[A\n 47%|███████████████████▊                      | 51/108 [00:20<00:25,  2.21it/s]\u001b[A\n 47%|███████████████████▊                      | 51/108 [00:21<00:27,  2.08it/s]\u001b[A\n 48%|████████████████████▏                     | 52/108 [00:22<00:38,  1.44it/s]\u001b[A\n 48%|████████████████████▏                     | 52/108 [00:22<00:39,  1.40it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:22<00:35,  1.54it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:22<00:37,  1.48it/s]\u001b[A\n 50%|█████████████████████                     | 54/108 [00:23<00:30,  1.75it/s]\u001b[A\n 50%|█████████████████████                     | 54/108 [00:23<00:31,  1.74it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:23<00:27,  1.96it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:23<00:26,  1.99it/s]\u001b[A\n 52%|█████████████████████▊                    | 56/108 [00:23<00:23,  2.24it/s]\u001b[A\n 52%|█████████████████████▊                    | 56/108 [00:23<00:21,  2.41it/s]\u001b[A\n 53%|██████████████████████▏                   | 57/108 [00:24<00:20,  2.47it/s]\u001b[A\n 53%|██████████████████████▏                   | 57/108 [00:24<00:18,  2.70it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:24<00:19,  2.58it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:24<00:18,  2.66it/s]\u001b[A\n 55%|██████████████████████▉                   | 59/108 [00:24<00:20,  2.43it/s]\u001b[A\n 55%|██████████████████████▉                   | 59/108 [00:24<00:19,  2.48it/s]\u001b[A\n 56%|███████████████████████▎                  | 60/108 [00:25<00:25,  1.85it/s]\u001b[A\n 56%|███████████████████████▎                  | 60/108 [00:25<00:25,  1.89it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:26<00:21,  2.15it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:26<00:21,  2.16it/s]\u001b[A\n 57%|████████████████████████                  | 62/108 [00:26<00:21,  2.19it/s]\u001b[A\n 57%|████████████████████████                  | 62/108 [00:26<00:20,  2.21it/s]\u001b[A\n 58%|████████████████████████▌                 | 63/108 [00:26<00:17,  2.54it/s]\u001b[A\n 58%|████████████████████████▌                 | 63/108 [00:26<00:17,  2.61it/s]\u001b[A\n 59%|████████████████████████▉                 | 64/108 [00:27<00:28,  1.54it/s]\u001b[A\n 59%|████████████████████████▉                 | 64/108 [00:27<00:28,  1.56it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:28<00:23,  1.86it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:28<00:23,  1.84it/s]\u001b[A\n 61%|█████████████████████████▋                | 66/108 [00:28<00:21,  1.97it/s]\u001b[A\n 61%|█████████████████████████▋                | 66/108 [00:28<00:21,  1.95it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:28<00:17,  2.28it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:28<00:17,  2.31it/s]\u001b[A\n 63%|██████████████████████████▍               | 68/108 [00:29<00:15,  2.65it/s]\u001b[A\n 63%|██████████████████████████▍               | 68/108 [00:29<00:14,  2.73it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:29<00:13,  2.95it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:29<00:13,  2.99it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:29<00:12,  2.98it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:29<00:12,  3.01it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:30<00:12,  2.89it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:30<00:12,  2.90it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:30<00:13,  2.68it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:30<00:14,  2.56it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:30<00:12,  2.80it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:30<00:12,  2.79it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:31<00:13,  2.60it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:31<00:13,  2.61it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:31<00:13,  2.50it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:31<00:13,  2.48it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:32<00:11,  2.81it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:32<00:11,  2.89it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:32<00:10,  2.87it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:32<00:10,  2.88it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:32<00:09,  3.17it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:32<00:09,  3.25it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:32<00:08,  3.30it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:32<00:09,  3.16it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:33<00:13,  2.01it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:33<00:14,  1.98it/s]\u001b[A\n 75%|███████████████████████████████▌          | 81/108 [00:34<00:13,  2.03it/s]\u001b[A\n 75%|███████████████████████████████▌          | 81/108 [00:34<00:13,  2.00it/s]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:34<00:11,  2.20it/s]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:34<00:11,  2.17it/s]\u001b[A\n 77%|████████████████████████████████▎         | 83/108 [00:35<00:12,  1.98it/s]\u001b[A\n 77%|████████████████████████████████▎         | 83/108 [00:35<00:12,  1.99it/s]\u001b[A\n 78%|████████████████████████████████▋         | 84/108 [00:35<00:10,  2.31it/s]\u001b[A\n 78%|████████████████████████████████▋         | 84/108 [00:35<00:10,  2.35it/s]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:35<00:09,  2.47it/s]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:36<00:09,  2.33it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:36<00:08,  2.57it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:36<00:08,  2.51it/s]\u001b[A\n 81%|█████████████████████████████████▊        | 87/108 [00:36<00:07,  2.94it/s]\u001b[A\n 81%|█████████████████████████████████▊        | 87/108 [00:36<00:07,  2.83it/s]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:36<00:06,  2.94it/s]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:36<00:06,  3.01it/s]\u001b[A\n 82%|██████████████████████████████████▌       | 89/108 [00:37<00:06,  2.81it/s]\u001b[A\n 82%|██████████████████████████████████▌       | 89/108 [00:37<00:06,  2.82it/s]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:37<00:07,  2.38it/s]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:37<00:07,  2.42it/s]\u001b[A\n 84%|███████████████████████████████████▍      | 91/108 [00:38<00:06,  2.70it/s]\u001b[A\n 84%|███████████████████████████████████▍      | 91/108 [00:38<00:05,  2.84it/s]\u001b[A\n 85%|███████████████████████████████████▊      | 92/108 [00:38<00:06,  2.34it/s]\u001b[A\n 85%|███████████████████████████████████▊      | 92/108 [00:38<00:06,  2.39it/s]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:38<00:05,  2.56it/s]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:38<00:05,  2.61it/s]\u001b[A\n 87%|████████████████████████████████████▌     | 94/108 [00:39<00:04,  2.89it/s]\u001b[A\n 87%|████████████████████████████████████▌     | 94/108 [00:39<00:04,  2.96it/s]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:39<00:04,  3.04it/s]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:39<00:04,  3.16it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:39<00:03,  3.26it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:39<00:03,  3.31it/s]\u001b[A\n 90%|█████████████████████████████████████▋    | 97/108 [00:39<00:03,  3.58it/s]\u001b[A\n 90%|█████████████████████████████████████▋    | 97/108 [00:39<00:02,  3.70it/s]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:40<00:02,  3.72it/s]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:40<00:02,  3.76it/s]\u001b[A\n 92%|██████████████████████████████████████▌   | 99/108 [00:40<00:02,  4.05it/s]\u001b[A\n 92%|██████████████████████████████████████▌   | 99/108 [00:40<00:02,  4.14it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:40<00:02,  3.01it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:40<00:02,  2.90it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:41<00:02,  3.06it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:41<00:02,  3.02it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 102/108 [00:41<00:01,  3.25it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 102/108 [00:41<00:01,  3.24it/s]\u001b[A\n 95%|███████████████████████████████████████  | 103/108 [00:41<00:01,  3.61it/s]\u001b[A\n 95%|███████████████████████████████████████  | 103/108 [00:41<00:01,  3.72it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:41<00:00,  4.11it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:41<00:00,  4.24it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 105/108 [00:42<00:00,  3.89it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 105/108 [00:42<00:00,  3.89it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:42<00:00,  3.94it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:42<00:00,  3.87it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 107/108 [00:42<00:00,  4.05it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 107/108 [00:42<00:00,  4.02it/s]\u001b[A\n100%|█████████████████████████████████████████| 108/108 [00:42<00:00,  4.28it/s]\u001b[A\n100%|█████████████████████████████████████████| 108/108 [00:42<00:00,  4.76it/s]\u001b[A\n\nDownloading builder script: 100%|██████████| 6.34k/6.34k [00:00<00:00, 20.0MB/s]\u001b[A\u001b[A\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\nTrainer is attempting to log a value of \"{'precision': 0.8990887613904827, 'recall': 0.9340813464235624, 'f1': 0.9162510748065348, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8185240963855421, 'recall': 0.8234848484848485, 'f1': 0.8209969788519639, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9453809844908968, 'recall': 0.9328010645375915, 'f1': 0.9390488948425988, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8960982970467773, 'recall': 0.9040887342322749, 'f1': 0.9000757821803615, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.0384245328605175, 'eval_LOC': {'precision': 0.8990887613904827, 'recall': 0.9340813464235624, 'f1': 0.9162510748065348, 'number': 2852}, 'eval_ORG': {'precision': 0.8185240963855421, 'recall': 0.8234848484848485, 'f1': 0.8209969788519639, 'number': 1320}, 'eval_PER': {'precision': 0.9453809844908968, 'recall': 0.9328010645375915, 'f1': 0.9390488948425988, 'number': 1503}, 'eval__': {'precision': 0.8960982970467773, 'recall': 0.9040887342322749, 'f1': 0.9000757821803615, 'number': 4598}, 'eval_overall_precision': 0.8940747142994334, 'eval_overall_recall': 0.9062591258639151, 'eval_overall_f1': 0.9001256888717007, 'eval_overall_accuracy': 0.9894396804886644, 'eval_runtime': 47.8841, 'eval_samples_per_second': 71.903, 'eval_steps_per_second': 2.255, 'epoch': 1.0}\n 33%|█████████████                          | 2813/8439 [32:20<53:38,  1.75it/s]\n100%|█████████████████████████████████████████| 108/108 [00:46<00:00,  4.28it/s]\u001b[A\n 33%|████████████▎                        | 2817/8439 [32:21<8:13:11,  5.26s/it]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.9246977547495682, 'recall': 0.9386395511921458, 'f1': 0.9316164955629023, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8401544401544402, 'recall': 0.8242424242424242, 'f1': 0.8321223709369026, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9076411960132891, 'recall': 0.9088489687292083, 'f1': 0.9082446808510638, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8991541964866623, 'recall': 0.9016963897346673, 'f1': 0.9004234987512216, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.03580339998006821, 'eval_LOC': {'precision': 0.9246977547495682, 'recall': 0.9386395511921458, 'f1': 0.9316164955629023, 'number': 2852}, 'eval_ORG': {'precision': 0.8401544401544402, 'recall': 0.8242424242424242, 'f1': 0.8321223709369026, 'number': 1320}, 'eval_PER': {'precision': 0.9076411960132891, 'recall': 0.9088489687292083, 'f1': 0.9082446808510638, 'number': 1503}, 'eval__': {'precision': 0.8991541964866623, 'recall': 0.9016963897346673, 'f1': 0.9004234987512216, 'number': 4598}, 'eval_overall_precision': 0.9001552493692995, 'eval_overall_recall': 0.9030468217657939, 'eval_overall_f1': 0.9015987171388308, 'eval_overall_accuracy': 0.9905849876659227, 'eval_runtime': 49.0719, 'eval_samples_per_second': 70.162, 'eval_steps_per_second': 2.201, 'epoch': 1.0}\n 33%|█████████████                          | 2813/8439 [32:21<54:24,  1.72it/s]\n100%|█████████████████████████████████████████| 108/108 [00:48<00:00,  4.76it/s]\u001b[A\n{'loss': 0.0259, 'grad_norm': 146801.71875, 'learning_rate': 3.261781988247992e-05, 'epoch': 1.07}\n{'loss': 0.0253, 'grad_norm': 72350.65625, 'learning_rate': 3.261781988247992e-05, 'epoch': 1.07}\n 36%|█████████████▊                         | 3000/8439 [34:16<33:51,  2.68it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 36%|█████████████▉                         | 3010/8439 [34:19<24:35,  3.68it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0217, 'grad_norm': 1104.5364990234375, 'learning_rate': 2.961985849622257e-05, 'epoch': 1.24}\n{'loss': 0.0231, 'grad_norm': 210651.8125, 'learning_rate': 2.961985849622257e-05, 'epoch': 1.24}\n 41%|████████████████▏                      | 3500/8439 [39:35<22:56,  3.59it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 42%|████████████████▏                      | 3512/8439 [39:38<24:15,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0249, 'grad_norm': 108868.640625, 'learning_rate': 2.6621897109965228e-05, 'epoch': 1.42}\n 47%|██████████████████▍                    | 3994/8439 [44:49<26:40,  2.78it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0226, 'grad_norm': 47145.16015625, 'learning_rate': 2.6621897109965228e-05, 'epoch': 1.42}\n 48%|██████████████████▌                    | 4018/8439 [44:57<20:20,  3.62it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0217, 'grad_norm': 5177.61376953125, 'learning_rate': 2.362393572370788e-05, 'epoch': 1.6}\n 53%|████████████████████▋                  | 4489/8439 [50:03<23:21,  2.82it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0212, 'grad_norm': 1302.0841064453125, 'learning_rate': 2.362393572370788e-05, 'epoch': 1.6}\n 54%|████████████████████▉                  | 4522/8439 [50:13<18:47,  3.47it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0227, 'grad_norm': 1314.383056640625, 'learning_rate': 2.0625974337450534e-05, 'epoch': 1.78}\n 59%|███████████████████████                | 4990/8439 [55:16<19:31,  2.95it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0214, 'grad_norm': 1047.1251220703125, 'learning_rate': 2.0625974337450534e-05, 'epoch': 1.78}\n 59%|███████████████████████▏               | 5020/8439 [55:25<16:09,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0219, 'grad_norm': 258196.859375, 'learning_rate': 1.762801295119319e-05, 'epoch': 1.96}\n 65%|████████████████████████             | 5486/8439 [1:00:33<17:08,  2.87it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0211, 'grad_norm': 173838.96875, 'learning_rate': 1.762801295119319e-05, 'epoch': 1.96}\n 65%|████████████████████████▏            | 5524/8439 [1:00:44<14:32,  3.34it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 66%|████████████████████████▌            | 5600/8439 [1:01:48<33:09,  1.43it/s]\n 66%|████████████████████████▌            | 5601/8439 [1:01:49<33:51,  1.40it/s]\u001b[A\n  2%|▊                                          | 2/108 [00:00<00:17,  6.06it/s]\u001b[A\n 66%|████████████████████████▌            | 5602/8439 [1:01:49<32:53,  1.44it/s]\u001b[A\n  4%|█▌                                         | 4/108 [00:01<00:32,  3.21it/s]\u001b[A\n 66%|████████████████████████▌            | 5603/8439 [1:01:50<31:51,  1.48it/s]\u001b[A\n 66%|████████████████████████▌            | 5604/8439 [1:01:51<30:09,  1.57it/s]\u001b[A\n  6%|██▊                                        | 7/108 [00:02<00:34,  2.89it/s]\u001b[A\n 66%|████████████████████████▌            | 5605/8439 [1:01:51<29:06,  1.62it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:02<00:35,  2.82it/s]\u001b[A\n 66%|████████████████████████▌            | 5606/8439 [1:01:52<30:20,  1.56it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:03<00:33,  2.93it/s]\u001b[A\n 66%|████████████████████████▌            | 5607/8439 [1:01:53<30:34,  1.54it/s]\u001b[A\n 66%|████████████████████████▌            | 5608/8439 [1:01:53<30:14,  1.56it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:04<00:32,  2.91it/s]\u001b[A\n 66%|████████████████████████▌            | 5609/8439 [1:01:54<31:53,  1.48it/s]\u001b[A\n 66%|████████████████████████▌            | 5610/8439 [1:01:55<34:49,  1.35it/s]\u001b[A\n 16%|██████▌                                   | 17/108 [00:06<00:46,  1.97it/s]\u001b[A\n 66%|████████████████████████▌            | 5611/8439 [1:01:55<30:55,  1.52it/s]\u001b[A\n 67%|████████████████████████▌            | 5612/8439 [1:01:56<29:26,  1.60it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:07<00:40,  2.18it/s]\u001b[A\n 67%|████████████████████████▌            | 5613/8439 [1:01:56<29:29,  1.60it/s]\u001b[A\n 67%|████████████████████████▌            | 5614/8439 [1:01:57<28:32,  1.65it/s]\u001b[A\n 21%|████████▉                                 | 23/108 [00:08<00:30,  2.80it/s]\u001b[A\n 67%|████████████████████████▌            | 5615/8439 [1:01:58<29:35,  1.59it/s]\u001b[A\n 23%|█████████▋                                | 25/108 [00:09<00:33,  2.49it/s]\u001b[A\n 67%|████████████████████████▌            | 5616/8439 [1:01:58<29:38,  1.59it/s]\u001b[A\n 67%|████████████████████████▋            | 5617/8439 [1:01:59<29:38,  1.59it/s]\u001b[A\n 26%|██████████▉                               | 28/108 [00:10<00:29,  2.71it/s]\u001b[A\n 67%|████████████████████████▋            | 5618/8439 [1:02:00<29:28,  1.60it/s]\u001b[A\n 67%|████████████████████████▋            | 5619/8439 [1:02:00<29:13,  1.61it/s]\u001b[A\n 67%|████████████████████████▋            | 5620/8439 [1:02:01<28:45,  1.63it/s]\u001b[A\n 67%|████████████████████████▋            | 5621/8439 [1:02:01<28:28,  1.65it/s]\u001b[A\n 31%|████████████▊                             | 33/108 [00:12<00:33,  2.21it/s]\u001b[A\n 67%|████████████████████████▋            | 5622/8439 [1:02:02<27:29,  1.71it/s]\u001b[A\n 67%|████████████████████████▋            | 5623/8439 [1:02:02<27:02,  1.74it/s]\u001b[A\n 33%|██████████████                            | 36/108 [00:13<00:27,  2.61it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:14<00:24,  2.95it/s]\u001b[A\n 35%|██████████████▊                           | 38/108 [00:14<00:22,  3.07it/s]\u001b[A\n 67%|████████████████████████▋            | 5624/8439 [1:02:03<31:23,  1.49it/s]\u001b[A\n 67%|████████████████████████▋            | 5625/8439 [1:02:04<28:46,  1.63it/s]\u001b[A\n 67%|████████████████████████▋            | 5626/8439 [1:02:04<27:13,  1.72it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:15<00:22,  2.88it/s]\u001b[A\n 40%|████████████████▋                         | 43/108 [00:16<00:24,  2.70it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:16<00:23,  2.78it/s]\u001b[A\n  0%|                                                   | 0/108 [00:00<?, ?it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:16<00:21,  2.98it/s]\u001b[A\n  2%|▊                                          | 2/108 [00:00<00:15,  6.66it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:17<00:24,  2.58it/s]\u001b[A\n  3%|█▏                                         | 3/108 [00:00<00:28,  3.69it/s]\u001b[A\n 44%|██████████████████▎                       | 47/108 [00:17<00:24,  2.52it/s]\u001b[A\n  4%|█▌                                         | 4/108 [00:01<00:36,  2.88it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:18<00:25,  2.32it/s]\u001b[A\n  5%|█▉                                         | 5/108 [00:01<00:38,  2.68it/s]\u001b[A\n 45%|███████████████████                       | 49/108 [00:18<00:25,  2.29it/s]\u001b[A\n  6%|██▍                                        | 6/108 [00:02<00:40,  2.52it/s]\u001b[A\n 46%|███████████████████▍                      | 50/108 [00:19<00:25,  2.24it/s]\u001b[A\n  6%|██▊                                        | 7/108 [00:02<00:43,  2.33it/s]\u001b[A\n 47%|███████████████████▊                      | 51/108 [00:19<00:24,  2.30it/s]\u001b[A\n  7%|███▏                                       | 8/108 [00:03<00:45,  2.20it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:03<00:46,  2.11it/s]\u001b[A\n  9%|███▉                                      | 10/108 [00:03<00:43,  2.24it/s]\u001b[A\n 48%|████████████████████▏                     | 52/108 [00:20<00:36,  1.54it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:04<00:40,  2.41it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:21<00:33,  1.62it/s]\u001b[A\n 11%|████▋                                     | 12/108 [00:04<00:39,  2.44it/s]\u001b[A\n 50%|█████████████████████                     | 54/108 [00:21<00:29,  1.84it/s]\u001b[A\n 12%|█████                                     | 13/108 [00:05<00:37,  2.53it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:22<00:25,  2.06it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:05<00:36,  2.60it/s]\u001b[A\n 52%|█████████████████████▊                    | 56/108 [00:22<00:21,  2.38it/s]\u001b[A\n 14%|█████▊                                    | 15/108 [00:05<00:35,  2.64it/s]\u001b[A\n 53%|██████████████████████▏                   | 57/108 [00:22<00:19,  2.63it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:23<00:21,  2.35it/s]\u001b[A\n 55%|██████████████████████▉                   | 59/108 [00:23<00:22,  2.15it/s]\u001b[A\n 15%|██████▏                                   | 16/108 [00:06<00:56,  1.64it/s]\u001b[A\n 16%|██████▌                                   | 17/108 [00:07<00:55,  1.64it/s]\u001b[A\n 56%|███████████████████████▎                  | 60/108 [00:24<00:26,  1.82it/s]\u001b[A\n 17%|███████                                   | 18/108 [00:07<00:44,  2.00it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:24<00:22,  2.10it/s]\u001b[A\n 18%|███████▍                                  | 19/108 [00:08<00:44,  1.98it/s]\u001b[A\n 57%|████████████████████████                  | 62/108 [00:25<00:21,  2.12it/s]\u001b[A\n 58%|████████████████████████▌                 | 63/108 [00:25<00:19,  2.35it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:08<00:44,  2.00it/s]\u001b[A\n 19%|████████▏                                 | 21/108 [00:09<00:37,  2.31it/s]\u001b[A\n 20%|████████▌                                 | 22/108 [00:09<00:35,  2.43it/s]\u001b[A\n 59%|████████████████████████▉                 | 64/108 [00:26<00:27,  1.59it/s]\u001b[A\n 21%|████████▉                                 | 23/108 [00:09<00:35,  2.37it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:26<00:22,  1.91it/s]\u001b[A\n 22%|█████████▎                                | 24/108 [00:10<00:34,  2.43it/s]\u001b[A\n 61%|█████████████████████████▋                | 66/108 [00:27<00:20,  2.01it/s]\u001b[A\n 23%|█████████▋                                | 25/108 [00:10<00:38,  2.17it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:27<00:17,  2.28it/s]\u001b[A\n 24%|██████████                                | 26/108 [00:11<00:33,  2.44it/s]\u001b[A\n 63%|██████████████████████████▍               | 68/108 [00:27<00:15,  2.51it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:28<00:14,  2.69it/s]\u001b[A\n 25%|██████████▌                               | 27/108 [00:11<00:31,  2.56it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:28<00:13,  2.75it/s]\u001b[A\n 26%|██████████▉                               | 28/108 [00:11<00:31,  2.52it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:28<00:13,  2.79it/s]\u001b[A\n 27%|███████████▎                              | 29/108 [00:12<00:39,  2.02it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:29<00:14,  2.48it/s]\u001b[A\n 28%|███████████▋                              | 30/108 [00:12<00:34,  2.29it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:29<00:13,  2.64it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:30<00:14,  2.40it/s]\u001b[A\n 29%|████████████                              | 31/108 [00:13<00:41,  1.87it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:30<00:13,  2.36it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:30<00:12,  2.61it/s]\u001b[A\n 30%|████████████▍                             | 32/108 [00:14<00:43,  1.76it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:31<00:11,  2.80it/s]\u001b[A\n 31%|████████████▊                             | 33/108 [00:14<00:37,  1.99it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:31<00:09,  3.10it/s]\u001b[A\n 31%|█████████████▏                            | 34/108 [00:14<00:30,  2.39it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:31<00:09,  3.20it/s]\u001b[A\n 32%|█████████████▌                            | 35/108 [00:15<00:30,  2.39it/s]\u001b[A\n 33%|██████████████                            | 36/108 [00:15<00:28,  2.51it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:32<00:14,  1.98it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:16<00:27,  2.60it/s]\u001b[A\n 35%|██████████████▊                           | 38/108 [00:16<00:25,  2.74it/s]\u001b[A\n 75%|███████████████████████████████▌          | 81/108 [00:33<00:13,  2.00it/s]\u001b[A\n 36%|███████████████▏                          | 39/108 [00:16<00:23,  2.99it/s]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:33<00:11,  2.20it/s]\u001b[A\n 37%|███████████████▌                          | 40/108 [00:16<00:22,  2.96it/s]\u001b[A\n 38%|███████████████▉                          | 41/108 [00:17<00:22,  2.99it/s]\u001b[A\n 77%|████████████████████████████████▎         | 83/108 [00:34<00:12,  2.08it/s]\u001b[A\n 78%|████████████████████████████████▋         | 84/108 [00:34<00:10,  2.29it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:17<00:24,  2.71it/s]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:34<00:10,  2.26it/s]\u001b[A\n 40%|████████████████▋                         | 43/108 [00:18<00:26,  2.46it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:35<00:09,  2.41it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:18<00:24,  2.63it/s]\u001b[A\n 81%|█████████████████████████████████▊        | 87/108 [00:35<00:07,  2.82it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:18<00:22,  2.83it/s]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:35<00:06,  2.98it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:19<00:25,  2.39it/s]\u001b[A\n 82%|██████████████████████████████████▌       | 89/108 [00:36<00:06,  2.76it/s]\u001b[A\n 44%|██████████████████▎                       | 47/108 [00:19<00:25,  2.39it/s]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:36<00:07,  2.38it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:20<00:26,  2.30it/s]\u001b[A\n 84%|███████████████████████████████████▍      | 91/108 [00:37<00:06,  2.63it/s]\u001b[A\n 45%|███████████████████                       | 49/108 [00:20<00:28,  2.04it/s]\u001b[A\n 85%|███████████████████████████████████▊      | 92/108 [00:37<00:07,  2.21it/s]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:38<00:06,  2.30it/s]\u001b[A\n 46%|███████████████████▍                      | 50/108 [00:21<00:28,  2.04it/s]\u001b[A\n 87%|████████████████████████████████████▌     | 94/108 [00:38<00:05,  2.73it/s]\u001b[A\n 47%|███████████████████▊                      | 51/108 [00:21<00:26,  2.13it/s]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:38<00:04,  2.87it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:38<00:04,  2.95it/s]\u001b[A\n 90%|█████████████████████████████████████▋    | 97/108 [00:39<00:03,  3.21it/s]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:39<00:03,  3.21it/s]\u001b[A\n 48%|████████████████████▏                     | 52/108 [00:22<00:36,  1.52it/s]\u001b[A\n 92%|██████████████████████████████████████▌   | 99/108 [00:39<00:02,  3.38it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:23<00:34,  1.61it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:40<00:03,  2.61it/s]\u001b[A\n 50%|█████████████████████                     | 54/108 [00:23<00:28,  1.87it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:40<00:02,  2.73it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:24<00:24,  2.18it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 102/108 [00:40<00:02,  2.84it/s]\u001b[A\n 52%|█████████████████████▊                    | 56/108 [00:24<00:20,  2.52it/s]\u001b[A\n 95%|███████████████████████████████████████  | 103/108 [00:41<00:01,  3.25it/s]\u001b[A\n 53%|██████████████████████▏                   | 57/108 [00:24<00:17,  2.87it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:41<00:01,  3.71it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 105/108 [00:41<00:00,  3.38it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:24<00:17,  2.78it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:41<00:00,  3.40it/s]\u001b[A\n 55%|██████████████████████▉                   | 59/108 [00:25<00:18,  2.58it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 107/108 [00:42<00:00,  3.53it/s]\u001b[A\n100%|█████████████████████████████████████████| 108/108 [00:42<00:00,  3.53it/s]\u001b[A\n 56%|███████████████████████▎                  | 60/108 [00:25<00:20,  2.29it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:26<00:16,  2.86it/s]\u001b[A\n 57%|████████████████████████                  | 62/108 [00:26<00:14,  3.21it/s]\u001b[A\n 58%|████████████████████████▌                 | 63/108 [00:26<00:11,  3.99it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n\n 59%|████████████████████████▉                 | 64/108 [00:27<00:15,  2.81it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:27<00:12,  3.40it/s]\u001b[A\n 61%|█████████████████████████▋                | 66/108 [00:27<00:11,  3.67it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:27<00:09,  4.39it/s]\u001b[A\n 63%|██████████████████████████▍               | 68/108 [00:27<00:07,  5.21it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:27<00:06,  5.80it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:27<00:06,  5.88it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:28<00:06,  5.71it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:28<00:06,  5.21it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:28<00:06,  5.61it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:28<00:06,  5.20it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:28<00:06,  4.98it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:29<00:05,  5.83it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:29<00:05,  5.80it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:29<00:04,  6.53it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:29<00:04,  6.47it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:29<00:06,  4.06it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.9441925357516567, 'recall': 0.9491584852734923, 'f1': 0.9466689980765868, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8951048951048951, 'recall': 0.8727272727272727, 'f1': 0.8837744533947066, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9538461538461539, 'recall': 0.948769128409847, 'f1': 0.95130086724483, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9196331076654292, 'recall': 0.9158329708568943, 'f1': 0.9177291053721259, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.048222772777080536, 'eval_LOC': {'precision': 0.9441925357516567, 'recall': 0.9491584852734923, 'f1': 0.9466689980765868, 'number': 2852}, 'eval_ORG': {'precision': 0.8951048951048951, 'recall': 0.8727272727272727, 'f1': 0.8837744533947066, 'number': 1320}, 'eval_PER': {'precision': 0.9538461538461539, 'recall': 0.948769128409847, 'f1': 0.95130086724483, 'number': 1503}, 'eval__': {'precision': 0.9196331076654292, 'recall': 0.9158329708568943, 'f1': 0.9177291053721259, 'number': 4598}, 'eval_overall_precision': 0.9284317559640204, 'eval_overall_recall': 0.9243648398715079, 'eval_overall_f1': 0.9263938344471003, 'eval_overall_accuracy': 0.9923939856689769, 'eval_runtime': 47.7485, 'eval_samples_per_second': 72.107, 'eval_steps_per_second': 2.262, 'epoch': 2.0}\n 67%|████████████████████████▋            | 5626/8439 [1:02:35<26:08,  1.79it/s]\n100%|█████████████████████████████████████████| 108/108 [00:46<00:00,  3.53it/s]\u001b[A\n                                                                                \u001b[A\n 67%|██████████████████████▋           | 5627/8439 [1:02:36<11:35:33, 14.84s/it]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:30<00:07,  3.54it/s]\u001b[A\n 67%|███████████████████████▎           | 5628/8439 [1:02:37<8:15:50, 10.58s/it]\u001b[A\n 67%|███████████████████████▎           | 5629/8439 [1:02:37<5:54:01,  7.56s/it]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:31<00:07,  2.95it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:32<00:07,  3.00it/s]\u001b[A\n 67%|███████████████████████▎           | 5630/8439 [1:02:38<4:20:00,  5.55s/it]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:32<00:05,  3.36it/s]\u001b[A\n 67%|███████████████████████▎           | 5631/8439 [1:02:39<3:11:38,  4.09s/it]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:33<00:06,  2.73it/s]\u001b[A\n 67%|███████████████████████▎           | 5632/8439 [1:02:39<2:20:46,  3.01s/it]\u001b[A\n 67%|███████████████████████▎           | 5633/8439 [1:02:40<1:48:47,  2.33s/it]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:34<00:05,  2.66it/s]\u001b[A\n 67%|███████████████████████▎           | 5634/8439 [1:02:40<1:25:34,  1.83s/it]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:35<00:04,  2.80it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:35<00:04,  2.97it/s]\u001b[A\n 67%|███████████████████████▎           | 5635/8439 [1:02:41<1:07:55,  1.45s/it]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:35<00:02,  3.61it/s]\u001b[A\n 67%|███████████████████████▎           | 5636/8439 [1:02:42<1:00:44,  1.30s/it]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:36<00:02,  2.94it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:36<00:02,  3.09it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 102/108 [00:37<00:01,  3.18it/s]\u001b[A\n 67%|████████████████████████▋            | 5637/8439 [1:02:43<53:49,  1.15s/it]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:37<00:00,  4.13it/s]\u001b[A\n 67%|████████████████████████▋            | 5638/8439 [1:02:43<44:45,  1.04it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:38<00:00,  3.91it/s]\u001b[A\n 67%|████████████████████████▋            | 5639/8439 [1:02:44<40:12,  1.16it/s]\u001b[A\n 67%|████████████████████████▋            | 5643/8439 [1:02:45<18:33,  2.51it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n 67%|████████████████████████▊            | 5656/8439 [1:02:48<12:34,  3.69it/s]Trainer is attempting to log a value of \"{'precision': 0.9523809523809523, 'recall': 0.9326788218793829, 'f1': 0.9424269264836137, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.879080118694362, 'recall': 0.8977272727272727, 'f1': 0.8883058470764618, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9589131875414182, 'recall': 0.9627411842980705, 'f1': 0.9608233731739707, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9246889325474787, 'recall': 0.9212701174423662, 'f1': 0.9229763590805099, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.053076814860105515, 'eval_LOC': {'precision': 0.9523809523809523, 'recall': 0.9326788218793829, 'f1': 0.9424269264836137, 'number': 2852}, 'eval_ORG': {'precision': 0.879080118694362, 'recall': 0.8977272727272727, 'f1': 0.8883058470764618, 'number': 1320}, 'eval_PER': {'precision': 0.9589131875414182, 'recall': 0.9627411842980705, 'f1': 0.9608233731739707, 'number': 1503}, 'eval__': {'precision': 0.9246889325474787, 'recall': 0.9212701174423662, 'f1': 0.9229763590805099, 'number': 4598}, 'eval_overall_precision': 0.9312872641970482, 'eval_overall_recall': 0.9274798014212012, 'eval_overall_f1': 0.9293796332422942, 'eval_overall_accuracy': 0.9926465405849877, 'eval_runtime': 44.0521, 'eval_samples_per_second': 78.157, 'eval_steps_per_second': 2.452, 'epoch': 2.0}\n 67%|████████████████████████▋            | 5626/8439 [1:02:48<27:13,  1.72it/s]\n100%|█████████████████████████████████████████| 108/108 [00:43<00:00,  4.22it/s]\u001b[A\n{'loss': 0.0172, 'grad_norm': 0.4061122536659241, 'learning_rate': 1.4630051564935846e-05, 'epoch': 2.13}\n 71%|██████████████████████████▏          | 5978/8439 [1:06:24<12:00,  3.42it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0179, 'grad_norm': 0.1641291081905365, 'learning_rate': 1.4630051564935846e-05, 'epoch': 2.13}\n 71%|██████████████████████████▍          | 6033/8439 [1:06:41<11:15,  3.56it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0191, 'grad_norm': 225582.9375, 'learning_rate': 1.16320901786785e-05, 'epoch': 2.31}\n 77%|████████████████████████████▍        | 6474/8439 [1:11:42<11:43,  2.79it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.02, 'grad_norm': 57519.9609375, 'learning_rate': 1.16320901786785e-05, 'epoch': 2.31}\n 77%|████████████████████████████▋        | 6537/8439 [1:12:02<08:55,  3.55it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0186, 'grad_norm': 245903.65625, 'learning_rate': 8.634128792421153e-06, 'epoch': 2.49}\n 83%|██████████████████████████████▌      | 6970/8439 [1:17:04<07:12,  3.39it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.016, 'grad_norm': 594.7088012695312, 'learning_rate': 8.634128792421153e-06, 'epoch': 2.49}\n 83%|██████████████████████████████▊      | 7042/8439 [1:17:26<06:37,  3.51it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0207, 'grad_norm': 275297.46875, 'learning_rate': 5.636167406163809e-06, 'epoch': 2.67}\n 88%|████████████████████████████████▋    | 7462/8439 [1:22:11<04:36,  3.53it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0186, 'grad_norm': 98509.2421875, 'learning_rate': 5.636167406163809e-06, 'epoch': 2.67}\n 89%|█████████████████████████████████    | 7547/8439 [1:22:36<04:16,  3.48it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0152, 'grad_norm': 0.16436885297298431, 'learning_rate': 2.6382060199064637e-06, 'epoch': 2.84}\n 94%|██████████████████████████████████▉  | 7960/8439 [1:27:24<02:30,  3.18it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n{'loss': 0.0164, 'grad_norm': 1797.4493408203125, 'learning_rate': 2.6382060199064637e-06, 'epoch': 2.84}\n 95%|███████████████████████████████████▎ | 8050/8439 [1:27:52<02:46,  2.33it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 99%|████████████████████████████████████▊| 8395/8439 [1:32:01<00:13,  3.31it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n 99%|████████████████████████████████████▊| 8396/8439 [1:32:02<00:14,  2.92it/s]\n  0%|                                                   | 0/108 [00:00<?, ?it/s]\u001b[A\n100%|████████████████████████████████████▊| 8397/8439 [1:32:03<00:23,  1.80it/s]\u001b[A\n  3%|█▏                                         | 3/108 [00:00<00:25,  4.15it/s]\u001b[A\n100%|████████████████████████████████████▊| 8398/8439 [1:32:03<00:23,  1.76it/s]\u001b[A\n100%|████████████████████████████████████▊| 8399/8439 [1:32:04<00:22,  1.75it/s]\u001b[A\n  6%|██▍                                        | 6/108 [00:01<00:32,  3.14it/s]\u001b[A\n100%|████████████████████████████████████▊| 8400/8439 [1:32:05<00:22,  1.76it/s]\u001b[A\n100%|████████████████████████████████████▊| 8401/8439 [1:32:05<00:22,  1.66it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:03<00:38,  2.56it/s]\u001b[A\n100%|████████████████████████████████████▊| 8402/8439 [1:32:06<00:23,  1.58it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:03<00:36,  2.65it/s]\u001b[A\n100%|████████████████████████████████████▊| 8403/8439 [1:32:07<00:22,  1.59it/s]\u001b[A\n100%|████████████████████████████████████▊| 8404/8439 [1:32:07<00:21,  1.60it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:04<00:35,  2.63it/s]\u001b[A\n100%|████████████████████████████████████▊| 8406/8439 [1:32:09<00:21,  1.50it/s]\u001b[A\n 15%|██████▏                                   | 16/108 [00:06<00:53,  1.70it/s]\u001b[A\n100%|████████████████████████████████████▊| 8407/8439 [1:32:09<00:20,  1.59it/s]\u001b[A\n100%|████████████████████████████████████▊| 8408/8439 [1:32:10<00:18,  1.64it/s]\u001b[A\n100%|████████████████████████████████████▊| 8409/8439 [1:32:10<00:17,  1.69it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:08<00:41,  2.10it/s]\u001b[A\n100%|████████████████████████████████████▊| 8410/8439 [1:32:11<00:16,  1.76it/s]\u001b[A\n 20%|████████▌                                 | 22/108 [00:08<00:31,  2.70it/s]\u001b[A\n100%|████████████████████████████████████▉| 8411/8439 [1:32:11<00:15,  1.75it/s]\u001b[A\n100%|████████████████████████████████████▉| 8412/8439 [1:32:12<00:16,  1.67it/s]\u001b[A\n 23%|█████████▋                                | 25/108 [00:09<00:33,  2.46it/s]\u001b[A\n100%|████████████████████████████████████▉| 8413/8439 [1:32:13<00:16,  1.55it/s]\u001b[A\n 25%|██████████▌                               | 27/108 [00:10<00:30,  2.67it/s]\u001b[A\n100%|████████████████████████████████████▉| 8414/8439 [1:32:13<00:16,  1.56it/s]\u001b[A\n100%|████████████████████████████████████▉| 8415/8439 [1:32:14<00:15,  1.51it/s]\u001b[A\n100%|████████████████████████████████████▉| 8416/8439 [1:32:15<00:14,  1.58it/s]\u001b[A\n100%|████████████████████████████████████▉| 8417/8439 [1:32:15<00:13,  1.68it/s]\u001b[A\n 30%|████████████▍                             | 32/108 [00:13<00:39,  1.92it/s]\u001b[A\n100%|████████████████████████████████████▉| 8418/8439 [1:32:16<00:12,  1.72it/s]\u001b[A\n100%|████████████████████████████████████▉| 8419/8439 [1:32:16<00:11,  1.74it/s]\u001b[A\n 32%|█████████████▌                            | 35/108 [00:14<00:29,  2.47it/s]\u001b[A\n100%|████████████████████████████████████▉| 8420/8439 [1:32:17<00:10,  1.78it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:14<00:24,  2.87it/s]\u001b[A\n100%|████████████████████████████████████▉| 8421/8439 [1:32:17<00:09,  1.84it/s]\u001b[A\n 36%|███████████████▏                          | 39/108 [00:15<00:20,  3.32it/s]\u001b[A\n100%|████████████████████████████████████▉| 8422/8439 [1:32:18<00:09,  1.85it/s]\u001b[A\n100%|████████████████████████████████████▉| 8423/8439 [1:32:18<00:08,  1.84it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:16<00:22,  2.98it/s]\u001b[A\n100%|████████████████████████████████████▉| 8424/8439 [1:32:19<00:08,  1.79it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:16<00:21,  3.04it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:17<00:20,  3.07it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:17<00:24,  2.55it/s]\u001b[A\n100%|████████████████████████████████████▉| 8425/8439 [1:32:21<00:13,  1.03it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:18<00:25,  2.37it/s]\u001b[A\n100%|████████████████████████████████████▉| 8426/8439 [1:32:22<00:11,  1.18it/s]\u001b[A\n100%|████████████████████████████████████▉| 8427/8439 [1:32:22<00:09,  1.23it/s]\u001b[A\n100%|████████████████████████████████████▉| 8428/8439 [1:32:23<00:08,  1.30it/s]\u001b[A\n100%|████████████████████████████████████▉| 8429/8439 [1:32:24<00:07,  1.38it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:21<00:32,  1.69it/s]\u001b[A\n100%|████████████████████████████████████▉| 8430/8439 [1:32:24<00:06,  1.39it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:22<00:24,  2.18it/s]\u001b[A\n100%|████████████████████████████████████▉| 8431/8439 [1:32:25<00:05,  1.41it/s]\u001b[A\n100%|████████████████████████████████████▉| 8432/8439 [1:32:25<00:04,  1.55it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:23<00:18,  2.67it/s]\u001b[A\n100%|████████████████████████████████████▉| 8433/8439 [1:32:26<00:03,  1.53it/s]\u001b[A\n100%|████████████████████████████████████▉| 8434/8439 [1:32:27<00:03,  1.39it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:24<00:22,  2.13it/s]\u001b[A\n100%|████████████████████████████████████▉| 8435/8439 [1:32:28<00:02,  1.42it/s]\u001b[A\n100%|████████████████████████████████████▉| 8436/8439 [1:32:28<00:02,  1.49it/s]\u001b[A\n100%|████████████████████████████████████▉| 8437/8439 [1:32:29<00:01,  1.37it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:26<00:22,  1.95it/s]\u001b[A\n100%|████████████████████████████████████▉| 8438/8439 [1:32:30<00:00,  1.47it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:27<00:17,  2.39it/s]\u001b[A\n100%|█████████████████████████████████████| 8439/8439 [1:32:30<00:00,  1.61it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:28<00:12,  3.23it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:28<00:10,  3.74it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:28<00:09,  4.09it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:28<00:08,  4.15it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:28<00:07,  4.68it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:29<00:07,  4.59it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:29<00:07,  4.58it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:29<00:05,  5.42it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:29<00:05,  5.51it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:29<00:04,  6.28it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:29<00:04,  6.28it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:30<00:06,  4.02it/s]\u001b[A\n 75%|███████████████████████████████▌          | 81/108 [00:30<00:06,  4.01it/s]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:30<00:05,  4.34it/s]\u001b[A\n 77%|████████████████████████████████▎         | 83/108 [00:30<00:06,  3.99it/s]\u001b[A\n 78%|████████████████████████████████▋         | 84/108 [00:31<00:05,  4.68it/s]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:31<00:04,  4.85it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:31<00:04,  5.09it/s]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:31<00:03,  6.19it/s]\u001b[A\n 82%|██████████████████████████████████▌       | 89/108 [00:31<00:03,  5.84it/s]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:32<00:03,  5.05it/s]\u001b[A\n 84%|███████████████████████████████████▍      | 91/108 [00:32<00:02,  5.78it/s]\u001b[A\n 85%|███████████████████████████████████▊      | 92/108 [00:32<00:03,  4.93it/s]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:32<00:02,  5.33it/s]\u001b[A\n 87%|████████████████████████████████████▌     | 94/108 [00:32<00:02,  5.99it/s]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:32<00:02,  6.45it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:33<00:01,  6.81it/s]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:33<00:01,  7.72it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:33<00:01,  6.63it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:33<00:01,  6.24it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n\n 94%|██████████████████████████████████████▋  | 102/108 [00:34<00:01,  5.02it/s]\u001b[A\n 95%|███████████████████████████████████████  | 103/108 [00:34<00:01,  4.75it/s]\u001b[A\n  0%|                                                   | 0/108 [00:00<?, ?it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:34<00:00,  4.97it/s]\u001b[A\n  2%|▊                                          | 2/108 [00:00<00:16,  6.25it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 105/108 [00:34<00:00,  4.20it/s]\u001b[A\n  3%|█▏                                         | 3/108 [00:00<00:22,  4.62it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:35<00:00,  3.94it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 107/108 [00:35<00:00,  3.82it/s]\u001b[A\n  4%|█▌                                         | 4/108 [00:01<00:31,  3.32it/s]\u001b[A\n100%|█████████████████████████████████████████| 108/108 [00:35<00:00,  4.24it/s]\u001b[A\n  5%|█▉                                         | 5/108 [00:01<00:28,  3.62it/s]\u001b[A\n  6%|██▍                                        | 6/108 [00:01<00:23,  4.28it/s]\u001b[A\n  6%|██▊                                        | 7/108 [00:01<00:23,  4.24it/s]\u001b[A\n  7%|███▏                                       | 8/108 [00:01<00:23,  4.17it/s]\u001b[A\n  8%|███▌                                       | 9/108 [00:02<00:22,  4.44it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n\n  9%|███▉                                      | 10/108 [00:02<00:20,  4.85it/s]\u001b[A\n 10%|████▎                                     | 11/108 [00:02<00:19,  5.03it/s]\u001b[A\n 11%|████▋                                     | 12/108 [00:02<00:18,  5.11it/s]\u001b[A\n 12%|█████                                     | 13/108 [00:02<00:17,  5.28it/s]\u001b[A\n 13%|█████▍                                    | 14/108 [00:03<00:17,  5.35it/s]\u001b[A\n 14%|█████▊                                    | 15/108 [00:03<00:17,  5.28it/s]\u001b[A\n 15%|██████▏                                   | 16/108 [00:03<00:28,  3.18it/s]\u001b[A\n 16%|██████▌                                   | 17/108 [00:04<00:27,  3.33it/s]\u001b[A\n 17%|███████                                   | 18/108 [00:04<00:22,  4.03it/s]\u001b[A\n 18%|███████▍                                  | 19/108 [00:04<00:22,  4.04it/s]\u001b[A\n 19%|███████▊                                  | 20/108 [00:04<00:22,  3.92it/s]\u001b[A\n 20%|████████▌                                 | 22/108 [00:04<00:16,  5.10it/s]\u001b[A\n 21%|████████▉                                 | 23/108 [00:05<00:16,  5.14it/s]\u001b[A\n 22%|█████████▎                                | 24/108 [00:05<00:16,  5.08it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.9615795090715048, 'recall': 0.9477559607293128, 'f1': 0.9546176938018718, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8770909090909091, 'recall': 0.9136363636363637, 'f1': 0.8949907235621523, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.956953642384106, 'recall': 0.9614105123087159, 'f1': 0.9591769000995685, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9240724762726489, 'recall': 0.9317094388864724, 'f1': 0.9278752436647174, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.0862874984741211, 'eval_LOC': {'precision': 0.9615795090715048, 'recall': 0.9477559607293128, 'f1': 0.9546176938018718, 'number': 2852}, 'eval_ORG': {'precision': 0.8770909090909091, 'recall': 0.9136363636363637, 'f1': 0.8949907235621523, 'number': 1320}, 'eval_PER': {'precision': 0.956953642384106, 'recall': 0.9614105123087159, 'f1': 0.9591769000995685, 'number': 1503}, 'eval__': {'precision': 0.9240724762726489, 'recall': 0.9317094388864724, 'f1': 0.9278752436647174, 'number': 4598}, 'eval_overall_precision': 0.9328300425861401, 'eval_overall_recall': 0.9381874817482722, 'eval_overall_f1': 0.9355010919679689, 'eval_overall_accuracy': 0.9928814753905791, 'eval_runtime': 40.9581, 'eval_samples_per_second': 84.062, 'eval_steps_per_second': 2.637, 'epoch': 3.0}\n100%|█████████████████████████████████████| 8439/8439 [1:32:42<00:00,  1.77it/s]\n100%|█████████████████████████████████████████| 108/108 [00:40<00:00,  4.24it/s]\u001b[A\n{'train_runtime': 5562.9958, 'train_samples_per_second': 24.268, 'train_steps_per_second': 1.517, 'train_loss': 0.03183711904360087, 'epoch': 3.0}\n100%|█████████████████████████████████████| 8439/8439 [1:32:42<00:00,  1.52it/s]\n\n 23%|█████████▋                                | 25/108 [00:05<00:18,  4.56it/s]\u001b[A\n 24%|██████████                                | 26/108 [00:05<00:15,  5.19it/s]\u001b[A\n 25%|██████████▌                               | 27/108 [00:05<00:15,  5.24it/s]\u001b[A\n 26%|██████████▉                               | 28/108 [00:06<00:15,  5.25it/s]\u001b[A\n 27%|███████████▎                              | 29/108 [00:06<00:18,  4.26it/s]\u001b[A\n 28%|███████████▋                              | 30/108 [00:06<00:16,  4.70it/s]\u001b[A\n 29%|████████████                              | 31/108 [00:07<00:20,  3.72it/s]\u001b[A\n 30%|████████████▍                             | 32/108 [00:07<00:21,  3.46it/s]\u001b[A\n 31%|████████████▊                             | 33/108 [00:07<00:18,  4.06it/s]\u001b[A\n 31%|█████████████▏                            | 34/108 [00:07<00:15,  4.79it/s]\u001b[A\n 32%|█████████████▌                            | 35/108 [00:07<00:15,  4.69it/s]\u001b[A\n 33%|██████████████                            | 36/108 [00:08<00:13,  5.16it/s]\u001b[A\n 34%|██████████████▍                           | 37/108 [00:08<00:12,  5.75it/s]\u001b[A\n 35%|██████████████▊                           | 38/108 [00:08<00:11,  6.28it/s]\u001b[A\n 36%|███████████████▏                          | 39/108 [00:08<00:09,  7.00it/s]\u001b[A\n 37%|███████████████▌                          | 40/108 [00:08<00:10,  6.71it/s]\u001b[A\n 38%|███████████████▉                          | 41/108 [00:08<00:09,  7.04it/s]\u001b[A\n 39%|████████████████▎                         | 42/108 [00:08<00:11,  5.78it/s]\u001b[A\n 40%|████████████████▋                         | 43/108 [00:09<00:12,  5.31it/s]\u001b[A\n 41%|█████████████████                         | 44/108 [00:09<00:10,  5.87it/s]\u001b[A\n 42%|█████████████████▌                        | 45/108 [00:09<00:09,  6.36it/s]\u001b[A\n 43%|█████████████████▉                        | 46/108 [00:09<00:11,  5.18it/s]\u001b[A\n 44%|██████████████████▎                       | 47/108 [00:09<00:12,  5.00it/s]\u001b[A\n 44%|██████████████████▋                       | 48/108 [00:10<00:12,  4.69it/s]\u001b[A\n 45%|███████████████████                       | 49/108 [00:10<00:13,  4.32it/s]\u001b[A\n 46%|███████████████████▍                      | 50/108 [00:10<00:13,  4.24it/s]\u001b[A\n 47%|███████████████████▊                      | 51/108 [00:10<00:13,  4.30it/s]\u001b[A\n 48%|████████████████████▏                     | 52/108 [00:11<00:19,  2.90it/s]\u001b[A\n 49%|████████████████████▌                     | 53/108 [00:11<00:17,  3.10it/s]\u001b[A\n 50%|█████████████████████                     | 54/108 [00:11<00:15,  3.60it/s]\u001b[A\n 51%|█████████████████████▍                    | 55/108 [00:12<00:13,  4.05it/s]\u001b[A\n 52%|█████████████████████▊                    | 56/108 [00:12<00:10,  4.75it/s]\u001b[A\n 53%|██████████████████████▏                   | 57/108 [00:12<00:09,  5.37it/s]\u001b[A\n 54%|██████████████████████▌                   | 58/108 [00:12<00:09,  5.33it/s]\u001b[A\n 55%|██████████████████████▉                   | 59/108 [00:12<00:09,  4.93it/s]\u001b[A\n 56%|███████████████████████▎                  | 60/108 [00:13<00:12,  3.84it/s]\u001b[A\n 56%|███████████████████████▋                  | 61/108 [00:13<00:10,  4.41it/s]\u001b[A\n 57%|████████████████████████                  | 62/108 [00:13<00:10,  4.45it/s]\u001b[A\n 58%|████████████████████████▌                 | 63/108 [00:13<00:08,  5.25it/s]\u001b[A\n 59%|████████████████████████▉                 | 64/108 [00:14<00:13,  3.18it/s]\u001b[A\n 60%|█████████████████████████▎                | 65/108 [00:14<00:11,  3.77it/s]\u001b[A\n 61%|█████████████████████████▋                | 66/108 [00:14<00:10,  3.97it/s]\u001b[A\n 62%|██████████████████████████                | 67/108 [00:14<00:08,  4.66it/s]\u001b[A\n 63%|██████████████████████████▍               | 68/108 [00:14<00:07,  5.46it/s]\u001b[A\n 64%|██████████████████████████▊               | 69/108 [00:14<00:06,  6.06it/s]\u001b[A\n 65%|███████████████████████████▏              | 70/108 [00:15<00:06,  6.05it/s]\u001b[A\n 66%|███████████████████████████▌              | 71/108 [00:15<00:06,  5.84it/s]\u001b[A\n 67%|████████████████████████████              | 72/108 [00:15<00:06,  5.26it/s]\u001b[A\n 68%|████████████████████████████▍             | 73/108 [00:15<00:06,  5.61it/s]\u001b[A\n 69%|████████████████████████████▊             | 74/108 [00:15<00:06,  5.23it/s]\u001b[A\n 69%|█████████████████████████████▏            | 75/108 [00:16<00:06,  5.00it/s]\u001b[A\n 70%|█████████████████████████████▌            | 76/108 [00:16<00:05,  5.81it/s]\u001b[A\n 71%|█████████████████████████████▉            | 77/108 [00:16<00:05,  5.78it/s]\u001b[A\n 72%|██████████████████████████████▎           | 78/108 [00:16<00:04,  6.54it/s]\u001b[A\n 73%|██████████████████████████████▋           | 79/108 [00:16<00:04,  6.49it/s]\u001b[A\n 74%|███████████████████████████████           | 80/108 [00:17<00:06,  4.07it/s]\u001b[A\n 75%|███████████████████████████████▌          | 81/108 [00:17<00:06,  4.08it/s]\u001b[A\n 76%|███████████████████████████████▉          | 82/108 [00:17<00:05,  4.42it/s]\u001b[A\n 77%|████████████████████████████████▎         | 83/108 [00:17<00:06,  4.02it/s]\u001b[A\n 78%|████████████████████████████████▋         | 84/108 [00:18<00:05,  4.72it/s]\u001b[A\n 79%|█████████████████████████████████         | 85/108 [00:18<00:04,  4.89it/s]\u001b[A\n 80%|█████████████████████████████████▍        | 86/108 [00:18<00:04,  5.12it/s]\u001b[A\n 81%|██████████████████████████████████▏       | 88/108 [00:18<00:03,  6.23it/s]\u001b[A\n 82%|██████████████████████████████████▌       | 89/108 [00:18<00:03,  5.83it/s]\u001b[A\n 83%|███████████████████████████████████       | 90/108 [00:19<00:03,  5.00it/s]\u001b[A\n 84%|███████████████████████████████████▍      | 91/108 [00:19<00:03,  5.67it/s]\u001b[A\n 85%|███████████████████████████████████▊      | 92/108 [00:19<00:03,  4.87it/s]\u001b[A\n 86%|████████████████████████████████████▏     | 93/108 [00:19<00:02,  5.25it/s]\u001b[A\n 87%|████████████████████████████████████▌     | 94/108 [00:19<00:02,  5.93it/s]\u001b[A\n 88%|████████████████████████████████████▉     | 95/108 [00:19<00:02,  6.37it/s]\u001b[A\n 89%|█████████████████████████████████████▎    | 96/108 [00:20<00:01,  6.78it/s]\u001b[A\n 91%|██████████████████████████████████████    | 98/108 [00:20<00:01,  7.71it/s]\u001b[A\n 93%|█████████████████████████████████████▉   | 100/108 [00:20<00:01,  6.64it/s]\u001b[A\n 94%|██████████████████████████████████████▎  | 101/108 [00:20<00:01,  6.70it/s]\u001b[A\n 94%|██████████████████████████████████████▋  | 102/108 [00:20<00:00,  6.96it/s]\u001b[A\n 96%|███████████████████████████████████████▍ | 104/108 [00:21<00:00,  8.37it/s]\u001b[A\n 97%|███████████████████████████████████████▊ | 105/108 [00:21<00:00,  7.93it/s]\u001b[A\n 98%|████████████████████████████████████████▏| 106/108 [00:21<00:00,  7.97it/s]\u001b[A\n 99%|████████████████████████████████████████▌| 107/108 [00:21<00:00,  8.30it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n  warnings.warn('{} seems not to be NE tag.'.format(chunk))\nTrainer is attempting to log a value of \"{'precision': 0.9555634553857092, 'recall': 0.9424964936886395, 'f1': 0.9489849955869372, 'number': 2852}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.8897005113221329, 'recall': 0.9227272727272727, 'f1': 0.9059129788025287, 'number': 1320}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9572368421052632, 'recall': 0.9680638722554891, 'f1': 0.9626199139927224, 'number': 1503}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nTrainer is attempting to log a value of \"{'precision': 0.9284479031560744, 'recall': 0.93410178338408, 'f1': 0.931266261925412, 'number': 4598}\" of type <class 'dict'> for key \"eval/_\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n                                                                                \n\u001b[A{'eval_loss': 0.07325486838817596, 'eval_LOC': {'precision': 0.9555634553857092, 'recall': 0.9424964936886395, 'f1': 0.9489849955869372, 'number': 2852}, 'eval_ORG': {'precision': 0.8897005113221329, 'recall': 0.9227272727272727, 'f1': 0.9059129788025287, 'number': 1320}, 'eval_PER': {'precision': 0.9572368421052632, 'recall': 0.9680638722554891, 'f1': 0.9626199139927224, 'number': 1503}, 'eval__': {'precision': 0.9284479031560744, 'recall': 0.93410178338408, 'f1': 0.931266261925412, 'number': 4598}, 'eval_overall_precision': 0.9349341595662277, 'eval_overall_recall': 0.9399396476199747, 'eval_overall_f1': 0.9374302218338916, 'eval_overall_accuracy': 0.9931281569364502, 'eval_runtime': 26.2615, 'eval_samples_per_second': 131.104, 'eval_steps_per_second': 4.112, 'epoch': 3.0}\n100%|█████████████████████████████████████| 8439/8439 [1:33:02<00:00,  1.61it/s]\n100%|█████████████████████████████████████████| 108/108 [00:25<00:00,  8.30it/s]\u001b[A\n{'train_runtime': 5582.8312, 'train_samples_per_second': 24.182, 'train_steps_per_second': 1.512, 'train_loss': 0.03154105356991439, 'epoch': 3.0}\n100%|█████████████████████████████████████| 8439/8439 [1:33:02<00:00,  1.51it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:55:15.344911Z","iopub.execute_input":"2025-06-12T12:55:15.345698Z","iopub.status.idle":"2025-06-12T12:55:24.682252Z","shell.execute_reply.started":"2025-06-12T12:55:15.345666Z","shell.execute_reply":"2025-06-12T12:55:24.681610Z"}},"outputs":[{"name":"stderr","text":"2025-06-12 12:55:19.364387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749732919.388136     115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749732919.395364     115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"pipeline=pipeline('token-classification','ner_train/checkpoint-8439')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:55:24.683381Z","iopub.execute_input":"2025-06-12T12:55:24.684247Z","iopub.status.idle":"2025-06-12T12:55:25.593616Z","shell.execute_reply.started":"2025-06-12T12:55:24.684227Z","shell.execute_reply":"2025-06-12T12:55:25.593004Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"pipeline('双方确定了今后发展中美关系的指导方针')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:55:28.877012Z","iopub.execute_input":"2025-06-12T12:55:28.877331Z","iopub.status.idle":"2025-06-12T12:55:29.068730Z","shell.execute_reply.started":"2025-06-12T12:55:28.877311Z","shell.execute_reply":"2025-06-12T12:55:29.067941Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[{'entity': '0', 'score': 1.0, 'index': 1, 'word': '双', 'start': 0, 'end': 1},\n {'entity': '0', 'score': 1.0, 'index': 2, 'word': '方', 'start': 1, 'end': 2},\n {'entity': '0', 'score': 1.0, 'index': 3, 'word': '确', 'start': 2, 'end': 3},\n {'entity': '0', 'score': 1.0, 'index': 4, 'word': '定', 'start': 3, 'end': 4},\n {'entity': '0', 'score': 1.0, 'index': 5, 'word': '了', 'start': 4, 'end': 5},\n {'entity': '0', 'score': 1.0, 'index': 6, 'word': '今', 'start': 5, 'end': 6},\n {'entity': '0', 'score': 1.0, 'index': 7, 'word': '后', 'start': 6, 'end': 7},\n {'entity': '0', 'score': 1.0, 'index': 8, 'word': '发', 'start': 7, 'end': 8},\n {'entity': '0', 'score': 1.0, 'index': 9, 'word': '展', 'start': 8, 'end': 9},\n {'entity': 'B-LOC',\n  'score': 0.99999964,\n  'index': 10,\n  'word': '中',\n  'start': 9,\n  'end': 10},\n {'entity': 'B-LOC',\n  'score': 0.99999964,\n  'index': 11,\n  'word': '美',\n  'start': 10,\n  'end': 11},\n {'entity': '0',\n  'score': 1.0,\n  'index': 12,\n  'word': '关',\n  'start': 11,\n  'end': 12},\n {'entity': '0',\n  'score': 1.0,\n  'index': 13,\n  'word': '系',\n  'start': 12,\n  'end': 13},\n {'entity': '0',\n  'score': 1.0,\n  'index': 14,\n  'word': '的',\n  'start': 13,\n  'end': 14},\n {'entity': '0',\n  'score': 1.0,\n  'index': 15,\n  'word': '指',\n  'start': 14,\n  'end': 15},\n {'entity': '0',\n  'score': 1.0,\n  'index': 16,\n  'word': '导',\n  'start': 15,\n  'end': 16},\n {'entity': '0',\n  'score': 1.0,\n  'index': 17,\n  'word': '方',\n  'start': 16,\n  'end': 17},\n {'entity': '0',\n  'score': 1.0,\n  'index': 18,\n  'word': '针',\n  'start': 17,\n  'end': 18}]"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"pipeline('2023年7月我在纽约参加学术会议。')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T12:55:52.501485Z","iopub.execute_input":"2025-06-12T12:55:52.502206Z","iopub.status.idle":"2025-06-12T12:55:52.521556Z","shell.execute_reply.started":"2025-06-12T12:55:52.502182Z","shell.execute_reply":"2025-06-12T12:55:52.520815Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[{'entity': '0',\n  'score': 1.0,\n  'index': 1,\n  'word': '202',\n  'start': 0,\n  'end': 3},\n {'entity': '0',\n  'score': 1.0,\n  'index': 2,\n  'word': '##3',\n  'start': 3,\n  'end': 4},\n {'entity': '0', 'score': 1.0, 'index': 3, 'word': '年', 'start': 4, 'end': 5},\n {'entity': '0', 'score': 1.0, 'index': 4, 'word': '7', 'start': 5, 'end': 6},\n {'entity': '0', 'score': 1.0, 'index': 5, 'word': '月', 'start': 6, 'end': 7},\n {'entity': '0', 'score': 1.0, 'index': 6, 'word': '我', 'start': 7, 'end': 8},\n {'entity': '0', 'score': 1.0, 'index': 7, 'word': '在', 'start': 8, 'end': 9},\n {'entity': 'B-LOC',\n  'score': 0.99999976,\n  'index': 8,\n  'word': '纽',\n  'start': 9,\n  'end': 10},\n {'entity': 'I-LOC',\n  'score': 0.99999976,\n  'index': 9,\n  'word': '约',\n  'start': 10,\n  'end': 11},\n {'entity': '0',\n  'score': 1.0,\n  'index': 10,\n  'word': '参',\n  'start': 11,\n  'end': 12},\n {'entity': '0',\n  'score': 1.0,\n  'index': 11,\n  'word': '加',\n  'start': 12,\n  'end': 13},\n {'entity': '0',\n  'score': 1.0,\n  'index': 12,\n  'word': '学',\n  'start': 13,\n  'end': 14},\n {'entity': '0',\n  'score': 1.0,\n  'index': 13,\n  'word': '术',\n  'start': 14,\n  'end': 15},\n {'entity': '0',\n  'score': 1.0,\n  'index': 14,\n  'word': '会',\n  'start': 15,\n  'end': 16},\n {'entity': '0',\n  'score': 1.0,\n  'index': 15,\n  'word': '议',\n  'start': 16,\n  'end': 17},\n {'entity': '0',\n  'score': 1.0,\n  'index': 16,\n  'word': '。',\n  'start': 17,\n  'end': 18}]"},"metadata":{}}],"execution_count":14}]}