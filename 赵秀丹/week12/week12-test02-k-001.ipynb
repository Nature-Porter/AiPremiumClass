{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2567fe",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T15:10:45.381628Z",
     "iopub.status.busy": "2025-06-12T15:10:45.380722Z",
     "iopub.status.idle": "2025-06-12T15:10:47.604914Z",
     "shell.execute_reply": "2025-06-12T15:10:47.604344Z"
    },
    "papermill": {
     "duration": 2.229735,
     "end_time": "2025-06-12T15:10:47.606365",
     "exception": false,
     "start_time": "2025-06-12T15:10:45.376630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7b7d6",
   "metadata": {
    "papermill": {
     "duration": 0.002014,
     "end_time": "2025-06-12T15:10:47.610879",
     "exception": false,
     "start_time": "2025-06-12T15:10:47.608865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. 利用课堂案例，实现分布式DDP模型训练。存盘后加载实现推理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3367793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:10:47.615987Z",
     "iopub.status.busy": "2025-06-12T15:10:47.615701Z",
     "iopub.status.idle": "2025-06-12T15:12:23.251224Z",
     "shell.execute_reply": "2025-06-12T15:12:23.250382Z"
    },
    "papermill": {
     "duration": 95.64045,
     "end_time": "2025-06-12T15:12:23.253418",
     "exception": false,
     "start_time": "2025-06-12T15:10:47.612968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: 14: No such file or directory\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\r\n",
      "Requirement already satisfied: fsspec==2025.3.2 in /usr/local/lib/python3.11/dist-packages (2025.3.2)\r\n"
     ]
    }
   ],
   "source": [
    "# 升级numpy（如果cesium已兼容numpy 2.0+）\n",
    "!pip install numpy>=2.0\n",
    "\n",
    "# 降级rich\n",
    "!pip install rich<14\n",
    "\n",
    "# 降级所有NVIDIA CUDA库（根据torch 2.6.0+cu124的要求）\n",
    "!pip install nvidia-cublas-cu12==12.4.5.8 \\\n",
    "            nvidia-cudnn-cu12==9.1.0.70 \\\n",
    "            nvidia-cufft-cu12==11.2.1.3 \\\n",
    "            nvidia-curand-cu12==10.3.5.147 \\\n",
    "            nvidia-cusolver-cu12==11.6.1.9 \\\n",
    "            nvidia-cusparse-cu12==12.3.1.170 \\\n",
    "            nvidia-nvjitlink-cu12==12.4.127\n",
    "\n",
    "# 升级fsspec\n",
    "!pip install fsspec==2025.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c15861e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:12:23.295925Z",
     "iopub.status.busy": "2025-06-12T15:12:23.295655Z",
     "iopub.status.idle": "2025-06-12T15:12:30.395384Z",
     "shell.execute_reply": "2025-06-12T15:12:30.394597Z"
    },
    "papermill": {
     "duration": 7.122098,
     "end_time": "2025-06-12T15:12:30.396967",
     "exception": false,
     "start_time": "2025-06-12T15:12:23.274869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install evaluate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2e784d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:12:30.441059Z",
     "iopub.status.busy": "2025-06-12T15:12:30.440245Z",
     "iopub.status.idle": "2025-06-12T15:12:30.449131Z",
     "shell.execute_reply": "2025-06-12T15:12:30.448491Z"
    },
    "papermill": {
     "duration": 0.031977,
     "end_time": "2025-06-12T15:12:30.450252",
     "exception": false,
     "start_time": "2025-06-12T15:12:30.418275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing week12_test02_ner_ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile week12_test02_ner_ddp.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "import evaluate  # pip install evaluate\n",
    "import seqeval   # pip install seqeval\n",
    "from datasets import load_dataset\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# 设置分布式环境\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "# 清理分布式环境\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "    \n",
    "\n",
    "def train(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "    # 数据集\n",
    "    ds = load_dataset('nlhappy/CLUE-NER')\n",
    "    # entity_index\n",
    "    entites = ['O'] + ['movie', 'name', 'game', 'address', 'position', \\\n",
    "               'company', 'scene', 'book', 'organization', 'government']\n",
    "    tags = ['O']\n",
    "    for entity in entites[1:]:\n",
    "        tags.append('B-' + entity.upper())\n",
    "        tags.append('I-' + entity.upper())\n",
    "    \n",
    "    entity_index = {entity:i for i, entity in enumerate(entites)}\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')\n",
    "    \n",
    "    def entity_tags_proc(item):\n",
    "        # item即是dataset中记录\n",
    "        text_len = len(item['text'])  # 根据文本长度生成tags列表\n",
    "        tags = [0] * text_len    # 初始值为‘O’\n",
    "        # 遍历实体列表，所有实体类别标记填入tags\n",
    "        entites = item['ents']\n",
    "        for ent in entites:\n",
    "            indices = ent['indices']  # 实体索引\n",
    "            label = ent['label']   # 实体名\n",
    "            tags[indices[0]] = entity_index[label] * 2 - 1\n",
    "            for idx in indices[1:]:\n",
    "                tags[idx] = entity_index[label] * 2\n",
    "        return {'ent_tag': tags}\n",
    "    \n",
    "    # 使用自定义回调函数处理数据集记录\n",
    "    ds1 = ds.map(entity_tags_proc)\n",
    "    \n",
    "    def data_input_proc(item):\n",
    "        # 输入文本先拆分为字符，再转换为模型输入的token索引\n",
    "        batch_texts = [list(text) for text in item['text']]\n",
    "        # 导入拆分为字符的文本列表时，需要设置参数is_split_into_words=True\n",
    "        input_data = tokenizer(batch_texts, truncation=True, add_special_tokens=False, max_length=512, \n",
    "                               is_split_into_words=True, padding='max_length')\n",
    "        input_data['labels'] = [tag + [0] * (512 - len(tag)) for tag in item['ent_tag']]\n",
    "        return input_data\n",
    "        \n",
    "    \n",
    "    ds2 = ds1.map(data_input_proc, batched=True)  # batch_size 1000\n",
    "    \n",
    "    \n",
    "    local_rank = rank\n",
    "    \n",
    "    id2lbl = {i:tag for i, tag in enumerate(tags)}\n",
    "    lbl2id = {tag:i for i, tag in enumerate(tags)}\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n",
    "                                                            num_labels=21,\n",
    "                                                            id2label=id2lbl,\n",
    "                                                            label2id=lbl2id)\n",
    "    model.to(local_rank)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"ner_train02\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n",
    "        num_train_epochs = 3,    # 训练 epoch\n",
    "        save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n",
    "        per_device_train_batch_size=16,  # 训练批次\n",
    "        per_device_eval_batch_size=16,\n",
    "        report_to='tensorboard',  # 训练输出记录\n",
    "        eval_strategy=\"epoch\",\n",
    "        local_rank=local_rank,   # 当前进程 RANK\n",
    "        fp16=True,               # 使用混合精度\n",
    "        lr_scheduler_type='linear',  # 动态学习率\n",
    "        warmup_steps=100,        # 预热步数\n",
    "        ddp_find_unused_parameters=False  # 优化DDP性能\n",
    "    )\n",
    "    \n",
    "    def compute_metric(result):\n",
    "        # result 是一个tuple (predicts, labels)\n",
    "        \n",
    "        # 获取评估对象\n",
    "        seqeval = evaluate.load('seqeval')\n",
    "        predicts,labels = result\n",
    "        predicts = np.argmax(predicts, axis=2)\n",
    "        \n",
    "        # 准备评估数据\n",
    "        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        results = seqeval.compute(predictions=predicts, references=labels)\n",
    "    \n",
    "        return results\n",
    "    \n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=ds2['train'],\n",
    "        eval_dataset=ds2['validation'],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metric\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337c40ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:12:30.492928Z",
     "iopub.status.busy": "2025-06-12T15:12:30.492200Z",
     "iopub.status.idle": "2025-06-12T16:18:28.711920Z",
     "shell.execute_reply": "2025-06-12T16:18:28.710964Z"
    },
    "papermill": {
     "duration": 3958.242648,
     "end_time": "2025-06-12T16:18:28.713569",
     "exception": false,
     "start_time": "2025-06-12T15:12:30.470921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 15:12:53.032481: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749741173.542300      83 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749741173.657185      83 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2025-06-12 15:13:21.111077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-06-12 15:13:21.112715: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749741201.134888      98 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749741201.139337      97 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749741201.142376      98 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1749741201.147941      97 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "[W612 15:13:25.387032342 socket.cpp:759] [c10d] The client socket has failed to connect to [localhost]:12355 (errno: 99 - Cannot assign requested address).\r\n",
      "README.md: 100%|██████████████████████████████| 21.0/21.0 [00:00<00:00, 149kB/s]\r\n",
      "dataset_infos.json: 100%|██████████████████████| 970/970 [00:00<00:00, 10.5MB/s]\r\n",
      "(…)-00000-of-00001-a33d0e4276aef9b4.parquet: 100%|█| 1.30M/1.30M [00:00<00:00, 2\r\n",
      "(…)-00000-of-00001-07f476b71c5edde6.parquet: 100%|█| 178k/178k [00:00<00:00, 332\r\n",
      "Generating train split: 100%|██| 10748/10748 [00:00<00:00, 116732.00 examples/s]\r\n",
      "Generating validation split: 100%|█| 1343/1343 [00:00<00:00, 342949.79 examples/\r\n",
      "tokenizer_config.json: 100%|██████████████████| 49.0/49.0 [00:00<00:00, 420kB/s]\r\n",
      "config.json: 100%|█████████████████████████████| 624/624 [00:00<00:00, 7.37MB/s]\r\n",
      "vocab.txt: 100%|█████████████████████████████| 110k/110k [00:00<00:00, 4.87MB/s]\r\n",
      "tokenizer.json: 100%|████████████████████████| 269k/269k [00:00<00:00, 13.0MB/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:01<00:00, 9661.58 examples/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:01<00:00, 9348.30 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 7843.12 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 6839.76 examples/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1800.20 examples/s]\r\n",
      "Map: 100%|███████████████████████| 10748/10748 [00:05<00:00, 1816.43 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 1769.92 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 1343/1343 [00:00<00:00, 1804.34 examples/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 412M/412M [00:02<00:00, 194MB/s]\r\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "  0%|                                                  | 0/1008 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 33%|█████████████▎                          | 336/1008 [20:31<39:58,  3.57s/it]\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:22,  1.77it/s]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:23,  1.73it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 3/42 [00:02<00:31,  1.24it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 3/42 [00:02<00:32,  1.20it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:35,  1.07it/s]\u001b[A\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:36,  1.04it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.01s/it]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.02s/it]\u001b[A\r\n",
      " 14%|██████▎                                     | 6/42 [00:05<00:37,  1.04s/it]\u001b[A\r\n",
      " 14%|██████▎                                     | 6/42 [00:05<00:39,  1.09s/it]\u001b[A\r\n",
      " 17%|███████▎                                    | 7/42 [00:06<00:37,  1.07s/it]\u001b[A\r\n",
      " 17%|███████▎                                    | 7/42 [00:07<00:38,  1.11s/it]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:07<00:37,  1.09s/it]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:08<00:37,  1.11s/it]\u001b[A\r\n",
      " 21%|█████████▍                                  | 9/42 [00:09<00:36,  1.11s/it]\u001b[A\r\n",
      " 21%|█████████▍                                  | 9/42 [00:09<00:37,  1.12s/it]\u001b[A\r\n",
      " 24%|██████████▏                                | 10/42 [00:10<00:35,  1.12s/it]\u001b[A\r\n",
      " 24%|██████████▏                                | 10/42 [00:10<00:36,  1.13s/it]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:11<00:34,  1.13s/it]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:11<00:35,  1.14s/it]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:12<00:33,  1.13s/it]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:12<00:34,  1.15s/it]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:13<00:32,  1.13s/it]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:13<00:33,  1.15s/it]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:14<00:31,  1.14s/it]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:14<00:30,  1.09s/it]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:15<00:31,  1.15s/it]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:16<00:32,  1.21s/it]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:17<00:29,  1.14s/it]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:17<00:31,  1.21s/it]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:18<00:28,  1.14s/it]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:18<00:29,  1.19s/it]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:19<00:27,  1.15s/it]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:19<00:28,  1.17s/it]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:20<00:26,  1.15s/it]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:21<00:26,  1.17s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:21<00:25,  1.15s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:22<00:25,  1.16s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:22<00:24,  1.16s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:23<00:24,  1.16s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:24<00:23,  1.16s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:24<00:23,  1.15s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:25<00:22,  1.16s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:25<00:21,  1.16s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:26<00:20,  1.16s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:26<00:20,  1.15s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:27<00:19,  1.16s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:27<00:19,  1.15s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:28<00:18,  1.16s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:29<00:18,  1.16s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:29<00:17,  1.15s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:30<00:17,  1.16s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:30<00:16,  1.15s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:31<00:16,  1.15s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:32<00:15,  1.16s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:32<00:14,  1.15s/it]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:33<00:13,  1.16s/it]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:33<00:13,  1.15s/it]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:34<00:12,  1.16s/it]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:34<00:12,  1.15s/it]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:35<00:11,  1.15s/it]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:36<00:11,  1.15s/it]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:36<00:10,  1.16s/it]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:37<00:10,  1.15s/it]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:37<00:09,  1.15s/it]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:38<00:09,  1.16s/it]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:39<00:08,  1.15s/it]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:39<00:08,  1.16s/it]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:40<00:06,  1.15s/it]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:40<00:06,  1.15s/it]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:41<00:05,  1.16s/it]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:41<00:05,  1.15s/it]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:42<00:04,  1.15s/it]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:42<00:04,  1.16s/it]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:43<00:03,  1.16s/it]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:44<00:03,  1.16s/it]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:44<00:02,  1.16s/it]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:45<00:02,  1.16s/it]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:46<00:01,  1.16s/it]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:46<00:01,  1.17s/it]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:47<00:00,  1.13s/it]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:47<00:00,  1.04s/it]\u001b[A\r\n",
      "\r\n",
      "Downloading builder script: 100%|██████████| 6.34k/6.34k [00:00<00:00, 21.6MB/s]\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5214446952595937, 'recall': 0.6193029490616622, 'f1': 0.5661764705882353, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6542553191489362, 'recall': 0.7987012987012987, 'f1': 0.7192982456140351, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6624472573839663, 'recall': 0.8306878306878307, 'f1': 0.7370892018779343, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6848137535816619, 'recall': 0.8101694915254237, 'f1': 0.7422360248447205, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6430769230769231, 'recall': 0.8461538461538461, 'f1': 0.7307692307692307, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7210884353741497, 'recall': 0.7019867549668874, 'f1': 0.7114093959731544, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8223552894211577, 'recall': 0.886021505376344, 'f1': 0.8530020703933746, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6625, 'recall': 0.7220708446866485, 'f1': 0.6910039113428944, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5866666666666667, 'recall': 0.812933025404157, 'f1': 0.681510164569216, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6330645161290323, 'recall': 0.7511961722488039, 'f1': 0.6870897155361051, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.017131974920630455, 'eval_ADDRESS': {'precision': 0.5214446952595937, 'recall': 0.6193029490616622, 'f1': 0.5661764705882353, 'number': 373}, 'eval_BOOK': {'precision': 0.6542553191489362, 'recall': 0.7987012987012987, 'f1': 0.7192982456140351, 'number': 154}, 'eval_COMPANY': {'precision': 0.6624472573839663, 'recall': 0.8306878306878307, 'f1': 0.7370892018779343, 'number': 378}, 'eval_GAME': {'precision': 0.6848137535816619, 'recall': 0.8101694915254237, 'f1': 0.7422360248447205, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6430769230769231, 'recall': 0.8461538461538461, 'f1': 0.7307692307692307, 'number': 247}, 'eval_MOVIE': {'precision': 0.7210884353741497, 'recall': 0.7019867549668874, 'f1': 0.7114093959731544, 'number': 151}, 'eval_NAME': {'precision': 0.8223552894211577, 'recall': 0.886021505376344, 'f1': 0.8530020703933746, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6625, 'recall': 0.7220708446866485, 'f1': 0.6910039113428944, 'number': 367}, 'eval_POSITION': {'precision': 0.5866666666666667, 'recall': 0.812933025404157, 'f1': 0.681510164569216, 'number': 433}, 'eval_SCENE': {'precision': 0.6330645161290323, 'recall': 0.7511961722488039, 'f1': 0.6870897155361051, 'number': 209}, 'eval_overall_precision': 0.6552380952380953, 'eval_overall_recall': 0.7838541666666666, 'eval_overall_f1': 0.713798725359419, 'eval_overall_accuracy': 0.9948546863365599, 'eval_runtime': 55.6634, 'eval_samples_per_second': 24.127, 'eval_steps_per_second': 0.755, 'epoch': 1.0}\r\n",
      " 33%|█████████████▎                          | 336/1008 [21:27<39:44,  3.55s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:54<00:00,  1.13s/it]\u001b[A\r\n",
      "                                                                                \u001b[ATrainer is attempting to log a value of \"{'precision': 0.5497630331753555, 'recall': 0.6219839142091153, 'f1': 0.5836477987421383, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5595854922279793, 'recall': 0.7012987012987013, 'f1': 0.622478386167147, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6928571428571428, 'recall': 0.7698412698412699, 'f1': 0.7293233082706767, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.625, 'recall': 0.8305084745762712, 'f1': 0.7132459970887919, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6538461538461539, 'recall': 0.8259109311740891, 'f1': 0.7298747763864043, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6870748299319728, 'recall': 0.6688741721854304, 'f1': 0.6778523489932885, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7796610169491526, 'recall': 0.8903225806451613, 'f1': 0.8313253012048194, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6788511749347258, 'recall': 0.7084468664850136, 'f1': 0.6933333333333332, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6126760563380281, 'recall': 0.8036951501154734, 'f1': 0.6953046953046952, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6058394160583942, 'recall': 0.7942583732057417, 'f1': 0.6873706004140786, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.017779717221856117, 'eval_ADDRESS': {'precision': 0.5497630331753555, 'recall': 0.6219839142091153, 'f1': 0.5836477987421383, 'number': 373}, 'eval_BOOK': {'precision': 0.5595854922279793, 'recall': 0.7012987012987013, 'f1': 0.622478386167147, 'number': 154}, 'eval_COMPANY': {'precision': 0.6928571428571428, 'recall': 0.7698412698412699, 'f1': 0.7293233082706767, 'number': 378}, 'eval_GAME': {'precision': 0.625, 'recall': 0.8305084745762712, 'f1': 0.7132459970887919, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.6538461538461539, 'recall': 0.8259109311740891, 'f1': 0.7298747763864043, 'number': 247}, 'eval_MOVIE': {'precision': 0.6870748299319728, 'recall': 0.6688741721854304, 'f1': 0.6778523489932885, 'number': 151}, 'eval_NAME': {'precision': 0.7796610169491526, 'recall': 0.8903225806451613, 'f1': 0.8313253012048194, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6788511749347258, 'recall': 0.7084468664850136, 'f1': 0.6933333333333332, 'number': 367}, 'eval_POSITION': {'precision': 0.6126760563380281, 'recall': 0.8036951501154734, 'f1': 0.6953046953046952, 'number': 433}, 'eval_SCENE': {'precision': 0.6058394160583942, 'recall': 0.7942583732057417, 'f1': 0.6873706004140786, 'number': 209}, 'eval_overall_precision': 0.6504667764964306, 'eval_overall_recall': 0.7711588541666666, 'eval_overall_f1': 0.7056896038129282, 'eval_overall_accuracy': 0.9945900037230082, 'eval_runtime': 56.8905, 'eval_samples_per_second': 23.607, 'eval_steps_per_second': 0.738, 'epoch': 1.0}\r\n",
      " 33%|█████████████▎                          | 336/1008 [21:28<39:58,  3.57s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:55<00:00,  1.04s/it]\u001b[A\r\n",
      "{'loss': 0.1017, 'grad_norm': 10823.0048828125, 'learning_rate': 2.802863436123348e-05, 'epoch': 1.49}\r\n",
      "{'loss': 0.1106, 'grad_norm': 9196.544921875, 'learning_rate': 2.802863436123348e-05, 'epoch': 1.49}\r\n",
      " 50%|███████████████████▊                    | 500/1008 [31:35<26:33,  3.14s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 50%|███████████████████▉                    | 502/1008 [31:39<26:27,  3.14s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      " 66%|██████████████████████████▌             | 670/1008 [42:09<21:04,  3.74s/it]\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:23,  1.70it/s]\u001b[A\r\n",
      " 67%|██████████████████████████▋             | 671/1008 [42:12<20:50,  3.71s/it]\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:34,  1.10it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.00s/it]\u001b[A\r\n",
      " 67%|██████████████████████████▋             | 672/1008 [42:15<19:40,  3.51s/it]\r\n",
      " 17%|███████▎                                    | 7/42 [00:06<00:36,  1.04s/it]\u001b[A\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:07<00:36,  1.07s/it]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:22,  1.75it/s]\u001b[A\r\n",
      " 21%|█████████▍                                  | 9/42 [00:09<00:36,  1.10s/it]\u001b[A\r\n",
      "  7%|███▏                                        | 3/42 [00:02<00:31,  1.23it/s]\u001b[A\r\n",
      " 24%|██████████▏                                | 10/42 [00:10<00:35,  1.11s/it]\u001b[A\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:35,  1.08it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:11<00:35,  1.15s/it]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.01s/it]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:12<00:34,  1.15s/it]\u001b[A\r\n",
      " 14%|██████▎                                     | 6/42 [00:05<00:38,  1.06s/it]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:13<00:33,  1.15s/it]\u001b[A\r\n",
      " 17%|███████▎                                    | 7/42 [00:06<00:37,  1.08s/it]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:14<00:32,  1.15s/it]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:08<00:37,  1.10s/it]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:16<00:31,  1.15s/it]\u001b[A\r\n",
      " 21%|█████████▍                                  | 9/42 [00:09<00:36,  1.12s/it]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:17<00:29,  1.15s/it]\u001b[A\r\n",
      " 24%|██████████▏                                | 10/42 [00:10<00:35,  1.12s/it]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:18<00:28,  1.15s/it]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:11<00:35,  1.13s/it]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:19<00:27,  1.15s/it]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:12<00:34,  1.14s/it]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:20<00:26,  1.15s/it]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:13<00:33,  1.14s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:21<00:25,  1.15s/it]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:14<00:32,  1.14s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:22<00:24,  1.15s/it]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:16<00:30,  1.15s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:24<00:22,  1.15s/it]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:17<00:29,  1.15s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:25<00:21,  1.15s/it]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:18<00:28,  1.15s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:26<00:20,  1.15s/it]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:19<00:27,  1.15s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:27<00:19,  1.15s/it]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:20<00:26,  1.15s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:28<00:18,  1.15s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:21<00:25,  1.15s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:29<00:17,  1.15s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:22<00:24,  1.16s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:30<00:16,  1.15s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:24<00:23,  1.16s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:32<00:15,  1.16s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:25<00:21,  1.16s/it]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:33<00:13,  1.16s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:26<00:20,  1.16s/it]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:34<00:12,  1.16s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:27<00:19,  1.15s/it]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:35<00:11,  1.16s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:28<00:18,  1.15s/it]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:36<00:10,  1.15s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:29<00:17,  1.16s/it]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:37<00:09,  1.13s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:31<00:16,  1.16s/it]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:38<00:07,  1.13s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:32<00:15,  1.17s/it]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:40<00:06,  1.14s/it]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:33<00:13,  1.16s/it]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:41<00:05,  1.14s/it]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:34<00:12,  1.16s/it]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:42<00:04,  1.15s/it]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:35<00:11,  1.16s/it]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:43<00:03,  1.15s/it]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:36<00:10,  1.16s/it]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:44<00:02,  1.16s/it]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:38<00:09,  1.16s/it]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:45<00:01,  1.17s/it]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:39<00:08,  1.17s/it]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:47<00:00,  1.12s/it]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:39<00:06,  1.04s/it]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:40<00:04,  1.11it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:41<00:03,  1.24it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:41<00:02,  1.35it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:42<00:01,  1.43it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:42<00:00,  1.51it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:43<00:00,  1.60it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.5598194130925508, 'recall': 0.6648793565683646, 'f1': 0.6078431372549019, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7870967741935484, 'recall': 0.7922077922077922, 'f1': 0.7896440129449839, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7025171624713958, 'recall': 0.8121693121693122, 'f1': 0.7533742331288343, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.723342939481268, 'recall': 0.8508474576271187, 'f1': 0.7819314641744548, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7123745819397993, 'recall': 0.8623481781376519, 'f1': 0.7802197802197802, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7687074829931972, 'recall': 0.7483443708609272, 'f1': 0.7583892617449663, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8067061143984221, 'recall': 0.8795698924731182, 'f1': 0.8415637860082305, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6990049751243781, 'recall': 0.7656675749318801, 'f1': 0.7308192457737323, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7472283813747228, 'recall': 0.7782909930715936, 'f1': 0.7624434389140272, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.668141592920354, 'recall': 0.722488038277512, 'f1': 0.6942528735632183, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.015033191069960594, 'eval_ADDRESS': {'precision': 0.5598194130925508, 'recall': 0.6648793565683646, 'f1': 0.6078431372549019, 'number': 373}, 'eval_BOOK': {'precision': 0.7870967741935484, 'recall': 0.7922077922077922, 'f1': 0.7896440129449839, 'number': 154}, 'eval_COMPANY': {'precision': 0.7025171624713958, 'recall': 0.8121693121693122, 'f1': 0.7533742331288343, 'number': 378}, 'eval_GAME': {'precision': 0.723342939481268, 'recall': 0.8508474576271187, 'f1': 0.7819314641744548, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.7123745819397993, 'recall': 0.8623481781376519, 'f1': 0.7802197802197802, 'number': 247}, 'eval_MOVIE': {'precision': 0.7687074829931972, 'recall': 0.7483443708609272, 'f1': 0.7583892617449663, 'number': 151}, 'eval_NAME': {'precision': 0.8067061143984221, 'recall': 0.8795698924731182, 'f1': 0.8415637860082305, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6990049751243781, 'recall': 0.7656675749318801, 'f1': 0.7308192457737323, 'number': 367}, 'eval_POSITION': {'precision': 0.7472283813747228, 'recall': 0.7782909930715936, 'f1': 0.7624434389140272, 'number': 433}, 'eval_SCENE': {'precision': 0.668141592920354, 'recall': 0.722488038277512, 'f1': 0.6942528735632183, 'number': 209}, 'eval_overall_precision': 0.7123608670181605, 'eval_overall_recall': 0.7916666666666666, 'eval_overall_f1': 0.749922910884983, 'eval_overall_accuracy': 0.9955207557706627, 'eval_runtime': 55.4434, 'eval_samples_per_second': 24.223, 'eval_steps_per_second': 0.758, 'epoch': 2.0}\r\n",
      " 67%|██████████████████████████▋             | 672/1008 [43:04<19:51,  3.55s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:54<00:00,  1.12s/it]\u001b[A\r\n",
      " 67%|█████████████████████████▍            | 674/1008 [43:07<1:19:31, 14.29s/it]Trainer is attempting to log a value of \"{'precision': 0.5477855477855478, 'recall': 0.6300268096514745, 'f1': 0.5860349127182045, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7515527950310559, 'recall': 0.7857142857142857, 'f1': 0.7682539682539682, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7162471395881007, 'recall': 0.828042328042328, 'f1': 0.7680981595092026, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7453416149068323, 'recall': 0.8135593220338984, 'f1': 0.7779578606158833, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7491039426523297, 'recall': 0.8461538461538461, 'f1': 0.7946768060836502, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7847222222222222, 'recall': 0.7483443708609272, 'f1': 0.7661016949152541, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8333333333333334, 'recall': 0.8817204301075269, 'f1': 0.8568443051201672, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7093596059113301, 'recall': 0.784741144414169, 'f1': 0.7451487710219923, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7688888888888888, 'recall': 0.7990762124711316, 'f1': 0.783691959229898, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.648068669527897, 'recall': 0.722488038277512, 'f1': 0.6832579185520362, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.014966717921197414, 'eval_ADDRESS': {'precision': 0.5477855477855478, 'recall': 0.6300268096514745, 'f1': 0.5860349127182045, 'number': 373}, 'eval_BOOK': {'precision': 0.7515527950310559, 'recall': 0.7857142857142857, 'f1': 0.7682539682539682, 'number': 154}, 'eval_COMPANY': {'precision': 0.7162471395881007, 'recall': 0.828042328042328, 'f1': 0.7680981595092026, 'number': 378}, 'eval_GAME': {'precision': 0.7453416149068323, 'recall': 0.8135593220338984, 'f1': 0.7779578606158833, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.7491039426523297, 'recall': 0.8461538461538461, 'f1': 0.7946768060836502, 'number': 247}, 'eval_MOVIE': {'precision': 0.7847222222222222, 'recall': 0.7483443708609272, 'f1': 0.7661016949152541, 'number': 151}, 'eval_NAME': {'precision': 0.8333333333333334, 'recall': 0.8817204301075269, 'f1': 0.8568443051201672, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.7093596059113301, 'recall': 0.784741144414169, 'f1': 0.7451487710219923, 'number': 367}, 'eval_POSITION': {'precision': 0.7688888888888888, 'recall': 0.7990762124711316, 'f1': 0.783691959229898, 'number': 433}, 'eval_SCENE': {'precision': 0.648068669527897, 'recall': 0.722488038277512, 'f1': 0.6832579185520362, 'number': 209}, 'eval_overall_precision': 0.7235311661198927, 'eval_overall_recall': 0.7897135416666666, 'eval_overall_f1': 0.7551750972762645, 'eval_overall_accuracy': 0.9955396616716307, 'eval_runtime': 52.9964, 'eval_samples_per_second': 25.341, 'eval_steps_per_second': 0.793, 'epoch': 2.0}\r\n",
      " 67%|██████████████████████████▋             | 672/1008 [43:08<19:40,  3.51s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:51<00:00,  1.60it/s]\u001b[A\r\n",
      "{'loss': 0.0101, 'grad_norm': 9814.0537109375, 'learning_rate': 4.955947136563877e-07, 'epoch': 2.98}\r\n",
      " 99%|█████████████████████████████████████▌| 998/1008 [1:03:15<00:31,  3.11s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.0101, 'grad_norm': 7321.1005859375, 'learning_rate': 4.955947136563877e-07, 'epoch': 2.98}\r\n",
      "100%|████████████████████████████████████▊| 1004/1008 [1:03:26<00:11,  2.91s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "100%|████████████████████████████████████▉| 1005/1008 [1:03:43<00:09,  3.28s/it]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:24,  1.64it/s]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 1006/1008 [1:03:46<00:06,  3.38s/it]\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:35,  1.07it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.02s/it]\u001b[A\r\n",
      "100%|████████████████████████████████████▉| 1007/1008 [1:03:50<00:03,  3.49s/it]\r\n",
      " 17%|███████▎                                    | 7/42 [00:06<00:37,  1.08s/it]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:08<00:38,  1.12s/it]\u001b[A\r\n",
      "100%|█████████████████████████████████████| 1008/1008 [1:03:53<00:00,  3.39s/it]\r\n",
      " 24%|██████████▏                                | 10/42 [00:09<00:30,  1.03it/s]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:10<00:26,  1.18it/s]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:11<00:23,  1.30it/s]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:11<00:20,  1.40it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:12<00:18,  1.48it/s]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:12<00:17,  1.51it/s]\u001b[A/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "  0%|                                                    | 0/42 [00:00<?, ?it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:14<00:21,  1.22it/s]\u001b[A\r\n",
      "  5%|██                                          | 2/42 [00:01<00:23,  1.74it/s]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:15<00:22,  1.09it/s]\u001b[A\r\n",
      "  7%|███▏                                        | 3/42 [00:02<00:31,  1.24it/s]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:16<00:24,  1.01s/it]\u001b[A\r\n",
      " 10%|████▏                                       | 4/42 [00:03<00:35,  1.07it/s]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:17<00:24,  1.05s/it]\u001b[A\r\n",
      " 12%|█████▏                                      | 5/42 [00:04<00:37,  1.01s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:18<00:23,  1.08s/it]\u001b[A\r\n",
      " 14%|██████▎                                     | 6/42 [00:05<00:37,  1.05s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:19<00:23,  1.10s/it]\u001b[A\r\n",
      " 17%|███████▎                                    | 7/42 [00:06<00:38,  1.09s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:21<00:22,  1.12s/it]\u001b[A\r\n",
      " 19%|████████▍                                   | 8/42 [00:08<00:37,  1.10s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:22<00:21,  1.13s/it]\u001b[A\r\n",
      " 21%|█████████▍                                  | 9/42 [00:09<00:36,  1.12s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:23<00:20,  1.14s/it]\u001b[A\r\n",
      " 24%|██████████▏                                | 10/42 [00:10<00:36,  1.13s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:24<00:19,  1.15s/it]\u001b[A\r\n",
      " 26%|███████████▎                               | 11/42 [00:11<00:35,  1.13s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:25<00:18,  1.16s/it]\u001b[A\r\n",
      " 29%|████████████▎                              | 12/42 [00:12<00:34,  1.14s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:26<00:17,  1.16s/it]\u001b[A\r\n",
      " 31%|█████████████▎                             | 13/42 [00:13<00:33,  1.14s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:28<00:16,  1.16s/it]\u001b[A\r\n",
      " 33%|██████████████▎                            | 14/42 [00:14<00:32,  1.14s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:29<00:15,  1.16s/it]\u001b[A\r\n",
      " 36%|███████████████▎                           | 15/42 [00:16<00:30,  1.15s/it]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:30<00:13,  1.16s/it]\u001b[A\r\n",
      " 38%|████████████████▍                          | 16/42 [00:17<00:29,  1.13s/it]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:31<00:13,  1.20s/it]\u001b[A\r\n",
      " 40%|█████████████████▍                         | 17/42 [00:18<00:28,  1.13s/it]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:32<00:11,  1.18s/it]\u001b[A\r\n",
      " 43%|██████████████████▍                        | 18/42 [00:19<00:27,  1.14s/it]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:33<00:10,  1.18s/it]\u001b[A\r\n",
      " 45%|███████████████████▍                       | 19/42 [00:20<00:26,  1.15s/it]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:35<00:09,  1.17s/it]\u001b[A\r\n",
      " 48%|████████████████████▍                      | 20/42 [00:21<00:25,  1.15s/it]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:36<00:08,  1.17s/it]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 21/42 [00:22<00:24,  1.15s/it]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:37<00:06,  1.16s/it]\u001b[A\r\n",
      " 52%|██████████████████████▌                    | 22/42 [00:24<00:23,  1.15s/it]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:38<00:05,  1.16s/it]\u001b[A\r\n",
      " 55%|███████████████████████▌                   | 23/42 [00:25<00:22,  1.16s/it]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:39<00:04,  1.16s/it]\u001b[A\r\n",
      " 57%|████████████████████████▌                  | 24/42 [00:26<00:20,  1.16s/it]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:40<00:03,  1.16s/it]\u001b[A\r\n",
      " 60%|█████████████████████████▌                 | 25/42 [00:27<00:19,  1.16s/it]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:42<00:02,  1.16s/it]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 26/42 [00:28<00:18,  1.16s/it]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:43<00:01,  1.16s/it]\u001b[A\r\n",
      " 64%|███████████████████████████▋               | 27/42 [00:29<00:17,  1.17s/it]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:44<00:00,  1.12s/it]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 28/42 [00:30<00:14,  1.06s/it]\u001b[A\r\n",
      " 69%|█████████████████████████████▋             | 29/42 [00:31<00:11,  1.09it/s]\u001b[A\r\n",
      " 71%|██████████████████████████████▋            | 30/42 [00:31<00:09,  1.22it/s]\u001b[A\r\n",
      " 74%|███████████████████████████████▋           | 31/42 [00:32<00:08,  1.33it/s]\u001b[A\r\n",
      " 76%|████████████████████████████████▊          | 32/42 [00:33<00:07,  1.43it/s]\u001b[A\r\n",
      " 79%|█████████████████████████████████▊         | 33/42 [00:33<00:06,  1.49it/s]\u001b[A\r\n",
      " 81%|██████████████████████████████████▊        | 34/42 [00:34<00:05,  1.55it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 35/42 [00:34<00:04,  1.60it/s]\u001b[A\r\n",
      " 86%|████████████████████████████████████▊      | 36/42 [00:35<00:03,  1.63it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 37/42 [00:36<00:03,  1.65it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▉    | 38/42 [00:36<00:02,  1.67it/s]\u001b[A\r\n",
      " 93%|███████████████████████████████████████▉   | 39/42 [00:37<00:01,  1.68it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.5608591885441527, 'recall': 0.6300268096514745, 'f1': 0.5934343434343434, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7352941176470589, 'recall': 0.8116883116883117, 'f1': 0.7716049382716049, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.713953488372093, 'recall': 0.8121693121693122, 'f1': 0.75990099009901, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7617554858934169, 'recall': 0.823728813559322, 'f1': 0.7915309446254072, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7517482517482518, 'recall': 0.8704453441295547, 'f1': 0.8067542213883677, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7531645569620253, 'recall': 0.7880794701986755, 'f1': 0.7702265372168285, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8142292490118577, 'recall': 0.886021505376344, 'f1': 0.8486096807415037, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6968215158924206, 'recall': 0.776566757493188, 'f1': 0.7345360824742267, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7227926078028748, 'recall': 0.812933025404157, 'f1': 0.7652173913043477, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.673728813559322, 'recall': 0.7607655502392344, 'f1': 0.7146067415730336, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.015537239611148834, 'eval_ADDRESS': {'precision': 0.5608591885441527, 'recall': 0.6300268096514745, 'f1': 0.5934343434343434, 'number': 373}, 'eval_BOOK': {'precision': 0.7352941176470589, 'recall': 0.8116883116883117, 'f1': 0.7716049382716049, 'number': 154}, 'eval_COMPANY': {'precision': 0.713953488372093, 'recall': 0.8121693121693122, 'f1': 0.75990099009901, 'number': 378}, 'eval_GAME': {'precision': 0.7617554858934169, 'recall': 0.823728813559322, 'f1': 0.7915309446254072, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.7517482517482518, 'recall': 0.8704453441295547, 'f1': 0.8067542213883677, 'number': 247}, 'eval_MOVIE': {'precision': 0.7531645569620253, 'recall': 0.7880794701986755, 'f1': 0.7702265372168285, 'number': 151}, 'eval_NAME': {'precision': 0.8142292490118577, 'recall': 0.886021505376344, 'f1': 0.8486096807415037, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.6968215158924206, 'recall': 0.776566757493188, 'f1': 0.7345360824742267, 'number': 367}, 'eval_POSITION': {'precision': 0.7227926078028748, 'recall': 0.812933025404157, 'f1': 0.7652173913043477, 'number': 433}, 'eval_SCENE': {'precision': 0.673728813559322, 'recall': 0.7607655502392344, 'f1': 0.7146067415730336, 'number': 209}, 'eval_overall_precision': 0.7169590643274854, 'eval_overall_recall': 0.7981770833333334, 'eval_overall_f1': 0.7553912507701787, 'eval_overall_accuracy': 0.99558183637379, 'eval_runtime': 52.823, 'eval_samples_per_second': 25.425, 'eval_steps_per_second': 0.795, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 1008/1008 [1:04:35<00:00,  3.38s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:51<00:00,  1.12s/it]\u001b[A\r\n",
      "{'train_runtime': 3875.9529, 'train_samples_per_second': 8.319, 'train_steps_per_second': 0.26, 'train_loss': 0.055507239604753164, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 1008/1008 [1:04:35<00:00,  3.85s/it]\r\n",
      "\r\n",
      " 95%|████████████████████████████████████████▉  | 40/42 [00:37<00:01,  1.68it/s]\u001b[A\r\n",
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:38<00:00,  1.69it/s]\u001b[A[rank0]:[W612 16:18:16.840717122 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n",
      "\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:38<00:00,  1.74it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.5788235294117647, 'recall': 0.6595174262734584, 'f1': 0.6165413533834587, 'number': 373}\" of type <class 'dict'> for key \"eval/ADDRESS\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7834394904458599, 'recall': 0.7987012987012987, 'f1': 0.7909967845659164, 'number': 154}\" of type <class 'dict'> for key \"eval/BOOK\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7172897196261683, 'recall': 0.8121693121693122, 'f1': 0.7617866004962779, 'number': 378}\" of type <class 'dict'> for key \"eval/COMPANY\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7585139318885449, 'recall': 0.8305084745762712, 'f1': 0.7928802588996765, 'number': 295}\" of type <class 'dict'> for key \"eval/GAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.75, 'recall': 0.8623481781376519, 'f1': 0.8022598870056497, 'number': 247}\" of type <class 'dict'> for key \"eval/GOVERNMENT\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7792207792207793, 'recall': 0.7947019867549668, 'f1': 0.7868852459016393, 'number': 151}\" of type <class 'dict'> for key \"eval/MOVIE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8198019801980198, 'recall': 0.8903225806451613, 'f1': 0.8536082474226804, 'number': 465}\" of type <class 'dict'> for key \"eval/NAME\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7058823529411765, 'recall': 0.784741144414169, 'f1': 0.7432258064516128, 'number': 367}\" of type <class 'dict'> for key \"eval/ORGANIZATION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.7233606557377049, 'recall': 0.815242494226328, 'f1': 0.7665580890336591, 'number': 433}\" of type <class 'dict'> for key \"eval/POSITION\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6695278969957081, 'recall': 0.7464114832535885, 'f1': 0.7058823529411764, 'number': 209}\" of type <class 'dict'> for key \"eval/SCENE\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.01610570028424263, 'eval_ADDRESS': {'precision': 0.5788235294117647, 'recall': 0.6595174262734584, 'f1': 0.6165413533834587, 'number': 373}, 'eval_BOOK': {'precision': 0.7834394904458599, 'recall': 0.7987012987012987, 'f1': 0.7909967845659164, 'number': 154}, 'eval_COMPANY': {'precision': 0.7172897196261683, 'recall': 0.8121693121693122, 'f1': 0.7617866004962779, 'number': 378}, 'eval_GAME': {'precision': 0.7585139318885449, 'recall': 0.8305084745762712, 'f1': 0.7928802588996765, 'number': 295}, 'eval_GOVERNMENT': {'precision': 0.75, 'recall': 0.8623481781376519, 'f1': 0.8022598870056497, 'number': 247}, 'eval_MOVIE': {'precision': 0.7792207792207793, 'recall': 0.7947019867549668, 'f1': 0.7868852459016393, 'number': 151}, 'eval_NAME': {'precision': 0.8198019801980198, 'recall': 0.8903225806451613, 'f1': 0.8536082474226804, 'number': 465}, 'eval_ORGANIZATION': {'precision': 0.7058823529411765, 'recall': 0.784741144414169, 'f1': 0.7432258064516128, 'number': 367}, 'eval_POSITION': {'precision': 0.7233606557377049, 'recall': 0.815242494226328, 'f1': 0.7665580890336591, 'number': 433}, 'eval_SCENE': {'precision': 0.6695278969957081, 'recall': 0.7464114832535885, 'f1': 0.7058823529411764, 'number': 209}, 'eval_overall_precision': 0.723935389133627, 'eval_overall_recall': 0.8024088541666666, 'eval_overall_f1': 0.7611548556430445, 'eval_overall_accuracy': 0.9955193014705882, 'eval_runtime': 47.1433, 'eval_samples_per_second': 28.488, 'eval_steps_per_second': 0.891, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 1008/1008 [1:04:44<00:00,  3.39s/it]\r\n",
      "100%|███████████████████████████████████████████| 42/42 [00:45<00:00,  1.74it/s]\u001b[A\r\n",
      "{'train_runtime': 3884.1495, 'train_samples_per_second': 8.301, 'train_steps_per_second': 0.26, 'train_loss': 0.05990001398123919, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 1008/1008 [1:04:44<00:00,  3.85s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!python week12_test02_ner_ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef6b636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T16:18:28.946760Z",
     "iopub.status.busy": "2025-06-12T16:18:28.946447Z",
     "iopub.status.idle": "2025-06-12T16:18:39.066565Z",
     "shell.execute_reply": "2025-06-12T16:18:39.065946Z"
    },
    "papermill": {
     "duration": 10.236173,
     "end_time": "2025-06-12T16:18:39.067936",
     "exception": false,
     "start_time": "2025-06-12T16:18:28.831763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 16:18:33.021193: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749745113.046806      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749745113.054573      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "##模型存在目录'ner_train02/checkpoint-1008' 加载\n",
    "from transformers import pipeline\n",
    "pipeline=pipeline('token-classification','ner_train02/checkpoint-1008')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53010d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T16:18:39.292646Z",
     "iopub.status.busy": "2025-06-12T16:18:39.291792Z",
     "iopub.status.idle": "2025-06-12T16:18:39.484695Z",
     "shell.execute_reply": "2025-06-12T16:18:39.483959Z"
    },
    "papermill": {
     "duration": 0.305825,
     "end_time": "2025-06-12T16:18:39.485865",
     "exception": false,
     "start_time": "2025-06-12T16:18:39.180040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-NAME',\n",
       "  'score': 0.8173873,\n",
       "  'index': 9,\n",
       "  'word': '马',\n",
       "  'start': 12,\n",
       "  'end': 13},\n",
       " {'entity': 'I-NAME',\n",
       "  'score': 0.8692206,\n",
       "  'index': 10,\n",
       "  'word': '斯',\n",
       "  'start': 13,\n",
       "  'end': 14},\n",
       " {'entity': 'I-NAME',\n",
       "  'score': 0.85123503,\n",
       "  'index': 11,\n",
       "  'word': '克',\n",
       "  'start': 14,\n",
       "  'end': 15},\n",
       " {'entity': 'B-ADDRESS',\n",
       "  'score': 0.86964536,\n",
       "  'index': 13,\n",
       "  'word': '上',\n",
       "  'start': 16,\n",
       "  'end': 17},\n",
       " {'entity': 'I-ADDRESS',\n",
       "  'score': 0.80002487,\n",
       "  'index': 14,\n",
       "  'word': '海',\n",
       "  'start': 17,\n",
       "  'end': 18},\n",
       " {'entity': 'I-COMPANY',\n",
       "  'score': 0.46123448,\n",
       "  'index': 15,\n",
       "  'word': '特',\n",
       "  'start': 18,\n",
       "  'end': 19},\n",
       " {'entity': 'I-COMPANY',\n",
       "  'score': 0.7973602,\n",
       "  'index': 16,\n",
       "  'word': '斯',\n",
       "  'start': 19,\n",
       "  'end': 20},\n",
       " {'entity': 'I-COMPANY',\n",
       "  'score': 0.8343343,\n",
       "  'index': 17,\n",
       "  'word': '拉',\n",
       "  'start': 20,\n",
       "  'end': 21},\n",
       " {'entity': 'I-COMPANY',\n",
       "  'score': 0.5760216,\n",
       "  'index': 18,\n",
       "  'word': '工',\n",
       "  'start': 21,\n",
       "  'end': 22},\n",
       " {'entity': 'I-COMPANY',\n",
       "  'score': 0.5637514,\n",
       "  'index': 19,\n",
       "  'word': '厂',\n",
       "  'start': 22,\n",
       "  'end': 23}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"2024年10月15日，马斯克在上海特斯拉工厂宣布了新款Model 3的价格。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08d3a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T16:18:39.704224Z",
     "iopub.status.busy": "2025-06-12T16:18:39.703571Z",
     "iopub.status.idle": "2025-06-12T16:18:39.720634Z",
     "shell.execute_reply": "2025-06-12T16:18:39.720062Z"
    },
    "papermill": {
     "duration": 0.126886,
     "end_time": "2025-06-12T16:18:39.721691",
     "exception": false,
     "start_time": "2025-06-12T16:18:39.594805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-NAME',\n",
       "  'score': 0.8034442,\n",
       "  'index': 1,\n",
       "  'word': '牛',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'I-NAME',\n",
       "  'score': 0.9430462,\n",
       "  'index': 2,\n",
       "  'word': '顿',\n",
       "  'start': 1,\n",
       "  'end': 2},\n",
       " {'entity': 'B-COMPANY',\n",
       "  'score': 0.574772,\n",
       "  'index': 11,\n",
       "  'word': '牛',\n",
       "  'start': 10,\n",
       "  'end': 11},\n",
       " {'entity': 'I-NAME',\n",
       "  'score': 0.58373725,\n",
       "  'index': 12,\n",
       "  'word': '顿',\n",
       "  'start': 11,\n",
       "  'end': 12}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(\"牛顿发明了微积分，而牛顿苹果是一款知名的电子产品品牌\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4084.209481,
   "end_time": "2025-06-12T16:18:42.780996",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T15:10:38.571515",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
