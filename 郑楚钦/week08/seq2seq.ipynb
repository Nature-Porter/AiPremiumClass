{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4b1ee3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:15.735749Z",
     "iopub.status.busy": "2025-05-08T16:15:15.735549Z",
     "iopub.status.idle": "2025-05-08T16:15:20.837952Z",
     "shell.execute_reply": "2025-05-08T16:15:20.837124Z"
    },
    "papermill": {
     "duration": 5.106804,
     "end_time": "2025-05-08T16:15:20.839210",
     "exception": false,
     "start_time": "2025-05-08T16:15:15.732406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chinese-couplets/couplet/vocabs\n",
      "/kaggle/input/chinese-couplets/couplet/test/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/in.txt\n",
      "/kaggle/input/chinese-couplets/couplet/test/.in.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/test/.out.txt.swp\n",
      "/kaggle/input/chinese-couplets/couplet/train/out.txt\n",
      "/kaggle/input/chinese-couplets/couplet/train/in.txt\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db5285e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:20.844880Z",
     "iopub.status.busy": "2025-05-08T16:15:20.844550Z",
     "iopub.status.idle": "2025-05-08T16:15:25.732804Z",
     "shell.execute_reply": "2025-05-08T16:15:25.731906Z"
    },
    "papermill": {
     "duration": 4.89238,
     "end_time": "2025-05-08T16:15:25.734120",
     "exception": false,
     "start_time": "2025-05-08T16:15:20.841740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabs 9130\n",
      "train/in.txt 770491\n",
      "train/out.txt 770491\n",
      "([1014, 17, 909, 191, 403, 1], [584, 174, 431, 85, 284, 1])\n",
      "test/in.txt 4000\n",
      "test/out.txt 4000\n",
      "([21, 380, 463, 11, 3, 309, 2643, 446, 40, 46, 44, 630, 1], [14, 600, 869, 244, 3, 524, 494, 1337, 54, 188, 588, 401, 1])\n"
     ]
    }
   ],
   "source": [
    "# 读取文件，每行以空格分隔\n",
    "def load_lines(filename='vocabs'):\n",
    "    with open(f'/kaggle/input/chinese-couplets/couplet/{filename}', 'r') as f:\n",
    "        lines = []\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            words = line.strip().split(' ')\n",
    "            lines.append(words)\n",
    "            line = f.readline()\n",
    "    print(filename, len(lines))\n",
    "    return lines\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "# 词汇表\n",
    "all_tokens = [i[0] for i in load_lines()]\n",
    "vocabs = {token: index for index, token in enumerate(all_tokens)}\n",
    "\n",
    "BOS = 0\n",
    "EOS = 1\n",
    "batch_size = 32\n",
    "MAX_LENGTH = 10\n",
    "train_data_size = 10000\n",
    "\n",
    "def collate(batch):\n",
    "    enc_input = []\n",
    "    dec_output = []\n",
    "    for x, y in batch:\n",
    "        enc_input.append(torch.tensor(x, device=device))\n",
    "        dec_output.append(torch.tensor(y, device=device))\n",
    "    enc_input = torch.nn.utils.rnn.pad_sequence(enc_input, batch_first=True)\n",
    "    dec_output = torch.nn.utils.rnn.pad_sequence(dec_output, batch_first=True)\n",
    "    return enc_input, dec_output\n",
    "    \n",
    "\n",
    "# 训练集\n",
    "data = [([*(vocabs.get(i) for i in x), EOS], [*(vocabs.get(j) for j in y), EOS]) for x, y in zip(\n",
    "    load_lines('train/in.txt')[:train_data_size], load_lines('train/out.txt')[:train_data_size]\n",
    ")]\n",
    "print(data[-1])\n",
    "dl = DataLoader(data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "# 测试集\n",
    "test_data = [([*(vocabs.get(i) for i in x), EOS], [*(vocabs.get(j) for j in y), EOS]) for x, y in zip(\n",
    "    load_lines('test/in.txt'), load_lines('test/out.txt')\n",
    ")]\n",
    "print(test_data[-1])\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4b9127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:25.739745Z",
     "iopub.status.busy": "2025-05-08T16:15:25.739520Z",
     "iopub.status.idle": "2025-05-08T16:15:25.754225Z",
     "shell.execute_reply": "2025-05-08T16:15:25.753523Z"
    },
    "papermill": {
     "duration": 0.018752,
     "end_time": "2025-05-08T16:15:25.755254",
     "exception": false,
     "start_time": "2025-05-08T16:15:25.736502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(BOS)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        step_size = encoder_outputs.size(1)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(BOS)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(step_size):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66e9e84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:25.760158Z",
     "iopub.status.busy": "2025-05-08T16:15:25.759944Z",
     "iopub.status.idle": "2025-05-08T16:15:25.768321Z",
     "shell.execute_reply": "2025-05-08T16:15:25.767833Z"
    },
    "papermill": {
     "duration": 0.011996,
     "end_time": "2025-05-08T16:15:25.769255",
     "exception": false,
     "start_time": "2025-05-08T16:15:25.757259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ac840b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:25.774527Z",
     "iopub.status.busy": "2025-05-08T16:15:25.773830Z",
     "iopub.status.idle": "2025-05-08T16:15:25.779693Z",
     "shell.execute_reply": "2025-05-08T16:15:25.779192Z"
    },
    "papermill": {
     "duration": 0.009342,
     "end_time": "2025-05-08T16:15:25.780642",
     "exception": false,
     "start_time": "2025-05-08T16:15:25.771300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate(encoder, decoder, input_tensor):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS:\n",
    "                decoded_words.append('</s>')\n",
    "                break\n",
    "            decoded_words.append(all_tokens[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=20):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(test_data)\n",
    "        print('>', ' '.join([all_tokens[j] for j in pair[0]]))\n",
    "        print('=', ' '.join([all_tokens[j] for j in pair[1]]))\n",
    "        output_words, _ = evaluate(encoder, decoder, torch.tensor(pair[0], device=device).view(1, -1))\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f08db52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:15:25.785503Z",
     "iopub.status.busy": "2025-05-08T16:15:25.785013Z",
     "iopub.status.idle": "2025-05-08T16:34:22.487898Z",
     "shell.execute_reply": "2025-05-08T16:34:22.487135Z"
    },
    "papermill": {
     "duration": 1136.708761,
     "end_time": "2025-05-08T16:34:22.491393",
     "exception": false,
     "start_time": "2025-05-08T16:15:25.782632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 15s (- 18m 45s) (5 6%) 2.7797\n",
      "2m 25s (- 16m 59s) (10 12%) 2.2753\n",
      "3m 36s (- 15m 36s) (15 18%) 1.9477\n",
      "4m 46s (- 14m 19s) (20 25%) 1.7189\n",
      "5m 58s (- 13m 9s) (25 31%) 1.5348\n",
      "7m 10s (- 11m 57s) (30 37%) 1.3829\n",
      "8m 20s (- 10m 43s) (35 43%) 1.2606\n",
      "9m 32s (- 9m 32s) (40 50%) 1.1575\n",
      "10m 43s (- 8m 20s) (45 56%) 1.0695\n",
      "11m 54s (- 7m 8s) (50 62%) 0.9956\n",
      "13m 4s (- 5m 56s) (55 68%) 0.9256\n",
      "14m 14s (- 4m 44s) (60 75%) 0.8681\n",
      "15m 25s (- 3m 33s) (65 81%) 0.8151\n",
      "16m 35s (- 2m 22s) (70 87%) 0.7667\n",
      "17m 45s (- 1m 11s) (75 93%) 0.7249\n",
      "18m 56s (- 0m 0s) (80 100%) 0.6884\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "\n",
    "encoder = EncoderRNN(len(vocabs), hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, len(vocabs)).to(device)\n",
    "\n",
    "train(dl, encoder, decoder, 80, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5fcf33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-08T16:34:22.497460Z",
     "iopub.status.busy": "2025-05-08T16:34:22.497155Z",
     "iopub.status.idle": "2025-05-08T16:34:22.632670Z",
     "shell.execute_reply": "2025-05-08T16:34:22.631845Z"
    },
    "papermill": {
     "duration": 0.139871,
     "end_time": "2025-05-08T16:34:22.633907",
     "exception": false,
     "start_time": "2025-05-08T16:34:22.494036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 春 融 北 国 千 山 雪 </s>\n",
      "= 秋 染 南 阳 万 树 枫 </s>\n",
      "< 水 改 江 城 人 面 花 </s>\n",
      "\n",
      "> 于 夫 下 海 网 张 也 </s>\n",
      "= 姜 女 攻 城 墙 倒 乎 </s>\n",
      "< 或 者 冲 开 眼 界 宽 </s>\n",
      "\n",
      "> 空 庭 草 色 和 烟 暖 </s>\n",
      "= 午 夜 书 声 带 月 寒 </s>\n",
      "< 雁 字 荷 香 好 壁 风 </s>\n",
      "\n",
      "> 鞭 尘 辞 虎 岁 </s>\n",
      "= 玉 兔 贺 新 春 </s>\n",
      "< 人 间 问 国 新 </s>\n",
      "\n",
      "> 杯 小 但 容 天 地 事 </s>\n",
      "= 舟 轻 可 载 古 今 愁 </s>\n",
      "< 学 过 不 用 大 波 心 </s>\n",
      "\n",
      "> 屈 平 槁 头 张 恨 水 </s>\n",
      "= 子 期 焦 尾 谢 冰 心 </s>\n",
      "< 悬 壸 济 世 英 雄 风 </s>\n",
      "\n",
      "> 男 女 情 深 成 一 对 </s>\n",
      "= 夫 妻 义 重 敬 双 亲 </s>\n",
      "< 亲 句 句 题 始 启 三 分\n",
      "\n",
      "> 山 门 外 三 脚 驴 子 </s>\n",
      "= 蒲 团 上 一 块 兜 楼 </s>\n",
      "< 木 铜 独 三 春 来 </s>\n",
      "\n",
      "> 望 断 残 亭 归 雁 远 </s>\n",
      "= 吟 成 落 日 白 帆 斜 </s>\n",
      "< 遥 云 漫 岭 幽 幽 </s>\n",
      "\n",
      "> 正 能 量 沸 腾 神 州 大 地 </s>\n",
      "= 中 国 梦 温 馨 枞 邑 人 家 </s>\n",
      "< 齐 衰 扫 王 庆 海 天 </s>\n",
      "\n",
      "> 佳 人 纤 手 心 如 玉 </s>\n",
      "= 秀 士 巧 舌 口 若 河 </s>\n",
      "< 古 今 古 老 小 康 花 </s>\n",
      "\n",
      "> 凤 舞 千 家 瑞 </s>\n",
      "= 梅 开 四 海 香 </s>\n",
      "< 人 间 一 点 春 </s>\n",
      "\n",
      "> 一 树 新 枝 依 老 节 </s>\n",
      "= 满 山 翠 竹 指 高 天 </s>\n",
      "< 三 围 再 涌 自 黄 昏 </s>\n",
      "\n",
      "> 擦 拳 磨 掌 ， 拍 案 击 节 研 三 国 </s>\n",
      "= 两 小 无 猜 ， 花 前 月 下 读 西 厢 </s>\n",
      "< 以 和 谐 雪 耻 ， 碧 血 乌 江 打 千 秋\n",
      "\n",
      "> 最 是 无 缘 ， 情 归 尽 处 天 垂 泪 </s>\n",
      "= 莫 非 有 约 ？ 梦 醒 来 时 帘 卷 风 </s>\n",
      "< 总 牵 知 己 ， 勤 到 其 中 众 遍 间 </s>\n",
      "\n",
      "> 开 窗 收 曙 色 </s>\n",
      "= 放 眼 纳 云 山 </s>\n",
      "< 柳 色 绿 光 </s>\n",
      "\n",
      "> 一 杯 在 手 品 清 淡 </s>\n",
      "= 双 月 映 湖 醉 瑟 琴 </s>\n",
      "< 画 卷 精 神 仙 金 </s>\n",
      "\n",
      "> 千 古 文 明 ， 百 年 奥 运 ， 三 分 经 略 ， 一 朝 写 出 天 荒 史 </s>\n",
      "= 九 州 面 貌 ， 五 色 风 光 ， 四 海 潮 流 ， 双 手 弹 成 世 纪 歌 </s>\n",
      "< 一 身 正 气 ， 千 里 荷 香 ， 百 年 犹 在 ， 十 年 翻 电 独 奇 观 </s>\n",
      "\n",
      "> 迎 风 丝 柳 梳 春 水 </s>\n",
      "= 傍 山 人 家 沐 曙 光 </s>\n",
      "< 旭 日 红 云 映 玉 花 </s>\n",
      "\n",
      "> 志 士 心 欢 ， 中 华 国 泰 </s>\n",
      "= 昊 天 日 丽 ， 大 地 春 新 </s>\n",
      "< 人 文 载 ， 九 州 地 人 </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1661983,
     "sourceId": 2726695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1153.628889,
   "end_time": "2025-05-08T16:34:25.397730",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-08T16:15:11.768841",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
