{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdcc61c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:45:17.375441Z",
     "iopub.status.busy": "2025-06-12T15:45:17.374908Z",
     "iopub.status.idle": "2025-06-12T15:45:25.089075Z",
     "shell.execute_reply": "2025-06-12T15:45:25.088328Z"
    },
    "papermill": {
     "duration": 7.71832,
     "end_time": "2025-06-12T15:45:25.090482",
     "exception": false,
     "start_time": "2025-06-12T15:45:17.372162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\r\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\r\n",
      "Collecting seqeval\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\r\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\r\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\r\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\r\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: seqeval\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=0d2dc25d5f255e0e02d63894c0a3fa864df7a6c4218529217d789264bc1c1a2b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\r\n",
      "Successfully built seqeval\r\n",
      "Installing collected packages: fsspec, seqeval, evaluate\r\n",
      "  Attempting uninstall: fsspec\r\n",
      "    Found existing installation: fsspec 2025.3.2\r\n",
      "    Uninstalling fsspec-2025.3.2:\r\n",
      "      Successfully uninstalled fsspec-2025.3.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\r\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2025.3.0 seqeval-1.2.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3530aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T15:45:25.096703Z",
     "iopub.status.busy": "2025-06-12T15:45:25.096096Z",
     "iopub.status.idle": "2025-06-12T15:45:25.103388Z",
     "shell.execute_reply": "2025-06-12T15:45:25.102864Z"
    },
    "papermill": {
     "duration": 0.011213,
     "end_time": "2025-06-12T15:45:25.104357",
     "exception": false,
     "start_time": "2025-06-12T15:45:25.093144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ner_ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ner_ddp.py\n",
    "\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification,TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "# 换了一个小点的model，要不然GPU内存不够\n",
    "# MODEL_NAME = 'google-bert/bert-base-chinese'\n",
    "MODEL_NAME = 'cycloneboy/chinese_mobilebert_base_f2'\n",
    "# DATASET_NAME = 'nlhappy/CLUE-NER'\n",
    "DATASET_NAME = 'doushabao4766/msra_ner_k_V3'\n",
    "DATASET_SHARDS = 12\n",
    "OUTPUT_DIR = 'ner_train'\n",
    "\n",
    "entites = ['O', 'PER', 'ORG', 'LOC']\n",
    "tags = ['O']\n",
    "for entity in entites[1:]:\n",
    "    tags.append('B-' + entity.upper())\n",
    "    tags.append('I-' + entity.upper())\n",
    "print(tags)\n",
    "id2lbl = {i:tag for i, tag in enumerate(tags)}\n",
    "lbl2id = {tag:i for i, tag in enumerate(tags)}\n",
    "\n",
    "def train(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12345'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, \n",
    "                                                        num_labels=len(tags),\n",
    "                                                        id2label=id2lbl,\n",
    "                                                        label2id=lbl2id)\n",
    "    model = model.to(rank)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    ds = load_dataset(DATASET_NAME)\n",
    "    ds['train'] = ds['train'].shard(num_shards=DATASET_SHARDS, index=DATASET_SHARDS >> 1)\n",
    "    ds['test'] = ds['test'].shard(num_shards=DATASET_SHARDS, index=DATASET_SHARDS >> 1)\n",
    "    print(ds)\n",
    "    \n",
    "    \n",
    "    def mapper(item):\n",
    "        input = tokenizer(item['tokens'],\n",
    "                          truncation=True,\n",
    "                          padding=True,\n",
    "                          max_length=512,\n",
    "                          add_special_tokens=False,\n",
    "                          is_split_into_words=True,\n",
    "                          # return_offsets_mapping=True,\n",
    "                          return_tensors=\"pt\")\n",
    "        len_limit = input[\"input_ids\"].shape[1]\n",
    "        input['labels'] = [arr[:len_limit] for arr in item['ner_tags']]\n",
    "        return input\n",
    "    \n",
    "    ds2 = ds.map(mapper, batched=True)\n",
    "    ds2.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n",
    "        num_train_epochs = 3,    # 训练 epoch\n",
    "        save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n",
    "        per_device_train_batch_size=32,  # 训练批次\n",
    "        per_device_eval_batch_size=32,\n",
    "        report_to='tensorboard',  # 训练输出记录\n",
    "        eval_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        fp16=True,\n",
    "        local_rank=rank,\n",
    "        lr_scheduler_type='linear',\n",
    "        warmup_steps=50,\n",
    "        ddp_find_unused_parameters=False\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer,padding=True)\n",
    "    \n",
    "    # metric 方法\n",
    "    def compute_metrics(result):\n",
    "        # result 是一个tuple (predicts, labels)\n",
    "        # 获取评估对象\n",
    "        seqeval = evaluate.load('seqeval')\n",
    "        predicts,labels = result\n",
    "        predicts = np.argmax(predicts, axis=2)\n",
    "        # 准备评估数据\n",
    "        predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n",
    "                     for ps,ls in zip(predicts,labels)]\n",
    "        return seqeval.compute(predictions=predicts, references=labels)\n",
    "    \n",
    "    trainer = Trainer(model, args, train_dataset=ds2['train'], eval_dataset=ds2['test'],\n",
    "                      data_collator=data_collator,compute_metrics=compute_metrics)\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "def main():\n",
    "    world_size = torch.cuda.device_count()\n",
    "    print('world_size', world_size)\n",
    "    mp.spawn(train, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89391678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:45:25.109245Z",
     "iopub.status.busy": "2025-06-12T15:45:25.109074Z",
     "iopub.status.idle": "2025-06-12T15:48:57.070134Z",
     "shell.execute_reply": "2025-06-12T15:48:57.069157Z"
    },
    "papermill": {
     "duration": 211.96501,
     "end_time": "2025-06-12T15:48:57.071531",
     "exception": false,
     "start_time": "2025-06-12T15:45:25.106521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-12 15:45:41.244796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749743141.466328      54 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749743141.530130      54 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\r\n",
      "world_size 2\r\n",
      "2025-06-12 15:46:03.933960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-06-12 15:46:03.934083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749743163.956977      69 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1749743163.956995      68 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1749743163.963797      69 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "E0000 00:00:1749743163.963915      68 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\r\n",
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\r\n",
      "config.json: 100%|█████████████████████████████| 832/832 [00:00<00:00, 6.60MB/s]\r\n",
      "pytorch_model.bin: 100%|█████████████████████| 111M/111M [00:01<00:00, 97.4MB/s]\r\n",
      "Some weights of MobileBertForTokenClassification were not initialized from the model checkpoint at cycloneboy/chinese_mobilebert_base_f2 and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "Some weights of MobileBertForTokenClassification were not initialized from the model checkpoint at cycloneboy/chinese_mobilebert_base_f2 and are newly initialized: ['classifier.bias', 'classifier.weight']\r\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\r\n",
      "model.safetensors:   0%|                             | 0.00/110M [00:00<?, ?B/s]\r\n",
      "vocab.txt: 100%|█████████████████████████████| 110k/110k [00:00<00:00, 7.43MB/s]\r\n",
      "model.safetensors:  38%|███████▌            | 41.9M/110M [00:00<00:00, 81.1MB/s]\r\n",
      "README.md: 100%|███████████████████████████████| 697/697 [00:00<00:00, 4.81MB/s]\r\n",
      "model.safetensors: 100%|██████████████████████| 110M/110M [00:01<00:00, 103MB/s]\r\n",
      "(…)-00000-of-00001-42717a92413393f9.parquet: 100%|█| 13.9M/13.9M [00:00<00:00, 1\r\n",
      "(…)-00000-of-00001-8899cab5fdab45bc.parquet: 100%|█| 946k/946k [00:00<00:00, 78.\r\n",
      "Generating train split: 100%|██| 45001/45001 [00:00<00:00, 254038.93 examples/s]\r\n",
      "Generating test split: 100%|█████| 3443/3443 [00:00<00:00, 291937.67 examples/s]\r\n",
      "DatasetDict({\r\n",
      "    train: Dataset({\r\n",
      "        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\r\n",
      "        num_rows: 3750\r\n",
      "    })\r\n",
      "    test: Dataset({\r\n",
      "        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\r\n",
      "        num_rows: 287\r\n",
      "    })\r\n",
      "})\r\n",
      "DatasetDict({\r\n",
      "    train: Dataset({\r\n",
      "        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\r\n",
      "        num_rows: 3750\r\n",
      "    })\r\n",
      "    test: Dataset({\r\n",
      "        features: ['id', 'tokens', 'ner_tags', 'knowledge'],\r\n",
      "        num_rows: 287\r\n",
      "    })\r\n",
      "})\r\n",
      "Map: 100%|█████████████████████████| 3750/3750 [00:01<00:00, 2134.29 examples/s]\r\n",
      "Map: 100%|█████████████████████████| 3750/3750 [00:01<00:00, 2088.56 examples/s]\r\n",
      "Map: 100%|███████████████████████████| 287/287 [00:00<00:00, 1655.54 examples/s]\r\n",
      "Map: 100%|███████████████████████████| 287/287 [00:00<00:00, 1792.29 examples/s]\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\r\n",
      "  0%|                                                   | 0/177 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.4868, 'grad_norm': 114340.1796875, 'learning_rate': 4.9e-05, 'epoch': 0.85}\r\n",
      "{'loss': 0.6942, 'grad_norm': 120945.0078125, 'learning_rate': 4.9e-05, 'epoch': 0.85}\r\n",
      " 33%|██████████████                            | 59/177 [00:49<01:26,  1.37it/s]\r\n",
      " 33%|██████████████                            | 59/177 [00:50<01:25,  1.37it/s]\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.82it/s]\u001b[A\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.43it/s]\u001b[A\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.70it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  3.02it/s]\u001b[A\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.29it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.47it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  3.49it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  4.44it/s]\u001b[A\r\n",
      "\r\n",
      "Downloading builder script: 100%|██████████| 6.34k/6.34k [00:00<00:00, 21.0MB/s]\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6444444444444445, 'recall': 0.6904761904761905, 'f1': 0.6666666666666666, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5301204819277109, 'recall': 0.4631578947368421, 'f1': 0.49438202247191015, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8088235294117647, 'recall': 0.8208955223880597, 'f1': 0.8148148148148148, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.06882156431674957, 'eval_LOC': {'precision': 0.6444444444444445, 'recall': 0.6904761904761905, 'f1': 0.6666666666666666, 'number': 126}, 'eval_ORG': {'precision': 0.5301204819277109, 'recall': 0.4631578947368421, 'f1': 0.49438202247191015, 'number': 95}, 'eval_PER': {'precision': 0.8088235294117647, 'recall': 0.8208955223880597, 'f1': 0.8148148148148148, 'number': 67}, 'eval_overall_precision': 0.6503496503496503, 'eval_overall_recall': 0.6458333333333334, 'eval_overall_f1': 0.6480836236933798, 'eval_overall_accuracy': 0.9824068065469753, 'eval_runtime': 2.4234, 'eval_samples_per_second': 118.427, 'eval_steps_per_second': 2.063, 'epoch': 1.0}\r\n",
      " 33%|██████████████                            | 59/177 [00:52<01:26,  1.37it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.47it/s]\u001b[A\r\n",
      "                                                                                \u001b[ATrainer is attempting to log a value of \"{'precision': 0.6861313868613139, 'recall': 0.746031746031746, 'f1': 0.714828897338403, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.42857142857142855, 'recall': 0.4421052631578947, 'f1': 0.43523316062176165, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.875, 'recall': 0.835820895522388, 'f1': 0.8549618320610687, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.06322645395994186, 'eval_LOC': {'precision': 0.6861313868613139, 'recall': 0.746031746031746, 'f1': 0.714828897338403, 'number': 126}, 'eval_ORG': {'precision': 0.42857142857142855, 'recall': 0.4421052631578947, 'f1': 0.43523316062176165, 'number': 95}, 'eval_PER': {'precision': 0.875, 'recall': 0.835820895522388, 'f1': 0.8549618320610687, 'number': 67}, 'eval_overall_precision': 0.6421404682274248, 'eval_overall_recall': 0.6666666666666666, 'eval_overall_f1': 0.6541737649063033, 'eval_overall_accuracy': 0.9826231163025453, 'eval_runtime': 2.2274, 'eval_samples_per_second': 128.849, 'eval_steps_per_second': 2.245, 'epoch': 1.0}\r\n",
      " 33%|██████████████                            | 59/177 [00:52<01:25,  1.37it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  4.44it/s]\u001b[A\r\n",
      "{'loss': 0.0776, 'grad_norm': 73919.2734375, 'learning_rate': 3.070866141732284e-05, 'epoch': 1.69}\r\n",
      "{'loss': 0.0819, 'grad_norm': 81186.6953125, 'learning_rate': 3.070866141732284e-05, 'epoch': 1.69}\r\n",
      " 67%|███████████████████████████▎             | 118/177 [01:41<00:43,  1.36it/s]\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.74it/s]\u001b[A\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.67it/s]\u001b[A\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.37it/s]\u001b[A\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.38it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  2.86it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.20it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  2.98it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.87it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.7863247863247863, 'recall': 0.7301587301587301, 'f1': 0.757201646090535, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6869565217391305, 'recall': 0.8315789473684211, 'f1': 0.7523809523809524, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8428571428571429, 'recall': 0.8805970149253731, 'f1': 0.8613138686131387, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.046616557985544205, 'eval_LOC': {'precision': 0.7863247863247863, 'recall': 0.7301587301587301, 'f1': 0.757201646090535, 'number': 126}, 'eval_ORG': {'precision': 0.6869565217391305, 'recall': 0.8315789473684211, 'f1': 0.7523809523809524, 'number': 95}, 'eval_PER': {'precision': 0.8428571428571429, 'recall': 0.8805970149253731, 'f1': 0.8613138686131387, 'number': 67}, 'eval_overall_precision': 0.7615894039735099, 'eval_overall_recall': 0.7986111111111112, 'eval_overall_f1': 0.7796610169491525, 'eval_overall_accuracy': 0.9887518927103612, 'eval_runtime': 2.4032, 'eval_samples_per_second': 119.425, 'eval_steps_per_second': 2.081, 'epoch': 2.0}\r\n",
      " 67%|███████████████████████████▎             | 118/177 [01:43<00:45,  1.29it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.20it/s]\u001b[A\r\n",
      "                                                                                \u001b[ATrainer is attempting to log a value of \"{'precision': 0.7966101694915254, 'recall': 0.746031746031746, 'f1': 0.7704918032786885, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6637168141592921, 'recall': 0.7894736842105263, 'f1': 0.7211538461538461, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8955223880597015, 'recall': 0.8955223880597015, 'f1': 0.8955223880597015, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.04673168808221817, 'eval_LOC': {'precision': 0.7966101694915254, 'recall': 0.746031746031746, 'f1': 0.7704918032786885, 'number': 126}, 'eval_ORG': {'precision': 0.6637168141592921, 'recall': 0.7894736842105263, 'f1': 0.7211538461538461, 'number': 95}, 'eval_PER': {'precision': 0.8955223880597015, 'recall': 0.8955223880597015, 'f1': 0.8955223880597015, 'number': 67}, 'eval_overall_precision': 0.7684563758389261, 'eval_overall_recall': 0.7951388888888888, 'eval_overall_f1': 0.781569965870307, 'eval_overall_accuracy': 0.9881750666955079, 'eval_runtime': 2.3989, 'eval_samples_per_second': 119.638, 'eval_steps_per_second': 2.084, 'epoch': 2.0}\r\n",
      " 67%|███████████████████████████▎             | 118/177 [01:43<00:43,  1.36it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.87it/s]\u001b[A\r\n",
      "{'loss': 0.0418, 'grad_norm': 62588.19921875, 'learning_rate': 1.1023622047244095e-05, 'epoch': 2.54}\r\n",
      "{'loss': 0.0444, 'grad_norm': 128402.8671875, 'learning_rate': 1.1023622047244095e-05, 'epoch': 2.54}\r\n",
      "100%|█████████████████████████████████████████| 177/177 [02:33<00:00,  1.44it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\r\n",
      "  warnings.warn(\r\n",
      "\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\r\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.41it/s]\u001b[A\r\n",
      " 40%|██████████████████                           | 2/5 [00:00<00:00,  4.40it/s]\u001b[A\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.11it/s]\r\n",
      " 60%|███████████████████████████                  | 3/5 [00:00<00:00,  3.11it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  2.72it/s]\u001b[A\r\n",
      " 80%|████████████████████████████████████         | 4/5 [00:01<00:00,  2.72it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.11it/s]\u001b[A\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.11it/s]\u001b[ATrainer is attempting to log a value of \"{'precision': 0.7803030303030303, 'recall': 0.8174603174603174, 'f1': 0.7984496124031008, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6929824561403509, 'recall': 0.8315789473684211, 'f1': 0.7559808612440191, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8840579710144928, 'recall': 0.9104477611940298, 'f1': 0.8970588235294118, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.047872792929410934, 'eval_LOC': {'precision': 0.7803030303030303, 'recall': 0.8174603174603174, 'f1': 0.7984496124031008, 'number': 126}, 'eval_ORG': {'precision': 0.6929824561403509, 'recall': 0.8315789473684211, 'f1': 0.7559808612440191, 'number': 95}, 'eval_PER': {'precision': 0.8840579710144928, 'recall': 0.9104477611940298, 'f1': 0.8970588235294118, 'number': 67}, 'eval_overall_precision': 0.7714285714285715, 'eval_overall_recall': 0.84375, 'eval_overall_f1': 0.8059701492537314, 'eval_overall_accuracy': 0.9887518927103612, 'eval_runtime': 2.4747, 'eval_samples_per_second': 115.974, 'eval_steps_per_second': 2.02, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████████| 177/177 [02:36<00:00,  1.32it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  3.11it/s]\u001b[A\r\n",
      "{'train_runtime': 156.5968, 'train_samples_per_second': 71.841, 'train_steps_per_second': 1.13, 'train_loss': 0.1762503318193942, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████████| 177/177 [02:36<00:00,  1.13it/s]\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8130081300813008, 'recall': 0.7936507936507936, 'f1': 0.8032128514056225, 'number': 126}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6923076923076923, 'recall': 0.8526315789473684, 'f1': 0.7641509433962264, 'number': 95}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8955223880597015, 'recall': 0.8955223880597015, 'f1': 0.8955223880597015, 'number': 67}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.04618549346923828, 'eval_LOC': {'precision': 0.8130081300813008, 'recall': 0.7936507936507936, 'f1': 0.8032128514056225, 'number': 126}, 'eval_ORG': {'precision': 0.6923076923076923, 'recall': 0.8526315789473684, 'f1': 0.7641509433962264, 'number': 95}, 'eval_PER': {'precision': 0.8955223880597015, 'recall': 0.8955223880597015, 'f1': 0.8955223880597015, 'number': 67}, 'eval_overall_precision': 0.7850162866449512, 'eval_overall_recall': 0.8368055555555556, 'eval_overall_f1': 0.8100840336134454, 'eval_overall_accuracy': 0.9883192731992213, 'eval_runtime': 2.6358, 'eval_samples_per_second': 108.884, 'eval_steps_per_second': 1.897, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████████| 177/177 [02:36<00:00,  1.44it/s]\r\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  3.11it/s]\u001b[A\r\n",
      "{'train_runtime': 156.757, 'train_samples_per_second': 71.767, 'train_steps_per_second': 1.129, 'train_loss': 0.23698968200360315, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████████| 177/177 [02:36<00:00,  1.13it/s]\r\n",
      "[rank0]:[W612 15:48:52.387433027 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!python ner_ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3dcae71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:48:57.109494Z",
     "iopub.status.busy": "2025-06-12T15:48:57.109232Z",
     "iopub.status.idle": "2025-06-12T15:49:06.635576Z",
     "shell.execute_reply": "2025-06-12T15:49:06.634895Z"
    },
    "papermill": {
     "duration": 9.546458,
     "end_time": "2025-06-12T15:49:06.636975",
     "exception": false,
     "start_time": "2025-06-12T15:48:57.090517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 15:49:00.678772: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749743340.701677      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749743340.708678      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-PER', 'score': 0.53758633, 'index': 1, 'word': '陆', 'start': 0, 'end': 1}\n",
      "{'entity': 'I-PER', 'score': 0.8065418, 'index': 2, 'word': '逊', 'start': 1, 'end': 2}\n",
      "{'entity': 'B-PER', 'score': 0.5385872, 'index': 8, 'word': '关', 'start': 7, 'end': 8}\n",
      "{'entity': 'I-PER', 'score': 0.9143277, 'index': 9, 'word': '羽', 'start': 8, 'end': 9}\n",
      "{'entity': 'B-ORG', 'score': 0.3699788, 'index': 12, 'word': '麦', 'start': 11, 'end': 12}\n",
      "{'entity': 'I-PER', 'score': 0.5531025, 'index': 13, 'word': '城', 'start': 12, 'end': 13}\n",
      "None\n",
      "{'entity': 'B-LOC', 'score': 0.9483459, 'index': 10, 'word': '中', 'start': 9, 'end': 10}\n",
      "{'entity': 'B-LOC', 'score': 0.92489845, 'index': 11, 'word': '美', 'start': 10, 'end': 11}\n",
      "None\n",
      "{'entity': 'B-ORG', 'score': 0.5045434, 'index': 1, 'word': '加', 'start': 0, 'end': 1}\n",
      "{'entity': 'I-ORG', 'score': 0.64310086, 'index': 2, 'word': '利', 'start': 1, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.730761, 'index': 3, 'word': '福', 'start': 2, 'end': 3}\n",
      "{'entity': 'I-ORG', 'score': 0.76036435, 'index': 4, 'word': '尼', 'start': 3, 'end': 4}\n",
      "{'entity': 'I-ORG', 'score': 0.6784655, 'index': 5, 'word': '亚', 'start': 4, 'end': 5}\n",
      "{'entity': 'I-ORG', 'score': 0.8546337, 'index': 6, 'word': '大', 'start': 5, 'end': 6}\n",
      "{'entity': 'I-ORG', 'score': 0.78960234, 'index': 7, 'word': '学', 'start': 6, 'end': 7}\n",
      "None\n",
      "{'entity': 'B-LOC', 'score': 0.91333425, 'index': 1, 'word': '澳', 'start': 0, 'end': 1}\n",
      "{'entity': 'I-LOC', 'score': 0.9320717, 'index': 2, 'word': '大', 'start': 1, 'end': 2}\n",
      "{'entity': 'I-LOC', 'score': 0.8231734, 'index': 3, 'word': '利', 'start': 2, 'end': 3}\n",
      "{'entity': 'I-LOC', 'score': 0.9213486, 'index': 4, 'word': '亚', 'start': 3, 'end': 4}\n",
      "{'entity': 'B-LOC', 'score': 0.9716673, 'index': 6, 'word': '日', 'start': 5, 'end': 6}\n",
      "{'entity': 'I-LOC', 'score': 0.98313177, 'index': 7, 'word': '本', 'start': 6, 'end': 7}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline('token-classification',  'ner_train/checkpoint-177')\n",
    "predict = lambda text: print([print(i) for i in pipe(text)][0])\n",
    "predict('陆逊火烧连营，关羽败走麦城')\n",
    "predict('双方确定了今后发展中美关系的指导方针。')\n",
    "predict('加利福尼亚大学在哪')\n",
    "predict('澳大利亚和日本进行了友好交流。')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 237.46076,
   "end_time": "2025-06-12T15:49:10.362660",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T15:45:12.901900",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
